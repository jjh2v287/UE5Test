=== CODEBASE STRUCTURE ===

ðŸ“„ AudioExtensions.Build.cs
ðŸ“„ AudioExtensionsLog.h
ðŸ“„ AudioExtensionsModule.cpp
ðŸ“„ AudioExtentionsModule.h
ðŸ“„ AudioParameter.cpp
ðŸ“„ AudioParameter.h
ðŸ“„ AudioParameterControllerInterface.cpp
ðŸ“„ AudioParameterControllerInterface.h
ðŸ“„ AudioPropertiesSheetAssetBase.h
ðŸ“„ IAudioEndpoint.cpp
ðŸ“„ IAudioEndpoint.h
ðŸ“„ IAudioExtensionPlugin.h
ðŸ“„ IAudioModulation.cpp
ðŸ“„ IAudioModulation.h
ðŸ“„ IAudioParameterInterfaceRegistry.cpp
ðŸ“„ IAudioParameterInterfaceRegistry.h
ðŸ“„ IAudioParameterTransmitter.cpp
ðŸ“„ IAudioParameterTransmitter.h
ðŸ“„ IAudioPropertiesSheet.h
ðŸ“„ IAudioProxyInitializer.cpp
ðŸ“„ IAudioProxyInitializer.h
ðŸ“„ ISoundfieldEndpoint.cpp
ðŸ“„ ISoundfieldEndpoint.h
ðŸ“„ ISoundfieldFormat.cpp
ðŸ“„ ISoundfieldFormat.h
ðŸ“„ ISoundWaveCloudStreaming.h
ðŸ“„ IWaveformTransformation.cpp
ðŸ“„ IWaveformTransformation.h
ðŸ“„ SoundGeneratorOutput.h


=== FILE CONTENTS ===


=== AudioExtensions.Build.cs ===
================================

// Copyright Epic Games, Inc. All Rights Reserved.

namespace UnrealBuildTool.Rules
{
	public class AudioExtensions : ModuleRules
	{
		public AudioExtensions(ReadOnlyTargetRules Target) : base(Target)
		{
			PublicDependencyModuleNames.AddRange(
				new string[]
				{
					"Core",
					"CoreUObject",
					"SignalProcessing",
					"AudioMixerCore"
				}
			);

			PublicIncludePathModuleNames.AddRange(
				new string[]
				{
					"AudioMixer",
				}
			);
		}
	}
}

================================


=== AudioExtensionsLog.h ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "Logging/LogMacros.h"

AUDIOEXTENSIONS_API DECLARE_LOG_CATEGORY_EXTERN(LogAudioExtensions, Display, All);

============================


=== AudioExtensionsModule.cpp ===
=================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Modules/ModuleManager.h"

#include "AudioExtensionsLog.h"
#include "AudioExtentionsModule.h"
#include "HAL/LowLevelMemStats.h"
#include "IAudioExtensionPlugin.h"
#include "Algo/ForEach.h"
#include "Misc/DataDrivenPlatformInfoRegistry.h"

DECLARE_LLM_MEMORY_STAT(TEXT("AudioSpatializationPlugins"), STAT_AudioSpatializationPluginsLLM, STATGROUP_LLMFULL);
LLM_DEFINE_TAG(Audio_SpatializationPlugins, NAME_None, TEXT("Audio"), GET_STATFNAME(STAT_AudioSpatializationPluginsLLM), GET_STATFNAME(STAT_AudioSummaryLLM));

DEFINE_LOG_CATEGORY(LogAudioExtensions)

FAudioExtensionsModule* FAudioExtensionsModule::Get()
{
	// This a fast check if loaded and will load the module if not.
	return FModuleManager::Get().LoadModulePtr<FAudioExtensionsModule>(TEXT("AudioExtensions"));
}

void FAudioExtensionsModule::StartupModule()
{
	// Load Platform specific Audio feature modules. 
	TArray<FName> Platforms = FDataDrivenPlatformInfoRegistry::GetSortedPlatformNames(EPlatformInfoType::TruePlatformsOnly);
	Algo::ForEach(Platforms,[](const FName InName)
	{
		// Load any modules that are named <PlatformName>AudioFeatures, which will load hidden platforms.
		// This equivalent, but slightly safer that using the wildcard "*AudioFeatures" but without the risk
		// of accidentally bringing in user modules.
		const FString PlatformModuleName = InName.ToString() + TEXT("AudioFeatures");

		// Most of these calls will fail, but will do so quickly as the module manager already knows about all
		// possible modules, so this is a quick lookup.
		FModuleManager::Get().LoadModule(*PlatformModuleName);
	});
		
	FModuleManager::Get().LoadModuleChecked(TEXT("SignalProcessing"));
	FModuleManager::Get().LoadModuleChecked(TEXT("AudioMixerCore"));
}

IMPLEMENT_MODULE(FAudioExtensionsModule, AudioExtensions);

=================================


=== AudioExtentionsModule.h ===
===============================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "Modules/ModuleInterface.h"

class FAudioExtensionsModule final : public IModuleInterface
{
public:
	static FAudioExtensionsModule* Get(); 
	
	virtual void StartupModule() override;
};
===============================


=== AudioParameter.cpp ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.
#include "AudioParameter.h"

#include "Algo/BinarySearch.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioParameter)

namespace Audio
{
	namespace ParameterPrivate
	{
		template <typename T>
		void SetOrMergeArray(const TArray<T>& InArray, TArray<T>& OutArray, bool bInMerge)
		{
			if (bInMerge)
			{
				OutArray.Append(InArray);
			}
			else
			{
				OutArray = InArray;
			}
		}
	} // ParameterPrivate

	const FString FParameterPath::NamespaceDelimiter = TEXT(AUDIO_PARAMETER_NAMESPACE_PATH_DELIMITER);

	FName FParameterPath::CombineNames(FName InLeft, FName InRight)
	{
		if (InLeft.IsNone())
		{
			return InRight;
		}

		const FString FullName = FString::Join(TArray<FString>({ *InLeft.ToString(), *InRight.ToString() }), *NamespaceDelimiter);
		return FName(FullName);
	}

	void FParameterPath::SplitName(FName InFullName, FName& OutNamespace, FName& OutParameterName)
	{
		FString FullName = InFullName.ToString();
		const int32 IndexOfDelim = FullName.Find(NamespaceDelimiter, ESearchCase::IgnoreCase, ESearchDir::FromEnd);
		if (IndexOfDelim != INDEX_NONE)
		{
			OutNamespace = FName(*FullName.Left(IndexOfDelim));
			OutParameterName = FName(*FullName.RightChop(IndexOfDelim + 1));
		}
		else
		{
			OutNamespace = FName();
			OutParameterName = InFullName;
		}
	}
} // namespace Audio

void FAudioParameter::Merge(const FAudioParameter& InParameter, bool bInTakeName, bool bInTakeType, bool bInMergeArrayTypes)
{
	if (bInTakeName)
	{
		ParamName = InParameter.ParamName;
	}

	if (bInTakeType)
	{
		ParamType = InParameter.ParamType;
	}

	switch (InParameter.ParamType)
	{
		case EAudioParameterType::Boolean:
		{
			BoolParam = InParameter.BoolParam;
		}
		break;

		case EAudioParameterType::BooleanArray:
		{
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayBoolParam, ArrayBoolParam, bInMergeArrayTypes);
		}
		break;

		case EAudioParameterType::Float:
		{
			FloatParam = InParameter.FloatParam;
		}
		break;

		case EAudioParameterType::FloatArray:
		{
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayFloatParam, ArrayFloatParam, bInMergeArrayTypes);
		}
		break;

		case EAudioParameterType::Integer:
		case EAudioParameterType::NoneArray:
		{
			if (bInMergeArrayTypes)
			{
				IntParam += InParameter.IntParam;
			}
			else
			{
				IntParam = InParameter.IntParam;
			}
		}
		break;

		case EAudioParameterType::IntegerArray:
		{
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayIntParam, ArrayIntParam, bInMergeArrayTypes);
		}
		break;

		case EAudioParameterType::None:
		{
			FloatParam = InParameter.FloatParam;
			BoolParam = InParameter.BoolParam;
			IntParam = InParameter.IntParam;
			ObjectParam = InParameter.ObjectParam;
			StringParam = InParameter.StringParam;

			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayBoolParam, ArrayBoolParam, bInMergeArrayTypes);
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayFloatParam, ArrayFloatParam, bInMergeArrayTypes);
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayIntParam, ArrayIntParam, bInMergeArrayTypes);
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayObjectParam, ArrayObjectParam, bInMergeArrayTypes);
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayStringParam, ArrayStringParam, bInMergeArrayTypes);

			if (!bInMergeArrayTypes)
			{
				ObjectProxies.Reset();
			}

			for (const TSharedPtr<Audio::IProxyData>& ProxyPtr : InParameter.ObjectProxies)
			{
				ObjectProxies.Emplace(ProxyPtr);
			}
		}
		break;

		case EAudioParameterType::Object:
		{
			ObjectParam = InParameter.ObjectParam;

			ObjectProxies.Reset();
			for (const TSharedPtr<Audio::IProxyData>& ProxyPtr : InParameter.ObjectProxies)
			{
				ObjectProxies.Emplace(ProxyPtr);
			}
		}
		break;

		case EAudioParameterType::ObjectArray:
		{
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayObjectParam, ArrayObjectParam, bInMergeArrayTypes);

			if (!bInMergeArrayTypes)
			{
				ObjectProxies.Reset();
			}

			for (const TSharedPtr<Audio::IProxyData>& ProxyPtr : InParameter.ObjectProxies)
			{
				ObjectProxies.Emplace(ProxyPtr);
			}
		}
		break;

		case EAudioParameterType::String:
		{
			StringParam = InParameter.StringParam;
		}
		break;

		case EAudioParameterType::StringArray:
		{
			Audio::ParameterPrivate::SetOrMergeArray(InParameter.ArrayStringParam, ArrayStringParam, bInMergeArrayTypes);
		}
		break;

		default:
			break;
	}
}

void FAudioParameter::Merge(TArray<FAudioParameter>&& InParams, TArray<FAudioParameter>& OutParams)
{
	if (InParams.IsEmpty())
	{
		return;
	}

	if (OutParams.IsEmpty())
	{
		OutParams = MoveTemp(InParams);
		return;
	}

	auto SortParamsPredicate = [](const FAudioParameter& A, const FAudioParameter& B) { return A.ParamName.FastLess(B.ParamName); };
	OutParams.Sort(SortParamsPredicate);

	for (FAudioParameter& NewParam : InParams)
	{
		const int32 ExistingElementIndex = Algo::LowerBound(OutParams, NewParam, SortParamsPredicate);
		if (OutParams.IsValidIndex(ExistingElementIndex))
		{
			FAudioParameter& ExistingParam = OutParams[ExistingElementIndex];
			if (ExistingParam.ParamName == NewParam.ParamName)
			{
				ExistingParam.Merge(NewParam);
				continue;
			}
		}

		OutParams.Emplace(MoveTemp(NewParam));
	}
}


==========================


=== AudioParameter.h ===
========================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "Containers/Array.h"
#include "Containers/UnrealString.h"
#include "HAL/Platform.h"
#include "HAL/PlatformCrt.h"
#include "IAudioProxyInitializer.h"
#include "Templates/UnrealTemplate.h"
#include "UObject/Interface.h"
#include "UObject/NameTypes.h"
#include "UObject/Object.h"
#include "UObject/ObjectMacros.h"
#include "UObject/ObjectPtr.h"

#include "AudioParameter.generated.h"

class UObject;


#define AUDIO_PARAMETER_NAMESPACE_PATH_DELIMITER "."

// Convenience macro for statically declaring an interface member's FName. AUDIO_PARAMETER_INTERFACE_NAMESPACE must be defined.
#define AUDIO_PARAMETER_INTERFACE_MEMBER_DEFINE(Name) (AUDIO_PARAMETER_INTERFACE_NAMESPACE AUDIO_PARAMETER_NAMESPACE_PATH_DELIMITER Name)

namespace Audio
{
	struct FParameterPath
	{
		static AUDIOEXTENSIONS_API const FString NamespaceDelimiter;

		// Combines names using the namespace delimiter
		static AUDIOEXTENSIONS_API FName CombineNames(FName InLeft, FName InRight);

		// Splits name into namespace & parameter name
		static AUDIOEXTENSIONS_API void SplitName(FName InFullName, FName& OutNamespace, FName& OutParameterName);
	};
}

UENUM()
enum class EAudioParameterType : uint8
{
	// 'Default' results in behavior that is resolved
	// based on the system interpreting it.  To support
	// legacy implementation, SoundCues cache all typed values
	// associated with a given parameter name. 
	// For MetaSounds, use a specific Type instead of this one. 
	None UMETA(DisplayName = "Default"),

	// Boolean value
	Boolean,

	// Integer value
	Integer,

	// Float value
	Float,

	// String value (not supported by legacy SoundCue system)
	String,

	// Object value (types other than SoundWave not supported by legacy SoundCue system)
	Object,

	// Array of default initialized values (not supported by legacy SoundCue system)
	// Hidden for now as no parameter types exist that support default construction
	NoneArray UMETA(Hidden, DisplayName = "Default (Array)"),

	// Array of boolean values (not supported by legacy SoundCue system)
	BooleanArray UMETA(DisplayName = "Boolean (Array)"),

	// Array of integer values (not supported by legacy SoundCue system)
	IntegerArray UMETA(DisplayName = "Integer (Array)"),

	// Array of float values (not supported by legacy SoundCue system)
	FloatArray UMETA(DisplayName = "Float (Array)"),

	// Array of string values (not supported by legacy SoundCue system)
	StringArray UMETA(DisplayName = "String (Array)"),

	// Array of object values (not supported by legacy SoundCue system)
	ObjectArray UMETA(DisplayName = "Object (Array)"),

	// Trigger value
	Trigger,

	COUNT UMETA(Hidden)
};


USTRUCT(BlueprintType)
struct FAudioParameter
{
	GENERATED_USTRUCT_BODY()

	FAudioParameter() = default;

	FAudioParameter(FName InName)
		: ParamName(InName)
	{
	}

	FAudioParameter(FName InName, float InValue)
		: ParamName(InName)
		, FloatParam(InValue)
		, ParamType(EAudioParameterType::Float)
	{
	}

	FAudioParameter(FName InName, bool InValue)
		: ParamName(InName)
		, BoolParam(InValue)
		, ParamType(EAudioParameterType::Boolean)
	{
	}

	FAudioParameter(FName InName, int32 InValue)
		: ParamName(InName)
		, IntParam(InValue)
		, ParamType(EAudioParameterType::Integer)
	{
	}

	FAudioParameter(FName InName, UObject* InValue)
		: ParamName(InName)
		, ObjectParam(InValue)
		, ParamType(EAudioParameterType::Object)
	{
	}

	FAudioParameter(FName InName, const FString& InValue)
		: ParamName(InName)
		, StringParam(InValue)
		, ParamType(EAudioParameterType::String)
	{
	}

	FAudioParameter(FName InName, const TArray<float>& InValue)
		: ParamName(InName)
		, ArrayFloatParam(InValue)
		, ParamType(EAudioParameterType::FloatArray)
	{
	}

	FAudioParameter(FName InName, TArray<float>&& InValue)
		: ParamName(InName)
		, ArrayFloatParam(MoveTemp(InValue))
		, ParamType(EAudioParameterType::FloatArray)
	{
	}

	FAudioParameter(FName InName, const TArray<bool>& InValue)
		: ParamName(InName)
		, ArrayBoolParam(InValue)
		, ParamType(EAudioParameterType::BooleanArray)
	{
	}

	FAudioParameter(FName InName, TArray<bool>&& InValue)
		: ParamName(InName)
		, ArrayBoolParam(MoveTemp(InValue))
		, ParamType(EAudioParameterType::BooleanArray)
	{
	}

	FAudioParameter(FName InName, const TArray<int32>& InValue)
		: ParamName(InName)
		, ArrayIntParam(InValue)
		, ParamType(EAudioParameterType::IntegerArray)
	{
	}

	FAudioParameter(FName InName, TArray<int32>&& InValue)
		: ParamName(InName)
		, ArrayIntParam(MoveTemp(InValue))
		, ParamType(EAudioParameterType::IntegerArray)
	{
	}

	FAudioParameter(FName InName, const TArray<UObject*>& InValue)
		: ParamName(InName)
		, ArrayObjectParam(InValue)
		, ParamType(EAudioParameterType::ObjectArray)
	{
	}

// We can't move TArray<UObject*> into a TArray<TObjectPtr<UObject>> since UE_OBJECT_PTR_GC_BARRIER was added
#if 0
	FAudioParameter(FName InName, TArray<UObject*>&& InValue)
		: ParamName(InName)
		, ArrayObjectParam(MoveTemp(InValue))
		, ParamType(EAudioParameterType::ObjectArray)
	{
	}
#endif

	FAudioParameter(FName InName, const TArray<FString>& InValue)
		: ParamName(InName)
		, ArrayStringParam(InValue)
		, ParamType(EAudioParameterType::StringArray)
	{
	}

	FAudioParameter(FName InName, TArray<FString>&& InValue)
		: ParamName(InName)
		, ArrayStringParam(MoveTemp(InValue))
		, ParamType(EAudioParameterType::StringArray)
	{
	}

	FAudioParameter(FName InName, EAudioParameterType Type)
		: ParamName(InName)
		, ParamType(Type)
	{
		if (Type == EAudioParameterType::Trigger)
		{
			BoolParam = true;
		}
	}

	// Static function to avoid int32 constructor collision
	static FAudioParameter CreateDefaultArray(FName InName, int32 InNum)
	{
		FAudioParameter NewParam(InName, InNum);
		NewParam.ParamType = EAudioParameterType::NoneArray;
		return NewParam;
	}

	// Sets values specified by type field of the given parameter on this parameter. If the provided parameter is set to type 'None', takes all values of the given parameter.
	// bInTakeName = Take the name of the provided parameter.
	// bInTakeType = Take the type of the provided parameter.
	// bInMergeArrayTypes - Appends array(s) for specified type if true, else swaps the local value with that of the provided parameter if false.
	AUDIOEXTENSIONS_API void Merge(const FAudioParameter& InParameter, bool bInTakeName = true, bool bInTakeType = true, bool bInMergeArrayTypes = false);

	// Moves InParams to OutParams that are not already included. For backward compatibility (i.e. SoundCues),
	// if a param is already in OutParams, attempts to merge param values together, but assigns the param the
	// incoming param's type. Currently existing OutParam values left if new value of the same type is provided
	// by InParam.
	static AUDIOEXTENSIONS_API void Merge(TArray<FAudioParameter>&& InParams, TArray<FAudioParameter>& OutParams);

	FAudioParameter(FAudioParameter&& InParameter) = default;
	FAudioParameter(const FAudioParameter& InParameter) = default;

	FAudioParameter& operator=(const FAudioParameter& InParameter) = default;
	FAudioParameter& operator=(FAudioParameter&& InParameter) = default;

	// Name of the parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName="Name"), Category = AudioParameter)
	FName ParamName;

	// Float value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (Float)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::None || ParamType == EAudioParameterType::Float"), Category = AudioParameter)
	float FloatParam = 0.f;

	// Boolean value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (Bool)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::None || ParamType == EAudioParameterType::Boolean"), Category = AudioParameter)
	bool BoolParam = false;

	// Integer value of parameter. If set to 'Default Construct', value is number of array items to construct.
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (Int)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::None || ParamType == EAudioParameterType::Integer || ParamType == EAudioParameterType::NoneArray"), Category = AudioParameter)
	int32 IntParam = 0;

	// Object value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (Object)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::None || ParamType == EAudioParameterType::Object"), Category = AudioParameter)
	TObjectPtr<UObject> ObjectParam = nullptr;

	// String value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (String)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::String"), Category = AudioParameter)
	FString StringParam;

	// Array Float value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (Float Array)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::FloatArray"), Category = AudioParameter)
	TArray<float> ArrayFloatParam;

	// Boolean value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (Bool Array)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::BooleanArray"), Category = AudioParameter)
	TArray<bool> ArrayBoolParam;

	// Integer value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (Int Array)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::IntegerArray"), Category = AudioParameter)
	TArray<int32> ArrayIntParam;

	// Object value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (Object Array)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::ObjectArray"), Category = AudioParameter)
	TArray<TObjectPtr<UObject>> ArrayObjectParam;

	// String value of parameter
	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Value (String Array)", DisplayAfter = "ParamType", EditConditionHides, EditCondition = "ParamType == EAudioParameterType::StringArray"), Category = AudioParameter)
	TArray<FString> ArrayStringParam;

	UPROPERTY(EditAnywhere, BlueprintReadWrite, meta = (DisplayName = "Type"), Category = AudioParameter)
	EAudioParameterType ParamType = EAudioParameterType::None;

	// Optional TypeName used to describe what constructed type this parameter should be initializing.
	UPROPERTY()
	FName TypeName;

	// Object proxies to be generated when parameter is passed to the AudioThread to represent ObjectParam/ArrayObjectParam safely
	TArray<TSharedPtr<Audio::IProxyData>> ObjectProxies;

	// Common find algorithm for default/legacy parameter system
	static const FAudioParameter* FindParam(const TArray<FAudioParameter>& InParams, FName InParamName)
	{
		if (!InParamName.IsNone())
		{
			for (const FAudioParameter& ExistingParam : InParams)
			{
				if (ExistingParam.ParamName == InParamName)
				{
					return &ExistingParam;
				}
			}
		}

		return nullptr;
	}

	// Common find & add algorithm for default/legacy parameter system.
	static FAudioParameter* FindOrAddParam(TArray<FAudioParameter>& OutParams, FName InParamName)
	{
		FAudioParameter* Param = nullptr;
		if (InParamName.IsNone())
		{
			return Param;
		}

		for (FAudioParameter& ExistingParam : OutParams)
		{
			if (ExistingParam.ParamName == InParamName)
			{
				Param = &ExistingParam;
				break;
			}
		}

		if (!Param)
		{
			Param = &OutParams.AddDefaulted_GetRef();
			Param->ParamName = InParamName;
		}

		return Param;
	}
};

========================


=== AudioParameterControllerInterface.cpp ===
=============================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioParameterControllerInterface.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioParameterControllerInterface)


UAudioParameterControllerInterface::UAudioParameterControllerInterface(FObjectInitializer const& InObjectInitializer)
	: UInterface(InObjectInitializer)
{
}


=============================================


=== AudioParameterControllerInterface.h ===
===========================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "AudioParameter.h"
#include "Containers/Array.h"
#include "Containers/UnrealString.h"
#include "HAL/Platform.h"
#include "IAudioProxyInitializer.h"
#include "Templates/UnrealTemplate.h"
#include "UObject/Interface.h"
#include "UObject/NameTypes.h"
#include "UObject/Object.h"
#include "UObject/ObjectMacros.h"
#include "UObject/UObjectGlobals.h"

#include "AudioParameterControllerInterface.generated.h"

class UObject;
struct FAudioParameter;
struct FFrame;


UINTERFACE(BlueprintType, meta = (CannotImplementInterfaceInBlueprint), MinimalAPI)
class UAudioParameterControllerInterface : public UInterface
{
	GENERATED_UINTERFACE_BODY()
};

// Base interface for any object implementing parameter control for a given sound instance controller.
class IAudioParameterControllerInterface : public IInterface
{
	GENERATED_IINTERFACE_BODY()

public:
	// Resets all parameters to their original values.
	UFUNCTION(BlueprintCallable, Category = "Audio|Parameter")
	virtual void ResetParameters() = 0;

	// Executes a named trigger.  Does *not* cache trigger value, so only executes if the sound
	// is already playing.  If the intent is for the trigger to execute immediately (if playing)
	// and be called on initialization for all future instances, call 'SetBoolParameter' with the
	// intended initial trigger behavior (true if trigger desired on initialization, false if not).
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Execute Trigger Parameter"), Category = "Audio|Parameter")
	virtual void SetTriggerParameter(FName InName) = 0;

	// Sets a named Boolean
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Boolean Parameter"), Category = "Audio|Parameter")
	virtual void SetBoolParameter(FName InName, bool InBool) = 0;
	
	// Sets a named Boolean Array
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Boolean Array Parameter"), Category = "Audio|Parameter")
	virtual void SetBoolArrayParameter(FName InName, const TArray<bool>& InValue) = 0;

	// Sets a named Int32
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Integer Parameter"), Category = "Audio|Parameter")
	virtual void SetIntParameter(FName InName, int32 InInt) = 0;

	// Sets a named Int32 Array
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Integer Array Parameter"), Category = "Audio|Parameter")
	virtual void SetIntArrayParameter(FName InName, const TArray<int32>& InValue) = 0;

	// Sets a named Float
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Float Parameter"), Category = "Audio|Parameter")
	virtual void SetFloatParameter(FName InName, float InFloat) = 0;
	
	// Sets a named Float Array
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Float Array Parameter"), Category = "Audio|Parameter")
	virtual void SetFloatArrayParameter(FName InName, const TArray<float>& InValue) = 0;
	
	// Sets a named String
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set String Parameter"), Category = "Audio|Parameter")
	virtual void SetStringParameter(FName InName, const FString& InValue) = 0;

	// Sets a named String Array
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set String Array Parameter"), Category = "Audio|Parameter")
	virtual void SetStringArrayParameter(FName InName, const TArray<FString>& InValue) = 0;

	// Sets a named UObject
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Object Parameter"), Category = "Audio|Parameter")
	virtual void SetObjectParameter(FName InName, UObject* InValue) = 0;

	// Sets a named UObject Array
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Object Array Parameter"), Category = "Audio|Parameter")
	virtual void SetObjectArrayParameter(FName InName, const TArray<UObject*>& InValue) = 0;

	// Sets an array of parameters as a batch
	UFUNCTION(BlueprintCallable, meta = (DisplayName = "Set Parameters"), Category = "Audio|Parameter")
	virtual void SetParameters_Blueprint(const TArray<FAudioParameter>& InParameters) = 0;

	// Sets a named parameter to the given parameter structure value
	virtual void SetParameter(FAudioParameter&& InValue) = 0;

	// Sets an array of parameters as a batch
	virtual void SetParameters(TArray<FAudioParameter>&& InValues) = 0;

	// Template Specialization for non-script clients.
	template<typename DataType> void SetParameter(FName InName, DataType&&) = delete;
	template<> void SetParameter(FName InName, bool&& InBool) { SetParameter({ InName, MoveTemp(InBool) }); }
	template<> void SetParameter(FName InName, float&& InFloat) { SetParameter({ InName, MoveTemp(InFloat) }); }
	template<> void SetParameter(FName InName, int32&& InInteger) { SetParameter({ InName, MoveTemp(InInteger) }); }
	template<> void SetParameter(FName InName, FString&& InString) { SetParameter({ InName, MoveTemp(InString) }); }
	template<> void SetParameter(FName InName, UObject*&& InObject) { SetParameter({ InName, MoveTemp(InObject) }); }
	template<> void SetParameter(FName InName, TArray<bool>&& InBools) { SetParameter({ InName, MoveTemp(InBools)}); }
	template<> void SetParameter(FName InName, TArray<float>&& InFloats) { SetParameter({ InName, MoveTemp(InFloats) }); }
	template<> void SetParameter(FName InName, TArray<int32>&& InIntegers) { SetParameter({ InName, MoveTemp(InIntegers) }); }
	template<> void SetParameter(FName InName, TArray<FString>&& InStrings) { SetParameter({ InName, MoveTemp(InStrings) }); }
	template<> void SetParameter(FName InName, TArray<UObject*>&& InObjects) { SetParameter({ InName, MoveTemp(InObjects) }); }
};

===========================================


=== AudioPropertiesSheetAssetBase.h ===
=======================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "UObject/Object.h"
#include "UObject/ObjectPtr.h"

#include "AudioPropertiesSheetAssetBase.generated.h"

class UAudioPropertiesBindings;

UCLASS(Abstract)
class AUDIOEXTENSIONS_API UAudioPropertiesSheetAssetBase : public UObject
{
	GENERATED_BODY()

public: 
#if WITH_EDITOR
	UFUNCTION(BlueprintCallable, BlueprintPure=false, Category="AudioProperties")
	virtual bool CopyToObjectProperties(UObject* TargetObject) const { return false; };
#endif
};
=======================================


=== IAudioEndpoint.cpp ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "IAudioEndpoint.h"

#include "AudioExtentionsModule.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(IAudioEndpoint)

DEFINE_LOG_CATEGORY(LogAudioEndpoints);

TUniquePtr<IAudioEndpointSettingsProxy> UDummyEndpointSettings::GetProxy() const
{
	FDummyEndpointSettingsProxy* Settings = new FDummyEndpointSettingsProxy();

	return TUniquePtr<IAudioEndpointSettingsProxy>(Settings);
}

Audio::FPatchInput IAudioEndpoint::PatchNewInput(float ExpectedDurationPerRender, float& OutSampleRate, int32& OutNumChannels)
{
	OutSampleRate = GetSampleRate();
	OutNumChannels = GetNumChannels();

	// For average case scenarios, we need to buffer at least the sum of the number of input frames and the number of output frames per callback.
	// A good heuristic for doing this while retaining some extra space in the buffer is doubling the max of these two values.
	int32 NumSamplesToBuffer = FMath::CeilToInt(ExpectedDurationPerRender * OutNumChannels * OutSampleRate);
	if (EndpointRequiresCallback())
	{
		NumSamplesToBuffer = FMath::Max(GetDesiredNumFrames() * OutNumChannels, NumSamplesToBuffer) * 2;
	}
	else
	{
		NumSamplesToBuffer *= 2;
	}

	return PatchMixer.AddNewInput(NumSamplesToBuffer, 1.0f);
}

void IAudioEndpoint::SetNewSettings(TUniquePtr<IAudioEndpointSettingsProxy>&& InNewSettings)
{
	FScopeLock ScopeLock(&CurrentSettingsCriticalSection);

	CurrentSettings = MoveTemp(InNewSettings);
}

void IAudioEndpoint::ProcessAudioIfNeccessary()
{
	const bool bShouldExecuteCallback = !RenderCallback.IsValid() && EndpointRequiresCallback();
	if (bShouldExecuteCallback)
	{
		RunCallbackSynchronously();
	}
}

bool IAudioEndpoint::IsImplemented()
{
	return false;
}

float IAudioEndpoint::GetSampleRate() const
{
	return 0;
}

int32 IAudioEndpoint::GetNumChannels() const
{
	return 0;
}

int32 IAudioEndpoint::PopAudio(float* OutAudio, int32 NumSamples)
{
	check(OutAudio);
	return PatchMixer.PopAudio(OutAudio, NumSamples, false);
}

void IAudioEndpoint::PollSettings(TFunctionRef<void(const IAudioEndpointSettingsProxy*)> SettingsCallback)
{
	FScopeLock ScopeLock(&CurrentSettingsCriticalSection);
	SettingsCallback(CurrentSettings.Get());
}

void IAudioEndpoint::DisconnectAllInputs()
{
	PatchMixer.DisconnectAllInputs();
}

void IAudioEndpoint::StartRunningAsyncCallback()
{
	if (!ensureMsgf(GetSampleRate() > 0.0f, TEXT("Invalid sample rate returned!")))
	{
		return;
	}

	float CallbackDuration = ((float)GetDesiredNumFrames()) / GetSampleRate();

	RenderCallback.Reset(new Audio::FMixerNullCallback(CallbackDuration, [&]()
	{
		RunCallbackSynchronously();
	}));
}

void IAudioEndpoint::StopRunningAsyncCallback()
{
	RenderCallback.Reset();
}

void IAudioEndpoint::RunCallbackSynchronously()
{
	const int32 NumSamplesToBuffer = GetDesiredNumFrames() * GetNumChannels();

	BufferForRenderCallback.Reset();
	BufferForRenderCallback.AddUninitialized(NumSamplesToBuffer);

	while (PatchMixer.MaxNumberOfSamplesThatCanBePopped() >= NumSamplesToBuffer)
	{
		int32 PopResult = PatchMixer.PopAudio(BufferForRenderCallback.GetData(), BufferForRenderCallback.Num(), false);
		check(PopResult == BufferForRenderCallback.Num() || PopResult < 0);

		const TArrayView<const float> PoppedAudio = TArrayView<const float>(BufferForRenderCallback);

		auto CallbackWithSettings = [&, PoppedAudio](const IAudioEndpointSettingsProxy* InSettings)
		{
			if (!OnAudioCallback(PoppedAudio, GetNumChannels(), InSettings))
			{
				DisconnectAllInputs();
			}
		};

		PollSettings(CallbackWithSettings);
	}
}

FName IAudioEndpointFactory::GetEndpointTypeName() 
{ 
	return FName(); 
}

FName IAudioEndpointFactory::GetTypeNameForDefaultEndpoint()
{
	static FName DefaultEndpointName = FName(TEXT("Default Endpoint"));
	return DefaultEndpointName;
}

FName IAudioEndpointFactory::GetModularFeatureName()
{
	static FName ModularFeatureName = TEXT("External Audio Endpoint");
	return ModularFeatureName;
}

void IAudioEndpointFactory::RegisterEndpointType(IAudioEndpointFactory* InFactory)
{
	IModularFeatures::Get().RegisterModularFeature(GetModularFeatureName(), InFactory);
}

void IAudioEndpointFactory::UnregisterEndpointType(IAudioEndpointFactory* InFactory)
{
	IModularFeatures::Get().UnregisterModularFeature(GetModularFeatureName(), InFactory);
}

IAudioEndpointFactory* IAudioEndpointFactory::Get(const FName& InName)
{
	if (InName == GetTypeNameForDefaultEndpoint() || InName == FName())
	{
		return nullptr;
	}

	IModularFeatures::Get().LockModularFeatureList();
	TArray<IAudioEndpointFactory*> Factories = IModularFeatures::Get().GetModularFeatureImplementations<IAudioEndpointFactory>(GetModularFeatureName());
	IModularFeatures::Get().UnlockModularFeatureList();

	for (IAudioEndpointFactory* Factory : Factories)
	{
		if (Factory && Factory->bIsImplemented && InName == Factory->GetEndpointTypeName())
		{
			return Factory;
		}
	}

	//If we got here, we're probably dealing with a platform-specific endpoint on a platform its not enabled for, so we'll want to mute it
	UE_LOG(LogAudioEndpoints, Display, TEXT("No endpoint implementation for %s found for this platform. Endpoint Submixes set to this type will not do anything."), *InName.ToString());
	return GetDummyFactory();
}

TArray<FName> IAudioEndpointFactory::GetAvailableEndpointTypes()
{
	// Ensure the module is loaded. This will cause any platform extension modules to load and register.
	ensure(FAudioExtensionsModule::Get() != nullptr);
	
	TArray<FName> EndpointNames;

	EndpointNames.Add(GetTypeNameForDefaultEndpoint());

	IModularFeatures::Get().LockModularFeatureList();
	TArray<IAudioEndpointFactory*> Factories = IModularFeatures::Get().GetModularFeatureImplementations<IAudioEndpointFactory>(GetModularFeatureName());
	IModularFeatures::Get().UnlockModularFeatureList();

	for (IAudioEndpointFactory* Factory : Factories)
	{
		EndpointNames.AddUnique(Factory->GetEndpointTypeName());
	}

	return EndpointNames;
}

TUniquePtr<IAudioEndpoint> IAudioEndpointFactory::CreateNewEndpointInstance(const FAudioPluginInitializationParams& InitInfo, const IAudioEndpointSettingsProxy& InitialSettings)
{
	return TUniquePtr<IAudioEndpoint>(new IAudioEndpoint());
}

UClass* IAudioEndpointFactory::GetCustomSettingsClass() const
{
	return nullptr;
}

const UAudioEndpointSettingsBase* IAudioEndpointFactory::GetDefaultSettings() const
{
	return GetDefault<UDummyEndpointSettings>();
}

IAudioEndpointFactory* IAudioEndpointFactory::GetDummyFactory()
{
	static IAudioEndpointFactory DummyFactory = IAudioEndpointFactory();
	return &DummyFactory;
}

==========================


=== IAudioEndpoint.h ===
========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "AudioMixerNullDevice.h"
#include "Containers/Array.h"
#include "Containers/ArrayView.h"
#include "CoreMinimal.h"
#include "CoreTypes.h"
#include "DSP/MultithreadedPatching.h"
#include "Features/IModularFeature.h"
#include "Features/IModularFeatures.h"
#include "HAL/CriticalSection.h"
#include "ISoundfieldFormat.h"
#include "Logging/LogMacros.h"
#include "Misc/AssertionMacros.h"
#include "Templates/UniquePtr.h"
#include "UObject/NameTypes.h"
#include "UObject/Object.h"
#include "UObject/ObjectMacros.h"
#include "UObject/UObjectGlobals.h"

#include "IAudioEndpoint.generated.h"

class UClass;
struct FAudioPluginInitializationParams;
template <typename FuncType> class TFunctionRef;

DECLARE_LOG_CATEGORY_EXTERN(LogAudioEndpoints, Display, All);

/**
 * Interfaces for Endpoints
 * 
 * This set of interfaces is useful for push audio to arbitrary outputs.
 * 
 */

/**  
 * This interface should be used to provide a non-uclass version of the data described in
 * your implementation of UAudioEndpointSettingsBase.
 */
class IAudioEndpointSettingsProxy
{
public:
	virtual ~IAudioEndpointSettingsProxy() {}
};

/**
 * This opaque class should be used for specifying settings for how audio should be
 * send to an external endpoint.
 */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class UAudioEndpointSettingsBase : public UObject
{
	GENERATED_BODY()

public:
	AUDIOEXTENSIONS_API virtual TUniquePtr<IAudioEndpointSettingsProxy> GetProxy() const PURE_VIRTUAL(UAudioEndpointSettingsBase::GetProxy, return nullptr;);
};

//A blank class for when unimplemented endpoint types are returned
class FDummyEndpointSettingsProxy : public IAudioEndpointSettingsProxy
{
};

UCLASS()
class UDummyEndpointSettings : public UAudioEndpointSettingsBase
{
	GENERATED_BODY()

	public:
		virtual TUniquePtr<IAudioEndpointSettingsProxy> GetProxy() const override;
};

/**
 * Class that allows audio to be sent to an arbitrary locale. This can be used for multi-device rendering, haptics systems, etc. 
 * Note that this only for interleaved audio buffers with no metadata for object-based or soundfield-based rendering.
 * For those, see 
 */
class IAudioEndpoint
{
public:
	virtual ~IAudioEndpoint() {};

	/**
	 * Create a new patch point for this endpoint. Please see MultithreadedPatching.h to see how to use the FPatchInput class.
	 * @param [in] ExpectedDurationPerRender The worst-case amount of time expected between render callbacks. This is used to determined how much to allocate for this input.
	 * @param [out] OutSampleRate. The sample rate expected to be pushed to the returned FPatchInput.
	 *                             If you need to resample your input, please see Audio::FResampler.
	 * @param [out] OutNumChannels. The number of channels expected to be pushed to the returned FPatchInput.
	 *                              If you need to downmix or upmix your input, try using the following:
	 *                              TArray<float> MixdownGainsMap;
	 *                              Audio::FMixerDevice::Get2DChannelMap(false, NumInputChannels, NumOutputChannels, false, MixdownGainsMap);
	 *                             	Audio::DownmixBuffer(NumInputChannels, NumOutputChannels, InputAudio, OutputAudio, MixdownGainsMap.GetData());
	 * @returns a new Audio::FPatchInput. The FPatchInput may be disconnected if this endpoint's sample rate or channel count changes, in which case you will need to reconnect by calling this again.
	 */
	AUDIOEXTENSIONS_API Audio::FPatchInput PatchNewInput(float ExpectedDurationPerRender, float& OutSampleRate, int32& OutNumChannels);

	/**
	 * Post new settings for this endpoint.
	 * There is no type safety on this call, so make sure that you are using the correct implementation
	 * of IAudioEndpointSettingsProxy for this implementation of IAudioEndpoint.
	 */
	AUDIOEXTENSIONS_API void SetNewSettings(TUniquePtr<IAudioEndpointSettingsProxy>&& InNewSettings);

	/**
	 * If this audio endpoint hasn't spawned a seperate callback thread but requires a callback, this should be executed somewhere.
	 */
	AUDIOEXTENSIONS_API void ProcessAudioIfNeccessary();

	/**
	* Whether this endpoint is of an implemented type
	*/
	AUDIOEXTENSIONS_API virtual bool IsImplemented();

protected:

	/** REQUIRED OVERRIDES: */

	/** This should return the sample rate we should be sending to this endpoint. If the sample rate changes, please call DisconnectAllInputs(). */
	AUDIOEXTENSIONS_API virtual float GetSampleRate() const;

	/** This should return the number of channels we should be sending to this endpoint. If the number of channels changes, please call DisconnectAllInputs. */
	AUDIOEXTENSIONS_API virtual int32 GetNumChannels() const;

	/** OPTIONAL OVERRIDES: */

	/**
	 * For endpoints that do not explicitly fire a timed callback to poll audio data,
	 * this should be overridden to return true, and  OnAudioCallback and GetDesiredNumFrames should be overridden.
	 */
	virtual bool EndpointRequiresCallback() const { return false; }
	virtual int32 GetDesiredNumFrames() const { return 0; }

	/**
	 * For endpoints that override EndpointRequiresCallback to return true, 
	 * this callback will be called every (GetDesiredNumFrames() / GetSampleRate()) seconds.
	 * @returns whether the endpoint is still valid. If this returns false, DisconnectAllInputs will be called automatically.
	 */
	virtual bool OnAudioCallback(const TArrayView<const float>& InAudio, const int32& NumChannels, const IAudioEndpointSettingsProxy* InSettings) { return false; };

	/** METHODS USED BY IMPLEMENTATIONS OF IAudioEndpoint: */

	/**
	 * This is used by the IAudioEndpoint implementation to poll buffered audio to process or send to the endpoint.
	 * Note that this is NOT thread safe if EndpointRequiresCallback() is overridden to return true. If that is the case, use an override of OnAudioCallback instead.
	 * 
	 * @param [in] OutAudio: Pointer to already allocated buffer of floats, at least NumSamples long. This will be filled with interleaved audio based on GetNumChannels().
	 * @param [in] NumSamples: The number of samples to fill OutAudio with.
	 * @returns [out] the number of samples polled from this thing.
	 */
	AUDIOEXTENSIONS_API int32 PopAudio(float* OutAudio, int32 NumSamples);

	/**
	 * Use this as a thread safe way to use the current settings posted to this IAudioEndpoint. Locks with IAudioEndpoint::SetSettings.
	 * @param[in] NewSettingsRetrieved lambda used to work with the retrieved settings.
	 *                                 This lambda is called immediately and synchronously, but is used
	 *                                 to safely scope usage of the IAudioEndpointSettingsProxy pointer.
	 */
	AUDIOEXTENSIONS_API void PollSettings(TFunctionRef<void(const IAudioEndpointSettingsProxy*)> NewSettingsRetrieved);

	/**
	 * Thread safe function to disconnect everything from this endpoint. 
	 * Anything that owns an Audio::FPatchInput will be notified and will have to call PatchNewInput() again to reconnect.
	 */
	AUDIOEXTENSIONS_API void DisconnectAllInputs();

	/**
	 * If EndpointRequiresCallback() returns true, this can be used to spawn an async thread and begin calling OnAudioCallback.
	 */
	AUDIOEXTENSIONS_API void StartRunningAsyncCallback();
	AUDIOEXTENSIONS_API void StopRunningAsyncCallback();

	/**
	 * If EndpointRequiresCallback() returns true, this can be used to manually run the callback.
	 */
	AUDIOEXTENSIONS_API void RunCallbackSynchronously();


private:
	// Owns a scoped thread and runs OnAudioCallback when StartRunningCallback() is called.
	TUniquePtr<Audio::FMixerNullCallback> RenderCallback;
	
	// If we have a render callback, we pop audio from the PatchMixer to this buffer before calling OnAudioCallback.
	Audio::FAlignedFloatBuffer BufferForRenderCallback;

	// Owns the current settings for this endpoint.
	TUniquePtr<IAudioEndpointSettingsProxy> CurrentSettings;
	FCriticalSection CurrentSettingsCriticalSection;

	// Object used to mix all inputs together. Polled when OnAudioCallback is executed or when PollAudio is called.
	Audio::FPatchMixer PatchMixer;
};


/**
 * This factory is used to expose Endpoint types to the editor.
 * Once a factory is constructed and RegisterEndpointType is called, it will be exposed as a type of endpoint
 * That a submix in the submix graph could be constructed with.
 */
class IAudioEndpointFactory : public IModularFeature
{
public:
	/** Virtual destructor */
	virtual ~IAudioEndpointFactory()
	{
	}

	/** Get the name for the endpoint type that this factory produces.  */
	AUDIOEXTENSIONS_API virtual FName GetEndpointTypeName();

	/** This is a special cased name for endpoint submixes that render directly to the default audio device in Audio::FMixerDevice::OnProcessAudioStream. */
	static AUDIOEXTENSIONS_API FName GetTypeNameForDefaultEndpoint();

	/** 
	 * This is used when calling IModularFeatures::Get().RegisterModularFeature for IAudioEndpointFactory implementations. 
	 * It's not needed if one uses RegisterEndpointType() to register IAudioEndpointFactory implementations. 
	 */
	static AUDIOEXTENSIONS_API FName GetModularFeatureName();

	/** 
	 * This needs to be called to make a soundfield format usable by the engine.
	 * It can be called from a ISoundfieldFactory subclass' constructor
	*/
	static AUDIOEXTENSIONS_API void RegisterEndpointType(IAudioEndpointFactory* InFactory);

	/**
	 * This needs to be called it an implementation of ISoundfieldFactory is about to be destroyed.
	 * It can be called from the destructor of an implementation of ISoundfieldFactory.
	 */
	static AUDIOEXTENSIONS_API void UnregisterEndpointType(IAudioEndpointFactory* InFactory);

	/**
	 * Get a registered endpoint factory by name.
	 */
	static AUDIOEXTENSIONS_API IAudioEndpointFactory* Get(const FName& InName);

	static AUDIOEXTENSIONS_API TArray<FName> GetAvailableEndpointTypes();

	/** Called for every new endpoint submix created with this factory's endpoint type. */
	AUDIOEXTENSIONS_API virtual TUniquePtr<IAudioEndpoint> CreateNewEndpointInstance(const FAudioPluginInitializationParams& InitInfo, const IAudioEndpointSettingsProxy& InitialSettings);

	/**
	 * Should return the StaticClass of this factory's implementation of UAudioEndpointSettingsBase.
	 */
	AUDIOEXTENSIONS_API virtual UClass* GetCustomSettingsClass() const;

	/**
	 * return the settings an endpoint should use 
	 */
	AUDIOEXTENSIONS_API virtual const UAudioEndpointSettingsBase* GetDefaultSettings() const;

	bool bIsImplemented = false;

	static AUDIOEXTENSIONS_API IAudioEndpointFactory* GetDummyFactory();
};

========================


=== IAudioExtensionPlugin.h ===
===============================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "CoreMinimal.h"
#include "Features/IModularFeature.h"
#include "HAL/LowLevelMemTracker.h"
#include "ISoundfieldFormat.h"
#include "Math/Interval.h"
#include "Modules/ModuleInterface.h"
#include "Modules/ModuleManager.h"
#include "UObject/ObjectMacros.h"
#include "AudioDefines.h"
#include "IAudioProxyInitializer.h"

#include "IAudioExtensionPlugin.generated.h"

// Forward Declarations
class FAudioDevice;
class FSoundEffectBase;
class FSoundEffectSource;
class FSoundEffectSubmix;
struct FWaveInstance;
class IAudioModulationManager;
class IAudioOcclusion;
class IAudioPluginListener;
class IAudioReverb;
class IAudioSourceDataOverride;
class IAudioSpatialization;
class USoundSubmix;

LLM_DECLARE_TAG_API(Audio_SpatializationPlugins, AUDIOEXTENSIONS_API);
// Convenience macro for Audio_SpatializationPlugins LLM scope to avoid misspells.
#define AUDIO_SPATIALIZATION_PLUGIN_LLM_SCOPE LLM_SCOPE_BYTAG(Audio_SpatializationPlugins);

/**
* Enumeration of audio plugin types
*
*/
enum class EAudioPlugin : uint8
{
	SPATIALIZATION = 0,
	REVERB = 1,
	OCCLUSION = 2,
	MODULATION = 3,
	SOURCEDATAOVERRIDE = 4,

	COUNT = 5
};


// Deprecated in favor of TSoundEffectSubmixPtr
using FSoundEffectSubmixPtr   = TSharedPtr<FSoundEffectSubmix, ESPMode::ThreadSafe>;

using TSoundEffectPtr		  = TSharedPtr<FSoundEffectBase, ESPMode::ThreadSafe>;
using TSoundEffectSourcePtr   = TSharedPtr<FSoundEffectSource, ESPMode::ThreadSafe>;
using TSoundEffectSubmixPtr   = TSharedPtr<FSoundEffectSubmix, ESPMode::ThreadSafe>;
using TAudioSpatializationPtr = TSharedPtr<IAudioSpatialization, ESPMode::ThreadSafe>;
using TAudioSourceDataOverridePtr = TSharedPtr<IAudioSourceDataOverride, ESPMode::ThreadSafe>;
using TAudioModulationPtr     = TSharedPtr<IAudioModulationManager, ESPMode::ThreadSafe>;
using TAudioOcclusionPtr      = TSharedPtr<IAudioOcclusion, ESPMode::ThreadSafe>;
using TAudioReverbPtr         = TSharedPtr<IAudioReverb, ESPMode::ThreadSafe>;
using TAudioPluginListenerPtr = TSharedPtr<IAudioPluginListener, ESPMode::ThreadSafe>;

/**
* FSpatializationParams
* Struct for retrieving parameters needed for computing spatialization and occlusion plugins.
*/
struct FSpatializationParams
{
	/** The listener position (is likely at the origin). */
	FVector ListenerPosition;

	/** The listener orientation. */
	FQuat ListenerOrientation;

	/** The emitter position relative to listener. */
	FVector EmitterPosition;

	/** The emitter world position. */
	FVector EmitterWorldPosition;

	/** The emitter world rotation. */
	FQuat EmitterWorldRotation;

	/** The emitter world rotation on callback ago. */
	FQuat LastEmitterWorldRotation;

	/** The left channel position. */
	FVector LeftChannelPosition;

	/** The right channel position. */
	FVector RightChannelPosition;

	/** The distance between listener and emitter. */
	float Distance;

	/** The distance used to compute attenuation. Maybe different from the distance between listener and emitter if it's overridden. */
	float AttenuationDistance;

	/** Deprecated */
	float NormalizedOmniRadius;

	/** The amount of non-spatialized this source is. 1.0 means fully 2D, 0.0 means fully 3D. */
	float NonSpatializedAmount;

	/** The time when this spatialization params was built. */
	double AudioClock;

	FSpatializationParams()
		: ListenerPosition(FVector::ZeroVector)
		, ListenerOrientation(FQuat::Identity)
		, EmitterPosition(FVector::ZeroVector)
		, EmitterWorldPosition(FVector::ZeroVector)
		, EmitterWorldRotation(FQuat::Identity)
		, LastEmitterWorldRotation(FQuat::Identity)
		, LeftChannelPosition(FVector::ZeroVector)
		, RightChannelPosition(FVector::ZeroVector)
		, Distance(0.0f)
		, AttenuationDistance(0.0f)
		, NormalizedOmniRadius(0.0f)
		, NonSpatializedAmount(0.0f)
		, AudioClock(0.0)
	{}
};

struct FAudioPluginInitializationParams
{
	//Maximum number of sources that can play simultaneously.
	uint32 NumSources;

	//Number of output channels.
	uint32 NumOutputChannels;

	//Sample rate.
	uint32 SampleRate;

	//Buffer length used for each callback.
	uint32 BufferLength;

	//Pointer to audio device owning this audio plugin.
	//IMPORTANT: This will be deprecated once the AudioMixer
	//           is taken out of the experimental branch.
	FAudioDevice* AudioDevicePtr;

	FAudioPluginInitializationParams()
		: NumSources(0)
		, NumOutputChannels(0)
		, SampleRate(0)
		, BufferLength(0)
		, AudioDevicePtr(nullptr)
	{}

};

struct FAudioPluginSourceInputData
{
	// The index of the source voice. Guaranteed to be between 0 and the max number of sources rendered.
	int32 SourceId;

	// The ID of the audio component associated with the wave instance.
	uint64 AudioComponentId;

	// The audio input buffer
	Audio::FAlignedFloatBuffer* AudioBuffer;

	// Number of channels of the source audio buffer.
	int32 NumChannels;

	// The listener orientation.
	FQuat ListenerOrientation;

	// Spatialization parameters.
	const FSpatializationParams* SpatializationParams;
};

struct FAudioPluginSourceOutputData
{
	// The audio output buffer
	Audio::FAlignedFloatBuffer AudioBuffer;
};

/** This is a class which should be overridden to provide users with settings to use for individual sounds */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class USpatializationPluginSourceSettingsBase : public UObject
{
	GENERATED_BODY()
};

/************************************************************************/
/* IAudioPluginFactory                                             */
/* This interface is inherited by spatialization, reverb and occlusion  */
/* plugins to describe specifics of a plugin such as platform support,  */
/* and display names.                                                   */
/************************************************************************/
class IAudioPluginFactory
{
public:
	/*
	* Returns human-readable string representing the display name of this plugin.
	* This is the name that will be used in settings and .ini files.
	* If multiple IAudioPlugin implementations are found that return identical strings here,
	* The first one of these loaded will be used.
	*
	* @return FString of the display name of this plugin.
	*/
	virtual FString GetDisplayName()
	{
		static FString DisplayName = FString(TEXT("Generic Audio Plugin"));
		return DisplayName;
	}

	/*
	* Returns whether this plugin supports use on the specified platform.
	* @param Platform an enumerated platform (i.e. Windows, Playstation4, etc.)
	* @return true if this plugin supports use on Platform, false otherwise.
	*/
	virtual bool SupportsPlatform(const FString& PlatformName) = 0;

	/*
	* Returns whether this plugin sends audio to an external renderer.
	* if this returns true, the audio engine will not mix the result of the audio process callback
	* from the plugin into the audio output.
	*
	* @return true only if the plugin will handle sending audio to the DAC itself.
	*/
	virtual bool IsExternalSend()
	{
		return false;
	}

	/*
	*  @return true if the plugin returns from its external submix to a submix in the plugin.
	*/
	virtual bool ReturnsToSubmixGraph() const
	{
		return false;
	}
};

/************************************************************************/
/* IAudioSpatializationFactory                                          */
/* Implement this modular feature to make your Spatialization plugin */
/* visible to the engine.                                               */
/************************************************************************/
class IAudioSpatializationFactory : public IAudioPluginFactory, public IModularFeature
{
public:
	/** Virtual destructor */
	virtual ~IAudioSpatializationFactory()
	{
	}

	// IModularFeature
	static FName GetModularFeatureName()
	{
		static FName AudioExtFeatureName = FName(TEXT("AudioSpatializationPlugin"));
		return AudioExtFeatureName;
	}

	/* Begin IAudioPluginWithMetadata implementation */
	virtual FString GetDisplayName() override
	{
		static FString DisplayName = FString(TEXT("Generic Audio Spatialization Plugin"));
		return DisplayName;
	}
	/* End IAudioPluginWithMetadata implementation */

	/**
	* @return the max amount of channels your plugin supports. For example, override this to
	*         return 2 to support spatializing mono and stereo sources.
	*/
	virtual int32 GetMaxSupportedChannels()
	{
		return 1;
	}

	/**
	* @return a new instance of your spatialization plugin, owned by a shared pointer.
	*/
	virtual TAudioSpatializationPtr CreateNewSpatializationPlugin(FAudioDevice* OwningDevice) = 0;

	/** 
	* @return the UClass type of your settings for spatialization. This allows us to only pass in user settings for your plugin.
	*/
	virtual UClass* GetCustomSpatializationSettingsClass() const
	{
		return nullptr;
	}
};

/**
* IAudioSpatialization
*
* This class represents instances of a plugin that will process spatialization for a stream of audio.
* Currently used to process a mono-stream through an HRTF spatialization algorithm into a stereo stream.
* This algorithm contains an audio effect assigned to every VoiceId (playing sound instance). It assumes
* the effect is updated in the audio engine update loop with new position information.
*
*/
class IAudioSpatialization 
{
public:
	/** Virtual destructor */
	virtual ~IAudioSpatialization()
	{
	}

	/**
	* Shuts down the audio plugin.
	*
	*/
	virtual void Shutdown()
	{
	}

	virtual void OnDeviceShutdown(FAudioDevice* AudioDevice)
	{
	}

	/** DEPRECATED: sets the spatialization effect parameters. */
	virtual void SetSpatializationParameters(uint32 SourceId, const FSpatializationParams& Params)
	{
	}

	/** DEPRECATED: Gets the spatialization effect parameters. */
	virtual void GetSpatializationParameters(uint32 SourceId, FSpatializationParams& OutParams)
	{
	}
	
	/** DEPRECATED: Initializes the spatialization effect with the given buffer length. */
	virtual void InitializeSpatializationEffect(uint32 BufferLength)
	{
	}

	/** DEPRECATED: Uses the given HRTF algorithm to spatialize a mono audio stream. */
	virtual void ProcessSpatializationForVoice(uint32 SourceId, float* InSamples, float* OutSamples, const FVector& Position)
	{
	}

	/** DEPRECATED: Uses the given HRTF algorithm to spatialize a mono audio stream, assumes the parameters have already been set before processing. */
	virtual void ProcessSpatializationForVoice(uint32 SourceId, float* InSamples, float* OutSamples)
	{
	}

	/** Called when a source is assigned to a voice. */
	virtual void OnInitSource(const uint32 SourceId, const FName& AudioComponentUserId, USpatializationPluginSourceSettingsBase* InSettings)
	{
	}

	virtual void OnInitSource(const uint32 SourceId, const FName& AudioComponentUserId, const uint32 NumChannels, USpatializationPluginSourceSettingsBase* InSettings)
	{
		OnInitSource(SourceId, AudioComponentUserId, InSettings);
	}

	/** Called when a source is done playing and is released. */
	virtual void OnReleaseSource(const uint32 SourceId)
	{
	}

	/** Processes audio with the given input and output data structs.*/
	virtual void ProcessAudio(const FAudioPluginSourceInputData& InputData, FAudioPluginSourceOutputData& OutputData)
	{
	}

	/** Called when all sources have finished processing. */
	virtual void OnAllSourcesProcessed()
	{
	}

	/** Returns whether or not the spatialization effect has been initialized */
	virtual bool IsSpatializationEffectInitialized() const
	{
		return false;
	}

	/** Initializes the spatialization plugin with the given buffer length. */
	virtual void Initialize(const FAudioPluginInitializationParams InitializationParams)
	{
	}

	/** Creates an audio spatialization effect. */
	virtual bool CreateSpatializationEffect(uint32 SourceId)
	{
		return true;
	}

	/**	Returns the spatialization effect for the given voice id. */
	virtual void* GetSpatializationEffect(uint32 SourceId)
	{
		return nullptr;
	}
};


/** This is a class which should be overridden to provide users with settings to use for individual sounds */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class USourceDataOverridePluginSourceSettingsBase : public UObject
{
	GENERATED_BODY()
};

/************************************************************************/
/* IAudioSourceDataOverrideFactory										*/
/* Implement this modular feature to make your SourceDataOverride plugin*/
/* visible to the engine.                                               */
/************************************************************************/
class IAudioSourceDataOverrideFactory : public IAudioPluginFactory, public IModularFeature
{
public:
	/** Virtual destructor */
	virtual ~IAudioSourceDataOverrideFactory()
	{
	}

	// IModularFeature
	static FName GetModularFeatureName()
	{
		static FName AudioExtFeatureName = FName(TEXT("AudioSourceDataOverridePlugin"));
		return AudioExtFeatureName;
	}

	/* Begin IAudioPluginWithMetadata implementation */
	virtual FString GetDisplayName() override
	{
		static FString DisplayName = FString(TEXT("Generic Audio Source Data Override Plugin"));
		return DisplayName;
	}
	/* End IAudioPluginWithMetadata implementation */

		/**
	* @return the UClass type of your settings for source data overrides. This allows us to only pass in user settings for your plugin.
	*/
	virtual UClass* GetCustomSourceDataOverrideSettingsClass() const
	{
		return nullptr;
	}

	/**
	* @return a new instance of your source data override plugin, owned by a shared pointer.
	*/
	virtual TAudioSourceDataOverridePtr CreateNewSourceDataOverridePlugin(FAudioDevice* OwningDevice) = 0;
};


/** Interface to allow a plugin to override a sound's actual position and simulate propagation (e.g. traversal around corners, etc). */
class IAudioSourceDataOverride
{
public:
	/** Virtual destructor */
	virtual ~IAudioSourceDataOverride()
	{
	}

	/** Initializes the source data override plugin with the given buffer length. */
	virtual void Initialize(const FAudioPluginInitializationParams InitializationParams)
	{
	}

	/** Called when a source is assigned to a voice. */
	virtual void OnInitSource(const uint32 SourceId, const FName& AudioComponentUserId, USourceDataOverridePluginSourceSettingsBase* InSettings)
	{
	}

	/** Called when a source is done playing and is released. */
	virtual void OnReleaseSource(const uint32 SourceId)
	{
	}

	/** Allows this plugin to override any source data. Called per audio source before any other parameters are updated on sound sources. */
	virtual void GetSourceDataOverrides(const uint32 SourceId, const FTransform& InListenerTransform, FWaveInstance* InOutWaveInstance)
	{
	}

	/** Called when all sources have finished processing. */
	virtual void OnAllSourcesProcessed()
	{
	}
};

/** This is a class which should be overridden to provide users with settings to use for individual sounds */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class UOcclusionPluginSourceSettingsBase : public UObject
{
	GENERATED_BODY()
};

/************************************************************************/
/* IAudioOcclusionFactory                                               */
/*                                                                      */
/************************************************************************/
class IAudioOcclusionFactory : public IAudioPluginFactory, public IModularFeature
{
public:
	/** Virtual destructor */
	virtual ~IAudioOcclusionFactory()
	{
	}

	// IModularFeature
	static FName GetModularFeatureName()
	{
		static FName AudioExtFeatureName = FName(TEXT("AudioOcclusionPlugin"));
		return AudioExtFeatureName;
	}

	/* Begin IAudioPluginWithMetadata implementation */
	virtual FString GetDisplayName() override
	{
		static FString DisplayName = FString(TEXT("Generic Audio Occlusion Plugin"));
		return DisplayName;
	}
	/* End IAudioPluginWithMetadata implementation */

	virtual TAudioOcclusionPtr CreateNewOcclusionPlugin(FAudioDevice* OwningDevice) = 0;

	/**
	* @return the UClass type of your settings for occlusion. This allows us to only pass in user settings for your plugin.
	*/
	virtual UClass* GetCustomOcclusionSettingsClass() const
	{
		return nullptr;
	}
};

class IAudioOcclusion
{
public:
	/** Virtual destructor */
	virtual ~IAudioOcclusion()
	{
	}

	/** Initialize the occlusion plugin with the same rate and number of sources. */
	virtual void Initialize(const FAudioPluginInitializationParams InitializationParams)
	{
	}

	/**
	* Shuts down the audio plugin.
	*
	*/
	virtual void Shutdown()
	{
	}

	/** Called when a source is assigned to a voice. */
	virtual void OnInitSource(const uint32 SourceId, const FName& AudioComponentUserId, const uint32 NumChannels, UOcclusionPluginSourceSettingsBase* InSettings)
	{
	}

	/** Called when a source is done playing and is released. */
	virtual void OnReleaseSource(const uint32 SourceId)
	{
	}

	/** Processes audio with the given input and output data structs.*/
	virtual void ProcessAudio(const FAudioPluginSourceInputData& InputData, FAudioPluginSourceOutputData& OutputData)
	{
	}
};

/************************************************************************/
/* IAudioModulationFactory                                              */
/*                                                                      */
/************************************************************************/
class IAudioModulationFactory : public IModularFeature
{
public:
	/** Virtual destructor */
	virtual ~IAudioModulationFactory()
	{
	}

	// IModularFeature
	static FName GetModularFeatureName()
	{
		static FName AudioExtFeatureName = FName(TEXT("AudioModulationPlugin"));
		return AudioExtFeatureName;
	}

	virtual const FName& GetDisplayName() const = 0;

	virtual TAudioModulationPtr CreateNewModulationPlugin(FAudioDevice* OwningDevice) = 0;

	/**
	* @return the UClass type of your settings for modulation. This allows us to only pass in user settings for your plugin.
	*/
	virtual UClass* GetCustomModulationSettingsClass() const
	{
		return nullptr;
	}
};


/** This is a class which should be overridden to provide users with settings to use for individual sounds */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class UReverbPluginSourceSettingsBase : public UObject
{
	GENERATED_BODY()
};
 
class IAudioReverbFactory : public IAudioPluginFactory, public IModularFeature
{
public:
	/** Virtual destructor */
	virtual ~IAudioReverbFactory()
	{
	}

	// IModularFeature
	static FName GetModularFeatureName()
	{
		static FName AudioExtFeatureName = FName(TEXT("AudioReverbPlugin"));
		return AudioExtFeatureName;
	}

	/* Begin IAudioPluginWithMetadata implementation */
	virtual FString GetDisplayName() override
	{
		static FString DisplayName = FString(TEXT("Generic Audio Reverb Plugin"));
		return DisplayName;
	}
	/* End IAudioPluginWithMetadata implementation */

	virtual TAudioReverbPtr CreateNewReverbPlugin(FAudioDevice* OwningDevice) = 0;

	/**
	* @return the UClass type of your settings for reverb. This allows us to only pass in user settings for your plugin.
	*/
	virtual UClass* GetCustomReverbSettingsClass() const
	{
		return nullptr;
	}
};

class IAudioReverb
{
public:
	/** Virtual destructor */
	virtual ~IAudioReverb()
	{
	}

	/** Initialize the reverb plugin with the same rate and number of sources. */
	virtual void Initialize(const FAudioPluginInitializationParams InitializationParams)
	{
	}

	/**
	* Shuts down the audio plugin.
	*
	*/
	virtual void Shutdown()
	{
	}

	virtual void OnDeviceShutdown(FAudioDevice* AudioDevice)
	{
	}

	/** Called when a source is assigned to a voice. */
	virtual void OnInitSource(const uint32 SourceId, const FName& AudioComponentUserId, const uint32 NumChannels, UReverbPluginSourceSettingsBase* InSettings) = 0;

	/** Called when a source is done playing and is released. */
	virtual void OnReleaseSource(const uint32 SourceId) = 0;

	/** Returns the plugin-managed effect submix instance */
	virtual FSoundEffectSubmixPtr GetEffectSubmix() = 0;

	virtual USoundSubmix* LoadSubmix()
	{
		return GetSubmix();
	}

	/** Returns the plugin-managed effect submix */
	virtual USoundSubmix* GetSubmix() = 0;

	/** Processes audio with the given input and output data structs.*/
	virtual void ProcessSourceAudio(const FAudioPluginSourceInputData& InputData, FAudioPluginSourceOutputData& OutputData)
	{
	}
};

/************************************************************************/
/* IAudioPluginListener                                                 */
/* Implementations of this interface can receive updates about the      */
/* audio listener's position in the game world, as well as other data.  */
/* to use this, register a ListenerObserver to an audio device using    */
/* FAudioDevice::RegisterPluginListener().                              */
/************************************************************************/
class IAudioPluginListener
{
public:
	virtual ~IAudioPluginListener()
	{
	}

	virtual void OnDeviceShutdown(FAudioDevice* AudioDevice)
	{
	}

	//This function is called when a game world initializes a listener with an audio device this
	//IAudioPluginListener is registered to. Please note that it is possible to miss this event
	//if you register this IAudioPluginListener after the listener is initialized.
	virtual void OnListenerInitialize(FAudioDevice* AudioDevice, UWorld* ListenerWorld)
	{
	}

	// This is overridable for any actions a plugin manager may need to do on the game thread.
	virtual void OnTick(UWorld* InWorld, const int32 ViewportIndex, const FTransform& ListenerTransform, const float InDeltaSeconds)
	{
	}

	// This is overridable for any actions a plugin manager may need to do on a level change.
	virtual void OnWorldChanged(FAudioDevice* AudioDevice, UWorld* InWorld)
	{
	}

	// Called when the listener is updated on the given audio device.
	virtual void OnListenerUpdated(FAudioDevice* AudioDevice, const int32 ViewportIndex, const FTransform& ListenerTransform, const float InDeltaSeconds)
	{
	}

	//Called when the listener is shutdown.
	virtual void OnListenerShutdown(FAudioDevice* AudioDevice)
	{
	}
};

===============================


=== IAudioModulation.cpp ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.
#include "IAudioModulation.h"

#include "Containers/Map.h"
#include "UObject/Object.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(IAudioModulation)


namespace Audio
{
	namespace ModulationPrivate
	{
		static std::atomic<FModulatorHandleId> NextHandleId = INDEX_NONE;
	}

	namespace ModulationInterfacePrivate
	{
		class FModulationParameterRegistry
		{
			TMap<FName, FModulationParameter> Values;

			mutable FCriticalSection ThreadSafeValueAccessor;

		public:
			bool IsRegistered(FName InName) const
			{
				FScopeLock Lock(&ThreadSafeValueAccessor);
				return Values.Contains(InName);
			}

			void Register(FName InName, FModulationParameter&& InParameter)
			{
				FScopeLock Lock(&ThreadSafeValueAccessor);
				if (FModulationParameter* Value = Values.Find(InName))
				{
					*Value = MoveTemp(InParameter);
				}
				else
				{
					Values.Add(InName, MoveTemp(InParameter));
				}
			}

			bool Unregister(FName InName)
			{
				FScopeLock Lock(&ThreadSafeValueAccessor);
				return Values.Remove(InName) > 0;
			}

			void UnregisterAll()
			{
				FScopeLock Lock(&ThreadSafeValueAccessor);
				Values.Reset();
			}

			const FModulationParameter& Get(FName InName) const
			{
				FScopeLock Lock(&ThreadSafeValueAccessor);

				static const FModulationParameter DefaultParameter { };
				if (const FModulationParameter* Param = Values.Find(InName))
				{
					return *Param;
				}

				return DefaultParameter;
			}
		} ParameterRegistry;
	}

	FModulatorHandleId CreateModulatorHandleId()
	{
		return ++ModulationPrivate::NextHandleId;
	}

	FModulationParameter::FModulationParameter()
		: MixFunction(GetDefaultMixFunction())
		, UnitFunction(GetDefaultUnitConversionFunction())
		, NormalizedFunction(GetDefaultNormalizedConversionFunction())
	{
	}

	FModulationParameter::FModulationParameter(FModulationParameter&& InParam)
		: ParameterName(MoveTemp(InParam.ParameterName))
		, DefaultValue(InParam.DefaultValue)
		, MinValue(InParam.MinValue)
		, MaxValue(InParam.MaxValue)
		, bRequiresConversion(InParam.bRequiresConversion)
	#if WITH_EDITORONLY_DATA
		, UnitDisplayName(MoveTemp(InParam.UnitDisplayName))
		, ClassName(MoveTemp(InParam.ClassName))
	#endif // WITH_EDITORONLY_DATA
		, MixFunction(MoveTemp(InParam.MixFunction))
		, UnitFunction(MoveTemp(InParam.UnitFunction))
		, NormalizedFunction(MoveTemp(InParam.NormalizedFunction))
	{
	}

	FModulationParameter::FModulationParameter(const FModulationParameter& InParam)
		: ParameterName(InParam.ParameterName)
		, DefaultValue(InParam.DefaultValue)
		, MinValue(InParam.MinValue)
		, MaxValue(InParam.MaxValue)
		, bRequiresConversion(InParam.bRequiresConversion)
#if WITH_EDITORONLY_DATA
		, UnitDisplayName(InParam.UnitDisplayName)
		, ClassName(InParam.ClassName)
#endif // WITH_EDITORONLY_DATA
		, MixFunction(InParam.MixFunction)
		, UnitFunction(InParam.UnitFunction)
		, NormalizedFunction(InParam.NormalizedFunction)
	{
	}

	FModulationParameter& FModulationParameter::operator=(const FModulationParameter& InParam)
	{
		ParameterName = InParam.ParameterName;
		DefaultValue = InParam.DefaultValue;
		MinValue = InParam.MinValue;
		MaxValue = InParam.MaxValue;
		bRequiresConversion = InParam.bRequiresConversion;

#if WITH_EDITORONLY_DATA
		UnitDisplayName = InParam.UnitDisplayName;
		ClassName = InParam.ClassName;
#endif // WITH_EDITORONLY_DATA

		MixFunction = InParam.MixFunction;
		UnitFunction = InParam.UnitFunction;
		NormalizedFunction = InParam.NormalizedFunction;

		return *this;
	}

	FModulationParameter& FModulationParameter::operator=(FModulationParameter&& InParam)
	{
		ParameterName = MoveTemp(InParam.ParameterName);
		DefaultValue = InParam.DefaultValue;
		MinValue = InParam.MinValue;
		MaxValue = InParam.MaxValue;
		bRequiresConversion = InParam.bRequiresConversion;

	#if WITH_EDITORONLY_DATA
		UnitDisplayName = MoveTemp(InParam.UnitDisplayName);
		ClassName = MoveTemp(InParam.ClassName);
	#endif // WITH_EDITORONLY_DATA

		MixFunction = MoveTemp(InParam.MixFunction);
		UnitFunction = MoveTemp(InParam.UnitFunction);
		NormalizedFunction = MoveTemp(InParam.NormalizedFunction);

		return *this;
	}

	const FModulationMixFunction& FModulationParameter::GetDefaultMixFunction()
	{
		static const FModulationMixFunction DefaultMixFunction = [](float& InOutValueA, float InValueB)
		{
			InOutValueA *= InValueB;
		};

		return DefaultMixFunction;
	}

	const FModulationUnitConversionFunction& FModulationParameter::GetDefaultUnitConversionFunction()
	{
		static const FModulationUnitConversionFunction ConversionFunction = [](float& InOutValue)
		{
		};

		return ConversionFunction;
	};

	const FModulationNormalizedConversionFunction& FModulationParameter::GetDefaultNormalizedConversionFunction()
	{
		static const FModulationNormalizedConversionFunction ConversionFunction = [](float& InOutValue)
		{
		};

		return ConversionFunction;
	};

	void RegisterModulationParameter(FName InName, FModulationParameter&& InParameter)
	{
		using namespace ModulationInterfacePrivate;
		ParameterRegistry.Register(InName, MoveTemp(InParameter));
	}

	bool UnregisterModulationParameter(FName InName)
	{
		using namespace ModulationInterfacePrivate;
		return ParameterRegistry.Unregister(InName);
	}

	void UnregisterAllModulationParameters()
	{
		using namespace ModulationInterfacePrivate;
		ParameterRegistry.UnregisterAll();
	}

	bool IsModulationParameterRegistered(FName InName)
	{
		using namespace ModulationInterfacePrivate;
		return ParameterRegistry.IsRegistered(InName);
	}

	const FModulationParameter& GetModulationParameter(FName InName)
	{
		using namespace ModulationInterfacePrivate;
		return ParameterRegistry.Get(InName);
	}

	FModulatorHandle::FModulatorHandle(Audio::FModulationParameter&& InParameter)
		: Parameter(InParameter)
		, HandleId(CreateModulatorHandleId())
	{
	}

	FModulatorHandle::FModulatorHandle(IAudioModulationManager& InModulation, const Audio::IModulatorSettings& InModulatorSettings, Audio::FModulationParameter&& InParameter)
		: Parameter(MoveTemp(InParameter))
		, HandleId(CreateModulatorHandleId())
		, Modulation(InModulation.AsShared())
	{
		ModulatorTypeId = InModulatorSettings.Register(HandleId, InModulation);
		if (ModulatorTypeId != INDEX_NONE)
		{
			ModulatorId = InModulatorSettings.GetModulatorId();
		}
	}

	FModulatorHandle::FModulatorHandle(const FModulatorHandle& InOther)
	{
		HandleId = CreateModulatorHandleId();

		if (TSharedPtr<IAudioModulationManager> ModPtr = InOther.Modulation.Pin())
		{
			ModPtr->RegisterModulator(HandleId, InOther.ModulatorId);
			Parameter = InOther.Parameter;
			ModulatorId = InOther.ModulatorId;
			ModulatorTypeId = InOther.ModulatorTypeId;
			Modulation = InOther.Modulation;
		}
	}

	FModulatorHandle::FModulatorHandle(FModulatorHandle&& InOther)
		: Parameter(MoveTemp(InOther.Parameter))
		, HandleId(InOther.HandleId)
		, ModulatorTypeId(InOther.ModulatorTypeId)
		, ModulatorId(InOther.ModulatorId)
		, Modulation(InOther.Modulation)
	{
		// Move does not register as presumed already activated or
		// copying default handle, which is invalid. Removes data
		// from handle being moved to avoid double deactivation on
		// destruction.
		InOther.Parameter = FModulationParameter();
		InOther.HandleId = INDEX_NONE;
		InOther.ModulatorTypeId = INDEX_NONE;
		InOther.ModulatorId = INDEX_NONE;
		InOther.Modulation.Reset();
	}

	FModulatorHandle::~FModulatorHandle()
	{
		if (TSharedPtr<IAudioModulationManager> ModPtr = Modulation.Pin())
		{
			ModPtr->UnregisterModulator(*this);
		}
	}

	FModulatorHandle& FModulatorHandle::operator=(const FModulatorHandle& InOther)
	{
		Parameter = InOther.Parameter;

		if (TSharedPtr<IAudioModulationManager> ModPtr = InOther.Modulation.Pin())
		{
			HandleId = CreateModulatorHandleId();
			ModulatorId = InOther.ModulatorId;
			ModulatorTypeId = InOther.ModulatorTypeId;
			Modulation = InOther.Modulation;

			if (ModulatorId != INDEX_NONE)
			{
				ModPtr->RegisterModulator(HandleId, ModulatorId);
			}
		}
		else
		{
			HandleId = INDEX_NONE;
			ModulatorId = INDEX_NONE;
			ModulatorTypeId = INDEX_NONE;
			Modulation.Reset();
		}

		return *this;
	}

	FModulatorHandle& FModulatorHandle::operator=(FModulatorHandle&& InOther)
	{
		if (HandleId != INDEX_NONE)
		{
			if (TSharedPtr<IAudioModulationManager> ModPtr = Modulation.Pin())
			{
				ModPtr->UnregisterModulator(*this);
			}
		}

		// Move does not activate as presumed already activated or
		// copying default handle, which is invalid. Removes data
		// from handle being moved to avoid double deactivation on
		// destruction.
		Parameter = MoveTemp(InOther.Parameter);
		HandleId = InOther.HandleId;
		ModulatorId = InOther.ModulatorId;
		ModulatorTypeId = InOther.ModulatorTypeId;
		Modulation = InOther.Modulation;

		InOther.Parameter = FModulationParameter();
		InOther.HandleId = INDEX_NONE;
		InOther.ModulatorId = INDEX_NONE;
		InOther.ModulatorTypeId = INDEX_NONE;
		InOther.Modulation.Reset();

		return *this;
	}

	FModulatorId FModulatorHandle::GetModulatorId() const
	{
		return ModulatorId;
	}

	const FModulationParameter& FModulatorHandle::GetParameter() const
	{
		return Parameter;
	}

	FModulatorTypeId FModulatorHandle::GetTypeId() const
	{
		return ModulatorTypeId;
	}

	uint32 FModulatorHandle::GetHandleId() const
	{
		return HandleId;
	}

	bool FModulatorHandle::GetValue(float& OutValue) const
	{
		check(IsValid());

		OutValue = 1.0f;

		if (TSharedPtr<IAudioModulationManager> ModPtr = Modulation.Pin())
		{
			return ModPtr->GetModulatorValue(*this, OutValue);
		}

		return false;
	}

	bool FModulatorHandle::GetValueThreadSafe(float& OutValue) const
	{
		check(IsValid());

		OutValue = 1.0f;
		if (TSharedPtr<IAudioModulationManager> ModPtr = Modulation.Pin())
		{
			return ModPtr->GetModulatorValueThreadSafe(*this, OutValue);
		}

		return false;
	}

	bool FModulatorHandle::IsValid() const
	{
		return ModulatorId != INDEX_NONE;
	}
} // namespace Audio

const Audio::FModulationParameter& USoundModulatorBase::GetOutputParameter() const
{
	return Audio::GetModulationParameter({ });
}

TSharedPtr<Audio::IProxyData> USoundModulatorBase::CreateProxyData(const Audio::FProxyDataInitParams& InitParams)
{
	// This should never be hit as all instances of modulators should implement their own version of the proxy data interface.
	checkNoEntry();
	return TSharedPtr<Audio::IProxyData>();
}

TUniquePtr<Audio::IModulatorSettings> USoundModulatorBase::CreateProxySettings() const
{
	checkNoEntry();
	return TUniquePtr<Audio::IModulatorSettings>();
}


============================


=== IAudioModulation.h ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "AudioDefines.h"
#include "CoreTypes.h"
#include "DSP/BufferVectorOperations.h"
#include "IAudioExtensionPlugin.h"
#include "IAudioProxyInitializer.h"
#include "Internationalization/Text.h"
#include "Math/MathFwd.h"
#include "Math/Rotator.h"
#include "Misc/AssertionMacros.h"
#include "Templates/Function.h"
#include "Templates/SharedPointer.h"
#include "Templates/UniquePtr.h"
#include "Templates/UnrealTemplate.h"
#include "UObject/NameTypes.h"
#include "UObject/Object.h"
#include "UObject/ObjectMacros.h"
#include "UObject/UObjectGlobals.h"

#include "IAudioModulation.generated.h"

// Forward Declarations
class IAudioModulationManager;
class ISoundModulatable;
class UObject;
class USoundModulatorBase;
struct FAudioPluginInitializationParams;
struct FAudioPluginSourceInputData;
struct FAudioPluginSourceOutputData;

#if !UE_BUILD_SHIPPING
class FCanvas;
class FCommonViewportClient;
class FViewport;
class UFont;
#endif // !UE_BUILD_SHIPPING

namespace Audio
{
	using FModulatorId = uint32;
	using FModulatorTypeId = uint32;
	using FModulatorHandleId = uint32;

	using FModulationUnitConversionFunction = TFunction<void(float& /* OutValueNormalizedToUnit */)>;
	using FModulationNormalizedConversionFunction = TFunction<void(float& /* OutValueUnitToNormalized */)>;
	using FModulationMixFunction = TFunction<void(float& /* OutNormalizedA */, float /* InNormalizedB */)>;


	struct FModulationParameter
	{
		AUDIOEXTENSIONS_API FModulationParameter();
		AUDIOEXTENSIONS_API FModulationParameter(const FModulationParameter& InParam);
		AUDIOEXTENSIONS_API FModulationParameter(FModulationParameter&& InParam);

		AUDIOEXTENSIONS_API FModulationParameter& operator=(FModulationParameter&& InParam);
		AUDIOEXTENSIONS_API FModulationParameter& operator=(const FModulationParameter& InParam);

		FName ParameterName;

		// Default value of parameter in unit space
		float DefaultValue = 1.0f;

		// Default minimum value of parameter in unit space
		float MinValue = 0.0f;

		// Default minimum value of parameter in unit space
		float MaxValue = 1.0f;

		// Whether or not unit conversion is required
		bool bRequiresConversion = false;

		uint32 TypeHash = INDEX_NONE;

#if WITH_EDITORONLY_DATA
		FText UnitDisplayName;

		FName ClassName;
#endif // WITH_EDITORONLY_DATA

		// Function used to mix normalized values together.
		FModulationMixFunction MixFunction;

		// Function used to convert value buffer from normalized, unitless space [0.0f, 1.0f] to unit space.
		FModulationUnitConversionFunction UnitFunction;

		// Function used to convert value buffer from unit space to normalized, unitless [0.0f, 1.0f] space.
		FModulationNormalizedConversionFunction NormalizedFunction;

		static AUDIOEXTENSIONS_API const FModulationMixFunction& GetDefaultMixFunction();
		static AUDIOEXTENSIONS_API const FModulationUnitConversionFunction& GetDefaultUnitConversionFunction();
		static AUDIOEXTENSIONS_API const FModulationNormalizedConversionFunction& GetDefaultNormalizedConversionFunction();

		friend FORCEINLINE uint32 GetTypeHash(const FModulationParameter& InModulationParameter)
		{
			return InModulationParameter.TypeHash;
		}
	};

	AUDIOEXTENSIONS_API bool IsModulationParameterRegistered(FName InName);
	AUDIOEXTENSIONS_API void RegisterModulationParameter(FName InName, FModulationParameter&& InParameter);
	AUDIOEXTENSIONS_API bool UnregisterModulationParameter(FName InName);
	AUDIOEXTENSIONS_API void UnregisterAllModulationParameters();
	AUDIOEXTENSIONS_API const FModulationParameter& GetModulationParameter(FName InName);

	/** Interface for cached off Modulator UObject data used as default settings to
	  * be converted to instanced proxy data per AudioDevice on the AudioRenderThread.
	  * If proxy is already active, implementation is expected to ignore register call
	  * and return existing modulator proxy's type Id & set parameter accordingly.
	  */
	class IModulatorSettings
	{
	public:
		virtual ~IModulatorSettings() = default;
		virtual TUniquePtr<IModulatorSettings> Clone() const = 0;
		virtual FModulatorId GetModulatorId() const = 0;
		virtual const Audio::FModulationParameter& GetOutputParameter() const = 0;
		virtual Audio::FModulatorTypeId Register(
			Audio::FModulatorHandleId HandleId,
			IAudioModulationManager& InModulation) const = 0;
	};

	/** Handle to a modulator which interacts with the modulation API to manage lifetime
	  * of modulator proxy objects internal to modulation plugin implementation.
	  */
	struct FModulatorHandle
	{
		FModulatorHandle() = default;
		AUDIOEXTENSIONS_API FModulatorHandle(Audio::FModulationParameter&& InParameter);
		AUDIOEXTENSIONS_API FModulatorHandle(IAudioModulationManager& InModulation, const Audio::IModulatorSettings& InModulatorSettings, Audio::FModulationParameter&& InParameter);
		AUDIOEXTENSIONS_API FModulatorHandle(const FModulatorHandle& InOther);
		AUDIOEXTENSIONS_API FModulatorHandle(FModulatorHandle&& InOther);

		AUDIOEXTENSIONS_API ~FModulatorHandle();

		AUDIOEXTENSIONS_API FModulatorHandle& operator=(const FModulatorHandle& InOther);
		AUDIOEXTENSIONS_API FModulatorHandle& operator=(FModulatorHandle&& InOther);

		AUDIOEXTENSIONS_API FModulatorId GetModulatorId() const;
		AUDIOEXTENSIONS_API const FModulationParameter& GetParameter() const;
		AUDIOEXTENSIONS_API FModulatorTypeId GetTypeId() const;
		AUDIOEXTENSIONS_API FModulatorHandleId GetHandleId() const;
		AUDIOEXTENSIONS_API bool GetValue(float& OutValue) const;
		AUDIOEXTENSIONS_API bool GetValueThreadSafe(float& OutValue) const;
		AUDIOEXTENSIONS_API bool IsValid() const;

		friend FORCEINLINE uint32 GetTypeHash(const FModulatorHandle& InModulatorHandle)
		{
			return HashCombineFast(InModulatorHandle.HandleId, InModulatorHandle.ModulatorId);
		}

		FORCEINLINE bool operator==(const FModulatorHandle& Other) const
		{
			return HandleId == Other.HandleId && ModulatorId == Other.ModulatorId;
		}

		FORCEINLINE bool operator!=(const FModulatorHandle& Other) const
		{
			return !(*this == Other);
		}

	private:
		FModulationParameter Parameter;
		FModulatorHandleId HandleId = INDEX_NONE;
		FModulatorTypeId ModulatorTypeId = INDEX_NONE;
		FModulatorId ModulatorId = INDEX_NONE;
		TWeakPtr<IAudioModulationManager> Modulation;
	};
} // namespace Audio

class IAudioModulationManager : public TSharedFromThis<IAudioModulationManager>
{
public:
	/** Virtual destructor */
	virtual ~IAudioModulationManager() = default;

	/** Initialize the modulation plugin with the same rate and number of sources */
	virtual void Initialize(const FAudioPluginInitializationParams& InitializationParams) = 0;

	virtual void OnAuditionEnd() = 0;

#if !UE_BUILD_SHIPPING
	/** Request to post help from active plugin (non-shipping builds only) */
	virtual bool OnPostHelp(FCommonViewportClient* ViewportClient, const TCHAR* Stream) = 0; 

	/** Render stats pertaining to modulation (non-shipping builds only) */
	virtual int32 OnRenderStat(FViewport* Viewport, FCanvas* Canvas, int32 X, int32 Y, const UFont& Font, const FVector* ViewLocation, const FRotator* ViewRotation) = 0;

	/** Toggle showing render stats pertaining to modulation (non-shipping builds only) */
	virtual bool OnToggleStat(FCommonViewportClient* ViewportClient, const TCHAR* Stream) = 0;
#endif //!UE_BUILD_SHIPPING

	/** Processes all modulators Run on the audio render thread prior to processing audio */
	virtual void ProcessModulators(const double InElapsed) = 0;

	/** Updates modulator definition on the AudioRender Thread with that provided by the UObject representation */
	virtual void UpdateModulator(const USoundModulatorBase& InModulator) = 0;

protected:
	virtual void RegisterModulator(uint32 InHandleId, Audio::FModulatorId InModulatorId) = 0;

	// Get the modulator value from the AudioRender Thread
	virtual bool GetModulatorValue(const Audio::FModulatorHandle& ModulatorHandle, float& OutValue) const = 0;

	// Get the modulator value from any thread.
	virtual bool GetModulatorValueThreadSafe(const Audio::FModulatorHandle& ModulatorHandle, float& OutValue) const = 0;

	virtual void UnregisterModulator(const Audio::FModulatorHandle& InHandle) = 0;

	friend Audio::FModulatorHandle;
};

/**
 * Base class for all modulators
 */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class USoundModulatorBase : public UObject, public IAudioProxyDataFactory
{
	GENERATED_BODY()

public:
	AUDIOEXTENSIONS_API virtual const Audio::FModulationParameter& GetOutputParameter() const;

	AUDIOEXTENSIONS_API virtual TSharedPtr<Audio::IProxyData> CreateProxyData(const Audio::FProxyDataInitParams& InitParams) override;

	AUDIOEXTENSIONS_API virtual TUniquePtr<Audio::IModulatorSettings> CreateProxySettings() const;
};

/** Proxy to modulator, allowing for modulator to be referenced by the Audio Render Thread independently
  * from the implementing modulation plugin (ex. for MetaSound implementation).
  */
class FSoundModulatorAssetProxy : public Audio::TProxyData<FSoundModulatorAssetProxy>, public TSharedFromThis<FSoundModulatorAssetProxy, ESPMode::ThreadSafe>
{
public:
	IMPL_AUDIOPROXY_CLASS(FSoundModulatorAssetProxy);

	FSoundModulatorAssetProxy(const FSoundModulatorAssetProxy& InAssetProxy)
		: Parameter(InAssetProxy.Parameter)
		, ModulatorSettings(InAssetProxy.ModulatorSettings.IsValid() ? InAssetProxy.ModulatorSettings->Clone() : nullptr)
	{
	}

	FSoundModulatorAssetProxy(const USoundModulatorBase& InModulatorBase)
		: Parameter(InModulatorBase.GetOutputParameter())
		, ModulatorSettings(InModulatorBase.CreateProxySettings())
	{
	}

	virtual Audio::FModulatorHandle CreateModulatorHandle(IAudioModulationManager& InModulation) const
	{
		check(ModulatorSettings.IsValid());

		Audio::FModulationParameter HandleParameter = Parameter;
		return Audio::FModulatorHandle(InModulation, *ModulatorSettings.Get(), MoveTemp(HandleParameter));
	}

	virtual Audio::FModulatorId GetModulatorId() const
	{
		check(ModulatorSettings.IsValid())
		return ModulatorSettings->GetModulatorId();
	}

protected:
	Audio::FModulationParameter Parameter;
	TUniquePtr<Audio::IModulatorSettings> ModulatorSettings;
};
using FSoundModulatorAssetProxyPtr = TSharedPtr<FSoundModulatorAssetProxy, ESPMode::ThreadSafe>;

/** Proxy to modulator, allowing for modulator to be referenced by the Audio Render Thread independently
  * from the implementing modulation plugin (ex. for MetaSound implementation).
  */
class FSoundModulationParameterAssetProxy : public Audio::TProxyData<FSoundModulationParameterAssetProxy>, public TSharedFromThis<FSoundModulationParameterAssetProxy, ESPMode::ThreadSafe>
{
public:
	IMPL_AUDIOPROXY_CLASS(FSoundModulationParameterAssetProxy);

	virtual const Audio::FModulationParameter& GetParameter() const
	{
		return Parameter;
	}

protected:
	Audio::FModulationParameter Parameter;
};
using FSoundModulationParameterAssetProxyPtr = TSharedPtr<FSoundModulationParameterAssetProxy, ESPMode::ThreadSafe>;

/** Interface to sound that is modulatable, allowing for certain specific
  * behaviors to be controlled on the sound level by the modulation system.
  */
class ISoundModulatable
{
public:
	virtual ~ISoundModulatable() = default;

	/**
	 * Gets the object definition id of the given playing sound's instance
	 */
	virtual uint32 GetObjectId() const = 0;

	/**
	 * Returns number of actively instances of sound playing (including virtualized instances)
	 */
	virtual int32 GetPlayCount() const = 0;

	/**
	 * Returns whether or not sound is an editor preview sound
	 */
	virtual bool IsPreviewSound() const = 0;

	/**
	 * Stops sound.
	 */
	virtual void Stop() = 0;
};

==========================


=== IAudioParameterInterfaceRegistry.cpp ===
============================================

// Copyright Epic Games, Inc. All Rights Reserved.
#include "IAudioParameterInterfaceRegistry.h"

#include "Algo/Transform.h"


namespace Audio
{
	namespace ParameterInterfaceRegistryPrivate
	{
		class FParameterInterfaceRegistry : public IAudioParameterInterfaceRegistry
		{
		public:
			virtual void IterateInterfaces(TFunction<void(FParameterInterfacePtr)> InFunction) const override
			{
				for (const FParameterInterfacePtr& InterfacePtr : Interfaces)
				{
					InFunction(InterfacePtr);
				}
			}

			virtual void RegisterInterface(FParameterInterfacePtr InInterface) override
			{
				Interfaces.Add(InInterface);
				if (RegistrationFunction)
				{
					RegistrationFunction(InInterface);
				}
			}

			virtual void OnRegistration(TUniqueFunction<void(FParameterInterfacePtr)>&& InFunction) override
			{
				RegistrationFunction = MoveTemp(InFunction);
			}
		};
	} // namespace ParameterInterfaceRegistryPrivate

	FParameterInterface::FParameterInterface(
		FName InName,
		const FVersion& InVersion,
		const UClass& InType
	)
		: NamePrivate(InName)
		, VersionPrivate(InVersion)
		, UClassOptions({ { InType.GetClassPathName() } })
	{
	}

	FParameterInterface::FParameterInterface(FName InName, const FVersion& InVersion)
		: NamePrivate(InName)
		, VersionPrivate(InVersion)
	{
	}

	FName FParameterInterface::GetName() const
	{
		return NamePrivate;
	}

	const FParameterInterface::FVersion& FParameterInterface::GetVersion() const
	{
		return VersionPrivate;
	}

	const UClass& FParameterInterface::GetType() const
	{
		return *UObject::StaticClass();
	}

	const TArray<FParameterInterface::FClassOptions>& FParameterInterface::GetUClassOptions() const
	{
		return UClassOptions;
	}

	const TArray<FParameterInterface::FInput>& FParameterInterface::GetInputs() const
	{
		return Inputs;
	}

	const TArray<FParameterInterface::FOutput>& FParameterInterface::GetOutputs() const
	{
		return Outputs;
	}

	const TArray<FParameterInterface::FEnvironmentVariable>& FParameterInterface::GetEnvironment() const
	{
		return Environment;
	}

	TArray<const UClass*> FParameterInterface::FindSupportedUClasses() const
	{
		TArray<const UClass*> SupportedUClasses;
		for (const FClassOptions& Options : UClassOptions)
		{
			if (const UClass* Class = FindObject<const UClass>(Options.ClassPath))
			{
				SupportedUClasses.Add(Class);
			}
		}

		return SupportedUClasses;
	}

	TUniquePtr<IAudioParameterInterfaceRegistry> IAudioParameterInterfaceRegistry::Instance;

	IAudioParameterInterfaceRegistry& IAudioParameterInterfaceRegistry::Get()
	{
		using namespace ParameterInterfaceRegistryPrivate;

		if (!Instance.IsValid())
		{
			Instance = MakeUnique<FParameterInterfaceRegistry>();
		}
		return *Instance;
	}
} // namespace Audio

============================================


=== IAudioParameterInterfaceRegistry.h ===
==========================================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "AudioParameter.h"
#include "AudioParameterControllerInterface.h"
#include "Containers/Array.h"
#include "Containers/Map.h"
#include "Containers/Set.h"
#include "HAL/Platform.h"
#include "Internationalization/Text.h"
#include "Misc/AssertionMacros.h"
#include "Templates/Function.h"
#include "Templates/SharedPointer.h"
#include "Templates/UniquePtr.h"
#include "UObject/Class.h"
#include "UObject/NameTypes.h"


namespace Audio
{
	// Forward Declarations
	class IAudioParameterInterfaceRegistry;

	// Interface for parameterizing data provided to or coming from an executable audio unit
	// (ex. Sound like a MetaSoundSource, arbitrary DSP graph like a MetaSoundPatch, etc.).
	// Can be used generically for processing either logically at a control or Game Thread
	// tick rate (ex. SoundCues), or by an underlying DSP operation via the Audio Render
	// Thread or delegated task (ex. MetaSounds, custom SoundGenerator, etc.)
	struct FParameterInterface
	{
		// Version of interface (higher numbers are more recent)
		struct FVersion
		{
			const int32 Major = 1;
			const int32 Minor = 0;
		};

		// Input of interface
		struct FInput
		{
			// Name to be displayed in editor or tools
			const FText DisplayName;

			// Description to be displayed in editor or tools
			const FText Description;

			// FName describing the type of the data.  May be
			// interpreted solely by a plugin or implementation
			// (ex. MetaSounds).  If blank, type is assumed to be
			// that described by the InitValue AudioParameter's
			// corresponding ParamType. If provided, DataType
			// must be constructible using the InitValue.
			const FName DataType;

			// Initial value of the given parameter
			const FAudioParameter InitValue;

			// Text to display in the editor or tools if the consuming
			// system of the given input parameter is not implemented (to avoid
			// passing data using the parameter system when not operated on).
			const FText RequiredText;

			// Visual sort order of the given input with respect to other inputs either
			// within the given interface or listed among other unrelated inputs.
			const int32 SortOrderIndex = 0;
		};

		// Output of interface
		struct FOutput
		{
			// Name to be displayed in editor or tools
			const FText DisplayName;

			// Description to be displayed in editor or tools
			const FText Description;

			// FName describing the type of the data.  May be
			// interpreted solely by a plugin or implementation
			// (ex. MetaSounds).  If blank, type is assumed to be
			// that described by ParamType.
			const FName DataType;

			// Name of output parameter used as a runtime identifier
			const FName ParamName;

			// Text to display in the editor or tools if the consuming
			// system of the given input parameter is not implemented (to avoid
			// passing data using the parameter system when not operated on).
			const FText RequiredText = FText();

			// Type of output parameter used as a runtime identifier if unspecified by the DataType.
			const EAudioParameterType ParamType = EAudioParameterType::None;

			// Visual sort order of the given input with respect to other outputs either
			// within the given interface or listed among other unrelated outputs.
			const int32 SortOrderIndex = 0;
		};

		// Read-only variable that cannot be modified by the sound instance,
		// and maybe shared amongst instances.
		struct FEnvironmentVariable
		{
			// Name to be displayed in editor or tools
			const FText DisplayName;

			// Description to be displayed in editor or tools
			const FText Description;

			// FName describing the type of the data.  May be
			// interpreted solely by a plugin or implementation
			// (ex. MetaSounds).  If blank, type is assumed to be
			// that described by ParamType.
			const FName DataType;

			// Name of variable used as a runtime identifier
			const FName ParamName;

			// Type of variable used as a runtime identifier if unspecified by the DataType.
			const EAudioParameterType ParamType = EAudioParameterType::None;
		};

		// Options used to restrict a corresponding UClass that interface may be applied to.
		struct FClassOptions
		{
			// Path to restricted UClass
			const FTopLevelAssetPath ClassPath;

			// Whether or not the class may be directly modifiable on an asset implementing
			// the given interface (added, removed, etc.)
			const bool bIsModifiable = true;

			// Whether or not the interface should be immediately added to the given class
			// type on creation.
			const bool bIsDefault = false;
		};

		FParameterInterface() = default;

		// Constructor used for parameter interface not limited to any particular UClass types
		AUDIOEXTENSIONS_API FParameterInterface(FName InName, const FVersion& InVersion);

		UE_DEPRECATED(5.3, "Set UClassOptions to determine what options apply for a given UClass (if any).")
		AUDIOEXTENSIONS_API FParameterInterface(FName InName, const FVersion& InVersion, const UClass& InClass);

		// Returns name of interface
		AUDIOEXTENSIONS_API FName GetName() const;

		// Returns version of interface
		AUDIOEXTENSIONS_API const FVersion& GetVersion() const;

		UE_DEPRECATED(5.3, "Use FParameterInterface::FindSupportedUClasses instead")
		AUDIOEXTENSIONS_API const UClass& GetType() const;

		AUDIOEXTENSIONS_API TArray<const UClass*> FindSupportedUClasses() const;

		// If specified, options used to restrict a corresponding UClass that interface may be
		// applied to.  If unspecified, interface is assumed to be applicable to any arbitrary UClass.
		AUDIOEXTENSIONS_API const TArray<FClassOptions>& GetUClassOptions() const;

		// Returns read-only array of inputs
		AUDIOEXTENSIONS_API const TArray<FInput>& GetInputs() const;

		// Returns read-only array of outputs
		AUDIOEXTENSIONS_API const TArray<FOutput>& GetOutputs() const;

		// Returns read-only array of environment variables
		AUDIOEXTENSIONS_API const TArray<FEnvironmentVariable>& GetEnvironment() const;

	private:
		FName NamePrivate;
		FVersion VersionPrivate;

	protected:
		TArray<FInput> Inputs;
		TArray<FOutput> Outputs;
		TArray<FEnvironmentVariable> Environment;
		TArray<FClassOptions> UClassOptions;
	};
	using FParameterInterfacePtr = TSharedPtr<FParameterInterface, ESPMode::ThreadSafe>;

	// Registry of engine-defined audio parameter interfaces, used to parameterize data provided
	// to or coming from an executable audio unit (ex. Sound like a MetaSoundSource, arbitrary DSP
	// graph like a MetaSoundPatch, etc.).
	class IAudioParameterInterfaceRegistry
	{
		static AUDIOEXTENSIONS_API TUniquePtr<IAudioParameterInterfaceRegistry> Instance;

	public:
		static AUDIOEXTENSIONS_API IAudioParameterInterfaceRegistry& Get();

		virtual ~IAudioParameterInterfaceRegistry() = default;

		// Iterate all registered interfaces
		virtual void IterateInterfaces(TFunction<void(FParameterInterfacePtr)> InFunction) const = 0;

		// Execute a given function when an interface is registered
		virtual void OnRegistration(TUniqueFunction<void(FParameterInterfacePtr)>&& InFunction) = 0;

		// Registers an interface
		virtual void RegisterInterface(FParameterInterfacePtr InInterface) = 0;

	protected:
		TSet<FParameterInterfacePtr> Interfaces;
		TUniqueFunction<void(FParameterInterfacePtr)> RegistrationFunction;
	};
} // namespace Audio

==========================================


=== IAudioParameterTransmitter.cpp ===
======================================

// Copyright Epic Games, Inc. All Rights Reserved.
#include "IAudioParameterTransmitter.h"
#include "UObject/Object.h"


namespace Audio
{
	const FName IParameterTransmitter::RouterName = "ParameterTransmitter";

	TArray<const TObjectPtr<UObject>*> ILegacyParameterTransmitter::GetReferencedObjects() const
	{
		return { };
	}

	FParameterTransmitterBase::FParameterTransmitterBase(TArray<FAudioParameter>&& InDefaultParams)
		: AudioParameters(MoveTemp(InDefaultParams))
		, bIsVirtualized(false)
	{
	}

	FParameterTransmitterBase::~FParameterTransmitterBase() = default;

	bool FParameterTransmitterBase::GetParameter(FName InName, FAudioParameter& OutValue) const
	{
		if (const FAudioParameter* Param = FAudioParameter::FindParam(AudioParameters, InName))
		{
			OutValue = *Param;
			return true;
		}

		return false;
	}

	void FParameterTransmitterBase::ResetParameters() 
	{
		AudioParameters.Reset();
	}
	
	bool FParameterTransmitterBase::Reset()
	{
		ResetParameters();
		return true;
	}

	const TArray<FAudioParameter>& FParameterTransmitterBase::GetParameters() const
	{
		return AudioParameters;
	}

	bool FParameterTransmitterBase::SetParameters(TArray<FAudioParameter>&& InParameters)
	{
		FAudioParameter::Merge(MoveTemp(InParameters), AudioParameters);
		return true;
	}

	void FParameterTransmitterBase::OnVirtualizeActiveSound()
	{ 
		bIsVirtualized = true;
		ResetParameters();
	}

	 void FParameterTransmitterBase::OnRealizeVirtualizedActiveSound(TArray<FAudioParameter>&& InParameters)
	 { 
		 bIsVirtualized = false;
		 SetParameters(MoveTemp(InParameters));
	 }
} // namespace Audio

======================================


=== IAudioParameterTransmitter.h ===
====================================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "AudioParameter.h"
#include "AudioParameterControllerInterface.h"
#include "Containers/Array.h"
#include "CoreTypes.h"
#include "IAudioProxyInitializer.h"
#include "Templates/UniquePtr.h"
#include "UObject/NameTypes.h"

// Forward Declarations
class UObject;

namespace Audio
{
	using DeviceID = uint32;

	/** Data passed to CreateParameterTransmitter. */
	struct FParameterTransmitterInitParams
	{
		// Unique ID for this audio instance.
		uint64 InstanceID = INDEX_NONE;

		// Audio sample rate.
		float SampleRate = 0.0f;

		TArray<FAudioParameter> DefaultParams;

		// Audio device ID
		DeviceID AudioDeviceID = INDEX_NONE;

	};

	// Reference collector functionality for legacy parameter system
	// (i.e. backwards compatibility with the SoundCue system). None of this
	// should be used by future assets supporting parameters (ex. MetaSounds)
	// as object pointers within parameters should NOT be cached on threads
	// other than the GameThread, utilizing a proxy methodology like MetaSounds
	// that copies UObject data when and where necessary.
	class ILegacyParameterTransmitter
	{
		public:
			virtual ~ILegacyParameterTransmitter() = default;

			AUDIOEXTENSIONS_API virtual TArray<const TObjectPtr<UObject>*> GetReferencedObjects() const;
	};

	/** Interface for a audio instance transmitter.
	 *
	 * An audio instance transmitter ushers control parameters to a single audio object instance.
	 */
	class IParameterTransmitter : public ILegacyParameterTransmitter
	{
		public:
			static AUDIOEXTENSIONS_API const FName RouterName;

			virtual ~IParameterTransmitter() = default;

			UE_DEPRECATED(5.2, "Use ResetParameters() or OnDeleteActiveSound() instead depending on use case.")
			virtual bool Reset() { ResetParameters(); return true; }

			// Reset parameters which stored on the transmitter.
			virtual void ResetParameters() {}

			// Called when the active sound is deleted due to the sound finishing,
			// being stopped, or being virtualized. 
			virtual void OnDeleteActiveSound() {}

			// Return the cached parameter with the given name if it exists
			// @return False if param not found, true if found.
			virtual bool GetParameter(FName InName, FAudioParameter& OutParam) const = 0;

			// Return reference to the cached parameter array.
			virtual const TArray<FAudioParameter>& GetParameters() const = 0;

			// Parameter Setters
			virtual bool SetParameters(TArray<FAudioParameter>&& InParameters) = 0;

			// Called when the active sound is virtualized  
			virtual void OnVirtualizeActiveSound() {}

			// Called when the virtualized active sound is realized 
			// @param Parameters to set 
			virtual void OnRealizeVirtualizedActiveSound(TArray<FAudioParameter>&& InParameters) {}
	};

	/** Base implementation for the parameter transmitter, which caches parameters
	  * and provides implementer to add additional logic to route parameter data accordingly.
	  */
	class FParameterTransmitterBase : public IParameterTransmitter
	{
	public:
		AUDIOEXTENSIONS_API FParameterTransmitterBase(TArray<FAudioParameter>&& InDefaultParams);
		AUDIOEXTENSIONS_API virtual ~FParameterTransmitterBase();

		AUDIOEXTENSIONS_API virtual bool GetParameter(FName InName, FAudioParameter& OutParam) const override;
		AUDIOEXTENSIONS_API virtual void ResetParameters() override;
		AUDIOEXTENSIONS_API virtual const TArray<FAudioParameter>& GetParameters() const override;
		UE_DEPRECATED(5.2, "Use ResetParameters() or OnDeleteActiveSound() instead depending on use case.")
		AUDIOEXTENSIONS_API virtual bool Reset() override;
		AUDIOEXTENSIONS_API virtual bool SetParameters(TArray<FAudioParameter>&& InParameters) override;
		AUDIOEXTENSIONS_API virtual void OnVirtualizeActiveSound() override;
		AUDIOEXTENSIONS_API virtual void OnRealizeVirtualizedActiveSound(TArray<FAudioParameter>&& InParameters);

	protected:
		TArray<FAudioParameter> AudioParameters;
		bool bIsVirtualized;
	};
} // namespace Audio

====================================


=== IAudioPropertiesSheet.h ===
===============================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "UObject/Object.h"
#include "UObject/ObjectPtr.h"

#include "IAudioPropertiesSheet.generated.h"


UCLASS(Abstract)
class AUDIOEXTENSIONS_API UAudioPropertySheetBaseAsset : public UObject
{
	GENERATED_BODY()

public: 
	virtual bool CopyToObjectProperties(TObjectPtr<UObject> TargetObject) { return false; };
};
===============================


=== IAudioProxyInitializer.cpp ===
==================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "IAudioProxyInitializer.h"

#include "AudioExtensionsLog.h"
#include "Logging/LogMacros.h"
#include "Containers/Set.h"
#include "Templates/SharedPointer.h"
#include "Templates/UniquePtr.h"
#include "UObject/NameTypes.h"

TUniquePtr<Audio::IProxyData> IAudioProxyDataFactory::CreateNewProxyData(const Audio::FProxyDataInitParams& InitParams) 
{
	return nullptr;
}

TSharedPtr<Audio::IProxyData> IAudioProxyDataFactory::CreateProxyData(const Audio::FProxyDataInitParams& InitParams) 
{
	// If the new interface is not overridden, use deprecated interface
	PRAGMA_DISABLE_DEPRECATION_WARNINGS
	TUniquePtr<Audio::IProxyData> Proxy = CreateNewProxyData(InitParams);
	PRAGMA_ENABLE_DEPRECATION_WARNINGS

	// Only log an error once per a proxy data type to avoid logspam.
	static TSet<FName> LoggedProxyWarnings;
	if (Proxy.IsValid())
	{
		const FName ProxyTypeName = Proxy->GetProxyTypeName();
		if (!LoggedProxyWarnings.Contains(ProxyTypeName))
		{
			LoggedProxyWarnings.Add(ProxyTypeName);
			UE_LOG(LogAudioExtensions, Warning, TEXT("Use of deprecated 'TUniquePtr<Audio::IProxyData> CreateNewProxyData(...)' for proxy type \"%s\". Please override 'TSharedPtr<Audio::IProxyData> CreateProxyData(...)'"), *ProxyTypeName.ToString());
		}
	}

	// Pass ownership of proxy from unique ptr to shared ptr. 
	return TSharedPtr<Audio::IProxyData>(Proxy.Release());
}

==================================


=== IAudioProxyInitializer.h ===
================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "Misc/AssertionMacros.h"
#include "Misc/CoreMiscDefines.h"
#include "Templates/Casts.h"
#include "Templates/SharedPointer.h"
#include "Templates/UniquePtr.h"
#include "UObject/NameTypes.h"

#include <type_traits>

/**
 * Interfaces for Audio Proxy Objects 
 * These are used to spawn thread safe instances of UObjects that may be garbage collected on the game thread.
 * In shipping builds, these are effectively abstract pointers, but CHECK_AUDIOPROXY_TYPES can optionally be used
 * to check downcasts.
 */

#define  IMPL_AUDIOPROXY_CLASS(FClassName) \
	static FName GetAudioProxyTypeName() \
	{ \
		static FName MyClassName = #FClassName; \
		return MyClassName; \
	} \
	static constexpr bool bWasAudioProxyClassImplemented = true; \
	friend class ::Audio::IProxyData; \
	friend class ::Audio::TProxyData<FClassName>;


namespace Audio
{
	// Forward Declarations
	class IProxyData;
	using IProxyDataPtr UE_DEPRECATED(5.2, "Replace IProxyDataPtr with TSharedPtr<Audio::IProxyData>") = TUniquePtr<Audio::IProxyData>;

	/*
	 * Base class that allows us to typecheck proxy data before downcasting it in debug builds.
	*/
	class IProxyData
	{
	private:
		FName ProxyTypeName;
	public:
		virtual ~IProxyData() = default;

		template<typename ProxyType>
		bool CheckTypeCast() const
		{
			const FName DestinationTypeName = ProxyType::GetAudioProxyTypeName();
			return ensureAlwaysMsgf(ProxyTypeName == DestinationTypeName, TEXT("Tried to downcast type %s to %s!"), *ProxyTypeName.ToString(), *DestinationTypeName.ToString());
		}

		FName GetProxyTypeName() const
		{
			return ProxyTypeName;
		}

		template<typename ProxyType>
		ProxyType& GetAs()
		{
			static_assert(std::is_base_of_v<IProxyData, ProxyType>, "Tried to downcast IProxyInitData to an unrelated type!");
			if (CheckTypeCast<ProxyType>())
			{
				return static_cast<ProxyType&>(*this);
			}
			else
			{
				// This is an illegal cast, and is considered a fatal error.
				checkNoEntry();
				return *((ProxyType*)0x1);
			}
		}

		template<typename ProxyType>
		const ProxyType& GetAs() const
		{
			static_assert(std::is_base_of_v<IProxyData, ProxyType>, "Tried to downcast IProxyInitData to an unrelated type!");
			if (CheckTypeCast<ProxyType>())
			{
				return static_cast<const ProxyType&>(*this);
			}
			else
			{
				// This is an illegal cast, and is considered a fatal error.
				checkNoEntry();
				return *((ProxyType*)0x1);
			}
		}

		IProxyData(FName InProxyTypeName)
			: ProxyTypeName(InProxyTypeName)
		{}

		UE_DEPRECATED(5.2, "Proxy data is stored in a TSharedPtr<> and no longer requires cloning")
		virtual TUniquePtr<IProxyData> Clone() const { return nullptr; }
	};

	/**
	 * This class can be implemented to create a custom, threadsafe instance of a given UObject.
	 * This is a CRTP class, and should always be subclassed with the name of the subclass.
	 */
	template <typename Type>
	class TProxyData : public IProxyData
	{
	protected:
		static constexpr bool bWasAudioProxyClassImplemented = false;

	public:
		TProxyData()
			: IProxyData(Type::GetAudioProxyTypeName())
		{
			static_assert(Type::bWasAudioProxyClassImplemented, "Make sure to include IMPL_AUDIOPROXY_CLASS(ClassName) in your implementation of TProxyData.");
		}
	};

	struct FProxyDataInitParams
	{
		FName NameOfFeatureRequestingProxy;
	};
} // namespace Audio

/*
* This can be subclassed to make a UClass an audio proxy factory.
*/
class IAudioProxyDataFactory
{
public:
	UE_DEPRECATED(5.2, "Call TSharedPtr<Audio::IProxyData> CreateProxyData(...) instead of a TUniquePtr<Audio::IProxyData> CreateNewProxyData(...).")
	AUDIOEXTENSIONS_API virtual TUniquePtr<Audio::IProxyData> CreateNewProxyData(const Audio::FProxyDataInitParams& InitParams);

	AUDIOEXTENSIONS_API virtual TSharedPtr<Audio::IProxyData> CreateProxyData(const Audio::FProxyDataInitParams& InitParams);
};

namespace Audio
{
	template <typename UClassToUse>
	IAudioProxyDataFactory* CastToProxyDataFactory(UObject* InObject)
	{
		if constexpr (std::is_base_of_v<IAudioProxyDataFactory, UClassToUse>)
		{
			if (InObject)
			{
				UClassToUse* DowncastObject = Cast<UClassToUse>(InObject);
				if (ensureAlways(DowncastObject))
				{
					return static_cast<IAudioProxyDataFactory*>(DowncastObject);
				}
			}
		}

		return nullptr;
	}
} // namespace Audio

================================


=== ISoundfieldEndpoint.cpp ===
===============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "ISoundfieldEndpoint.h"

#include "AudioExtentionsModule.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(ISoundfieldEndpoint)

ISoundfieldEndpoint::ISoundfieldEndpoint(int32 NumRenderCallbacksToBuffer)
{
	NumRenderCallbacksToBuffer = FMath::Max(NumRenderCallbacksToBuffer, 2);
	AudioPacketBuffer.AddDefaulted(NumRenderCallbacksToBuffer);
}

bool ISoundfieldEndpoint::PushAudio(TUniquePtr<ISoundfieldAudioPacket>&& InPacket)
{
	if (GetRemainderInPacketBuffer() > 0)
	{
		int32 WriteIndex = WriteCounter.GetValue();
		AudioPacketBuffer[WriteIndex] = MoveTemp(InPacket);
		WriteCounter.Set((WriteIndex + 1) % AudioPacketBuffer.Num());
		return true;
	}
	else
	{
		return false;
	}
}

void ISoundfieldEndpoint::SetNewSettings(TUniquePtr<ISoundfieldEndpointSettingsProxy>&& InNewSettings)
{
	FScopeLock ScopeLock(&CurrentSettingsCriticalSection);
	CurrentSettings = MoveTemp(InNewSettings);
}

int32 ISoundfieldEndpoint::GetNumPacketsBuffer()
{
	const int32 ReadIndex = ReadCounter.GetValue();
	const int32 WriteIndex = WriteCounter.GetValue();

	if (WriteIndex >= ReadIndex)
	{
		return WriteIndex - ReadIndex;
	}
	else
	{
		return AudioPacketBuffer.Num() - ReadIndex + WriteIndex;
	}
}

int32 ISoundfieldEndpoint::GetRemainderInPacketBuffer()
{
	const uint32 ReadIndex = ReadCounter.GetValue();
	const uint32 WriteIndex = WriteCounter.GetValue();

	return (AudioPacketBuffer.Num() - 1 - WriteIndex + ReadIndex) % AudioPacketBuffer.Num();
}

void ISoundfieldEndpoint::ProcessAudioIfNecessary()
{
	const bool bShouldProcessAudio = !RenderCallback.IsValid() && EndpointRequiresCallback();
	if (bShouldProcessAudio)
	{
		RunCallbackSynchronously();
	}
}

TUniquePtr<ISoundfieldAudioPacket> ISoundfieldEndpoint::PopAudio()
{
	if (GetNumPacketsBuffer() > 0)
	{
		const int32 ReadIndex = ReadCounter.GetValue();
		TUniquePtr<ISoundfieldAudioPacket> PoppedPacket = MoveTemp(AudioPacketBuffer[ReadIndex]);
		ReadCounter.Set((ReadIndex + 1) % AudioPacketBuffer.Num());
		return PoppedPacket;
	}
	else
	{
		return nullptr;
	}
}

void ISoundfieldEndpoint::PollSettings(TFunctionRef<void(const ISoundfieldEndpointSettingsProxy*)> SettingsCallback)
{
	FScopeLock ScopeLock(&CurrentSettingsCriticalSection);
	SettingsCallback(CurrentSettings.Get());
}

void ISoundfieldEndpoint::StartRunningCallback()
{
	float CallbackDuration = GetDesiredCallbackPeriodicity();

	RenderCallback.Reset(new Audio::FMixerNullCallback(CallbackDuration, [&]()
	{
		RunCallbackSynchronously();
	}));
}

void ISoundfieldEndpoint::StopRunningCallback()
{
	RenderCallback.Reset();
}

void ISoundfieldEndpoint::RunCallbackSynchronously()
{
	auto CallbackWithSettings = [&](const ISoundfieldEndpointSettingsProxy* InSettings)
	{
		while (TUniquePtr<ISoundfieldAudioPacket> PoppedPacket = PopAudio())
		{
			OnAudioCallback(MoveTemp(PoppedPacket), InSettings);
		}
	};

	PollSettings(CallbackWithSettings);
}

ISoundfieldEndpointFactory* ISoundfieldEndpointFactory::Get(const FName& InName)
{
	if (InName == DefaultSoundfieldEndpointName() || InName == FName())
	{
		return nullptr;
	}
	IModularFeatures::Get().LockModularFeatureList();
	TArray<ISoundfieldEndpointFactory*> Factories = IModularFeatures::Get().GetModularFeatureImplementations<ISoundfieldEndpointFactory>(GetModularFeatureName());
	IModularFeatures::Get().UnlockModularFeatureList();

	for (ISoundfieldEndpointFactory* Factory : Factories)
	{
		if (Factory && InName == Factory->GetEndpointTypeName())
		{
			return Factory;
		}
	}

	ensureMsgf(false, TEXT("Soundfield Endpoint Type %s not found!"), *InName.ToString());
	return nullptr;
}

TArray<FName> ISoundfieldEndpointFactory::GetAllSoundfieldEndpointTypes()
{
	// Ensure the module is loaded. This will cause any platform extension modules to load and register. 
	ensure(FAudioExtensionsModule::Get() != nullptr);
	
	TArray<FName> SoundfieldFormatNames;

	SoundfieldFormatNames.Add(DefaultSoundfieldEndpointName());

	IModularFeatures::Get().LockModularFeatureList();
	TArray<ISoundfieldEndpointFactory*> Factories = IModularFeatures::Get().GetModularFeatureImplementations<ISoundfieldEndpointFactory>(GetModularFeatureName());
	IModularFeatures::Get().UnlockModularFeatureList();

	for (ISoundfieldEndpointFactory* Factory : Factories)
	{
		SoundfieldFormatNames.Add(Factory->GetEndpointTypeName());
	}

	return SoundfieldFormatNames;
}

FName ISoundfieldEndpointFactory::DefaultSoundfieldEndpointName()
{
	static FName DefaultEndpointName = FName(TEXT("Default Soundfield Endpoint"));
	return DefaultEndpointName;
}

TUniquePtr<ISoundfieldDecoderStream> ISoundfieldEndpointFactory::CreateDecoderStream(const FAudioPluginInitializationParams& InitInfo, const ISoundfieldEncodingSettingsProxy& InitialSettings)
{
	// Endpoint soundfield formats don't ever get decoded in our audio engine, since they are external sends.
	checkNoEntry();
	return nullptr;
}

FName ISoundfieldEndpointFactory::GetSoundfieldFormatName()
{
	return GetEndpointTypeName();
}

bool ISoundfieldEndpointFactory::CanTranscodeToSoundfieldFormat(FName DestinationFormat, const ISoundfieldEncodingSettingsProxy& DestinationEncodingSettings)
{
	return false;
}


===============================


=== ISoundfieldEndpoint.h ===
=============================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "AudioMixerNullDevice.h"
#include "Containers/Array.h"
#include "CoreMinimal.h"
#include "CoreTypes.h"
#include "DSP/MultithreadedPatching.h"
#include "Features/IModularFeatures.h"
#include "HAL/CriticalSection.h"
#include "HAL/ThreadSafeCounter.h"
#include "ISoundfieldFormat.h"
#include "Misc/AssertionMacros.h"
#include "Templates/SubclassOf.h"
#include "Templates/UniquePtr.h"
#include "UObject/NameTypes.h"
#include "UObject/Object.h"
#include "UObject/ObjectMacros.h"
#include "UObject/UObjectGlobals.h"

#include "ISoundfieldEndpoint.generated.h"

class UClass;
struct FAudioPluginInitializationParams;
template <typename FuncType> class TFunctionRef;


/**
 * Interfaces for Soundfield Endpoints
 * 
 * This set of interfaces can be used to 
 * 
 */

/**  
 * This interface should be used to provide a non-uclass version of the data described in
 * your implementation of USoundfieldEndpointSettingsBase.
 */
class ISoundfieldEndpointSettingsProxy
{
public:
	virtual ~ISoundfieldEndpointSettingsProxy() {};
};

/**
 * This opaque class should be used for specifying settings for how audio should be
 * send to an external endpoint.
 */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class USoundfieldEndpointSettingsBase : public UObject
{
	GENERATED_BODY()

public:
	AUDIOEXTENSIONS_API virtual TUniquePtr<ISoundfieldEndpointSettingsProxy> GetProxy() const PURE_VIRTUAL(USoundfieldEndpointSettingsBase::GetProxy, return nullptr;);
};

/**
 * Class that allows soundfield-encoded audio to be sent to an arbitrary locale.
 * For endpoint types that support receiving our downmixed interleaved audio data directly, implement IAudioEndpoint instead.
 */
class ISoundfieldEndpoint
{
public:
	/**
	 * @param [NumRenderCallbacksToBuffer] Maximum number of ISoundfieldPackets that should be buffered.
	 */
	AUDIOEXTENSIONS_API ISoundfieldEndpoint(int32 NumRenderCallbacksToBuffer);

	virtual ~ISoundfieldEndpoint() {};

	/**
	 * Push a soundfield packet to the buffer.
	 */
	AUDIOEXTENSIONS_API bool PushAudio(TUniquePtr<ISoundfieldAudioPacket>&& InPacket);

	/**
	 * Post new settings for this endpoint.
	 * There is no type safety on this call, so make sure that you are using the correct implementation
	 * of IAudioEndpointSettingsProxy for this implementation of IAudioEndpoint.
	 */
	AUDIOEXTENSIONS_API void SetNewSettings(TUniquePtr<ISoundfieldEndpointSettingsProxy>&& InNewSettings);

	// Returns the amount of ISoundfieldAudioPackets currently buffered for this endpoint.
	AUDIOEXTENSIONS_API int32 GetNumPacketsBuffer();

	// Returns the amount of ISoundfieldAudioPackets that can be buffered for this endpoint before reaching capacity.
	AUDIOEXTENSIONS_API int32 GetRemainderInPacketBuffer();

	/**
	 * If this endpoint hasn't created it's own async callback thread but still requires an explicit callback, this should be called.
	 */
	AUDIOEXTENSIONS_API void ProcessAudioIfNecessary();

protected:

	/** OPTIONAL OVERRIDES: */

	/**
	 * For endpoints that do not explicitly fire a timed callback to poll audio data,
	 * this should be overridden to return true, and  OnAudioCallback and GetDesiredCallbackFrequency should be overridden.
	 */
	virtual bool EndpointRequiresCallback() const { return false; }

	/**
	 * For endpoints that return true for EndpointRequiresCallback, this should return the duration between OnAudioCallback calls in seconds.
	 */
	virtual float GetDesiredCallbackPeriodicity() const { return 0; }

	/**
	 * For endpoints that override EndpointRequiresCallback to return true, 
	 * this callback will be called every (GetDesiredNumFrames() / GetSampleRate()) seconds.
	 * @param [in] InPacket the next buffer of audio. Can be nullptr if PushAudio hasn't been called in a while and the buffer is starved.
	 * @param [in] InSettings is the most recent soundfield settings for this endpoint. Can be null.
	 */
	virtual void OnAudioCallback(TUniquePtr<ISoundfieldAudioPacket>&& InPacket, const ISoundfieldEndpointSettingsProxy* InSettings) { return; };

	/** METHODS USED BY IMPLEMENTATIONS OF ISoundfieldEndpoint: */

	/**
	 * This is used by the IAudioEndpoint implementation to poll buffered audio to process or send to the endpoint.
	 * Note that this is NOT thread safe if EndpointRequiresCallback() is overridden to return true. If that is the case, use an override of OnAudioCallback instead.
	 * 
	 * 
	 */
	AUDIOEXTENSIONS_API TUniquePtr<ISoundfieldAudioPacket> PopAudio();

	/**
	 * Use this as a thread safe way to use the current settings posted to this IAudioEndpoint. Locks with IAudioEndpoint::SetSettings.
	 * @param[in] NewSettingsRetrieved lambda used to work with the retrieved settings.
	 *                                 This lambda is called immediately and synchronously, but is used
	 *                                 to safely scope usage of the IAudioEndpointSettingsProxy pointer.
	 *                                 Note that the resulting ISoundfieldEndpointSettingsProxy can be null.
	 */
	AUDIOEXTENSIONS_API void PollSettings(TFunctionRef<void(const ISoundfieldEndpointSettingsProxy*)> SettingsCallback);

	/**
	 * If EndpointRequiresCallback() returns true, this will be used to spawn an async thread and begin calling OnAudioCallback.
	 */
	AUDIOEXTENSIONS_API void StartRunningCallback();
	AUDIOEXTENSIONS_API void StopRunningCallback();

	AUDIOEXTENSIONS_API void RunCallbackSynchronously();

private:
	// Owns a scoped thread and runs OnAudioCallback when StartRunningCallback() is called.
	TUniquePtr<Audio::FMixerNullCallback> RenderCallback;
	
	// This array is used as a non-copying circular buffer for ISoundfieldAudioPackets.
	TArray<TUniquePtr<ISoundfieldAudioPacket>> AudioPacketBuffer;
	FThreadSafeCounter ReadCounter;
	FThreadSafeCounter WriteCounter;

	// Owns the current settings for this endpoint.
	TUniquePtr<ISoundfieldEndpointSettingsProxy> CurrentSettings;
	FCriticalSection CurrentSettingsCriticalSection;
};

/**
 * This factory is used to expose Soundfield Endpoint types to the editor.
 * Once a factory is constructed and RegisterEndpointType is called, it will be exposed as a type of endpoint
 * That a submix in the submix graph could be constructed with.
 * Also note that an implementation of ISoundfieldDecoder is not necessary for soundfield formats that are only used for
 * soundfield endpoints.
 */
class ISoundfieldEndpointFactory : public ISoundfieldFactory
{
public:
	/** Virtual destructor */
	virtual ~ISoundfieldEndpointFactory()
	{
	}

	/** Get the name for the endpoint type that this factory produces.  */
	virtual FName GetEndpointTypeName() = 0;

	/** This is the FName used to register Soundfield Endpoint factories with the modular feature system. */
	static FName GetModularFeatureName()
	{
		static FName SoundfieldEndpointName = FName(TEXT("Soundfield Endpoint"));
		return SoundfieldEndpointName;
	}

	/** 
	 * This needs to be called to make a soundfield format usable by the engine.
	 * It can be called from a ISoundfieldFactory subclass' constructor
	*/
	static void RegisterEndpointType(ISoundfieldEndpointFactory* InFactory)
	{
		IModularFeatures::Get().RegisterModularFeature(GetModularFeatureName(), InFactory);
	}

	/**
	 * This needs to be called it an implementation of ISoundfieldFactory is about to be destroyed.
	 * It can be called from the destructor of an implementation of ISoundfieldFactory.
	 */
	static void UnregisterEndpointType(ISoundfieldEndpointFactory* InFactory)
	{
		IModularFeatures::Get().UnregisterModularFeature(GetModularFeatureName(), InFactory);
	}

	/**
	 * Get a registered endpoint factory by name.
	 */
	static AUDIOEXTENSIONS_API ISoundfieldEndpointFactory* Get(const FName& InName);

	static AUDIOEXTENSIONS_API TArray<FName> GetAllSoundfieldEndpointTypes();

	/**
	 * This is the default name used when a user creates a soundfield endpoint submix.
	 * Soundfied Endpoint submixes with this type will send their audio to the default output
	 * with no encoding.
	 */
	static AUDIOEXTENSIONS_API FName DefaultSoundfieldEndpointName();

	/** This function is not necessary to override, since audio sent to an endpoint does not need to be decoded to interleaved audio buffers. */
	AUDIOEXTENSIONS_API TUniquePtr<ISoundfieldDecoderStream> CreateDecoderStream(const FAudioPluginInitializationParams& InitInfo, const ISoundfieldEncodingSettingsProxy& InitialSettings) override;

	/** REQUIRED OVERRIDES: */

	/**
	 * These overrides are required from ISoundfieldFactory:
	 * ISoundfieldFactory::CreateNewEncoderStream
	 * ISoundfieldFactory::CreateNewTranscoderStream
	 * ISoundfieldFactory::CreateNewMixerStream
	 * ISoundfieldFactory::CreateEmptyPacket
	 * ISoundfieldFactory::CanTranscodeFromSoundfieldFormat
	 * ISoundfieldFactory::GetCustomEncodingSettingsClass
	 * ISoundfieldFactory::GetDefaultEncodingSettings
	 */

	/** Called for every new endpoint submix created with this factory's endpoint type. */
	virtual TUniquePtr<ISoundfieldEndpoint> CreateNewEndpointInstance(const FAudioPluginInitializationParams& InitInfo, const ISoundfieldEndpointSettingsProxy& InitialSettings) = 0;


	/**
	 * Should return the StaticClass of this factory's implementation of USoundfieldEndpointSettingsBase.
	 */
	virtual UClass* GetCustomEndpointSettingsClass() const
	{
		return nullptr;
	}

	/**
	 * return the settings an endpoint should use if a soundfield endpoint submix did not have their settings specified.
	 */
	virtual USoundfieldEndpointSettingsBase* GetDefaultEndpointSettings() = 0;

	bool IsEndpointFormat() override { return true; }

	AUDIOEXTENSIONS_API virtual FName GetSoundfieldFormatName() override;
	AUDIOEXTENSIONS_API virtual bool CanTranscodeToSoundfieldFormat(FName DestinationFormat, const ISoundfieldEncodingSettingsProxy& DestinationEncodingSettings) override;
};

=============================


=== ISoundfieldFormat.cpp ===
=============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "ISoundfieldFormat.h"

#include "AudioExtentionsModule.h"
#include "ISoundfieldEndpoint.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(ISoundfieldFormat)

FName ISoundfieldFactory::GetFormatNameForNoEncoding()
{
	static FName NoEncodingFormatName = FName(TEXT("No Encoding"));
	return NoEncodingFormatName;
}

FName ISoundfieldFactory::GetFormatNameForInheritedEncoding()
{
	static FName InheritedFormatName = FName(TEXT("Inherited Encoding"));
	return InheritedFormatName;
}

FName ISoundfieldFactory::GetModularFeatureName()
{
	static FName SoundfieldFactoryName = FName(TEXT("Soundfield Format"));
	return SoundfieldFactoryName;
}

void ISoundfieldFactory::RegisterSoundfieldFormat(ISoundfieldFactory* InFactory)
{
	check(IsInGameThread());
	IModularFeatures::Get().RegisterModularFeature(GetModularFeatureName(), InFactory);
}

void ISoundfieldFactory::UnregisterSoundfieldFormat(ISoundfieldFactory* InFactory)
{
	check(IsInGameThread());
	IModularFeatures::Get().UnregisterModularFeature(GetModularFeatureName(), InFactory);
}

ISoundfieldFactory* ISoundfieldFactory::Get(const FName& InName)
{
	if (InName == GetFormatNameForNoEncoding() || InName == FName())
	{
		return nullptr;
	}

	IModularFeatures::Get().LockModularFeatureList();
	TArray<ISoundfieldFactory*> Factories = IModularFeatures::Get().GetModularFeatureImplementations<ISoundfieldFactory>(GetModularFeatureName());
	IModularFeatures::Get().UnlockModularFeatureList();

	for (ISoundfieldFactory* Factory : Factories)
	{
		if (Factory && InName == Factory->GetSoundfieldFormatName())
		{
			if (Factory->IsEndpointFormat())
			{
				ensureAlwaysMsgf(false, TEXT("This format is only supported for endpoints. Use ISoundfieldEndpointFactory::Get instead."));
			}

			return Factory;
		}
	}

	ensureAlwaysMsgf(false, TEXT("Soundfield Format %s not found!"), *InName.ToString());
	return nullptr;
}

TArray<FName> ISoundfieldFactory::GetAvailableSoundfieldFormats()
{
	// Ensure the module is loaded. This will cause any platform extension modules to load and register. 
	ensure(FAudioExtensionsModule::Get() != nullptr);
	
	TArray<FName> SoundfieldFormatNames;

	SoundfieldFormatNames.Add(GetFormatNameForInheritedEncoding());
	SoundfieldFormatNames.Add(GetFormatNameForNoEncoding());

	IModularFeatures::Get().LockModularFeatureList();
	TArray<ISoundfieldFactory*> Factories = IModularFeatures::Get().GetModularFeatureImplementations<ISoundfieldFactory>(GetModularFeatureName());
	IModularFeatures::Get().UnlockModularFeatureList();

	for (ISoundfieldFactory* Factory : Factories)
	{
		SoundfieldFormatNames.Add(Factory->GetSoundfieldFormatName());
	}

	return SoundfieldFormatNames;
}


=============================


=== ISoundfieldFormat.h ===
===========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "AudioMixer.h"
#include "Containers/Array.h"
#include "CoreMinimal.h"
#include "CoreTypes.h"
#include "Features/IModularFeature.h"
#include "Features/IModularFeatures.h"
#include "Math/Quat.h"
#include "Misc/AssertionMacros.h"
#include "Templates/TypeHash.h"
#include "Templates/UniquePtr.h"
#include "UObject/NameTypes.h"
#include "UObject/Object.h"
#include "UObject/ObjectMacros.h"
#include "UObject/ObjectPtr.h"
#include "UObject/UObjectGlobals.h"

#include "ISoundfieldFormat.generated.h"

class FArchive;
class UClass;


/**
 * Interfaces for Soundfield Encoding and Decoding
 * 
 * This set of interfaces can be implemented to add support for encoding to and decoding from a soundfield format.
 * There are four classes that are required to implement a soundfield format:
 *
 * ISoundfieldPacket: Container for a single audio callback's resulting data for the soundfield format.
 *                    For example, for first order ambisonics, this would contain an interleaved buffer of floats.
 *                    For a proprietary spatial audio format, this would contain a bitstream.
 *
 * USoundfieldEncodingSettingsBase: These are game thread-local, inspectable settings to define how a soundfield is getting encoded.
 *                                  For example, this may contain the order of an ambisonics sound field.
 *
 * ISoundfieldEncodingSettingsProxy: This should contain all data from USoundfieldEncodingSettingsBase that needs to be read by an
 *                                   encoder or transcoder stream to apply the settings from an implementation of USoundfieldEncodingSettingsBase.
 * 
 * 
 * ISoundfieldEncoderStream: Class that encodes interleaved audio from a set of arbitrary locations to an ISoundfieldPacket.
 * ISoundfieldDecoderStream: Class that decodes audio from an ISoundfieldPacket to interleaved audio at a set of arbitrary locations.
 * ISoundfieldTranscodeStream: Class that translates a soundfield stream from one type to another.
 * ISoundfieldMixerStream: Class that sums together multiple incoming ISoundfieldPackets into one ISoundfieldPacket.
 *
 * ISoundfieldFactory: Factory class that declares the name of your format and creates new encoder, decoders, transcoders and mixers as requested.
 * 
 */

// List of classes that that interface with Soundfield objects:
namespace Audio
{
	class FMixerDevice;
	class FMixerSourceManager;
	class FMixerSubmix;

	struct FChannelPositionInfo
	{
		EAudioMixerChannel::Type Channel = EAudioMixerChannel::DefaultChannel;

		// Horizontal angle of the position of this channel, in radians.
		// Increases as the channel moves clockwise about the listener.
		// Goes from -PI to PI.
		float Azimuth = 0.0f;
		// Vertical angle of the position of this channel, in radians.
		// Increases as the height of the channel increases proportional to the channel's distance from the listener.
		// Goes from -PI to PI.
		float Elevation = 0.0f;

		// distance from the listener. By default, channels are typically on the unit sphere and have a radius of 1.0f.
		// For spatialized inputs, this radius will be expressed in Unreal Units.
		float Radius = 1.0f;
	};
}

/** 
 * This helper function is used to downcast abstract objects during callbacks.
 * Since implementing this API requires frequent downcasting of opaque data, and RTTI is not
 * enabled by default in our codebase, This is useful for avoiding programmer error.
 */
template<typename ToType, typename FromType>
ToType& DowncastSoundfieldRef(FromType& InRef)
{
#if PLATFORM_WINDOWS
	constexpr bool bIsToTypeChildClass = std::is_base_of<FromType, ToType>::value;
	static_assert(bIsToTypeChildClass, "Tried to cast a reference to an unrelated type.");
#endif

	check(&InRef != nullptr);

	return *static_cast<ToType*>(&InRef);
}


/**
 * This interface should be used to provide a non-uclass version of the data described in
 * your implementation of USoundfieldEncodingSettingsBase. We will then pass this proxy 
 * object to the soundfield stream classes.
 */
class ISoundfieldEncodingSettingsProxy
{
public:
	virtual ~ISoundfieldEncodingSettingsProxy() {};

	/** 
	 * This should return a unique 
	 * This is used so that we don't call the same encode operation multiple times for a single source being sent to identical submixes. 
	 */
	virtual uint32 GetUniqueId() const = 0;

	/** This should return a new, identical encoding settings. */
	virtual TUniquePtr<ISoundfieldEncodingSettingsProxy> Duplicate() const = 0;
};

/** 
 * This opaque class should be used for specifying settings for how audio should be encoded
 * to your soundfield format for a given submix or file.
 */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class USoundfieldEncodingSettingsBase : public UObject
{
	GENERATED_BODY()

public:
	AUDIOEXTENSIONS_API virtual TUniquePtr<ISoundfieldEncodingSettingsProxy> GetProxy() const PURE_VIRTUAL(USoundfieldEncodingSettingsBase::GetProxy, return nullptr;);
};

struct FAudioPluginInitializationParams;

/**
 * This interface represents all encoded soundfield audio from a single render callback.
 */
class ISoundfieldAudioPacket
{
public:
	virtual ~ISoundfieldAudioPacket() {};

	/**
	 * Read or write this packet to a byte buffer.
	 */
	virtual void Serialize(FArchive& Ar) = 0;

	/**
	 * Create a new version of this packet.
	 */
	virtual TUniquePtr<ISoundfieldAudioPacket> Duplicate() const = 0;

	/**
	 * Zero out the contents of this packet.
	 */
	virtual void Reset() = 0;
};

/**
 * Positional data for each channel.
 */
struct FSoundfieldSpeakerPositionalData
{
	int32 NumChannels = 0;

	const TArray<Audio::FChannelPositionInfo>* ChannelPositions = nullptr;

	// For encoding, this is the rotation of the emitter source relative to the world.
	// For decoding, this is the rotation of the listener relative to the output speaker bed.
	FQuat Rotation = FQuat::Identity;
};

/**
 * All input parameters for a single Encode operation.
 */
struct FSoundfieldEncoderInputData
{
	/*
	 * Input buffer of interleaved floats. Each channel of the interleaved AudioBuffer corresponds to a channel index in PositionalData.
	 */
	Audio::FAlignedFloatBuffer& AudioBuffer;

	// Number of channels of the source audio buffer.
	int32 NumChannels;

	// if the input audio was already encoded to ambisonics,
	// this will point to the settings the audio was encoded with.
	// Otherwise, this will be a null pointer.
	ISoundfieldEncodingSettingsProxy& InputSettings;

	FSoundfieldSpeakerPositionalData& PositionalData;
};

class ISoundfieldEncoderStream
{
public:
	virtual ~ISoundfieldEncoderStream() {};

	virtual void Encode(const FSoundfieldEncoderInputData& InputData, ISoundfieldAudioPacket& OutputData) = 0;
	virtual void EncodeAndMixIn(const FSoundfieldEncoderInputData& InputData, ISoundfieldAudioPacket& OutputData) = 0;
};

struct FSoundfieldDecoderInputData
{
	ISoundfieldAudioPacket& SoundfieldBuffer;

	// The positions of the channels we will output FSoundfieldDecoderOutputData::AudioBuffer to.
	FSoundfieldSpeakerPositionalData& PositionalData;

	int32 NumFrames;
	float SampleRate;
};

struct FSoundfieldDecoderOutputData
{
	Audio::FAlignedFloatBuffer& AudioBuffer;
};

class ISoundfieldDecoderStream
{
public:
	virtual ~ISoundfieldDecoderStream() {};

	virtual void Decode(const FSoundfieldDecoderInputData& InputData, FSoundfieldDecoderOutputData& OutputData) = 0;
	virtual void DecodeAndMixIn(const FSoundfieldDecoderInputData& InputData, FSoundfieldDecoderOutputData& OutputData) = 0;
};

class ISoundfieldTranscodeStream
{
public:
	virtual ~ISoundfieldTranscodeStream() {};

	virtual void Transcode(const ISoundfieldAudioPacket& InputData, const ISoundfieldEncodingSettingsProxy& InputSettings, ISoundfieldAudioPacket& OutputData, const ISoundfieldEncodingSettingsProxy& OutputSettings) = 0;
	virtual void TranscodeAndMixIn(const ISoundfieldAudioPacket& InputData, const ISoundfieldEncodingSettingsProxy& InputSettings, ISoundfieldAudioPacket& PacketToMixTo, const ISoundfieldEncodingSettingsProxy& OutputSettings) = 0;
};

struct FSoundfieldMixerInputData
{
	// Packet that should be mixed into the output.
	const ISoundfieldAudioPacket& InputPacket;
	// settings used to encode both the input packet than the packet we are mixing to.
	const ISoundfieldEncodingSettingsProxy& EncodingSettings;
	// The amount, in linear gain, to
	float SendLevel;
};

class ISoundfieldMixerStream
{
public:
	virtual ~ISoundfieldMixerStream() {};

	virtual void MixTogether(const FSoundfieldMixerInputData& InputData, ISoundfieldAudioPacket& PacketToMixInto) = 0;
};

class ISoundfieldFactory : public IModularFeature
{
public:
	/** Virtual destructor */
	virtual ~ISoundfieldFactory()
	{
	}

	/** When a submix has this format name, it is using interleaved, floating point audio with no metadata. */
	static AUDIOEXTENSIONS_API FName GetFormatNameForNoEncoding();

	/** When a submix has this format name, it derives its format from the submix it sends audio to. */
	static AUDIOEXTENSIONS_API FName GetFormatNameForInheritedEncoding();

	/** This is the FName used to register Soundfield Format factories with the modular feature system. */
	static AUDIOEXTENSIONS_API FName GetModularFeatureName();

	/** 
	 * This needs to be called to make a soundfield format usable by the engine.
	 * It can be called from a ISoundfieldFactory subclass' constructor
	*/
	static AUDIOEXTENSIONS_API void RegisterSoundfieldFormat(ISoundfieldFactory* InFactory);

	/**
	 * This needs to be called it an implementation of ISoundfieldFactory is about to be destroyed.
	 * It can be called from the destructor of an implementation of ISoundfieldFactory.
	 */
	static AUDIOEXTENSIONS_API void UnregisterSoundfieldFormat(ISoundfieldFactory* InFactory);

	/**
	 * Get a registered soundfield format factory by name.
	 */
	static AUDIOEXTENSIONS_API ISoundfieldFactory* Get(const FName& InName);

	static AUDIOEXTENSIONS_API TArray<FName> GetAvailableSoundfieldFormats();

	/** Get soundfield format name  */
	virtual FName GetSoundfieldFormatName() = 0;

	/** Called when a stream is opened. */
	virtual TUniquePtr<ISoundfieldEncoderStream> CreateEncoderStream(const FAudioPluginInitializationParams& InitInfo, const ISoundfieldEncodingSettingsProxy& InitialSettings) = 0;
	virtual TUniquePtr<ISoundfieldDecoderStream> CreateDecoderStream(const FAudioPluginInitializationParams& InitInfo, const ISoundfieldEncodingSettingsProxy& InitialSettings) = 0;

	// Transcoder streams are fed a soundfield audio packet with either a different format entirely, or the same format and different settings.
	// Specifying and returns a Transcoder Stream is not necessary if CanTranscodeSoundfieldFormat and ShouldReencodeBetween always returns false.
	virtual TUniquePtr<ISoundfieldTranscodeStream> CreateTranscoderStream(const FName SourceFormat, const ISoundfieldEncodingSettingsProxy& InitialSourceSettings, const FName DestinationFormat, const ISoundfieldEncodingSettingsProxy& InitialDestinationSettings, const FAudioPluginInitializationParams& InitInfo) = 0;
	virtual TUniquePtr<ISoundfieldMixerStream> CreateMixerStream(const ISoundfieldEncodingSettingsProxy& InitialSettings) = 0;
	virtual TUniquePtr<ISoundfieldAudioPacket> CreateEmptyPacket() = 0;

	/*
	* Override this function to determine whether an incoming ISoundfieldPacket would need to be explicitly operated on between two submixes with the same format, but potentially different encoding settings.
	* If this returns true, a new transcoder will be created.
	* if this returns false, then the source submix's ISoundfieldPacket will be passed down directly.
	*/
	virtual bool IsTranscodeRequiredBetweenSettings(const ISoundfieldEncodingSettingsProxy& SourceSettings, const ISoundfieldEncodingSettingsProxy& DestinationSettings)
	{
		return true;
	}

	/**
	 * Override this function to decide whether this soundfield format can read and convert from a source format.
	 */
	virtual bool CanTranscodeFromSoundfieldFormat(FName SourceFormat, const ISoundfieldEncodingSettingsProxy& SourceEncodingSettings) = 0;
	virtual bool CanTranscodeToSoundfieldFormat(FName DestinationFormat, const ISoundfieldEncodingSettingsProxy& DestinationEncodingSettings) = 0;

	/**
	 * If this is overridden to true, we will set up a separate encoding stream for every submix plugged into this soundfield submix.
	 * Otherwise, we mix all non-soundfield submixes plugged into this soundfield submix together and use one encoding stream.
	 */
	virtual bool ShouldEncodeAllStreamsIndependently(const ISoundfieldEncodingSettingsProxy& EncodingSettings)
	{
		return false;
	}

	/**
	 * Should return the StaticClass of your implementation of USoundfieldEncodingSettingsBase.
	 */
	virtual UClass* GetCustomEncodingSettingsClass() const
	{
		return nullptr;
	}

	virtual const USoundfieldEncodingSettingsBase* GetDefaultEncodingSettings() = 0;

	/** 
	 * This is overridden to return true for soundfield formats that are only used for sending audio externally.
	 * Rather than overriding this, consider implementing ISoundfieldEndpointFactory.
	*/
	virtual bool IsEndpointFormat() { return false; }
};

class ISoundfieldEffectSettingsProxy
{
public:
	virtual ~ISoundfieldEffectSettingsProxy() {};
};

UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class USoundfieldEffectSettingsBase : public UObject
{
	GENERATED_BODY()

protected:
	AUDIOEXTENSIONS_API virtual TUniquePtr<ISoundfieldEffectSettingsProxy> GetNewProxy() const PURE_VIRTUAL(USoundfieldEffectSettingsBase::GetProxy, return nullptr;);

private:
	// This is called by any engine system that is explicitly marked as a friend.
	TUniquePtr<ISoundfieldEffectSettingsProxy> PrivateGetProxy() const { return GetNewProxy(); }

	// List of classes that use USoundfieldEffectSettingsBase:
	friend Audio::FMixerSubmix;
	friend Audio::FMixerSourceManager;
};

/**
 * Single instance that actually processes the soundfield.
 */
class ISoundfieldEffectInstance
{
public:
	virtual ~ISoundfieldEffectInstance() {};

	virtual void ProcessAudio(ISoundfieldAudioPacket& InOutPacket, const ISoundfieldEncodingSettingsProxy& EncodingSettings, const ISoundfieldEffectSettingsProxy& ProcessorSettings) = 0;
};

/**
 * This opaque class should be used for specifying settings for how audio should be encoded
 * to your soundfield format for a given submix or file.
 */
UCLASS(config = Engine, abstract, editinlinenew, BlueprintType, MinimalAPI)
class USoundfieldEffectBase : public UObject
{
	GENERATED_BODY()

public:

	/**
	 * TODO: Filter classes settable on here by GetSettingsClass.
	 */
	UPROPERTY(EditAnywhere, Category = EffectPreset)
	TObjectPtr<USoundfieldEffectSettingsBase> Settings;

protected:
	/*
	 * Get the implementation of USoundfieldProcessorSettingsBase that is used for this processor's settings. Will always be called on the CDO.
	 */
	AUDIOEXTENSIONS_API virtual bool SupportsFormat(const FName& InFormat) const PURE_VIRTUAL(USoundfieldEncodingSettingsBase::SupportsFormat, return false;);

	/*
	 * Get the implementation of USoundfieldProcessorSettingsBase that is used for this processor's settings. Will always be called on the CDO.
	 */
	AUDIOEXTENSIONS_API virtual const UClass* GetSettingsClass() const PURE_VIRTUAL(USoundfieldEncodingSettingsBase::GetSettingsClass, return nullptr;);
	
	/**
	 * return the default processor settings we should use when none is provided. Will always be called on the CDO.
	 */
	AUDIOEXTENSIONS_API virtual const USoundfieldEffectSettingsBase* GetDefaultSettings() const PURE_VIRTUAL(USoundfieldEncodingSettingsBase::GetDefaultSettings, return nullptr;);

	/**
	 * Spawn a new instance of this processor.
	 */
	AUDIOEXTENSIONS_API virtual TUniquePtr<ISoundfieldEffectInstance> GetNewProcessor(const ISoundfieldEncodingSettingsProxy& EncodingSettings) const PURE_VIRTUAL(USoundfieldEncodingSettingsBase::GetProxy, return nullptr;);

private:

	const USoundfieldEffectSettingsBase* PrivateGetDefaultSettings() const { return GetDefaultSettings(); };
	TUniquePtr<ISoundfieldEffectInstance> PrivateGetNewProcessor(const ISoundfieldEncodingSettingsProxy& EncodingSettings) const { return GetNewProcessor(EncodingSettings); }

	// List of classes that use USoundfieldEffectBase:
	friend Audio::FMixerSourceManager;
	friend Audio::FMixerSubmix;

};

/** This is used in FMixerSourceVoice to make sure we only encode sources once for each type of stream.  */
struct FSoundfieldEncodingKey
{
	FName SoundfieldFormat;
	int32 EncodingSettingsID;

	FSoundfieldEncodingKey()
		: SoundfieldFormat(ISoundfieldFactory::GetFormatNameForNoEncoding())
		, EncodingSettingsID(0)
	{
	}

	FSoundfieldEncodingKey(ISoundfieldFactory* Factory, ISoundfieldEncodingSettingsProxy& InSettings)
		: SoundfieldFormat(Factory ? Factory->GetSoundfieldFormatName() : ISoundfieldFactory::GetFormatNameForNoEncoding())
		, EncodingSettingsID(InSettings.GetUniqueId())
	{
	}

	inline bool operator==(const FSoundfieldEncodingKey& Other) const
	{
		return (SoundfieldFormat == Other.SoundfieldFormat) && (EncodingSettingsID == Other.EncodingSettingsID);
	} 

	friend inline uint32 GetTypeHash(const FSoundfieldEncodingKey& Value)
	{
		return HashCombine(Value.EncodingSettingsID, Value.SoundfieldFormat.GetNumber());
	}
};

===========================


=== ISoundWaveCloudStreaming.h ===
==================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "UObject/Object.h"
#include "Features/IModularFeature.h"
#include "Misc/Guid.h"

#include "ISoundWaveCloudStreaming.generated.h"

//
// Forward declarations
//
class USoundWave;
class IDetailLayoutBuilder;


namespace Audio
{

	class ISoundWaveCloudStreamingFeature : public IModularFeature
	{
	public:
		static FName GetModularFeatureName() { return TEXT("SoundWaveCloudStreaming"); }
		virtual ~ISoundWaveCloudStreamingFeature() = default;

		/** Returns the GUID of this plugin. */
		virtual FGuid GetPluginGUID() const = 0;

		/** Checks if the given sound wave can be turned into cloud streamable. */
		virtual bool CanOverrideFormat(const USoundWave* InWaveToOverride) = 0;
		
		/** Gets the format name to use when overriding the given sound wave for cloud streaming. */
		virtual FName GetOverrideFormatName(const USoundWave* InWaveToOverride) = 0;
#if WITH_EDITOR
		/** Gets a hash of the parameters for the DDC. */
		virtual FString GetOverrideParameterDDCHash(const USoundWave* InWaveToOverride) = 0;

		/** Add editor customization for an instance. */
		virtual bool AddCustomizationCloudStreamingPlatformDetails(IDetailLayoutBuilder& InDetailLayoutBuilder) = 0;
#endif // WITH_EDITOR
	};

}


/** Platform specific enabling of Sound Wave cloud streaming. */
UENUM()
enum class ESoundWaveCloudStreamingPlatformProjectEnableType : uint8
{
	/** Enabled for this platform. */
	Enabled,

	/** Disabled for this platform. */
	Disabled,
};

/** Platform specific settings for Sound Wave cloud streaming. */
USTRUCT()
struct FSoundWaveCloudStreamingPlatformProjectSettings
{
	GENERATED_USTRUCT_BODY()

	FSoundWaveCloudStreamingPlatformProjectSettings()
	{
		EnablementSetting = ESoundWaveCloudStreamingPlatformProjectEnableType::Disabled;
	}

	bool IsDefault() const
	{
		return EnablementSetting == ESoundWaveCloudStreamingPlatformProjectEnableType::Disabled;
	}

	/** Overrides whether to use cloud streaming on this platform. */
	UPROPERTY(EditAnywhere, Category = Platforms)
	ESoundWaveCloudStreamingPlatformProjectEnableType EnablementSetting;
};



/** Platform specific enabling of Sound Wave cloud streaming. */
UENUM()
enum class ESoundWaveCloudStreamingPlatformEnableType : uint8
{
	/** Use Sound Wave setting. */
	Inherited,

	/** Disables Sound Wave cloud streaming for this platform. */
	Disabled,

	/** Used in Slate widget configuration to indicate multiple selected objects have different values. */
	SWC_MultipleValues UMETA(Hidden, DisplayName="Multiple values")
};

/** Platform specific settings for Sound Wave cloud streaming. */
USTRUCT()
struct FSoundWaveCloudStreamingPlatformSettings
{
	GENERATED_USTRUCT_BODY()

	FSoundWaveCloudStreamingPlatformSettings()
	{
		EnablementSetting = ESoundWaveCloudStreamingPlatformEnableType::Inherited;
	}

	bool IsDefault() const
	{
		return EnablementSetting == ESoundWaveCloudStreamingPlatformEnableType::Inherited;
	}

	/** Overrides whether to use cloud streaming on this platform. */
	UPROPERTY(EditAnywhere, Category = Platforms)
	ESoundWaveCloudStreamingPlatformEnableType EnablementSetting;
};

==================================


=== IWaveformTransformation.cpp ===
===================================

// Copyright Epic Games, Inc. All Rights Reserved.


#include "IWaveformTransformation.h"
#include "Templates/SharedPointer.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(IWaveformTransformation)

TArray<Audio::FTransformationPtr> UWaveformTransformationChain::CreateTransformations() const
{
	TArray<Audio::FTransformationPtr> TransformationPtrs;

	for(UWaveformTransformationBase* Transformation : Transformations)
	{
		if(Transformation)
		{
			TransformationPtrs.Add(Transformation->CreateTransformation());
		}
	}
	
	return TransformationPtrs;
}


===================================


=== IWaveformTransformation.h ===
=================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "Containers/Array.h"
#include "HAL/Platform.h"
#include "DSP/BufferVectorOperations.h"
#include "Templates/SharedPointer.h"
#include "Templates/UniquePtr.h"
#include "UObject/Object.h"
#include "UObject/ObjectMacros.h"
#include "UObject/ObjectPtr.h"
#include "UObject/UObjectGlobals.h"

#include "IWaveformTransformation.generated.h"

namespace Audio
{
	// information about the current state of the wave file we are transforming
	struct FWaveformTransformationWaveInfo
	{
		float SampleRate = 0.f;
		int32 NumChannels = 0;
		Audio::FAlignedFloatBuffer* Audio = nullptr;
		uint32 StartFrameOffset = 0;
		uint32 NumEditedSamples = 0;
	};

	/*
	 * Base class for the object that processes waveform data
	 * Pass tweakable variables from its paired settings UObject in the constructor in UWaveformTransformationBase::CreateTransformation
	 *
	 * note: WaveTransformation vs WaveformTransformation is to prevent UHT class name conflicts without having to namespace everything - remember this in derived classes!
	 */
	class IWaveTransformation
	{
	public:

		// Applies the transformation to the waveform and modifies WaveInfo with the resulting changes
		virtual void ProcessAudio(FWaveformTransformationWaveInfo& InOutWaveInfo) const {};
		
		virtual bool SupportsRealtimePreview() const { return false; }
		virtual bool CanChangeFileLength() const { return false; }
		virtual bool CanChangeChannelCount() const { return false; }

		virtual ~IWaveTransformation() {};
	};

	using FTransformationPtr = TUniquePtr<Audio::IWaveTransformation>;
}

// Information about the the wave file we are transforming for Transformation UObjects
struct FWaveTransformUObjectConfiguration
{
	int32 NumChannels = 0;
	float SampleRate = 0;
	float StartTime = 0.f; 
	float EndTime = -1.f; 
};

// Base class to hold editor configurable properties for an arbitrary transformation of audio waveform data
UCLASS(Abstract, EditInlineNew, MinimalAPI)
class UWaveformTransformationBase : public UObject
{
	GENERATED_BODY()

public:
	virtual Audio::FTransformationPtr CreateTransformation() const { return nullptr; }
	virtual void UpdateConfiguration(FWaveTransformUObjectConfiguration& InOutConfiguration) {};
	
	virtual bool IsEditorOnly() const override { return true; }
};

// Object that holds an ordered list of transformations to perform on a sound wave
UCLASS(EditInlineNew, MinimalAPI)
class UWaveformTransformationChain : public UObject
{
	GENERATED_BODY()
	
public:
	UPROPERTY(EditAnywhere, Instanced, Category = "Transformations")
	TArray<TObjectPtr<UWaveformTransformationBase>> Transformations;

	virtual bool IsEditorOnly() const override { return true; }
	
	AUDIOEXTENSIONS_API TArray<Audio::FTransformationPtr> CreateTransformations() const;
};

=================================


=== SoundGeneratorOutput.h ===
==============================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "SoundGeneratorOutput.generated.h"

/**
 * Base class for generators that have outputs that can be exposed to other game code.
 *
 * NOTE: This is not widely supported and should be considered experimental.
 */
USTRUCT(BlueprintType)
struct FSoundGeneratorOutput
{
	GENERATED_BODY()

	/** The output's name */
	UPROPERTY(BlueprintReadOnly, Category = SoundGeneratorOutput)
	FName Name;
};

==============================

