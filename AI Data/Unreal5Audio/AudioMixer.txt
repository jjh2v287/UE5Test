=== CODEBASE STRUCTURE ===

ðŸ“„ AudioBusSubsystem.cpp
ðŸ“„ AudioBusSubsystem.h
ðŸ“„ AudioDeviceNotificationSubsystem.cpp
ðŸ“„ AudioDeviceNotificationSubsystem.h
ðŸ“„ AudioGenerator.cpp
ðŸ“„ AudioGenerator.h
ðŸ“„ AudioMixer.Build.cs
ðŸ“„ AudioMixerBlueprintLibrary.cpp
ðŸ“„ AudioMixerBlueprintLibrary.h
ðŸ“„ AudioMixerBuffer.cpp
ðŸ“„ AudioMixerBuffer.h
ðŸ“„ AudioMixerBus.cpp
ðŸ“„ AudioMixerBus.h
ðŸ“„ AudioMixerChannelMaps.cpp
ðŸ“„ AudioMixerClock.cpp
ðŸ“„ AudioMixerClock.h
ðŸ“„ AudioMixerClockHandle.cpp
ðŸ“„ AudioMixerClockHandle.h
ðŸ“„ AudioMixerClockManager.cpp
ðŸ“„ AudioMixerClockManager.h
ðŸ“„ AudioMixerDevice.cpp
ðŸ“„ AudioMixerDevice.h
ðŸ“„ AudioMixerEffectsManager.cpp
ðŸ“„ AudioMixerEffectsManager.h
ðŸ“„ AudioMixerModule.cpp
ðŸ“„ AudioMixerModule.h
ðŸ“„ AudioMixerQuantizedCommands.cpp
ðŸ“„ AudioMixerQuantizedCommands.h
ðŸ“„ AudioMixerSource.cpp
ðŸ“„ AudioMixerSource.h
ðŸ“„ AudioMixerSourceBuffer.cpp
ðŸ“„ AudioMixerSourceBuffer.h
ðŸ“„ AudioMixerSourceDecode.cpp
ðŸ“„ AudioMixerSourceDecode.h
ðŸ“„ AudioMixerSourceManager.cpp
ðŸ“„ AudioMixerSourceManager.h
ðŸ“„ AudioMixerSourceOutputBuffer.cpp
ðŸ“„ AudioMixerSourceOutputBuffer.h
ðŸ“„ AudioMixerSourceVoice.cpp
ðŸ“„ AudioMixerSourceVoice.h
ðŸ“„ AudioMixerSubmix.cpp
ðŸ“„ AudioMixerSubmix.h
ðŸ“„ AudioMixerSubmixEffectDynamicsProcessor.cpp
ðŸ“„ AudioMixerSubmixEffectDynamicsProcessor.h
ðŸ“„ AudioMixerSubmixEffectEQ.cpp
ðŸ“„ AudioMixerSubmixEffectEQ.h
ðŸ“„ AudioMixerSubmixEffectReverb.cpp
ðŸ“„ AudioMixerSubmixEffectReverb.h
ðŸ“„ FileDecoder.cpp
ðŸ“„ FileDecoder.h
ðŸ“„ QuartzMetronome.cpp
ðŸ“„ QuartzMetronome.h
ðŸ“„ QuartzSubsystem.cpp
ðŸ“„ QuartzSubsystem.h
ðŸ“„ SoundFile.h
ðŸ“„ SoundFileIO.cpp
ðŸ“„ SoundFileIO.h
ðŸ“„ SoundFileIOEnums.h
ðŸ“„ SoundFileIOManager.cpp
ðŸ“„ SoundFileIOManager.h
ðŸ“„ SoundFileIOManagerImpl.cpp
ðŸ“„ SoundFileIOManagerImpl.h
ðŸ“„ SoundWaveDecoder.cpp
ðŸ“„ SoundWaveDecoder.h
ðŸ“„ SynthComponent.cpp
ðŸ“„ SynthComponent.h


=== FILE CONTENTS ===


=== AudioBusSubsystem.cpp ===
=============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioBusSubsystem.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSourceManager.h"
#include "DSP/MultithreadedPatching.h"
#include "UObject/UObjectIterator.h"

std::atomic<uint32> Audio::FAudioBusKey::InstanceIdCounter = 0;

UAudioBusSubsystem::UAudioBusSubsystem()
{
}

bool UAudioBusSubsystem::ShouldCreateSubsystem(UObject* Outer) const
{
	return !IsRunningDedicatedServer();
}

void UAudioBusSubsystem::Initialize(FSubsystemCollectionBase& Collection)
{
	UE_LOG(LogAudioMixer, Log, TEXT("Initializing Audio Bus Subsystem for audio device with ID %d"), GetMixerDevice()->DeviceID);
	InitDefaultAudioBuses();
}

void UAudioBusSubsystem::Deinitialize()
{
	UE_LOG(LogAudioMixer, Log, TEXT("Deinitializing Audio Bus Subsystem for audio device with ID %d"), GetMixerDevice() ? GetMixerDevice()->DeviceID : -1);
	ShutdownDefaultAudioBuses();
}

void UAudioBusSubsystem::StartAudioBus(Audio::FAudioBusKey InAudioBusKey, int32 InNumChannels, bool bInIsAutomatic)
{
	if (IsInGameThread())
	{
		if (ActiveAudioBuses_GameThread.Contains(InAudioBusKey))
		{
			return;
		}

		FActiveBusData BusData;
		BusData.BusKey = InAudioBusKey;
		BusData.NumChannels = InNumChannels;
		BusData.bIsAutomatic = bInIsAutomatic;

		ActiveAudioBuses_GameThread.Add(InAudioBusKey, BusData);

		FAudioThread::RunCommandOnAudioThread([this, InAudioBusKey, InNumChannels, bInIsAutomatic]()
		{
			if (Audio::FMixerSourceManager* MixerSourceManager = GetMutableSourceManager())
			{
				MixerSourceManager->StartAudioBus(InAudioBusKey, InNumChannels, bInIsAutomatic);
			}
		});
	}
	else
	{
		// If we're not the game thread, this needs to be on the game thread, so queue up a command to execute it on the game thread
		if (Audio::FMixerDevice* MixerDevice = GetMutableMixerDevice())
		{
			MixerDevice->GameThreadMPSCCommand([this, InAudioBusKey, InNumChannels, bInIsAutomatic]
			{
				StartAudioBus(InAudioBusKey, InNumChannels, bInIsAutomatic);
			});
		}
	}
}

void UAudioBusSubsystem::StopAudioBus(Audio::FAudioBusKey InAudioBusKey)
{
	if (IsInGameThread())
	{
		if (!ActiveAudioBuses_GameThread.Contains(InAudioBusKey))
		{
			return;
		}

		ActiveAudioBuses_GameThread.Remove(InAudioBusKey);

		FAudioThread::RunCommandOnAudioThread([this, InAudioBusKey]()
		{
			if (Audio::FMixerSourceManager* MixerSourceManager = GetMutableSourceManager())
			{
				MixerSourceManager->StopAudioBus(InAudioBusKey);
			}
		});
	}
	else
	{
		// If we're not the game thread, this needs to be on the game thread, so queue up a command to execute it on the game thread
		if (Audio::FMixerDevice* MixerDevice = GetMutableMixerDevice())
		{
			MixerDevice->GameThreadMPSCCommand([this, InAudioBusKey]
			{
				StopAudioBus(InAudioBusKey);
			});
		}
	}
}

bool UAudioBusSubsystem::IsAudioBusActive(Audio::FAudioBusKey InAudioBusKey) const
{
	if (IsInGameThread())
	{
		return ActiveAudioBuses_GameThread.Contains(InAudioBusKey);
	}

	check(IsInAudioThread());
	if (const Audio::FMixerSourceManager* MixerSourceManager = GetSourceManager())
	{
		return MixerSourceManager->IsAudioBusActive(InAudioBusKey);
	}
	return false;
}

Audio::FPatchInput UAudioBusSubsystem::AddPatchInputForAudioBus(Audio::FAudioBusKey InAudioBusKey, int32 InFrames, int32 InChannels, float InGain)
{
	Audio::FMixerSourceManager* SourceManager = GetMutableSourceManager();
	check(SourceManager);

	Audio::FMixerDevice* MixerDevice = GetMutableMixerDevice();
	if (!MixerDevice)
	{
		return Audio::FPatchInput();
	}

	Audio::FPatchInput PatchInput = MixerDevice->MakePatch(InFrames, InChannels, InGain);
	SourceManager->AddPendingAudioBusConnection(InAudioBusKey, InChannels, false, PatchInput);
	return PatchInput;
}

Audio::FPatchOutputStrongPtr UAudioBusSubsystem::AddPatchOutputForAudioBus(Audio::FAudioBusKey InAudioBusKey, int32 InFrames, int32 InChannels, float InGain)
{
	Audio::FMixerSourceManager* SourceManager = GetMutableSourceManager();
	check(SourceManager);

	Audio::FMixerDevice* MixerDevice = GetMutableMixerDevice();
	if (!MixerDevice)
	{
		return nullptr;
	}

	Audio::FPatchOutputStrongPtr PatchOutput = MixerDevice->MakePatch(InFrames, InChannels, InGain);
	SourceManager->AddPendingAudioBusConnection(InAudioBusKey, InChannels, false, PatchOutput);
	return PatchOutput;
}

Audio::FPatchInput UAudioBusSubsystem::AddPatchInputForSoundAndAudioBus(uint64 SoundInstanceID, Audio::FAudioBusKey AudioBusKey, int32 InFrames, int32 NumChannels, float InGain)
{
	Audio::FMixerDevice* MixerDevice = GetMutableMixerDevice();
	if (!MixerDevice)
	{
		return {};
	}

	if (Audio::FPatchOutputStrongPtr PatchOutput = MixerDevice->MakePatch(InFrames, NumChannels, InGain))
	{
		Audio::FPatchInput PatchInput = MoveTemp(PatchOutput);
		AddPendingConnection(SoundInstanceID, FPendingConnection{ FPendingConnection::FPatchVariant(TInPlaceType<Audio::FPatchInput>(), PatchInput), MoveTemp(AudioBusKey), InFrames, NumChannels });
		return PatchInput;
	}

	return {};
}

Audio::FPatchOutputStrongPtr UAudioBusSubsystem::AddPatchOutputForSoundAndAudioBus(uint64 SoundInstanceID, Audio::FAudioBusKey AudioBusKey, int32 InFrames, int32 NumChannels, float InGain)
{
	Audio::FMixerDevice* MixerDevice = GetMutableMixerDevice();
	if (!MixerDevice)
	{
		return {};
	}

	if (Audio::FPatchOutputStrongPtr PatchOutput = MixerDevice->MakePatch(InFrames, NumChannels, InGain))
	{
		AddPendingConnection(SoundInstanceID, FPendingConnection{ FPendingConnection::FPatchVariant(TInPlaceType<Audio::FPatchOutputStrongPtr>(), PatchOutput), MoveTemp(AudioBusKey), InFrames, NumChannels });
		return PatchOutput;
	}

	return {};
}

void UAudioBusSubsystem::AddPendingConnection(uint64 SoundInstanceID, FPendingConnection&& PendingConnection)
{
	FScopeLock ScopeLock(&Mutex);
	FSoundInstanceConnections& SoundInstanceConnections = SoundInstanceConnectionMap.FindOrAdd(SoundInstanceID);
	SoundInstanceConnections.PendingConnections.Add(MoveTemp(PendingConnection));
}

void UAudioBusSubsystem::ConnectPatches(uint64 SoundInstanceID)
{
	TArray<FPendingConnection> PendingConnections = ExtractPendingConnectionsIfReady(SoundInstanceID);
	if (!PendingConnections.IsEmpty())
	{
		Audio::FMixerSourceManager* SourceManager = GetMutableSourceManager();
		check(SourceManager);
		for (FPendingConnection& PendingConnection : PendingConnections)
		{
			switch (PendingConnection.PatchVariant.GetIndex())
			{
			case FPendingConnection::FPatchVariant::IndexOfType<Audio::FPatchInput>():
				SourceManager->AddPendingAudioBusConnection(MoveTemp(PendingConnection.AudioBusKey), PendingConnection.NumChannels, PendingConnection.bIsAutomatic, MoveTemp(PendingConnection.PatchVariant.Get<Audio::FPatchInput>()));
				break;
			case FPendingConnection::FPatchVariant::IndexOfType<Audio::FPatchOutputStrongPtr>():
				SourceManager->AddPendingAudioBusConnection(MoveTemp(PendingConnection.AudioBusKey), PendingConnection.NumChannels, PendingConnection.bIsAutomatic, MoveTemp(PendingConnection.PatchVariant.Get<Audio::FPatchOutputStrongPtr>()));
				break;
			}
		}
	}
}

void UAudioBusSubsystem::RemoveSound(uint64 SoundInstanceID)
{
	FScopeLock ScopeLock(&Mutex);
	SoundInstanceConnectionMap.Remove(SoundInstanceID);
}

TArray<UAudioBusSubsystem::FPendingConnection> UAudioBusSubsystem::ExtractPendingConnectionsIfReady(uint64 SoundInstanceID)
{
	FScopeLock ScopeLock(&Mutex);
	if (FSoundInstanceConnections* SoundInstanceConnections = SoundInstanceConnectionMap.Find(SoundInstanceID))
	{
		TArray<FPendingConnection> PendingConnections = MoveTemp(SoundInstanceConnections->PendingConnections);
		SoundInstanceConnections->PendingConnections.Empty();
		return PendingConnections;
	}
	return {};
}

void UAudioBusSubsystem::InitDefaultAudioBuses()
{
	if (!ensure(IsInGameThread()))
	{
		return;
	}

	if (const UAudioSettings* AudioSettings = GetDefault<UAudioSettings>())
	{
		TArray<TStrongObjectPtr<UAudioBus>> StaleBuses = DefaultAudioBuses;
		DefaultAudioBuses.Reset();

		for (const FDefaultAudioBusSettings& BusSettings : AudioSettings->DefaultAudioBuses)
		{
			if (UObject* BusObject = BusSettings.AudioBus.TryLoad())
			{
				if (UAudioBus* AudioBus = Cast<UAudioBus>(BusObject))
				{
					const int32 NumChannels = static_cast<int32>(AudioBus->AudioBusChannels) + 1;
					StartAudioBus(Audio::FAudioBusKey(AudioBus->GetUniqueID()), NumChannels, false /* bInIsAutomatic */);

					TStrongObjectPtr<UAudioBus>AddedBus(AudioBus);
					DefaultAudioBuses.AddUnique(AddedBus);
					StaleBuses.Remove(AddedBus);
				}
			}
		}

		for (TStrongObjectPtr<UAudioBus>& Bus : StaleBuses)
		{
			if (Bus.IsValid())
			{
				StopAudioBus(Audio::FAudioBusKey(Bus->GetUniqueID()));
			}
		}
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Failed to initialize Default Audio Buses. Audio Settings not found."));
	}
}

void UAudioBusSubsystem::ShutdownDefaultAudioBuses()
{
	if (!ensure(IsInGameThread()))
	{
		return;
	}

	for (TObjectIterator<UAudioBus> It; It; ++It)
	{
		UAudioBus* AudioBus = *It;
		if (AudioBus)
		{
			StopAudioBus(Audio::FAudioBusKey(AudioBus->GetUniqueID()));
		}
	}

	DefaultAudioBuses.Reset();
}

=============================


=== AudioBusSubsystem.h ===
===========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "DSP/MultithreadedPatching.h"
#include "Misc/TVariant.h"
#include "Subsystems/AudioEngineSubsystem.h"
#include "Templates/TypeHash.h"
#include "UObject/StrongObjectPtr.h"

#include "AudioBusSubsystem.generated.h"

class UAudioBus;

namespace Audio
{
	// Forward declarations 
	class FMixerAudioBus;
	class FMixerSourceManager;

	struct FAudioBusKey
	{
		uint32 ObjectId = INDEX_NONE; // from a corresponding UObject (UAudioBus) if applicable
		uint32 InstanceId = INDEX_NONE;

		FAudioBusKey()
			: InstanceId(InstanceIdCounter++)
		{
		}

		// For construction with a given UObject unique id 
		FAudioBusKey(uint32 InObjectId)
			: ObjectId(InObjectId)
		{
		}

		const bool IsValid() const
		{
			return ObjectId != INDEX_NONE || InstanceId != INDEX_NONE;
		}

		FORCEINLINE friend uint32 GetTypeHash(const FAudioBusKey& Key)
		{
			return HashCombineFast(Key.ObjectId, Key.InstanceId);
		}
		 		
		FORCEINLINE friend bool operator==(const FAudioBusKey& InLHS, const FAudioBusKey& InRHS) 
		{
			return (InLHS.ObjectId == InRHS.ObjectId) && (InLHS.InstanceId == InRHS.InstanceId);
		}

		FORCEINLINE friend bool operator!=(const FAudioBusKey& InLHS, const FAudioBusKey& InRHS) 
		{
			return !(InLHS == InRHS);
		}
		

	private:
		static AUDIOMIXER_API std::atomic<uint32> InstanceIdCounter;
	};
}

/**
*  UAudioBusSubsystem
*/
UCLASS(MinimalAPI)
class UAudioBusSubsystem : public UAudioEngineSubsystem
{
	GENERATED_BODY()

public:
	AUDIOMIXER_API UAudioBusSubsystem();
	virtual ~UAudioBusSubsystem() = default;

	//~ Begin USubsystem interface
	AUDIOMIXER_API virtual bool ShouldCreateSubsystem(UObject* Outer) const override;
	AUDIOMIXER_API virtual void Initialize(FSubsystemCollectionBase& Collection) override;
	AUDIOMIXER_API virtual void Deinitialize() override;
	//~ End USubsystem interface

	// Audio bus API from FMixerDevice
	AUDIOMIXER_API void StartAudioBus(Audio::FAudioBusKey InAudioBusKey, int32 InNumChannels, bool bInIsAutomatic);
	AUDIOMIXER_API void StopAudioBus(Audio::FAudioBusKey InAudioBusKey);
	AUDIOMIXER_API bool IsAudioBusActive(Audio::FAudioBusKey InAudioBusKey) const;
	
	AUDIOMIXER_API Audio::FPatchInput AddPatchInputForAudioBus(Audio::FAudioBusKey InAudioBusKey, int32 InFrames, int32 InChannels, float InGain = 1.f);
	AUDIOMIXER_API Audio::FPatchOutputStrongPtr AddPatchOutputForAudioBus(Audio::FAudioBusKey InAudioBusKey, int32 InFrames, int32 InChannels, float InGain = 1.f);

	AUDIOMIXER_API Audio::FPatchInput AddPatchInputForSoundAndAudioBus(uint64 SoundInstanceID, Audio::FAudioBusKey AudioBusKey, int32 InFrames, int32 NumChannels, float InGain = 1.f);
	AUDIOMIXER_API Audio::FPatchOutputStrongPtr AddPatchOutputForSoundAndAudioBus(uint64 SoundInstanceID, Audio::FAudioBusKey AudioBusKey, int32 InFrames, int32 NumChannels, float InGain = 1.f);
	AUDIOMIXER_API void ConnectPatches(uint64 SoundInstanceID);
	AUDIOMIXER_API void RemoveSound(uint64 SoundInstanceID);

	AUDIOMIXER_API void InitDefaultAudioBuses();
	AUDIOMIXER_API void ShutdownDefaultAudioBuses();

private:
	struct FActiveBusData
	{
		Audio::FAudioBusKey BusKey = 0;
		int32 NumChannels = 0;
		bool bIsAutomatic = false;
	};

	TArray<TStrongObjectPtr<UAudioBus>> DefaultAudioBuses; 
	// The active audio bus list accessible on the game thread
	TMap<Audio::FAudioBusKey, FActiveBusData> ActiveAudioBuses_GameThread;

	struct FPendingConnection
	{
		using FPatchVariant = TVariant<Audio::FPatchInput, Audio::FPatchOutputStrongPtr>;
		FPatchVariant PatchVariant;
		Audio::FAudioBusKey AudioBusKey;
		int32 BlockSizeFrames = 0;
		int32 NumChannels = 0;
		bool bIsAutomatic = false;
	};

	void AddPendingConnection(uint64 SoundInstanceID, FPendingConnection&& PendingConnection);

	struct FSoundInstanceConnections
	{
		TArray<FPendingConnection> PendingConnections;
	};

	TArray<FPendingConnection> ExtractPendingConnectionsIfReady(uint64 SoundInstanceID);

	TMap<uint64, FSoundInstanceConnections> SoundInstanceConnectionMap;
	FCriticalSection Mutex;
};

===========================


=== AudioDeviceNotificationSubsystem.cpp ===
============================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioDeviceNotificationSubsystem.h"
#include "CoreGlobals.h"
#include "AudioThread.h"
#include "Async/Async.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioDeviceNotificationSubsystem)

void UAudioDeviceNotificationSubsystem::Initialize(FSubsystemCollectionBase& Collection)
{
}

void UAudioDeviceNotificationSubsystem::Deinitialize()
{
	DefaultCaptureDeviceChanged.Clear();
	DefaultRenderDeviceChanged.Clear();
	DeviceAdded.Clear();
	DeviceRemoved.Clear();
	DeviceStateChanged.Clear();

	DefaultCaptureDeviceChangedNative.Clear();
	DefaultRenderDeviceChangedNative.Clear();
	DeviceAddedNative.Clear();
	DeviceRemovedNative.Clear();
	DeviceStateChangedNative.Clear();
}

void UAudioDeviceNotificationSubsystem::OnDefaultCaptureDeviceChanged(const Audio::EAudioDeviceRole InAudioDeviceRole, const FString& DeviceId)
{
	TWeakObjectPtr<UAudioDeviceNotificationSubsystem> WeakThis(this);
	AsyncTask(ENamedThreads::GameThread, [WeakThis, InAudioDeviceRole, DeviceId]()
	{
		if (WeakThis.IsValid())
		{
			EAudioDeviceChangedRole NewRole = WeakThis->GetDeviceChangedRole(InAudioDeviceRole);
			WeakThis->DefaultCaptureDeviceChanged.Broadcast(NewRole, DeviceId);
			WeakThis->DefaultCaptureDeviceChangedNative.Broadcast(NewRole, DeviceId);
		}
	});
}

void UAudioDeviceNotificationSubsystem::OnDefaultRenderDeviceChanged(const Audio::EAudioDeviceRole InAudioDeviceRole, const FString& DeviceId)
{
	TWeakObjectPtr<UAudioDeviceNotificationSubsystem> WeakThis(this);
	AsyncTask(ENamedThreads::GameThread, [WeakThis, InAudioDeviceRole, DeviceId]()
	{
		if (WeakThis.IsValid())
		{
			EAudioDeviceChangedRole NewRole = WeakThis->GetDeviceChangedRole(InAudioDeviceRole);
			WeakThis->DefaultRenderDeviceChanged.Broadcast(NewRole, DeviceId);
			WeakThis->DefaultRenderDeviceChangedNative.Broadcast(NewRole, DeviceId);
		}
	});
}

void UAudioDeviceNotificationSubsystem::OnDeviceAdded(const FString& DeviceId, bool bIsRenderDevice)
{
	// We currently ignore changes in non-render devices
	if (!bIsRenderDevice)
	{
		return;
	}

	TWeakObjectPtr<UAudioDeviceNotificationSubsystem> WeakThis(this);
	AsyncTask(ENamedThreads::GameThread, [WeakThis, DeviceId]()
	{
		if (WeakThis.IsValid())
		{
			WeakThis->DeviceAdded.Broadcast(DeviceId);
			WeakThis->DeviceAddedNative.Broadcast(DeviceId);
		}
	});
}

void UAudioDeviceNotificationSubsystem::OnDeviceRemoved(const FString& DeviceId, bool bIsRenderDevice)
{
	// We currently ignore changes in non-render devices
	if (!bIsRenderDevice)
	{
		return;
	}
	
	TWeakObjectPtr<UAudioDeviceNotificationSubsystem> WeakThis(this);
	AsyncTask(ENamedThreads::GameThread, [WeakThis, DeviceId]()
	{
		if (WeakThis.IsValid())
		{
			WeakThis->DeviceRemoved.Broadcast(DeviceId);
			WeakThis->DeviceRemovedNative.Broadcast(DeviceId);
		}
	});
}

void UAudioDeviceNotificationSubsystem::OnDeviceStateChanged(const FString& DeviceId, const Audio::EAudioDeviceState InState, bool bIsRenderDevice)
{
	// We currently ignore changes in non-render devices
	if (!bIsRenderDevice)
	{
		return;
	}
	
	TWeakObjectPtr<UAudioDeviceNotificationSubsystem> WeakThis(this);
	AsyncTask(ENamedThreads::GameThread, [WeakThis, DeviceId, InState]()
	{
		if (WeakThis.IsValid())
		{
			EAudioDeviceChangedState NewState = WeakThis->GetDeviceChangedState(InState);
			WeakThis->DeviceStateChanged.Broadcast(DeviceId, NewState);
			WeakThis->DeviceStateChangedNative.Broadcast(DeviceId, NewState);
		}
	});
}

void UAudioDeviceNotificationSubsystem::OnDeviceSwitched(const FString& DeviceId)
{
	TWeakObjectPtr<UAudioDeviceNotificationSubsystem> WeakThis(this);
	AsyncTask(ENamedThreads::GameThread, [WeakThis, DeviceId]()
	{
		if (WeakThis.IsValid())
		{
			WeakThis->DeviceSwitched.Broadcast(DeviceId);
			WeakThis->DeviceSwitchedNative.Broadcast(DeviceId);
		}
	});
}

EAudioDeviceChangedRole UAudioDeviceNotificationSubsystem::GetDeviceChangedRole(Audio::EAudioDeviceRole InRole) const
{
	EAudioDeviceChangedRole Role;
	switch (InRole)
	{
		case Audio::EAudioDeviceRole::Console:
			Role = EAudioDeviceChangedRole::Console;
			break;

		case Audio::EAudioDeviceRole::Multimedia:
			Role = EAudioDeviceChangedRole::Multimedia;
			break;

		case Audio::EAudioDeviceRole::Communications:
			Role = EAudioDeviceChangedRole::Communications;
			break;
			
		default:
			Role = EAudioDeviceChangedRole::Invalid;
			break;
	}

	return Role;
}

EAudioDeviceChangedState UAudioDeviceNotificationSubsystem::GetDeviceChangedState(Audio::EAudioDeviceState InState) const
{
	EAudioDeviceChangedState OutState;
	switch (InState)
	{
	case Audio::EAudioDeviceState::Active:
		OutState = EAudioDeviceChangedState::Active;
		break;

	case Audio::EAudioDeviceState::Disabled:
		OutState = EAudioDeviceChangedState::Disabled;
		break;

	case Audio::EAudioDeviceState::NotPresent:
		OutState = EAudioDeviceChangedState::NotPresent;
		break;

	case Audio::EAudioDeviceState::Unplugged:
		OutState = EAudioDeviceChangedState::Unplugged;
		break;

	default:
		OutState = EAudioDeviceChangedState::Invalid;
		break;
	}

	return OutState;
}


============================================


=== AudioDeviceNotificationSubsystem.h ===
==========================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "Subsystems/EngineSubsystem.h"
#include "Engine/Engine.h"
#include "AudioMixer.h"
#include "Delegates/Delegate.h"
#include "AudioDeviceNotificationSubsystem.generated.h"

/**
 *	EAudioDeviceChangedRole
 */
UENUM(BlueprintType)
enum class EAudioDeviceChangedRole : uint8
{
	Invalid,
	Console,
	Multimedia,
	Communications,
	Count UMETA(Hidden)
};

/**
 *	EAudioDeviceChangedState
 */
UENUM(BlueprintType)
enum class EAudioDeviceChangedState : uint8
{
	Invalid,
	Active,
	Disabled,
	NotPresent,
	Unplugged,
	Count UMETA(Hidden)
};

DECLARE_DYNAMIC_MULTICAST_DELEGATE_TwoParams(FOnAudioDefaultDeviceChanged, EAudioDeviceChangedRole, AudioDeviceRole, FString, DeviceId);
DECLARE_DYNAMIC_MULTICAST_DELEGATE_TwoParams(FOnAudioDeviceStateChanged, FString, DeviceId, EAudioDeviceChangedState, NewState);
DECLARE_DYNAMIC_MULTICAST_DELEGATE_OneParam(FOnAudioDeviceChange, FString, DeviceId);

DECLARE_MULTICAST_DELEGATE_TwoParams(FOnAudioDefaultDeviceChangedNative, EAudioDeviceChangedRole, FString);
DECLARE_MULTICAST_DELEGATE_TwoParams(FOnAudioDeviceStateChangedNative, FString, EAudioDeviceChangedState);
DECLARE_MULTICAST_DELEGATE_OneParam(FOnAudioDeviceChangeNative, FString);

/**
 *  UAudioDeviceNotificationSubsystem
 */
UCLASS(MinimalAPI)
class UAudioDeviceNotificationSubsystem : public UEngineSubsystem
													   , public Audio::IAudioMixerDeviceChangedListener
{
	GENERATED_BODY()

public: 

	virtual ~UAudioDeviceNotificationSubsystem() = default;

	static UAudioDeviceNotificationSubsystem* Get() { return GEngine->GetEngineSubsystem<UAudioDeviceNotificationSubsystem>(); }

	//~ Begin UEngineSubsystem Interface
	AUDIOMIXER_API virtual void Initialize(FSubsystemCollectionBase& Collection) override;
	AUDIOMIXER_API virtual void Deinitialize() override;
	//~ End UEngineSubsystem Interface

	//~ Begin IAudioMixerDeviceChangedListener Interface
	AUDIOMIXER_API virtual void OnDefaultCaptureDeviceChanged(const Audio::EAudioDeviceRole InAudioDeviceRole, const FString& DeviceId) override;
	AUDIOMIXER_API virtual void OnDefaultRenderDeviceChanged(const Audio::EAudioDeviceRole InAudioDeviceRole, const FString& DeviceId) override;
	AUDIOMIXER_API virtual void OnDeviceAdded(const FString& DeviceId, bool bIsRenderDevice) override;
	AUDIOMIXER_API virtual void OnDeviceRemoved(const FString& DeviceId, bool bIsRenderDevice) override;
	AUDIOMIXER_API virtual void OnDeviceStateChanged(const FString& DeviceId, const Audio::EAudioDeviceState InState, bool bIsRenderDevice) override;
	//~ End IAudioMixerDeviceChangedListener Interface

	AUDIOMIXER_API virtual void OnDeviceSwitched(const FString& DeviceId);

	/** Multicast delegate triggered when default capture device changes */
	UPROPERTY(BlueprintAssignable, Category = "Audio Delegates")
	FOnAudioDefaultDeviceChanged DefaultCaptureDeviceChanged;
	/** Multicast delegate triggered when default capture device changes (native code only) */
	FOnAudioDefaultDeviceChangedNative DefaultCaptureDeviceChangedNative;

	/** Multicast delegate triggered when default render device changes */
	UPROPERTY(BlueprintAssignable, Category = "Audio Delegates")
	FOnAudioDefaultDeviceChanged DefaultRenderDeviceChanged;
	/** Multicast delegate triggered when default render device changes (native code only) */
	FOnAudioDefaultDeviceChangedNative DefaultRenderDeviceChangedNative;

	/** Multicast delegate triggered when a device is added */
	UPROPERTY(BlueprintAssignable, Category = "Audio Delegates")
	FOnAudioDeviceChange DeviceAdded;
	/** Multicast delegate triggered when a device is added (native code only) */
	FOnAudioDeviceChangeNative DeviceAddedNative;

	/** Multicast delegate triggered when a device is removed */
	UPROPERTY(BlueprintAssignable, Category = "Audio Delegates")
	FOnAudioDeviceChange DeviceRemoved;
	/** Multicast delegate triggered when a device is removed (native code only) */
	FOnAudioDeviceChangeNative DeviceRemovedNative;

	/** Multicast delegate triggered on device state change */
	UPROPERTY(BlueprintAssignable, Category = "Audio Delegates")
	FOnAudioDeviceStateChanged DeviceStateChanged;
	/** Multicast delegate triggered on device state change (native code only) */
	FOnAudioDeviceStateChangedNative DeviceStateChangedNative;

	/** Multicast delegate triggered on device switch */
	UPROPERTY(BlueprintAssignable, Category = "Audio Delegates")
	FOnAudioDeviceChange DeviceSwitched;
	/** Multicast delegate triggered on device switch (native code only) */
	FOnAudioDeviceChangeNative DeviceSwitchedNative;

protected:

	AUDIOMIXER_API EAudioDeviceChangedRole GetDeviceChangedRole(Audio::EAudioDeviceRole InRole) const;
	AUDIOMIXER_API EAudioDeviceChangedState GetDeviceChangedState(Audio::EAudioDeviceState InState) const;
};


==========================================


=== AudioGenerator.cpp ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Generators/AudioGenerator.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioGenerator)

UAudioGenerator::UAudioGenerator() 
{
}

UAudioGenerator::~UAudioGenerator()
{
}

FAudioGeneratorHandle UAudioGenerator::AddGeneratorDelegate(FOnAudioGenerate InFunction)
{
	static int32 Id = 0;

	FAudioGeneratorHandle NewHandle;
	NewHandle.Id = Id++;

	FScopeLock Lock(&CritSect);
	OnGeneratedMap.Add(NewHandle.Id, MoveTemp(InFunction));
	return NewHandle;
}

void UAudioGenerator::RemoveGeneratorDelegate(FAudioGeneratorHandle InHandle)
{
	FScopeLock Lock(&CritSect);
	OnGeneratedMap.Remove(InHandle.Id);
}

void UAudioGenerator::Init(int32 InSampleRate, int32 InNumChannels)
{
	SampleRate = InSampleRate;
	NumChannels = InNumChannels;
}

void UAudioGenerator::OnGeneratedAudio(const float* InAudio, int32 NumSamples)
{
	FScopeLock Lock(&CritSect);
	for (auto& It : OnGeneratedMap)
	{
		It.Value(InAudio, NumSamples);
	}
}



==========================


=== AudioGenerator.h ===
========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "UObject/ObjectMacros.h"
#include "UObject/Object.h"

#include "AudioGenerator.generated.h"

struct FAudioGeneratorHandle
{
	int32 Id;

	FAudioGeneratorHandle()
		: Id(INDEX_NONE)
	{}
};

typedef TFunction<void(const float * InAudio, int32 NumSamples)> FOnAudioGenerate;

UCLASS(ClassGroup = (Custom), meta = (BlueprintSpawnableComponent), MinimalAPI)
class UAudioGenerator : public UObject
{
	GENERATED_BODY()

public:
	AUDIOMIXER_API UAudioGenerator();
	AUDIOMIXER_API virtual ~UAudioGenerator();

	// Returns the sample rate of the generator
	int32 GetSampleRate() const { return SampleRate; }

	// Returns the number of channels of the generator
	int32 GetNumChannels() const { return NumChannels; }

	// Adds a generator delegate. Returns a handle for the generator delegate, so it can be removed.
	AUDIOMIXER_API FAudioGeneratorHandle AddGeneratorDelegate(FOnAudioGenerate InFunction);

	// Removes the given audio generator delegate handle
	AUDIOMIXER_API void RemoveGeneratorDelegate(FAudioGeneratorHandle InHandle);

protected:

	// Called by derived classes to initialize the sample rate and num channels of the generator
	AUDIOMIXER_API void Init(int32 InSampleRate, int32 InNumChannels);

	// Called by derived classes when new audio is generated
	AUDIOMIXER_API void OnGeneratedAudio(const float* InAudio, int32 NumSamples);

	FCriticalSection CritSect;
	int32 SampleRate;
	int32 NumChannels;
	TMap<uint32, FOnAudioGenerate> OnGeneratedMap;
};

========================


=== AudioMixer.Build.cs ===
===========================

// Copyright Epic Games, Inc. All Rights Reserved.

namespace UnrealBuildTool.Rules
{
	public class AudioMixer : ModuleRules
	{
		public AudioMixer(ReadOnlyTargetRules Target) : base(Target)
		{
			PrivateIncludePathModuleNames.Add("TargetPlatform");
			PublicIncludePathModuleNames.Add("TargetPlatform");

			PublicIncludePathModuleNames.Add("Engine");

			PublicDependencyModuleNames.AddRange(
				new string[]
				{
					"Core",
					"CoreUObject",
					"AudioLinkEngine",
				}
			);

			PrivateDependencyModuleNames.AddRange(
				new string[]
				{
					"Engine",
					"NonRealtimeAudioRenderer",
					"AudioMixerCore",
					"SignalProcessing",
					"AudioPlatformConfiguration",
					"SoundFieldRendering",
					"AudioExtensions",
					"AudioLinkCore",
					"HeadMountedDisplay",
					"TraceLog"
				}
			);

			AddEngineThirdPartyPrivateStaticDependencies(Target,
					"UEOgg",
					"Vorbis",
					"VorbisFile",
					"libOpus",
					"UELibSampleRate"
					);

			// Circular references that need to be cleaned up
			CircularlyReferencedDependentModules.AddRange(
				new string[] {
					"NonRealtimeAudioRenderer",
					"SoundFieldRendering"
				}
			);
		}
	}
}

===========================


=== AudioMixerBlueprintLibrary.cpp ===
======================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerBlueprintLibrary.h"

#include "Algo/Transform.h"
#include "Async/Async.h"
#include "AudioBusSubsystem.h"
#include "AudioCompressionSettingsUtils.h"
#include "AudioDevice.h"
#include "AudioDeviceManager.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSubmix.h"
#include "ContentStreaming.h"
#include "CoreMinimal.h"
#include "DSP/ConstantQ.h"
#include "DSP/SpectrumAnalyzer.h"
#include "Engine/World.h"
#include "Sound/SoundEffectPreset.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioMixerBlueprintLibrary)

// This is our global recording task:
static TUniquePtr<Audio::FAudioRecordingData> RecordingData;

FAudioOutputDeviceInfo::FAudioOutputDeviceInfo(const Audio::FAudioPlatformDeviceInfo& InDeviceInfo)
	: Name(InDeviceInfo.Name)
	, DeviceId(InDeviceInfo.DeviceId)
	, NumChannels(InDeviceInfo.NumChannels)
	, SampleRate(InDeviceInfo.SampleRate)
	, Format(EAudioMixerStreamDataFormatType(InDeviceInfo.Format))
	, bIsSystemDefault(InDeviceInfo.bIsSystemDefault)
	, bIsCurrentDevice(false)
{
	for (EAudioMixerChannel::Type i : InDeviceInfo.OutputChannelArray)
	{
		OutputChannelArray.Emplace(EAudioMixerChannelType(i));
	}

}

FString UAudioMixerBlueprintLibrary::Conv_AudioOutputDeviceInfoToString(const FAudioOutputDeviceInfo& InDeviceInfo)
{
	FString output = FString::Printf(TEXT("Device Name: %s, \nDevice Id: %s, \nNum Channels: %u, \nSample Rate: %u, \nFormat: %s,  \nIs System Default: %u, \n"),
		*InDeviceInfo.Name, *InDeviceInfo.DeviceId, InDeviceInfo.NumChannels, InDeviceInfo.SampleRate,
		*DataFormatAsString(EAudioMixerStreamDataFormatType(InDeviceInfo.Format)), InDeviceInfo.bIsSystemDefault);

	output.Append("Output Channel Array: \n");

	for (int32 i = 0; i < InDeviceInfo.NumChannels; ++i)
	{
		if (i < InDeviceInfo.OutputChannelArray.Num())
		{
			output += FString::Printf(TEXT("	%d: %s \n"), i, ToString(InDeviceInfo.OutputChannelArray[i]));
		}
	}

	return output;
}

FString DataFormatAsString(EAudioMixerStreamDataFormatType type)
{
	switch (type)
	{
	case EAudioMixerStreamDataFormatType::Unknown:
		return FString("Unknown");
		break;
	case EAudioMixerStreamDataFormatType::Float:
		return FString("Float");
		break;
	case EAudioMixerStreamDataFormatType::Int16:
		return FString("Int16");
		break;
	case EAudioMixerStreamDataFormatType::Unsupported:
		return FString("Unsupported");
		break;
	default:
		return FString("Invalid Format Type");
	}
}


void UAudioMixerBlueprintLibrary::AddMasterSubmixEffect(const UObject* WorldContextObject, USoundEffectSubmixPreset* SubmixEffectPreset)
{
	if (!SubmixEffectPreset)
	{
		UE_LOG(LogAudioMixer, Warning, TEXT("AddMasterSubmixEffect was passed invalid submix effect preset"));
		return;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		FSoundEffectSubmixInitData InitData;
		InitData.SampleRate = MixerDevice->GetSampleRate();
		InitData.DeviceID = MixerDevice->DeviceID;
		InitData.PresetSettings = nullptr;
		InitData.ParentPresetUniqueId = SubmixEffectPreset->GetUniqueID();

		// Immediately create a new sound effect base here before the object becomes potentially invalidated
		TSoundEffectSubmixPtr SoundEffectSubmix = USoundEffectPreset::CreateInstance<FSoundEffectSubmixInitData, FSoundEffectSubmix>(InitData, *SubmixEffectPreset);
		SoundEffectSubmix->SetEnabled(true);

		MixerDevice->AddMasterSubmixEffect(SoundEffectSubmix);
	}
}

void UAudioMixerBlueprintLibrary::RemoveMasterSubmixEffect(const UObject* WorldContextObject, USoundEffectSubmixPreset* SubmixEffectPreset)
{
	if (!SubmixEffectPreset)
	{
		UE_LOG(LogAudioMixer, Warning, TEXT("RemoveMasterSubmixEffect was passed invalid submix effect preset"));
		return;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		// Get the unique id for the preset object on the game thread. Used to refer to the object on audio render thread.
		uint32 SubmixPresetUniqueId = SubmixEffectPreset->GetUniqueID();

		MixerDevice->RemoveMasterSubmixEffect(SubmixPresetUniqueId);
	}
}

void UAudioMixerBlueprintLibrary::ClearMasterSubmixEffects(const UObject* WorldContextObject)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->ClearMasterSubmixEffects();
	}
}

int32 UAudioMixerBlueprintLibrary::AddSubmixEffect(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, USoundEffectSubmixPreset* SubmixEffectPreset)
{
	if (!SubmixEffectPreset || !InSoundSubmix)
	{
		return 0;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		FSoundEffectSubmixInitData InitData;
		InitData.DeviceID = MixerDevice->DeviceID;
		InitData.SampleRate = MixerDevice->GetSampleRate();
		InitData.ParentPresetUniqueId = SubmixEffectPreset->GetUniqueID();

		TSoundEffectSubmixPtr SoundEffectSubmix = USoundEffectPreset::CreateInstance<FSoundEffectSubmixInitData, FSoundEffectSubmix>(InitData, *SubmixEffectPreset);
		SoundEffectSubmix->SetEnabled(true);

		return MixerDevice->AddSubmixEffect(InSoundSubmix, SoundEffectSubmix);
	}

	return 0;
}

void UAudioMixerBlueprintLibrary::RemoveSubmixEffectPreset(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, USoundEffectSubmixPreset* InSubmixEffectPreset)
{
	RemoveSubmixEffect(WorldContextObject, InSoundSubmix, InSubmixEffectPreset);
}

void UAudioMixerBlueprintLibrary::RemoveSubmixEffect(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, USoundEffectSubmixPreset* InSubmixEffectPreset)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		uint32 SubmixPresetUniqueId = InSubmixEffectPreset->GetUniqueID();
		MixerDevice->RemoveSubmixEffect(InSoundSubmix, SubmixPresetUniqueId);
	}
}

void UAudioMixerBlueprintLibrary::RemoveSubmixEffectPresetAtIndex(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, int32 SubmixChainIndex)
{
	RemoveSubmixEffectAtIndex(WorldContextObject, InSoundSubmix, SubmixChainIndex);
}

void UAudioMixerBlueprintLibrary::RemoveSubmixEffectAtIndex(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, int32 SubmixChainIndex)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->RemoveSubmixEffectAtIndex(InSoundSubmix, SubmixChainIndex);
	}
}

void UAudioMixerBlueprintLibrary::ReplaceSoundEffectSubmix(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, int32 SubmixChainIndex, USoundEffectSubmixPreset* SubmixEffectPreset)
{
	ReplaceSubmixEffect(WorldContextObject, InSoundSubmix, SubmixChainIndex, SubmixEffectPreset);
}

void UAudioMixerBlueprintLibrary::ReplaceSubmixEffect(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, int32 SubmixChainIndex, USoundEffectSubmixPreset* SubmixEffectPreset)
{
	if (!SubmixEffectPreset || !InSoundSubmix)
	{
		return;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		FSoundEffectSubmixInitData InitData;
		InitData.SampleRate = MixerDevice->GetSampleRate();

		TSoundEffectSubmixPtr SoundEffectSubmix = USoundEffectPreset::CreateInstance<FSoundEffectSubmixInitData, FSoundEffectSubmix>(InitData, *SubmixEffectPreset);
		SoundEffectSubmix->SetEnabled(true);

		MixerDevice->ReplaceSoundEffectSubmix(InSoundSubmix, SubmixChainIndex, SoundEffectSubmix);
	}
}

void UAudioMixerBlueprintLibrary::ClearSubmixEffects(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->ClearSubmixEffects(InSoundSubmix);
	}
}

void UAudioMixerBlueprintLibrary::SetSubmixEffectChainOverride(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, TArray<USoundEffectSubmixPreset*> InSubmixEffectPresetChain, float InFadeTimeSec)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		TArray<FSoundEffectSubmixPtr> NewSubmixEffectPresetChain;

		for (USoundEffectSubmixPreset* SubmixEffectPreset : InSubmixEffectPresetChain)
		{
			if (SubmixEffectPreset)
			{
				FSoundEffectSubmixInitData InitData;
				InitData.DeviceID = MixerDevice->DeviceID;
				InitData.SampleRate = MixerDevice->GetSampleRate();
				InitData.ParentPresetUniqueId = SubmixEffectPreset->GetUniqueID();

				TSoundEffectSubmixPtr SoundEffectSubmix = USoundEffectPreset::CreateInstance<FSoundEffectSubmixInitData, FSoundEffectSubmix>(InitData, *SubmixEffectPreset);
				SoundEffectSubmix->SetEnabled(true);

				NewSubmixEffectPresetChain.Add(SoundEffectSubmix);
			}
		}
		
		if (NewSubmixEffectPresetChain.Num() > 0)
		{
			MixerDevice->SetSubmixEffectChainOverride(InSoundSubmix, NewSubmixEffectPresetChain, InFadeTimeSec);
		}
	}
}

void UAudioMixerBlueprintLibrary::ClearSubmixEffectChainOverride(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, float InFadeTimeSec)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->ClearSubmixEffectChainOverride(InSoundSubmix, InFadeTimeSec);
	}
}

void UAudioMixerBlueprintLibrary::StartRecordingOutput(const UObject* WorldContextObject, float ExpectedDuration, USoundSubmix* SubmixToRecord)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->StartRecording(SubmixToRecord, ExpectedDuration);
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Output recording is an audio mixer only feature."));
	}
}

USoundWave* UAudioMixerBlueprintLibrary::StopRecordingOutput(const UObject* WorldContextObject, EAudioRecordingExportType ExportType, const FString& Name, FString Path, USoundSubmix* SubmixToRecord, USoundWave* ExistingSoundWaveToOverwrite)
{
	if (RecordingData.IsValid())
	{
		UE_LOG(LogAudioMixer, Warning, TEXT("Abandoning existing write operation. If you'd like to export multiple submix recordings at the same time, use Start/Finish Recording Submix Output instead."));
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		float SampleRate;
		float ChannelCount;

		// call the thing here.
		Audio::FAlignedFloatBuffer& RecordedBuffer = MixerDevice->StopRecording(SubmixToRecord, ChannelCount, SampleRate);

		if (RecordedBuffer.Num() == 0)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("No audio data. Did you call Start Recording Output?"));
			return nullptr;
		}

		// Pack output data into a TSampleBuffer and record out:
		RecordingData.Reset(new Audio::FAudioRecordingData());
		RecordingData->InputBuffer = Audio::TSampleBuffer<int16>(RecordedBuffer, ChannelCount, SampleRate);

		switch (ExportType)
		{
		case EAudioRecordingExportType::SoundWave:
		{
			USoundWave* ResultingSoundWave = RecordingData->Writer.SynchronouslyWriteSoundWave(RecordingData->InputBuffer, &Name, &Path);
			RecordingData.Reset();
			return ResultingSoundWave;
			break;
		}
		case EAudioRecordingExportType::WavFile:
		{
			RecordingData->Writer.BeginWriteToWavFile(RecordingData->InputBuffer, Name, Path, [SubmixToRecord]()
			{
				if (SubmixToRecord && SubmixToRecord->OnSubmixRecordedFileDone.IsBound())
				{
					SubmixToRecord->OnSubmixRecordedFileDone.Broadcast(nullptr);
				}

				// I'm gonna try this, but I do not feel great about it.
				RecordingData.Reset();
			});
			break;
		}
		default:
			break;
		}	
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Output recording is an audio mixer only feature."));
	}

	return nullptr;
}

void UAudioMixerBlueprintLibrary::PauseRecordingOutput(const UObject* WorldContextObject, USoundSubmix* SubmixToPause)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->PauseRecording(SubmixToPause);
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Output recording is an audio mixer only feature."));
	}
}

void UAudioMixerBlueprintLibrary::ResumeRecordingOutput(const UObject* WorldContextObject, USoundSubmix* SubmixToResume)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->ResumeRecording(SubmixToResume);
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Output recording is an audio mixer only feature."));
	}
}

void UAudioMixerBlueprintLibrary::StartAnalyzingOutput(const UObject* WorldContextObject, USoundSubmix* SubmixToAnalyze, EFFTSize FFTSize, EFFTPeakInterpolationMethod InterpolationMethod, EFFTWindowType WindowType, float HopSize, EAudioSpectrumType AudioSpectrumType)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		FSoundSpectrumAnalyzerSettings Settings = USoundSubmix::GetSpectrumAnalyzerSettings(FFTSize, InterpolationMethod, WindowType, HopSize, AudioSpectrumType);
		MixerDevice->StartSpectrumAnalysis(SubmixToAnalyze, Settings);
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Spectrum Analysis is an audio mixer only feature."));
	}
}

void UAudioMixerBlueprintLibrary::StopAnalyzingOutput(const UObject* WorldContextObject, USoundSubmix* SubmixToStopAnalyzing)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->StopSpectrumAnalysis(SubmixToStopAnalyzing);
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Spectrum Analysis is an audio mixer only feature."));
	}
}

TArray<FSoundSubmixSpectralAnalysisBandSettings> UAudioMixerBlueprintLibrary::MakeMusicalSpectralAnalysisBandSettings(int32 InNumNotes, EMusicalNoteName InStartingMusicalNote, int32 InStartingOctave, int32 InAttackTimeMsec, int32 InReleaseTimeMsec)
{
	// Make values sane.
	InNumNotes = FMath::Clamp(InNumNotes, 0, 10000);
	InStartingOctave = FMath::Clamp(InStartingOctave, -1, 10);
	InAttackTimeMsec = FMath::Clamp(InAttackTimeMsec, 0, 10000);
	InReleaseTimeMsec = FMath::Clamp(InReleaseTimeMsec, 0, 10000);

	// Some assumptions here on what constitutes "music". 12 notes, equal temperament.
	const float BandsPerOctave = 12.f;
	// This QFactor makes the bandwidth equal to the difference in frequency between adjacent notes.
	const float QFactor = 1.f / (FMath::Pow(2.f, 1.f / BandsPerOctave) - 1.f);

	// Base note index off of A4 which we know to be 440 hz.
	// Make note relative to A
	int32 NoteIndex = static_cast<int32>(InStartingMusicalNote) - static_cast<int32>(EMusicalNoteName::A);
	// Make relative to 4th octave of A
	NoteIndex += 12 * (InStartingOctave - 4);

	const float StartingFrequency = 440.f * FMath::Pow(2.f, static_cast<float>(NoteIndex) / 12.f);


	TArray<FSoundSubmixSpectralAnalysisBandSettings> BandSettingsArray;
	for (int32 i = 0; i < InNumNotes; i++)
	{
		FSoundSubmixSpectralAnalysisBandSettings BandSettings;

		BandSettings.BandFrequency = Audio::FPseudoConstantQ::GetConstantQCenterFrequency(i, StartingFrequency, BandsPerOctave);

		BandSettings.QFactor = QFactor;
		BandSettings.AttackTimeMsec = InAttackTimeMsec;
		BandSettings.ReleaseTimeMsec = InReleaseTimeMsec;

		BandSettingsArray.Add(BandSettings);
	}

	return BandSettingsArray;
}

TArray<FSoundSubmixSpectralAnalysisBandSettings> UAudioMixerBlueprintLibrary::MakeFullSpectrumSpectralAnalysisBandSettings(int32 InNumBands, float InMinimumFrequency, float InMaximumFrequency, int32 InAttackTimeMsec, int32 InReleaseTimeMsec)
{
	// Make inputs sane.
	InNumBands = FMath::Clamp(InNumBands, 0, 10000);
	InMinimumFrequency = FMath::Clamp(InMinimumFrequency, 20.0f, 20000.0f);
	InMaximumFrequency = FMath::Clamp(InMaximumFrequency, InMinimumFrequency, 20000.0f);
	InAttackTimeMsec = FMath::Clamp(InAttackTimeMsec, 0, 10000);
	InReleaseTimeMsec = FMath::Clamp(InReleaseTimeMsec, 0, 10000);

	// Calculate CQT settings needed to space bands.
	const float NumOctaves = FMath::Loge(InMaximumFrequency / InMinimumFrequency) / FMath::Loge(2.f);
	const float BandsPerOctave = static_cast<float>(InNumBands) / FMath::Max(NumOctaves, 0.01f);
	const float QFactor = 1.f / (FMath::Pow(2.f, 1.f / FMath::Max(BandsPerOctave, 0.01f)) - 1.f);

	TArray<FSoundSubmixSpectralAnalysisBandSettings> BandSettingsArray;
	for (int32 i = 0; i < InNumBands; i++)
	{
		FSoundSubmixSpectralAnalysisBandSettings BandSettings;

		BandSettings.BandFrequency = Audio::FPseudoConstantQ::GetConstantQCenterFrequency(i, InMinimumFrequency, BandsPerOctave);

		BandSettings.QFactor = QFactor;
		BandSettings.AttackTimeMsec = InAttackTimeMsec;
		BandSettings.ReleaseTimeMsec = InReleaseTimeMsec;

		BandSettingsArray.Add(BandSettings);
	}

	return BandSettingsArray;
}

TArray<FSoundSubmixSpectralAnalysisBandSettings> UAudioMixerBlueprintLibrary::MakePresetSpectralAnalysisBandSettings(EAudioSpectrumBandPresetType InBandPresetType, int32 InNumBands, int32 InAttackTimeMsec, int32 InReleaseTimeMsec)
{
	float MinimumFrequency = 20.f;
	float MaximumFrequency = 20000.f;

	// Likely all these are debatable. What we are shooting for is the most active frequency
	// ranges, so when an instrument plays a significant amount of spectral energy from that
	// instrument will show up in the frequency range. 
	switch (InBandPresetType)
	{
		case EAudioSpectrumBandPresetType::KickDrum:
			MinimumFrequency = 40.f;
			MaximumFrequency = 100.f;
			break;

		case EAudioSpectrumBandPresetType::SnareDrum:
			MinimumFrequency = 150.f;
			MaximumFrequency = 4500.f;
			break;

		case EAudioSpectrumBandPresetType::Voice:
			MinimumFrequency = 300.f;
			MaximumFrequency = 3000.f;
			break;

		case EAudioSpectrumBandPresetType::Cymbals:
			MinimumFrequency = 6000.f;
			MaximumFrequency = 16000.f;
			break;

		// More presets can be added. The possibilities are endless.
	}

	return MakeFullSpectrumSpectralAnalysisBandSettings(InNumBands, MinimumFrequency, MaximumFrequency, InAttackTimeMsec, InReleaseTimeMsec);
}

void UAudioMixerBlueprintLibrary::GetMagnitudeForFrequencies(const UObject* WorldContextObject, const TArray<float>& Frequencies, TArray<float>& Magnitudes, USoundSubmix* SubmixToAnalyze /*= nullptr*/)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->GetMagnitudesForFrequencies(SubmixToAnalyze, Frequencies, Magnitudes);
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Getting magnitude for frequencies is an audio mixer only feature."));
	}
}

void UAudioMixerBlueprintLibrary::GetPhaseForFrequencies(const UObject* WorldContextObject, const TArray<float>& Frequencies, TArray<float>& Phases, USoundSubmix* SubmixToAnalyze /*= nullptr*/)
{
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		MixerDevice->GetPhasesForFrequencies(SubmixToAnalyze, Frequencies, Phases);
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Output recording is an audio mixer only feature."));
	}
}

void UAudioMixerBlueprintLibrary::AddSourceEffectToPresetChain(const UObject* WorldContextObject, USoundEffectSourcePresetChain* PresetChain, FSourceEffectChainEntry Entry)
{
	if (!PresetChain)
	{
		UE_LOG(LogAudioMixer, Warning, TEXT("AddSourceEffectToPresetChain was passed invalid preset chain"));
		return;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		TArray<FSourceEffectChainEntry> Chain;

		uint32 PresetChainId = PresetChain->GetUniqueID();

		if (!MixerDevice->GetCurrentSourceEffectChain(PresetChainId, Chain))
		{
			Chain = PresetChain->Chain;
		}

		Chain.Add(Entry);
		MixerDevice->UpdateSourceEffectChain(PresetChainId, Chain, PresetChain->bPlayEffectChainTails);
	}
}

void UAudioMixerBlueprintLibrary::RemoveSourceEffectFromPresetChain(const UObject* WorldContextObject, USoundEffectSourcePresetChain* PresetChain, int32 EntryIndex)
{
	if (!PresetChain)
	{
		UE_LOG(LogAudioMixer, Warning, TEXT("RemoveSourceEffectFromPresetChain was passed invalid preset chain"));
		return;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		TArray<FSourceEffectChainEntry> Chain;

		uint32 PresetChainId = PresetChain->GetUniqueID();

		if (!MixerDevice->GetCurrentSourceEffectChain(PresetChainId, Chain))
		{
			Chain = PresetChain->Chain;
		}

		if (EntryIndex >= 0 && EntryIndex < Chain.Num())
		{
			Chain.RemoveAt(EntryIndex);
			MixerDevice->UpdateSourceEffectChain(PresetChainId, Chain, PresetChain->bPlayEffectChainTails);
		}
	}

}

void UAudioMixerBlueprintLibrary::SetBypassSourceEffectChainEntry(const UObject* WorldContextObject, USoundEffectSourcePresetChain* PresetChain, int32 EntryIndex, bool bBypassed)
{
	if (!PresetChain)
	{
		UE_LOG(LogAudioMixer, Warning, TEXT("SetBypassSourceEffectChainEntry was passed invalid preset chain"));
		return;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		TArray<FSourceEffectChainEntry> Chain;

		uint32 PresetChainId = PresetChain->GetUniqueID();

		if (!MixerDevice->GetCurrentSourceEffectChain(PresetChainId, Chain))
		{
			Chain = PresetChain->Chain;
		}

		if (EntryIndex >= 0 && EntryIndex < Chain.Num())
		{
			Chain[EntryIndex].bBypass = bBypassed;
			MixerDevice->UpdateSourceEffectChain(PresetChainId, Chain, PresetChain->bPlayEffectChainTails);
		}
	}
}

int32 UAudioMixerBlueprintLibrary::GetNumberOfEntriesInSourceEffectChain(const UObject* WorldContextObject, USoundEffectSourcePresetChain* PresetChain)
{
	if (!PresetChain)
	{
		UE_LOG(LogAudioMixer, Warning, TEXT("GetNumberOfEntriesInSourceEffectChain was passed invalid preset chain"));
		return 0;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		TArray<FSourceEffectChainEntry> Chain;

		uint32 PresetChainId = PresetChain->GetUniqueID();

		if (!MixerDevice->GetCurrentSourceEffectChain(PresetChainId, Chain))
		{
			return PresetChain->Chain.Num();
		}

		return Chain.Num();
	}

	return 0;
}

void UAudioMixerBlueprintLibrary::PrimeSoundForPlayback(USoundWave* SoundWave, const FOnSoundLoadComplete OnLoadCompletion)
{
	if (!SoundWave)
	{
		UE_LOG(LogAudioMixer, Warning, TEXT("Prime Sound For Playback called with a null SoundWave pointer."));
	}
	else
	{
		IStreamingManager::Get().GetAudioStreamingManager().RequestChunk(SoundWave->CreateSoundWaveProxy(), 1, [OnLoadCompletion, SoundWave](EAudioChunkLoadResult InResult)
		{
			AsyncTask(ENamedThreads::GameThread, [OnLoadCompletion, SoundWave, InResult]() {
				if (InResult == EAudioChunkLoadResult::Completed || InResult == EAudioChunkLoadResult::AlreadyLoaded)
				{
					OnLoadCompletion.ExecuteIfBound(SoundWave, false);
				}
				else
				{
					OnLoadCompletion.ExecuteIfBound(SoundWave, true);
				}
			});
		});
	}
}

void UAudioMixerBlueprintLibrary::PrimeSoundCueForPlayback(USoundCue* SoundCue)
{
	if (SoundCue)
	{
		SoundCue->PrimeSoundCue();
	}
}

float UAudioMixerBlueprintLibrary::TrimAudioCache(float InMegabytesToFree)
{
	uint64 NumBytesToFree = (uint64) (((double)InMegabytesToFree) * 1024.0 * 1024.0);
	uint64 NumBytesFreed = IStreamingManager::Get().GetAudioStreamingManager().TrimMemory(NumBytesToFree);
	return (float)(((double) NumBytesFreed / 1024) / 1024.0);
}

void UAudioMixerBlueprintLibrary::StartAudioBus(const UObject* WorldContextObject, UAudioBus* AudioBus)
{
	if (!AudioBus)
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Start Audio Bus called with an invalid Audio Bus."));
		return;
	}
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		uint32 AudioBusId = AudioBus->GetUniqueID();
		int32 NumChannels = (int32)AudioBus->AudioBusChannels + 1;

		UAudioBusSubsystem* AudioBusSubsystem = MixerDevice->GetSubsystem<UAudioBusSubsystem>();
		check(AudioBusSubsystem);
		AudioBusSubsystem->StartAudioBus(Audio::FAudioBusKey(AudioBusId), NumChannels, false);
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Audio buses are an audio mixer only feature. Please run the game with audio mixer enabled for this feature."));
	}
}

void UAudioMixerBlueprintLibrary::StopAudioBus(const UObject* WorldContextObject, UAudioBus* AudioBus)
{
	if (!AudioBus)
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Stop Audio Bus called with an invalid Audio Bus."));
		return;
	}
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		uint32 AudioBusId = AudioBus->GetUniqueID();
		UAudioBusSubsystem* AudioBusSubsystem = MixerDevice->GetSubsystem<UAudioBusSubsystem>();
		check(AudioBusSubsystem);
		AudioBusSubsystem->StopAudioBus(Audio::FAudioBusKey(AudioBusId));
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Audio buses are an audio mixer only feature. Please run the game with audio mixer enabled for this feature."));
	}
}

bool UAudioMixerBlueprintLibrary::IsAudioBusActive(const UObject* WorldContextObject, UAudioBus* AudioBus)
{
	if (!AudioBus)
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Is Audio Bus Active called with an invalid Audio Bus."));
		return false;
	}
	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		uint32 AudioBusId = AudioBus->GetUniqueID(); 
		UAudioBusSubsystem* AudioBusSubsystem = MixerDevice->GetSubsystem<UAudioBusSubsystem>();
		check(AudioBusSubsystem);
		return AudioBusSubsystem->IsAudioBusActive(Audio::FAudioBusKey(AudioBusId));
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Audio buses are an audio mixer only feature. Please run the game with audio mixer enabled for this feature."));
		return false;
	}
}

void UAudioMixerBlueprintLibrary::RegisterAudioBusToSubmix(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, UAudioBus* AudioBus)
{
	if (!SoundSubmix)
	{
		UE_LOG(LogAudioMixer, Error, TEXT("RegisterAudioBusToSubmix called with an invalid Submix."));
		return;
	}

	if (!AudioBus)
	{
		UE_LOG(LogAudioMixer, Error, TEXT("RegisterAudioBusToSubmix called with an invalid Audio Bus."));
		return;
	}

	if (!IsInAudioThread())
	{
		//Send this over to the audio thread, with the same settings
		FAudioThread::RunCommandOnAudioThread([WorldContextObject, SoundSubmix, AudioBus]()
		{
			RegisterAudioBusToSubmix(WorldContextObject, SoundSubmix, AudioBus);
		});

		return;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		Audio::FMixerSubmixPtr MixerSubmixPtr = MixerDevice->GetSubmixInstance(SoundSubmix).Pin();

		if (MixerSubmixPtr.IsValid())
		{
			UAudioBusSubsystem* AudioBusSubsystem = MixerDevice->GetSubsystem<UAudioBusSubsystem>();
			check(AudioBusSubsystem);

			const Audio::FAudioBusKey AudioBusKey = Audio::FAudioBusKey(AudioBus->GetUniqueID());
			MixerSubmixPtr->RegisterAudioBus(AudioBusKey, AudioBusSubsystem->AddPatchInputForAudioBus(AudioBusKey, MixerDevice->GetNumOutputFrames(), AudioBus->GetNumChannels()));
		}
		else
		{
			UE_LOG(LogAudioMixer, Error, TEXT("Submix not found in audio mixer."));
		}
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Audio mixer device not found."));
	}
}

void UAudioMixerBlueprintLibrary::UnregisterAudioBusFromSubmix(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, UAudioBus* AudioBus)
{
	if (!SoundSubmix)
	{
		UE_LOG(LogAudioMixer, Error, TEXT("UnregisterAudioBusToSubmix called with an invalid Submix."));
		return;
	}

	if (!AudioBus)
	{
		UE_LOG(LogAudioMixer, Error, TEXT("UnregisterAudioBusToSubmix called with an invalid Audio Bus."));
		return;
	}

	if (!IsInAudioThread())
	{
		//Send this over to the audio thread, with the same settings
		FAudioThread::RunCommandOnAudioThread([WorldContextObject, SoundSubmix, AudioBus]()
		{
			UnregisterAudioBusFromSubmix(WorldContextObject, SoundSubmix, AudioBus);
		});

		return;
	}

	if (Audio::FMixerDevice* MixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject))
	{
		Audio::FMixerSubmixPtr MixerSubmixPtr = MixerDevice->GetSubmixInstance(SoundSubmix).Pin();

		if (MixerSubmixPtr.IsValid())
		{
			const Audio::FAudioBusKey AudioBusKey(AudioBus->GetUniqueID());
			MixerSubmixPtr->UnregisterAudioBus(AudioBusKey);
		}
		else
		{
			UE_LOG(LogAudioMixer, Error, TEXT("Submix not found in audio mixer."));
		}
	}
	else
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Audio mixer device not found."));
	}
}

void UAudioMixerBlueprintLibrary::GetAvailableAudioOutputDevices(const UObject* WorldContextObject, const FOnAudioOutputDevicesObtained& OnObtainDevicesEvent)
{
	if (!OnObtainDevicesEvent.IsBound())
	{
		return;
	}

	if (!IsInAudioThread())
	{
		//Send this over to the audio thread, with the same settings
		FAudioThread::RunCommandOnAudioThread([WorldContextObject, OnObtainDevicesEvent]()
		{
			GetAvailableAudioOutputDevices(WorldContextObject, OnObtainDevicesEvent);
		}); 

		return;
	}

	TArray<FAudioOutputDeviceInfo> OutputDeviceInfos; //The array of audio device info to return

	//Verifies its safe to access the audio mixer device interface
	Audio::FMixerDevice* AudioMixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject);
	if (AudioMixerDevice)
	{
		if (Audio::IAudioMixerPlatformInterface* MixerPlatform = AudioMixerDevice->GetAudioMixerPlatform())
		{
			if (Audio::IAudioPlatformDeviceInfoCache* DeviceInfoCache = MixerPlatform->GetDeviceInfoCache())
			{
				TArray<Audio::FAudioPlatformDeviceInfo> AllDevices = DeviceInfoCache->GetAllActiveOutputDevices();
				Algo::Transform(AllDevices, OutputDeviceInfos, [](auto& i) -> FAudioOutputDeviceInfo { return { i }; });
			}
			else 
			{
				uint32 NumOutputDevices = 0;
				MixerPlatform->GetNumOutputDevices(NumOutputDevices);
				OutputDeviceInfos.Reserve(NumOutputDevices);
				FAudioOutputDeviceInfo CurrentOutputDevice = MixerPlatform->GetPlatformDeviceInfo();

				for (uint32 i = 0; i < NumOutputDevices; ++i)
				{
					Audio::FAudioPlatformDeviceInfo DeviceInfo;
					MixerPlatform->GetOutputDeviceInfo(i, DeviceInfo);

					FAudioOutputDeviceInfo NewInfo(DeviceInfo);
					NewInfo.bIsCurrentDevice = (NewInfo.DeviceId == CurrentOutputDevice.DeviceId);

					OutputDeviceInfos.Emplace(MoveTemp(NewInfo));
				}
			}
		}
	}

	//Send data through delegate on game thread
	FAudioThread::RunCommandOnGameThread([OnObtainDevicesEvent, OutputDeviceInfos]()
	{
		OnObtainDevicesEvent.ExecuteIfBound(OutputDeviceInfos);
	});
}

void UAudioMixerBlueprintLibrary::GetCurrentAudioOutputDeviceName(const UObject* WorldContextObject, const FOnMainAudioOutputDeviceObtained& OnObtainCurrentDeviceEvent)
{
	if (!OnObtainCurrentDeviceEvent.IsBound())
	{
		return;
	}

	if (!IsInAudioThread())
	{
		//Send this over to the audio thread, with the same settings
		FAudioThread::RunCommandOnAudioThread([WorldContextObject, OnObtainCurrentDeviceEvent]()
		{
			GetCurrentAudioOutputDeviceName(WorldContextObject, OnObtainCurrentDeviceEvent);
		});

		return;
	}

	TArray<FAudioOutputDeviceInfo> toReturn; //The array of audio device info to return

	//Verifies its safe to access the audio mixer device interface
	Audio::FMixerDevice* AudioMixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject);
	if (AudioMixerDevice)
	{
		Audio::IAudioMixerPlatformInterface* MixerPlatform = AudioMixerDevice->GetAudioMixerPlatform();
		if (MixerPlatform)
		{
			//Send data through delegate on game thread
			FString CurrentDeviceName = MixerPlatform->GetCurrentDeviceName();
			FAudioThread::RunCommandOnGameThread([OnObtainCurrentDeviceEvent, CurrentDeviceName]()
			{
				OnObtainCurrentDeviceEvent.ExecuteIfBound(CurrentDeviceName);
			});
		}
	}

}

void UAudioMixerBlueprintLibrary::SwapAudioOutputDevice(const UObject* WorldContextObject, const FString& NewDeviceId, const FOnCompletedDeviceSwap& OnCompletedDeviceSwap)
{
	if (!OnCompletedDeviceSwap.IsBound())
	{
		return;
	}

	if (!IsInAudioThread())
	{
		//Send this over to the audio thread, with the same settings
		FAudioThread::RunCommandOnAudioThread([WorldContextObject, NewDeviceId, OnCompletedDeviceSwap]()
		{
			SwapAudioOutputDevice(WorldContextObject, NewDeviceId, OnCompletedDeviceSwap);
		});

		return;
	}

	//Verifies its safe to access the audio mixer device interface
	Audio::FMixerDevice* AudioMixerDevice = FAudioDeviceManager::GetAudioMixerDeviceFromWorldContext(WorldContextObject);
	if (AudioMixerDevice)
	{
		Audio::IAudioMixerPlatformInterface* MixerPlatform = AudioMixerDevice->GetAudioMixerPlatform();

		//Send message to swap device
		if (MixerPlatform)
		{
			bool result = MixerPlatform->RequestDeviceSwap(NewDeviceId, /*force*/ false, TEXT("UAudioMixerBlueprintLibrary::SwapAudioOutputDevice"));
			FAudioOutputDeviceInfo CurrentOutputDevice = MixerPlatform->GetPlatformDeviceInfo();

			//Send data through delegate on game thread
			FSwapAudioOutputResult SwapResult;
			SwapResult.CurrentDeviceId = CurrentOutputDevice.DeviceId;
			SwapResult.RequestedDeviceId = NewDeviceId;
			SwapResult.Result = result ? ESwapAudioOutputDeviceResultState::Success : ESwapAudioOutputDeviceResultState::Failure;
			FAudioThread::RunCommandOnGameThread([OnCompletedDeviceSwap, SwapResult]()
			{
				OnCompletedDeviceSwap.ExecuteIfBound(SwapResult);
			});
		}
	}
}

======================================


=== AudioMixerBlueprintLibrary.h ===
====================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "Kismet/BlueprintFunctionLibrary.h"
#include "SubmixEffects/AudioMixerSubmixEffectDynamicsProcessor.h"
#include "Sound/SoundEffectSource.h"
#include "Sound/AudioBus.h"
#include "SampleBuffer.h"
#include "Sound/SoundCue.h"
#include "Sound/SoundSubmixSend.h"
#include "DSP/SpectrumAnalyzer.h"
#include "AudioMixer.h"
#include "AudioMixerTypes.h"
#include "AudioMixerBlueprintLibrary.generated.h"

class USoundSubmix;

/** 
* Called when a load request for a sound has completed.
*/
DECLARE_DYNAMIC_DELEGATE_TwoParams(FOnSoundLoadComplete, const class USoundWave*, LoadedSoundWave, const bool, WasCancelled);



UENUM(BlueprintType)
enum class EMusicalNoteName : uint8
{
	C  = 0,
	Db = 1,
	D  = 2,
	Eb = 3,
	E  = 4,
	F  = 5,
	Gb = 6,
	G  = 7,
	Ab = 8,
	A  = 9,
	Bb = 10,
	B  = 11,
};

//Duplicate of Audio::EAudioMixerStreamDataFormat::Type, to get around UHT's lack of namespace support
UENUM()
enum class EAudioMixerStreamDataFormatType : uint8
{
	Unknown,
	Float,
	Int16,
	Unsupported
};

FString DataFormatAsString(EAudioMixerStreamDataFormatType type);

//A copy of Audio::EAudioMixerChannel::Type to get around UHT's refusal of namespaces
UENUM()
enum class EAudioMixerChannelType : uint8
{
	FrontLeft,
	FrontRight,
	FrontCenter,
	LowFrequency,
	BackLeft,
	BackRight,
	FrontLeftOfCenter,
	FrontRightOfCenter,
	BackCenter,
	SideLeft,
	SideRight,
	TopCenter,
	TopFrontLeft,
	TopFrontCenter,
	TopFrontRight,
	TopBackLeft,
	TopBackCenter,
	TopBackRight,
	Unknown,
	ChannelTypeCount,
	DefaultChannel = FrontLeft
};

inline const TCHAR* ToString(EAudioMixerChannelType InType)
{
	switch (InType)
	{
		case EAudioMixerChannelType::FrontLeft:				return TEXT("FrontLeft");
		case EAudioMixerChannelType::FrontRight:			return TEXT("FrontRight");
		case EAudioMixerChannelType::FrontCenter:			return TEXT("FrontCenter");
		case EAudioMixerChannelType::LowFrequency:			return TEXT("LowFrequency");
		case EAudioMixerChannelType::BackLeft:				return TEXT("BackLeft");
		case EAudioMixerChannelType::BackRight:				return TEXT("BackRight");
		case EAudioMixerChannelType::FrontLeftOfCenter:		return TEXT("FrontLeftOfCenter");
		case EAudioMixerChannelType::FrontRightOfCenter:	return TEXT("FrontRightOfCenter");
		case EAudioMixerChannelType::BackCenter:			return TEXT("BackCenter");
		case EAudioMixerChannelType::SideLeft:				return TEXT("SideLeft");
		case EAudioMixerChannelType::SideRight:				return TEXT("SideRight");
		case EAudioMixerChannelType::TopCenter:				return TEXT("TopCenter");
		case EAudioMixerChannelType::TopFrontLeft:			return TEXT("TopFrontLeft");
		case EAudioMixerChannelType::TopFrontCenter:		return TEXT("TopFrontCenter");
		case EAudioMixerChannelType::TopFrontRight:			return TEXT("TopFrontRight");
		case EAudioMixerChannelType::TopBackLeft:			return TEXT("TopBackLeft");
		case EAudioMixerChannelType::TopBackCenter:			return TEXT("TopBackCenter");
		case EAudioMixerChannelType::TopBackRight:			return TEXT("TopBackRight");
		case EAudioMixerChannelType::Unknown:				return TEXT("Unknown");

		default:
			return TEXT("UNSUPPORTED");
	}
}

// Resulting State of SwapAudioOutputDevice call
UENUM(BlueprintType)
enum class ESwapAudioOutputDeviceResultState : uint8
{
	Failure, 
	Success, 
	None,
};

/**
 * Out structure for use with AudioMixerBlueprintLibrary::SwapAudioOutputDevice
 */
USTRUCT(BlueprintType)
struct FSwapAudioOutputResult
{
	GENERATED_USTRUCT_BODY()

	FSwapAudioOutputResult() = default;

	/** ID of the currently set device.  This is the device at the time of the call, NOT the resulting deviceId */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	FString CurrentDeviceId;

	/** ID of the requested device. */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	FString RequestedDeviceId;

	/** Result of the call */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	ESwapAudioOutputDeviceResultState Result = ESwapAudioOutputDeviceResultState::None;
};

/**
 * Platform audio output device info, in a Blueprint-readable format
 */
USTRUCT(BlueprintType)
struct FAudioOutputDeviceInfo
{
	GENERATED_USTRUCT_BODY()

	FAudioOutputDeviceInfo()
		: Name("")
		, DeviceId("")
		, NumChannels(0)
		, SampleRate(0)
		, Format(EAudioMixerStreamDataFormatType::Unknown)
		, bIsSystemDefault(true)
		, bIsCurrentDevice(false)
	{};

	AUDIOMIXER_API FAudioOutputDeviceInfo(const Audio::FAudioPlatformDeviceInfo& InDeviceInfo);

	/** The name of the audio device */
	UPROPERTY(BlueprintReadOnly, Category="Audio")
	FString Name;

	/** ID of the device. */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	FString DeviceId;

	/** The number of channels supported by the audio device */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	int32 NumChannels = 0;

	/** The sample rate of the audio device */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	int32 SampleRate = 0;

	/** The data format of the audio stream */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	EAudioMixerStreamDataFormatType Format = EAudioMixerStreamDataFormatType::Unknown;

	/** The output channel array of the audio device */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	TArray<EAudioMixerChannelType> OutputChannelArray;

	/** Whether or not this device is the system default */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	uint8 bIsSystemDefault : 1;

	/** Whether or not this device is the device currently in use */
	UPROPERTY(BlueprintReadOnly, Category = "Audio")
	uint8 bIsCurrentDevice : 1;
};

/**
 * Called when a list of all available audio devices is retrieved
 */
DECLARE_DYNAMIC_DELEGATE_OneParam(FOnAudioOutputDevicesObtained, const TArray<FAudioOutputDeviceInfo>&, AvailableDevices);

/**
 * Called when a list of all available audio devices is retrieved
 */
DECLARE_DYNAMIC_DELEGATE_OneParam(FOnMainAudioOutputDeviceObtained, const FString&, CurrentDevice);

/**
 * Called when the system has swapped to another audio output device
 */
DECLARE_DYNAMIC_DELEGATE_OneParam(FOnCompletedDeviceSwap, const FSwapAudioOutputResult&, SwapResult);

UCLASS(meta=(ScriptName="AudioMixerLibrary"), MinimalAPI)
class UAudioMixerBlueprintLibrary : public UBlueprintFunctionLibrary
{
	GENERATED_BODY()

public:
	/**
	* Returns the device info in a human readable format
	* @param info - The audio device data to print
	* @return The data in a string format
	*/
	UFUNCTION(BlueprintPure, meta = (DisplayName = "Audio Output Device Info To String", CompactNodeTitle = "->", BlueprintAutocast), Category = "Audio")
	static AUDIOMIXER_API FString Conv_AudioOutputDeviceInfoToString(const FAudioOutputDeviceInfo& Info);

	/** Adds a submix effect preset to the master submix. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta=(WorldContext="WorldContextObject"))
	static AUDIOMIXER_API void AddMasterSubmixEffect(const UObject* WorldContextObject, USoundEffectSubmixPreset* SubmixEffectPreset);

	/** Removes a submix effect preset from the master submix. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta=(WorldContext="WorldContextObject"))
	static AUDIOMIXER_API void RemoveMasterSubmixEffect(const UObject* WorldContextObject, USoundEffectSubmixPreset* SubmixEffectPreset);

	/** Clears all master submix effects. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void ClearMasterSubmixEffects(const UObject* WorldContextObject);

	/** Adds a submix effect preset to the given submix at the end of its submix effect chain. Returns the number of submix effects. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API int32 AddSubmixEffect(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, USoundEffectSubmixPreset* SubmixEffectPreset);

	UE_DEPRECATED(4.27, "RemoveSubmixEffectPreset is deprecated, use RemoveSubmixEffect.")
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject", DeprecatedFunction))
	static AUDIOMIXER_API void RemoveSubmixEffectPreset(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, USoundEffectSubmixPreset* SubmixEffectPreset);

	/** Removes all instances of a submix effect preset from the given submix. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void RemoveSubmixEffect(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, USoundEffectSubmixPreset* SubmixEffectPreset);

	UE_DEPRECATED(4.27, "RemoveSubmixEffectPresetAtIndex is deprecated, use RemoveSubmixEffectAtIndex.")
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject", DeprecatedFunction))
	static AUDIOMIXER_API void RemoveSubmixEffectPresetAtIndex(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, int32 SubmixChainIndex);

	/** Removes the submix effect at the given submix chain index, if there is a submix effect at that index. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void RemoveSubmixEffectAtIndex(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, int32 SubmixChainIndex);

	UE_DEPRECATED(4.27, "ReplaceSoundEffectSubmix is deprecated, use ReplaceSubmixEffect.")
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject", DeprecatedFunction))
	static AUDIOMIXER_API void ReplaceSoundEffectSubmix(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, int32 SubmixChainIndex, USoundEffectSubmixPreset* SubmixEffectPreset);

	/** Replaces the submix effect at the given submix chain index, adds the effect if there is none at that index. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void ReplaceSubmixEffect(const UObject* WorldContextObject, USoundSubmix* InSoundSubmix, int32 SubmixChainIndex, USoundEffectSubmixPreset* SubmixEffectPreset);

	/** Clears all submix effects on the given submix. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void ClearSubmixEffects(const UObject* WorldContextObject, USoundSubmix* SoundSubmix);

	/** Sets a submix effect chain override on the given submix. The effect chain will cross fade from the base effect chain or current override to the new override. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void SetSubmixEffectChainOverride(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, TArray<USoundEffectSubmixPreset*> SubmixEffectPresetChain, float FadeTimeSec);

	/** Clears all submix effect overrides on the given submix and returns it to the default effect chain. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void ClearSubmixEffectChainOverride(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, float FadeTimeSec);

	/** Start recording audio. By leaving the Submix To Record field blank, you can record the master output of the game. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Recording", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = 1))
	static AUDIOMIXER_API void StartRecordingOutput(const UObject* WorldContextObject, float ExpectedDuration, USoundSubmix* SubmixToRecord = nullptr);
	
	/** Stop recording audio. Path can be absolute, or relative (to the /Saved/BouncedWavFiles folder). By leaving the Submix To Record field blank, you can record the master output of the game.  */
	UFUNCTION(BlueprintCallable, Category = "Audio|Recording", meta = (WorldContext = "WorldContextObject", DisplayName = "Finish Recording Output", AdvancedDisplay = 4))
	static AUDIOMIXER_API USoundWave* StopRecordingOutput(const UObject* WorldContextObject, EAudioRecordingExportType ExportType, const FString& Name, FString Path, USoundSubmix* SubmixToRecord = nullptr, USoundWave* ExistingSoundWaveToOverwrite= nullptr);

	/** Pause recording audio, without finalizing the recording to disk. By leaving the Submix To Record field blank, you can record the master output of the game. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Recording", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = 1))
	static AUDIOMIXER_API void PauseRecordingOutput(const UObject* WorldContextObject, USoundSubmix* SubmixToPause = nullptr);

	/** Resume recording audio after pausing. By leaving the Submix To Pause field blank, you can record the master output of the game. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Recording", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = 1))
	static AUDIOMIXER_API void ResumeRecordingOutput(const UObject* WorldContextObject, USoundSubmix* SubmixToPause = nullptr);

	/** Start spectrum analysis of the audio output. By leaving the Submix To Analyze blank, you can analyze the master output of the game. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Analysis", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = 1))
	static AUDIOMIXER_API void StartAnalyzingOutput(const UObject* WorldContextObject, USoundSubmix* SubmixToAnalyze = nullptr, EFFTSize FFTSize = EFFTSize::DefaultSize, EFFTPeakInterpolationMethod InterpolationMethod = EFFTPeakInterpolationMethod::Linear, EFFTWindowType WindowType = EFFTWindowType::Hann, float HopSize = 0, EAudioSpectrumType SpectrumType = EAudioSpectrumType::MagnitudeSpectrum);

	/** Stop spectrum analysis. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Analysis", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = 1))
	static AUDIOMIXER_API void StopAnalyzingOutput(const UObject* WorldContextObject, USoundSubmix* SubmixToStopAnalyzing = nullptr);

	/** Make an array of musically spaced bands with ascending frequency.
	 *
	 *  @param InNumSemitones - The number of semitones to represent.
	 *  @param InStartingMuiscalNote - The name of the first note in the array.
	 *  @param InStartingOctave - The octave of the first note in the array.
	 *  @param InAttackTimeMsec - The attack time (in milliseconds) to apply to each band's envelope tracker.
	 *  @param InReleaseTimeMsec - The release time (in milliseconds) to apply to each band's envelope tracker.
	 */
	UFUNCTION(BlueprintPure, Category = "Audio|Analysis", meta = (AdvancedDisplay = 3))
	static AUDIOMIXER_API TArray<FSoundSubmixSpectralAnalysisBandSettings> MakeMusicalSpectralAnalysisBandSettings(int32 InNumSemitones=60, EMusicalNoteName InStartingMusicalNote = EMusicalNoteName::C, int32 InStartingOctave = 2, int32 InAttackTimeMsec = 10, int32 InReleaseTimeMsec = 10);

	/** Make an array of logarithmically spaced bands. 
	 *
	 *  @param InNumBands - The number of bands to used to represent the spectrum.
	 *  @param InMinimumFrequency - The center frequency of the first band.
	 *  @param InMaximumFrequency - The center frequency of the last band.
	 *  @param InAttackTimeMsec - The attack time (in milliseconds) to apply to each band's envelope tracker.
	 *  @param InReleaseTimeMsec - The release time (in milliseconds) to apply to each band's envelope tracker.
	 */
	UFUNCTION(BlueprintPure, Category = "Audio|Analysis", meta = (AdvancedDisplay = 3))
	static AUDIOMIXER_API TArray<FSoundSubmixSpectralAnalysisBandSettings> MakeFullSpectrumSpectralAnalysisBandSettings(int32 InNumBands = 30, float InMinimumFrequency=40.f, float InMaximumFrequency=16000.f, int32 InAttackTimeMsec = 10, int32 InReleaseTimeMsec = 10);

	/** Make an array of bands which span the frequency range of a given EAudioSpectrumBandPresetType. 
	 *
	 *  @param InBandPresetType - The type audio content which the bands encompass.
	 *  @param InNumBands - The number of bands used to represent the spectrum.
	 *  @param InAttackTimeMsec - The attack time (in milliseconds) to apply to each band's envelope tracker.
	 *  @param InReleaseTimeMsec - The release time (in milliseconds) to apply to each band's envelope tracker.
	 */
	UFUNCTION(BlueprintPure, Category = "Audio|Analysis", meta = (AdvancedDisplay = 2))
	static AUDIOMIXER_API TArray<FSoundSubmixSpectralAnalysisBandSettings> MakePresetSpectralAnalysisBandSettings(EAudioSpectrumBandPresetType InBandPresetType, int32 InNumBands = 10, int32 InAttackTimeMsec = 10, int32 InReleaseTimeMsec = 10);

	/** Retrieve the magnitudes for the given frequencies. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Analysis", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = 3))
	static AUDIOMIXER_API void GetMagnitudeForFrequencies(const UObject* WorldContextObject, const TArray<float>& Frequencies, TArray<float>& Magnitudes, USoundSubmix* SubmixToAnalyze = nullptr);

	/** Retrieve the phases for the given frequencies. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Analysis", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = 3))
	static AUDIOMIXER_API void GetPhaseForFrequencies(const UObject* WorldContextObject, const TArray<float>& Frequencies, TArray<float>& Phases, USoundSubmix* SubmixToAnalyze = nullptr);

	/** Adds source effect entry to preset chain. Only effects the instance of the preset chain */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void AddSourceEffectToPresetChain(const UObject* WorldContextObject, USoundEffectSourcePresetChain* PresetChain, FSourceEffectChainEntry Entry);

	/** Removes source effect entry from preset chain. Only affects the instance of preset chain. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void RemoveSourceEffectFromPresetChain(const UObject* WorldContextObject, USoundEffectSourcePresetChain* PresetChain, int32 EntryIndex);

	/** Set whether or not to bypass the effect at the source effect chain index. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void SetBypassSourceEffectChainEntry(const UObject* WorldContextObject, USoundEffectSourcePresetChain* PresetChain, int32 EntryIndex, bool bBypassed);

	/** Returns the number of effect chain entries in the given source effect chain. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API int32 GetNumberOfEntriesInSourceEffectChain(const UObject* WorldContextObject, USoundEffectSourcePresetChain* PresetChain);

	/** Begin loading a sound into the cache so that it can be played immediately. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Cache")
	static AUDIOMIXER_API void PrimeSoundForPlayback(USoundWave* SoundWave, const FOnSoundLoadComplete OnLoadCompletion);

	/** Begin loading any sounds referenced by a sound cue into the cache so that it can be played immediately. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Cache")
	static AUDIOMIXER_API void PrimeSoundCueForPlayback(USoundCue* SoundCue);

	/** Trim memory used by the audio cache. Returns the number of megabytes freed. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Cache")
	static AUDIOMIXER_API float TrimAudioCache(float InMegabytesToFree);

	/** Starts the given audio bus. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Bus", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void StartAudioBus(const UObject* WorldContextObject, UAudioBus* AudioBus);

	/** Stops the given audio bus. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Bus", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void StopAudioBus(const UObject* WorldContextObject, UAudioBus* AudioBus);

	/** Queries if the given audio bus is active (and audio can be mixed to it). */
	UFUNCTION(BlueprintCallable, Category = "Audio|Bus", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API bool IsAudioBusActive(const UObject* WorldContextObject, UAudioBus* AudioBus);

	/** Registers an audio bus to a submix so the submix output can be routed to the audiobus. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Bus", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void RegisterAudioBusToSubmix(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, UAudioBus* AudioBus);

	/** Unregisters an audio bus that could have been registered to a submix. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Bus", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void UnregisterAudioBusFromSubmix(const UObject* WorldContextObject, USoundSubmix* SoundSubmix, UAudioBus* AudioBus);

	/**
	* Gets information about all audio output devices available in the system
	* @param OnObtainDevicesEvent - the event to fire when the audio endpoint devices have been retrieved
	*/
	UFUNCTION(BlueprintCallable, Category = "Audio", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void GetAvailableAudioOutputDevices(const UObject* WorldContextObject, const FOnAudioOutputDevicesObtained& OnObtainDevicesEvent);

	/**
	* Gets information about the currently used audio output device
	* @param OnObtainCurrentDeviceEvent - the event to fire when the audio endpoint devices have been retrieved
	*/
	UFUNCTION(BlueprintCallable, Category = "Audio", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void GetCurrentAudioOutputDeviceName(const UObject* WorldContextObject, const FOnMainAudioOutputDeviceObtained& OnObtainCurrentDeviceEvent);

	/**
	* Hotswaps to the requested audio output device
	* @param NewDeviceId - the device Id to swap to
	* @param OnCompletedDeviceSwap - the event to fire when the audio endpoint devices have been retrieved
	*/
	UFUNCTION(BlueprintCallable, Category = "Audio", meta = (WorldContext = "WorldContextObject"))
	static AUDIOMIXER_API void SwapAudioOutputDevice(const UObject* WorldContextObject, const FString& NewDeviceId, const FOnCompletedDeviceSwap& OnCompletedDeviceSwap);
};


====================================


=== AudioMixerBuffer.cpp ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerBuffer.h"
#include "AudioMixerDevice.h"
#include "AudioDecompress.h"
#include "Interfaces/IAudioFormat.h"
#include "AudioMixerSourceDecode.h"
#include "AudioMixerTrace.h"
#include "AudioStreaming.h"

namespace Audio
{

	FMixerBuffer::FMixerBuffer(FAudioDevice* InAudioDevice, USoundWave* InWave, EBufferType::Type InBufferType)
		: FSoundBuffer(InAudioDevice)
		, RealtimeAsyncHeaderParseTask(nullptr)
		, DecompressionState(nullptr)
		, BufferType(InBufferType)
		, SampleRate(InWave->GetSampleRateForCurrentPlatform())
		, NumFrames(0)
		, BitsPerSample(16) // TODO: support more bits, currently hard-coded to 16
		, Data(nullptr)
		, DataSize(0)
		, bIsRealTimeSourceReady(false)
		, bIsDynamicResource(false)
	{
		// Set the base-class NumChannels to wave's NumChannels
		NumChannels = InWave->NumChannels;
	}

	FMixerBuffer::~FMixerBuffer()
	{
		if (bAllocationInPermanentPool)
		{
			UE_LOG(LogAudioMixer, Fatal, TEXT("Can't free resource '%s' as it was allocated in permanent pool."), *ResourceName);
		}

		if (DecompressionState)
		{
			delete DecompressionState;
			DecompressionState = nullptr;
		}

		switch (BufferType)
		{
			case EBufferType::PCM:
			{
				if (Data)
				{
					FMemory::Free((void*)Data);
				}
			}
			break;

			case EBufferType::PCMPreview:
			{
				if (bIsDynamicResource && Data)
				{
					FMemory::Free((void*)Data);
				}
			}
			break;

			case EBufferType::PCMRealTime:
			case EBufferType::Streaming:
			// Buffers are freed as part of the ~FSoundSource
			break;

			case EBufferType::Invalid:
			// nothing
			break;
		}
	}

	int32 FMixerBuffer::GetSize()
	{
		switch (BufferType)
		{
			case EBufferType::PCM:
			case EBufferType::PCMPreview:
				return DataSize;

			case EBufferType::PCMRealTime:
				return (DecompressionState ? DecompressionState->GetSourceBufferSize() : 0) + (MONO_PCM_BUFFER_SIZE * NumChannels);

			case EBufferType::Streaming:
				return MONO_PCM_BUFFER_SIZE * NumChannels;

			case EBufferType::Invalid:
			break;
		}

		return 0;
	}

	int32 FMixerBuffer::GetCurrentChunkIndex() const
	{
		if (DecompressionState)
		{
			return DecompressionState->GetCurrentChunkIndex();
		}

		return 0;
	}

	int32 FMixerBuffer::GetCurrentChunkOffset() const
	{
		if (DecompressionState)
		{
			return DecompressionState->GetCurrentChunkOffset();
		}
		return 0;
	}

	bool FMixerBuffer::IsRealTimeSourceReady()
	{
		// If we have a realtime async header parse task, then we check if its done
		if (RealtimeAsyncHeaderParseTask)
		{
			bool bIsDone = RealtimeAsyncHeaderParseTask->IsDone();
			if (bIsDone)
			{
				delete RealtimeAsyncHeaderParseTask;
				RealtimeAsyncHeaderParseTask = nullptr;
			}
			return bIsDone;
		}

		// Otherwise, we weren't a real time decoding sound buffer (or we've already asked and it was ready)
		return true;
	}

	bool FMixerBuffer::ReadCompressedInfo(USoundWave* SoundWave)
	{
		if (!DecompressionState)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Attempting to read compressed info without a compression state instance for resource '%s'"), *ResourceName);
			return false;
		}

		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(FMixerBuffer::ReadCompressedInfo);

		FSoundQualityInfo QualityInfo;

		if (!SoundWave->GetResourceData() || !SoundWave->GetResourceSize())
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Failed to read compressed info of '%s' because there was no resource data or invalid resource size."), *ResourceName);
			return false;
		}

		if (DecompressionState->ReadCompressedInfo(SoundWave->GetResourceData(), SoundWave->GetResourceSize(), &QualityInfo))
		{
			NumFrames = QualityInfo.SampleDataSize / (QualityInfo.NumChannels * sizeof(int16));
			return true;
		}
		else
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Failed to read compressed info of '%s'."), *ResourceName);
		}
		return false;
	}

	void FMixerBuffer::Seek(const float SeekTime)
	{
		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(FMixerBuffer::Seek);

		if (ensure(DecompressionState))
		{
			DecompressionState->SeekToTime(SeekTime);
		}
	}

	FMixerBuffer* FMixerBuffer::Init(FAudioDevice* InAudioDevice, USoundWave* InWave, bool bForceRealtime)
	{
		// Can't create a buffer without any source data
		if (InWave == nullptr || InWave->NumChannels == 0)
		{
			return nullptr;
		}

		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(FMixerBuffer::Init);

#if WITH_EDITOR
		InWave->InvalidateSoundWaveIfNeccessary();
#endif // WITH_EDITOR

		FAudioDeviceManager* AudioDeviceManager = FAudioDevice::GetAudioDeviceManager();

		FMixerBuffer* Buffer = nullptr;

		EDecompressionType DecompressionType = InWave->DecompressionType;

		if (bForceRealtime  && DecompressionType != DTYPE_Setup && DecompressionType != DTYPE_Streaming && DecompressionType != DTYPE_Procedural)
		{
			DecompressionType = DTYPE_RealTime;
		}

		switch (DecompressionType)
		{
			case DTYPE_Setup:
			{
				// We've circumvented the level-load precache mechanism, precache synchronously // TODO: support async loading here?
				const bool bSynchronous = true;
				InAudioDevice->Precache(InWave, bSynchronous, false);
				check(InWave->DecompressionType != DTYPE_Setup);
				Buffer = Init(InAudioDevice, InWave, bForceRealtime);
			}
			break;
		
			case DTYPE_Procedural:
			{
				// Always create a new buffer for procedural or bus buffers
				Buffer = FMixerBuffer::CreateProceduralBuffer(InAudioDevice, InWave);
			}
			break;

			case DTYPE_RealTime:
			{
				// Always create a new buffer for real-time buffers
				Buffer = FMixerBuffer::CreateRealTimeBuffer(InAudioDevice, InWave);
			}
			break;
			
			case DTYPE_Streaming:
			{
				Buffer = FMixerBuffer::CreateStreamingBuffer(InAudioDevice, InWave);
			}
			break;

			case DTYPE_Invalid:
			default:
			{
				// Invalid will be set if the wave cannot be played.
			}
			break;
		}

		return Buffer;
	}

	FMixerBuffer* FMixerBuffer::CreatePreviewBuffer(FAudioDevice* AudioDevice, USoundWave* InWave)
	{
		// Create a new buffer
		FMixerBuffer* Buffer = new FMixerBuffer(AudioDevice, InWave, EBufferType::PCMPreview);

		Buffer->bIsDynamicResource = InWave->bDynamicResource;
		return Buffer;
	}

	FMixerBuffer* FMixerBuffer::CreateProceduralBuffer(FAudioDevice* AudioDevice, USoundWave* InWave)
	{
		FMixerBuffer* Buffer = new FMixerBuffer(AudioDevice, InWave, EBufferType::PCMRealTime);

		// No tracking of this resource needed
		Buffer->ResourceID = 0;
		InWave->ResourceID = 0;

		return Buffer;
	}

	FMixerBuffer* FMixerBuffer::CreateNativeBuffer(FAudioDevice* AudioDevice, USoundWave* InWave)
	{
		check(InWave->GetPrecacheState() == ESoundWavePrecacheState::Done);

		FMixerBuffer* Buffer = new FMixerBuffer(AudioDevice, InWave, EBufferType::PCM);
		return Buffer;
	}

	FMixerBuffer* FMixerBuffer::CreateStreamingBuffer(FAudioDevice* AudioDevice, USoundWave* InWave)
	{
		if (!InWave)
		{
			return nullptr;
		}
		
		// Ignore attempts to create if this wave has been flagged as containing errors
		if (InWave->HasError())
		{
			UE_LOG(LogAudioMixer, VeryVerbose, TEXT("FMixerBuffer::CreateStreamingBuffer, ignoring '%s' as it contains previously seen errors"), *InWave->GetName() );
			return nullptr;
		}

		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(FMixerBuffer::CreateStreamingBuffer);

		FMixerBuffer* Buffer = new FMixerBuffer(AudioDevice, InWave, EBufferType::Streaming);

		FSoundQualityInfo QualityInfo = { 0 };
		
		Buffer->DecompressionState = IAudioInfoFactoryRegistry::Get().Create(InWave->GetRuntimeFormat());

		// Get the header information of our compressed format
		if (Buffer->DecompressionState && Buffer->DecompressionState->StreamCompressedInfo(InWave, &QualityInfo))
		{
			// Refresh the wave data
			InWave->SetSampleRate(QualityInfo.SampleRate);
			InWave->NumChannels = QualityInfo.NumChannels;
			if (QualityInfo.SampleDataSize != 0)
			{
				InWave->RawPCMDataSize = QualityInfo.SampleDataSize;
			}
			if (QualityInfo.Duration != 0.0f)
			{
				InWave->Duration = QualityInfo.Duration;
			}
		}
		else
		{
			// Failed to stream in compressed info, so mark the wave as having an error.
			if (Buffer->DecompressionState)
			{
				InWave->SetError(TEXT("ICompressedAudioInfo::StreamCompressedInfo failed"));
			}

			// When set to seekable streaming, missing the first chunk is possible and
			// does not signify any issue with the asset itself, so don't mark it as invalid.
			if (InWave && !InWave->IsSeekable())
			{
				UE_LOG(LogAudioMixer, Warning,
					TEXT("FMixerBuffer::CreateStreamingBuffer failed to StreamCompressedInfo on SoundWave '%s'.  Invalidating wave resource data (asset now requires re-cook)."),
					*InWave->GetName());

				InWave->DecompressionType = DTYPE_Invalid;
				InWave->NumChannels = 0;
				InWave->RemoveAudioResource();
			}

			delete Buffer;
			Buffer = nullptr;
		}

		return Buffer;
	}

	FMixerBuffer* FMixerBuffer::CreateRealTimeBuffer(FAudioDevice* AudioDevice, USoundWave* InWave)
	{
		check(AudioDevice);
		check(InWave);
		check(InWave->GetPrecacheState() == ESoundWavePrecacheState::Done);

		// Create a new buffer for real-time sounds
		FMixerBuffer* Buffer = new FMixerBuffer(AudioDevice, InWave, EBufferType::PCMRealTime);

		FName FormatName = InWave->GetRuntimeFormat();
		if (InWave->GetResourceData() == nullptr)
		{
			InWave->InitAudioResource(FormatName);
		}

		Buffer->DecompressionState = IAudioInfoFactoryRegistry::Get().Create(FormatName);
		check(Buffer->DecompressionState);

		if (Buffer->DecompressionState)
		{
			FHeaderParseAudioTaskData NewTaskData;
			NewTaskData.MixerBuffer = Buffer;
			NewTaskData.SoundWave = InWave;

			check(Buffer->RealtimeAsyncHeaderParseTask == nullptr);
			Buffer->RealtimeAsyncHeaderParseTask = CreateAudioTask(AudioDevice->DeviceID, NewTaskData);

			Buffer->NumChannels = InWave->NumChannels;
		}
		else
		{
			InWave->DecompressionType = DTYPE_Invalid;
			InWave->NumChannels = 0;

			InWave->RemoveAudioResource();

			delete Buffer;
			Buffer = nullptr;
		}

		return Buffer;
	}

	EBufferType::Type FMixerBuffer::GetType() const
	{
		return BufferType;
	}

	bool FMixerBuffer::IsRealTimeBuffer() const
	{
		return BufferType == EBufferType::PCMRealTime || BufferType == EBufferType::Streaming;
	}

	ICompressedAudioInfo* FMixerBuffer::GetDecompressionState(bool bTakesOwnership)
	{
		ICompressedAudioInfo* Output = DecompressionState;
		if (bTakesOwnership)
		{
			DecompressionState = nullptr;
		}
		return Output;
	}

	void FMixerBuffer::GetPCMData(uint8** OutData, uint32* OutDataSize)
	{
		*OutData = Data;
		*OutDataSize = DataSize;
	}

	void FMixerBuffer::EnsureHeaderParseTaskFinished()
	{
		if (RealtimeAsyncHeaderParseTask)
		{
			RealtimeAsyncHeaderParseTask->EnsureCompletion();
			delete RealtimeAsyncHeaderParseTask;
			RealtimeAsyncHeaderParseTask = nullptr;
		}
	}
}

============================


=== AudioMixerBuffer.h ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "AudioMixer.h"
#include "Audio.h"

namespace Audio
{
	namespace EBufferType
	{
		enum Type
		{
			PCM,
			PCMPreview,
			PCMRealTime,
			Streaming,
			Invalid,
		};
	}

	class FMixerDevice;
	class FMixerBuffer;
	class IAudioTask;

	class FMixerBuffer : public FSoundBuffer
	{
	public:
		FMixerBuffer(FAudioDevice* InAudioDevice, USoundWave* InWave, EBufferType::Type InBufferType);
		~FMixerBuffer();

		//~ Begin FSoundBuffer Interface
		int32 GetSize() override;
		int32 GetCurrentChunkIndex() const override;
		int32 GetCurrentChunkOffset() const override;
		bool IsRealTimeSourceReady() override;
		bool ReadCompressedInfo(USoundWave* SoundWave) override;
		void Seek(const float SeekTime) override;
		//~ End FSoundBuffer Interface

		static FMixerBuffer* Init(FAudioDevice* AudioDevice, USoundWave* InWave, bool bForceRealtime);
		static FMixerBuffer* CreatePreviewBuffer(FAudioDevice* AudioDevice, USoundWave* InWave);
		static FMixerBuffer* CreateProceduralBuffer(FAudioDevice* AudioDevice, USoundWave* InWave);
		static FMixerBuffer* CreateNativeBuffer(FAudioDevice* AudioDevice, USoundWave* InWave);
		static FMixerBuffer* CreateStreamingBuffer(FAudioDevice* AudioDevice, USoundWave* InWave);
		static FMixerBuffer* CreateRealTimeBuffer(FAudioDevice* AudioDevice, USoundWave* InWave);

		/** Returns the buffer's format */
		EBufferType::Type GetType() const;
		bool IsRealTimeBuffer() const;

		/** Retrieve the compressed audio info pointer. This transfers ownership of the decompression state. */
		ICompressedAudioInfo* GetDecompressionState(bool bTakesOwnership = false);

		/** Returns the contained raw PCM data and data size */
		void GetPCMData(uint8** OutData, uint32* OutDataSize);

		void EnsureHeaderParseTaskFinished();

		float GetSampleRate() const { return SampleRate; }
		int32 GetNumChannels() const { return NumChannels; }
		uint32 GetNumFrames() const { return NumFrames; }
		void InitSampleRate(const float InSampleRate) { SampleRate = InSampleRate; }

	private:

		/** Async task for parsing real-time decompressed compressed info headers. */
		IAudioTask* RealtimeAsyncHeaderParseTask;

		/** Wrapper to handle the decompression of audio codecs. */
		ICompressedAudioInfo* DecompressionState;

		/** Format of the sound referenced by this buffer */
		EBufferType::Type BufferType;

		/** Sample rate of the audio buffer. */
		int32 SampleRate;

		/** Number of frames of the audio. */
		uint32 NumFrames;

		/** Number of bits per sample. */
		int16 BitsPerSample;

		/** Ptr to raw PCM data. */
		uint8* Data;

		/** The raw PCM data size. */
		uint32 DataSize;

		/** Bool indicating the that the real-time source is ready for real-time decoding. */
		FThreadSafeBool bIsRealTimeSourceReady;

		/** Set to true when the PCM data should be freed when the buffer is destroyed */
		bool bIsDynamicResource;
	};
}


==========================


=== AudioMixerBus.cpp ===
=========================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerBus.h"

#include "Algo/ForEach.h"
#include "AudioMixerSourceManager.h"
#include "DSP/AlignedBuffer.h"
#include "DSP/FloatArrayMath.h"

namespace Audio
{
	FMixerAudioBus::FMixerAudioBus(FMixerSourceManager* InSourceManager, bool bInIsAutomatic, int32 InNumChannels)
		: CurrentBufferIndex(1)
		, NumChannels(InNumChannels)
		, NumFrames(InSourceManager->GetNumOutputFrames())
		, SourceManager(InSourceManager)
		, bIsAutomatic(bInIsAutomatic)
	{
		SetNumOutputChannels(NumChannels);
	}

	void FMixerAudioBus::SetNumOutputChannels(int32 InNumOutputChannels)
	{
		NumChannels = InNumOutputChannels;
		const int32 NumSamples = NumChannels * NumFrames;
		for (int32 i = 0; i < 2; ++i)
		{
			MixedSourceData[i].Reset();
			MixedSourceData[i].AddZeroed(NumSamples);
		}
	}

	void FMixerAudioBus::Update()
	{
		CurrentBufferIndex = !CurrentBufferIndex;
	}

	void FMixerAudioBus::AddInstanceId(const int32 InSourceId, int32 InNumOutputChannels)
	{
		InstanceIds.Add(InSourceId);
	}

	bool FMixerAudioBus::RemoveInstanceId(const int32 InSourceId)
	{
		InstanceIds.Remove(InSourceId);

		// Return true if there is no more instances or sends
		return bIsAutomatic && !InstanceIds.Num() && !AudioBusSends[(int32)EBusSendType::PreEffect].Num() && !AudioBusSends[(int32)EBusSendType::PostEffect].Num();
	}

	void FMixerAudioBus::AddSend(EBusSendType BusSendType, const FAudioBusSend& InAudioBusSend)
	{
		// Make sure we don't have duplicates in the bus sends
		for (FAudioBusSend& BusSend : AudioBusSends[(int32)BusSendType])
		{
			// If it's already added, just update the send level
			if (BusSend.SourceId == InAudioBusSend.SourceId)
			{
				BusSend.SendLevel = InAudioBusSend.SendLevel;
				return;
			}
		}

		// It's a new source id so just add it
		AudioBusSends[(int32)BusSendType].Add(InAudioBusSend);
	}

	bool FMixerAudioBus::RemoveSend(EBusSendType BusSendType, const int32 InSourceId)
	{
		TArray<FAudioBusSend>& Sends = AudioBusSends[(int32)BusSendType];

		for (int32 i = Sends.Num() - 1; i >= 0; --i)
		{
			// Remove this source id's send
			if (Sends[i].SourceId == InSourceId)
			{
				Sends.RemoveAtSwap(i, EAllowShrinking::No);

				// There will only be one entry
				break;
			}
		}

		// Return true if there is no more instances or sends and this is an automatic audio bus
		return bIsAutomatic && !InstanceIds.Num() && !AudioBusSends[(int32)EBusSendType::PreEffect].Num() && !AudioBusSends[(int32)EBusSendType::PostEffect].Num();
	}

	void FMixerAudioBus::MixBuffer()
	{
		// Mix the patch mixer's inputs into the source data
		const int32 NumSamples = NumFrames * NumChannels;
		const int32 NumOutputFrames = SourceManager->GetNumOutputFrames();

		FAlignedFloatBuffer& MixBuffer = MixedSourceData[CurrentBufferIndex];
		float* BusDataBufferPtr = MixBuffer.GetData();

		PatchMixer.PopAudio(BusDataBufferPtr, NumSamples, false);

		for (int32 BusSendType = 0; BusSendType < (int32)EBusSendType::Count; ++BusSendType)
		{
			// Loop through the send list for this bus
			for (const FAudioBusSend& AudioBusSend : AudioBusSends[BusSendType])
			{
				const float* SourceBufferPtr = nullptr;

				// If the audio source mixing to this audio bus is itself a source bus, we need to use the previous renderer buffer to avoid infinite recursion
				if (SourceManager->IsSourceBus(AudioBusSend.SourceId))
				{
					SourceBufferPtr = SourceManager->GetPreviousSourceBusBuffer(AudioBusSend.SourceId);
				}
				// If the source mixing into this is not itself a bus, then simply mix the pre-attenuation audio of the source into the bus
				// The source will have already computed its buffers for this frame
				else if (BusSendType == (int32)EBusSendType::PostEffect)
				{
					SourceBufferPtr = SourceManager->GetPreDistanceAttenuationBuffer(AudioBusSend.SourceId);
				}
				else
				{
					SourceBufferPtr = SourceManager->GetPreEffectBuffer(AudioBusSend.SourceId);
				}

				// It's possible we may not have a source buffer ptr here if the sound is not playing
				if (SourceBufferPtr)
				{
					const int32 NumSourceChannels = SourceManager->GetNumChannels(AudioBusSend.SourceId);
					const int32 NumSourceSamples = NumSourceChannels * NumOutputFrames;

					// Up-mix or down-mix if source channels differ from bus channels
					if (NumSourceChannels != NumChannels)
					{
						FAlignedFloatBuffer ChannelMap;
						SourceManager->Get2DChannelMap(AudioBusSend.SourceId, NumChannels, ChannelMap);
						Algo::ForEach(ChannelMap, [SendLevel = AudioBusSend.SendLevel](float& ChannelValue) { ChannelValue *= SendLevel; });
						DownmixAndSumIntoBuffer(NumSourceChannels, NumChannels, SourceBufferPtr, BusDataBufferPtr, NumOutputFrames, ChannelMap.GetData());
					}
					else
					{
						TArrayView<const float> SourceBufferView(SourceBufferPtr, NumOutputFrames * NumChannels);
						TArrayView<float> BusDataBufferView(BusDataBufferPtr, NumOutputFrames * NumChannels);
						ArrayMixIn(SourceBufferView, BusDataBufferView, AudioBusSend.SendLevel);
					}
				}
			}
		}

		// Send the mix to the patch splitter's outputs
		PatchSplitter.PushAudio(BusDataBufferPtr, NumSamples);
	}

	void FMixerAudioBus::CopyCurrentBuffer(Audio::FAlignedFloatBuffer& InChannelMap, int32 InNumOutputChannels, FAlignedFloatBuffer& OutBuffer, int32 NumOutputFrames) const
	{
		check(NumChannels != InNumOutputChannels);
		DownmixAndSumIntoBuffer(NumChannels, InNumOutputChannels, MixedSourceData[CurrentBufferIndex], OutBuffer, InChannelMap.GetData());
	}

	void FMixerAudioBus::CopyCurrentBuffer(int32 InNumOutputChannels, FAlignedFloatBuffer& OutBuffer, int32 NumOutputFrames) const
	{
		const float* RESTRICT CurrentBuffer = GetCurrentBusBuffer();

		check(NumChannels == InNumOutputChannels);

		FMemory::Memcpy(OutBuffer.GetData(), CurrentBuffer, sizeof(float) * NumOutputFrames * InNumOutputChannels);
	}

	const float* FMixerAudioBus::GetCurrentBusBuffer() const
	{
		return MixedSourceData[CurrentBufferIndex].GetData();
	}

	const float* FMixerAudioBus::GetPreviousBusBuffer() const
	{
		return MixedSourceData[!CurrentBufferIndex].GetData();
	}

	void FMixerAudioBus::AddNewPatchOutput(const FPatchOutputStrongPtr& InPatchOutputStrongPtr)
	{
		PatchSplitter.AddNewPatch(InPatchOutputStrongPtr);
	}

	void FMixerAudioBus::AddNewPatchInput(const FPatchInput& InPatchInput)
	{
		return PatchMixer.AddNewInput(InPatchInput);
	}

	void FMixerAudioBus::RemovePatchInput(const FPatchInput& PatchInput)
	{
		return PatchMixer.RemovePatch(PatchInput);
	}
}

=========================


=== AudioMixerBus.h ===
=======================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "Audio.h"
#include "DSP/MultithreadedPatching.h"
#include "Sound/AudioSettings.h"

namespace Audio
{
	class FMixerSourceManager;

	// Struct holding mappings of runtime source ids (bus instances) to bus send level
	struct FAudioBusSend
	{
		int32 SourceId = INDEX_NONE;
		float SendLevel = 0.0f;
	};

	// Bus instance data. Holds source id bus instances and bus sends data
	class FMixerAudioBus
	{
	public:
		// Allow anybody to add a pre-existing patch output object to the audio bus
		void AddNewPatchOutput(const FPatchOutputStrongPtr& InPatchOutputStrongPtr);

		// Allow anybody to write audio into this audio bus from any thread.
		void AddNewPatchInput(const FPatchInput& InPatchInput);

		// Allow anybody to write audio into this audio bus from any thread.
		void RemovePatchInput(const FPatchInput& InPatchInput);

	private:

		// Creates an audio bus.
		// SourceMnager		The owning source manager object.
		// bInIsAutomatic	Whether or not this audio bus was created automatically via source buses.
		// InNumChannels	The number of channels of the source bus.
		// InNumFrames		The number of frames to mix per mix buffer call. I.e. source manager render size.
		FMixerAudioBus(FMixerSourceManager* SourceManager, bool bInIsAutomatic, int32 InNumChannels);
		
		// Sets whether or not this audio bus is automatic.
		void SetAutomatic(bool bInIsAutomatic) { bIsAutomatic = bInIsAutomatic; }

		// Returns if this is a manual audio bus vs automatic
		bool IsAutomatic() const { return bIsAutomatic; }

		// Returns the number of channels of the audio bus
		int32 GetNumChannels() const { return NumChannels; }

		// Update the mixer bus after a render block
		void Update();

		// Adds a source id for instances of this bus
		void AddInstanceId(const int32 InSourceInstanceId, int32 InNumOutputChannels);

		// Removes the source id from this bus. Returns true if there are no more instances or sends.
		bool RemoveInstanceId(const int32 InSourceId);

		// Adds a bus send to the bus
		void AddSend(EBusSendType BusSendType, const FAudioBusSend& InBusSend);

		// Removes the source instance from this bus's send list
		bool RemoveSend(EBusSendType BusSendType, const int32 InSourceId);

		// Gets the current mixed bus buffer
		const float* GetCurrentBusBuffer() const;

		// Gets the previous mixed bus buffer
		const float* GetPreviousBusBuffer() const;

		// Compute the mixed buffer
		void MixBuffer();

		// Copies the current internal buffer to a provided output buffer. Only supports mono or stereo input/output formats.
		void CopyCurrentBuffer(Audio::FAlignedFloatBuffer& InChannelMap, int32 InNumOutputChannels, FAlignedFloatBuffer& OutBuffer, int32 NumOutputFrames) const;
		void CopyCurrentBuffer(int32 InNumOutputChannels, FAlignedFloatBuffer& OutBuffer, int32 NumOutputFrames) const;

		// If this bus was constructed before
		void SetNumOutputChannels(int32 InNumOutputChannels);

		// Array of instance ids. These are sources which are instances of this.
		// It's possible for this data to have bus sends but no instance ids.
		// This means a source would send its audio to the bus if the bus had an instance.
		// Once and instance plays, it will then start sending its audio to the bus instances.
		TArray<int32> InstanceIds;

		// Bus sends to this instance
		TArray<FAudioBusSend> AudioBusSends[(int32)EBusSendType::Count];

		// The mixed source data. This is double-buffered to allow buses to send audio to themselves.
		// Buses feed audio to each other by storing their previous buffer. Current buses mix in previous other buses (including themselves)
		FAlignedFloatBuffer MixedSourceData[2];

		// The index of the bus data currently being rendered
		int32 CurrentBufferIndex;

		// The number of channels of this bus
		int32 NumChannels;

		// The number of output frames
		int32 NumFrames;

		// Owning soruce manager
		FMixerSourceManager* SourceManager;

		// Multiple places can produce and consume from audio buses
		Audio::FPatchMixer PatchMixer;
		Audio::FPatchSplitter PatchSplitter;

		// Was created manually, not via source buses.
		bool bIsAutomatic;

		friend FMixerSourceManager;
		friend FMixerSubmix;
	};

}

=======================


=== AudioMixerChannelMaps.cpp ===
=================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Audio.h"
#include "AudioMixer.h"
#include "AudioMixerDevice.h"
#include "DSP/ChannelMap.h"
#include "Misc/ConfigCacheIni.h"

namespace Audio
{
	// Make a channel map cache
	static TArray<TArray<float>> ChannelMapCache;
	static TArray<TArray<float>> VorbisChannelMapCache;

	int32 FMixerDevice::GetChannelMapCacheId(const int32 NumSourceChannels, const int32 NumOutputChannels, const bool bIsCenterChannelOnly)
	{
		if (ensure(NumSourceChannels > 0) && 
			ensure(NumOutputChannels > 0) &&
			ensure(NumSourceChannels <= AUDIO_MIXER_MAX_OUTPUT_CHANNELS) &&
			ensure(NumOutputChannels <= AUDIO_MIXER_MAX_OUTPUT_CHANNELS) )
		{
			int32 Index = (NumSourceChannels - 1) + AUDIO_MIXER_MAX_OUTPUT_CHANNELS * (NumOutputChannels - 1);
			if (bIsCenterChannelOnly)
			{
				Index += AUDIO_MIXER_MAX_OUTPUT_CHANNELS * AUDIO_MIXER_MAX_OUTPUT_CHANNELS;
			}			
			return Index;
		}			   		 
		return 0;	
	}

	void FMixerDevice::Get2DChannelMap(bool bIsVorbis, const int32 NumSourceChannels, const bool bIsCenterChannelOnly, Audio::FAlignedFloatBuffer& OutChannelMap) const
	{
		Get2DChannelMap(bIsVorbis, NumSourceChannels, PlatformInfo.NumChannels, bIsCenterChannelOnly, OutChannelMap);
	}

	void FMixerDevice::Get2DChannelMap(bool bIsVorbis, const int32 NumSourceChannels, const int32 NumOutputChannels, const bool bIsCenterChannelOnly, Audio::FAlignedFloatBuffer& OutChannelMap)
	{
		if (NumSourceChannels <= 0 ||
			NumOutputChannels <= 0 ||
			NumSourceChannels > AUDIO_MIXER_MAX_OUTPUT_CHANNELS || 
			NumOutputChannels > AUDIO_MIXER_MAX_OUTPUT_CHANNELS
			)
		{
			// Return a zero'd channel map buffer in the case of an unsupported channel configuration
			OutChannelMap.AddZeroed(AUDIO_MIXER_MAX_OUTPUT_CHANNELS * AUDIO_MIXER_MAX_OUTPUT_CHANNELS);

#if !NO_LOGGING			
			// Anti-Spam warning.
			static uint64 TimeOfLastLogMsgInCycles = 0;
			constexpr double MinTimeBetweenWarningsInMs = 5000.f; // 5 Secs.
			double ElapsedTimeInMs = FPlatformTime::ToMilliseconds64(FPlatformTime::Cycles64() - TimeOfLastLogMsgInCycles);

			if (ElapsedTimeInMs > MinTimeBetweenWarningsInMs)
			{
				TimeOfLastLogMsgInCycles = FPlatformTime::Cycles64();
				UE_LOG(LogAudioMixer, Warning, TEXT("Unsupported source channel (%d) count or output channels (%d)"), NumSourceChannels, NumOutputChannels);
			}	
#endif //!NO_LOGGING
			
			// Bail.
			return;
		}

		// 5.1 Vorbis files have a non-standard channel order so pick a channel map from the 5.1 vorbis channel maps based on the output channels
		if (bIsVorbis && NumSourceChannels == 6)
		{
			OutChannelMap = VorbisChannelMapCache[NumOutputChannels - 1];
		}
		else
		{
			const int32 CacheID = GetChannelMapCacheId(NumSourceChannels, NumOutputChannels, bIsCenterChannelOnly);
			OutChannelMap = ChannelMapCache[CacheID];
		}
	}

	void FMixerDevice::CacheChannelMap(const int32 NumSourceChannels, const int32 NumOutputChannels, const bool bIsCenterChannelOnly)
	{
		if (NumSourceChannels <= 0 ||
			NumOutputChannels <= 0 ||
			NumSourceChannels > AUDIO_MIXER_MAX_OUTPUT_CHANNELS || 
			NumOutputChannels > AUDIO_MIXER_MAX_OUTPUT_CHANNELS
			)
		{
			return;
		}
		// Generate the unique cache ID for the channel count configuration
		const int32 CacheID = GetChannelMapCacheId(NumSourceChannels, NumOutputChannels, bIsCenterChannelOnly);

		// Setup parameters for generating channel maps. 
		FChannelMapParams Params;
		Params.NumInputChannels = NumSourceChannels;
		Params.NumOutputChannels = NumOutputChannels;
		Params.Order = EChannelMapOrder::OutputMajorOrder; // Downmix code expects OutputMajorOrder
		Params.bIsCenterChannelOnly = bIsCenterChannelOnly;

		switch (MonoChannelUpmixMethod)
		{
			case EMonoChannelUpmixMethod::Linear:
				Params.MonoUpmixMethod = EChannelMapMonoUpmixMethod::Linear;
				break;

			case EMonoChannelUpmixMethod::EqualPower:
				Params.MonoUpmixMethod = EChannelMapMonoUpmixMethod::EqualPower;
				break;

			case EMonoChannelUpmixMethod::FullVolume:
				Params.MonoUpmixMethod = EChannelMapMonoUpmixMethod::FullVolume;
				break;

			default:
				Params.MonoUpmixMethod = EChannelMapMonoUpmixMethod::EqualPower;
				checkNoEntry();
		}

		bool bSuccess = Create2DChannelMap(Params, ChannelMapCache[CacheID]);
		check(bSuccess);
	}

	void FMixerDevice::InitializeChannelMaps()
	{	
		// If we haven't yet created the static channel map cache
		if (!ChannelMapCache.Num())
		{
			// Make a matrix big enough for every possible configuration, double it to account for center channel only 
			ChannelMapCache.AddZeroed(AUDIO_MIXER_MAX_OUTPUT_CHANNELS * AUDIO_MIXER_MAX_OUTPUT_CHANNELS * 2);

			// Create a vorbis channel map cache
			VorbisChannelMapCache.AddZeroed(AUDIO_MIXER_MAX_OUTPUT_CHANNELS);

			// Loop through all input to output channel map configurations and cache them
			for (int32 OutputChannelCount = 1; OutputChannelCount < AUDIO_MIXER_MAX_OUTPUT_CHANNELS + 1; ++OutputChannelCount)
			{
				for (int32 InputChannelCount = 1; InputChannelCount < AUDIO_MIXER_MAX_OUTPUT_CHANNELS + 1; ++InputChannelCount)
				{
					// Cache non-vorbis channel maps
					CacheChannelMap(InputChannelCount, OutputChannelCount, true /* bIsCenterChannelOnly */);
					CacheChannelMap(InputChannelCount, OutputChannelCount, false /* bIsCenterChannelOnly */);
				}
				// Cache vorbis channel maps. 
				bool bSuccess = CreateVorbis2DChannelMap(OutputChannelCount, EChannelMapOrder::OutputMajorOrder, VorbisChannelMapCache[OutputChannelCount - 1]);
				check(bSuccess);
			}
		}
	}

	void FMixerDevice::InitializeChannelAzimuthMap(const int32 NumChannels)
	{
		// Initialize and cache 2D channel maps
		InitializeChannelMaps();

		// Now setup the hard-coded values
		if (NumChannels == 2)
		{
			DefaultChannelAzimuthPositions[EAudioMixerChannel::FrontLeft] = { EAudioMixerChannel::FrontLeft, 270 };
			DefaultChannelAzimuthPositions[EAudioMixerChannel::FrontRight] = { EAudioMixerChannel::FrontRight, 90 };
		}
		else
		{
			DefaultChannelAzimuthPositions[EAudioMixerChannel::FrontLeft] = { EAudioMixerChannel::FrontLeft, 330 };
			DefaultChannelAzimuthPositions[EAudioMixerChannel::FrontRight] = { EAudioMixerChannel::FrontRight, 30 };
		}

		if (bAllowCenterChannel3DPanning)
		{
			// Allow center channel for azimuth computations
			DefaultChannelAzimuthPositions[EAudioMixerChannel::FrontCenter] = { EAudioMixerChannel::FrontCenter, 0 };
		}
		else
		{
			// Ignore front center for azimuth computations. 
			DefaultChannelAzimuthPositions[EAudioMixerChannel::FrontCenter] = { EAudioMixerChannel::FrontCenter, INDEX_NONE };
		}

		// Always ignore low frequency channel for azimuth computations. 
		DefaultChannelAzimuthPositions[EAudioMixerChannel::LowFrequency] = { EAudioMixerChannel::LowFrequency, INDEX_NONE };

		DefaultChannelAzimuthPositions[EAudioMixerChannel::BackLeft] = { EAudioMixerChannel::BackLeft, 210 };
		DefaultChannelAzimuthPositions[EAudioMixerChannel::BackRight] = { EAudioMixerChannel::BackRight, 150 };
		DefaultChannelAzimuthPositions[EAudioMixerChannel::FrontLeftOfCenter] = { EAudioMixerChannel::FrontLeftOfCenter, 15 };
		DefaultChannelAzimuthPositions[EAudioMixerChannel::FrontRightOfCenter] = { EAudioMixerChannel::FrontRightOfCenter, 345 };
		DefaultChannelAzimuthPositions[EAudioMixerChannel::BackCenter] = { EAudioMixerChannel::BackCenter, 180 };
		DefaultChannelAzimuthPositions[EAudioMixerChannel::SideLeft] = { EAudioMixerChannel::SideLeft, 250 };
		DefaultChannelAzimuthPositions[EAudioMixerChannel::SideRight] = { EAudioMixerChannel::SideRight, 110 };

		// Check any engine ini overrides for these default positions
		if (NumChannels != 2)
		{
			int32 AzimuthPositionOverride = 0;
			for (int32 ChannelOverrideIndex = 0; ChannelOverrideIndex < EAudioMixerChannel::MaxSupportedChannel; ++ChannelOverrideIndex)
			{
				EAudioMixerChannel::Type MixerChannelType = EAudioMixerChannel::Type(ChannelOverrideIndex);
				
				// Don't allow overriding the center channel if its not allowed to spatialize.
				if (MixerChannelType != EAudioMixerChannel::FrontCenter || bAllowCenterChannel3DPanning)
				{
					const TCHAR* ChannelName = EAudioMixerChannel::ToString(MixerChannelType);
					if (GConfig->GetInt(TEXT("AudioChannelAzimuthMap"), ChannelName, AzimuthPositionOverride, GEngineIni))
					{
						if (AzimuthPositionOverride >= 0 && AzimuthPositionOverride < 360)
						{
							// Make sure no channels have this azimuth angle first, otherwise we'll get some bad math later
							bool bIsUnique = true;
							for (int32 ExistingChannelIndex = 0; ExistingChannelIndex < EAudioMixerChannel::MaxSupportedChannel; ++ExistingChannelIndex)
							{
								if (DefaultChannelAzimuthPositions[ExistingChannelIndex].Azimuth == AzimuthPositionOverride)
								{
									bIsUnique = false;

									// If the override is setting the same value as our default, don't print a warning
									if (ExistingChannelIndex != ChannelOverrideIndex)
									{
										const TCHAR* ExistingChannelName = EAudioMixerChannel::ToString(EAudioMixerChannel::Type(ExistingChannelIndex));
										UE_LOG(LogAudioMixer, Warning, TEXT("Azimuth value '%d' for audio mixer channel '%s' is already used by '%s'. Azimuth values must be unique."),
											AzimuthPositionOverride, ChannelName, ExistingChannelName);
									}
									break;
								}
							}

							if (bIsUnique)
							{
								DefaultChannelAzimuthPositions[MixerChannelType].Azimuth = AzimuthPositionOverride;
							}
						}
						else
						{
							UE_LOG(LogAudioMixer, Warning, TEXT("Azimuth value, %d, for audio mixer channel %s out of range. Must be [0, 360)."), AzimuthPositionOverride, ChannelName);
						}
					}
				}
			}
		}

		// Sort the current mapping by azimuth
		struct FCompareByAzimuth
		{
			FORCEINLINE bool operator()(const FChannelPositionInfo& A, const FChannelPositionInfo& B) const
			{
				return A.Azimuth < B.Azimuth;
			}
		};

		// Build a array of azimuth positions of only the current audio device's output channels
		DeviceChannelAzimuthPositions.Reset();

		// Setup the default channel azimuth positions
		TArray<FChannelPositionInfo> DevicePositions;
		for (EAudioMixerChannel::Type Channel : PlatformInfo.OutputChannelArray)
		{
			// Only track non-LFE and non-Center channel azimuths for use with 3d channel mappings
			if (Channel != EAudioMixerChannel::LowFrequency && DefaultChannelAzimuthPositions[Channel].Azimuth >= 0)
			{
				DeviceChannelAzimuthPositions.Add(DefaultChannelAzimuthPositions[Channel]);
			}
		}
		DeviceChannelAzimuthPositions.Sort(FCompareByAzimuth());
	}

	const TArray<EAudioMixerChannel::Type>& FMixerDevice::GetChannelArray() const
	{
		return PlatformInfo.OutputChannelArray;
	}
	const FChannelPositionInfo* FMixerDevice::GetDefaultChannelPositions() const
	{
		return DefaultChannelAzimuthPositions;
	}
}

=================================


=== AudioMixerClock.cpp ===
===========================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Quartz/AudioMixerClock.h"
#include "Quartz/AudioMixerClockManager.h"
#include "AudioMixerSourceManager.h"
#include "Sound/QuartzSubscription.h"
#include "HAL/UnrealMemory.h" // Memcpy


static float HeadlessClockSampleRateCvar = 100000.f;
FAutoConsoleVariableRef CVarHeadlessClockSampleRate(
	TEXT("au.Quartz.HeadlessClockSampleRate"),
	HeadlessClockSampleRateCvar,
	TEXT("Sample rate to use for Quartz Clocks/Metronomes when no Mixer Device is present.\n")
	TEXT("0: Not Enabled, 1: Enabled"),
	ECVF_Default);

namespace Audio
{
	// FQuartzClockProxy Implementation
	// ctor
	FQuartzClockProxy::FQuartzClockProxy(TSharedPtr<FQuartzClock, ESPMode::ThreadSafe> InClock)
		: ClockId(InClock->GetName())
		, SharedQueue(InClock->GetCommandQueue())
		, ClockWeakPtr(InClock)
	{
	}

	bool FQuartzClockProxy::IsValid() const
	{
		return SharedQueue.Pin().IsValid();
	}

	bool FQuartzClockProxy::DoesClockExist() const
	{
		return IsValid();
	}

	bool FQuartzClockProxy::IsClockRunning() const
	{
		TSharedPtr<FQuartzClock, ESPMode::ThreadSafe> ClockPtr = ClockWeakPtr.Pin();
		if (!ClockPtr)
		{
			return false;
		}

		return ClockPtr->IsRunning();
	}

	float FQuartzClockProxy::GetDurationOfQuantizationTypeInSeconds(const EQuartzCommandQuantization& QuantizationType, float Multiplier) const
	{
		TSharedPtr<FQuartzClock, ESPMode::ThreadSafe> ClockPtr = ClockWeakPtr.Pin();
		if (!ClockPtr)
		{
			return 0.f;
		}

		return ClockPtr->GetDurationOfQuantizationTypeInSeconds(QuantizationType, Multiplier);
	}

	float FQuartzClockProxy::GetBeatProgressPercent(
		const EQuartzCommandQuantization& QuantizationType) const
	{
		TSharedPtr<FQuartzClock, ESPMode::ThreadSafe> ClockPtr = ClockWeakPtr.Pin();
		if (!ClockPtr)
		{
			return 0.f;
		}

		return ClockPtr->GetBeatProgressPercent(QuantizationType);
	}

	Audio::FQuartzClockTickRate FQuartzClockProxy::GetTickRate() const
	{
		TSharedPtr<FQuartzClock, ESPMode::ThreadSafe> ClockPtr = ClockWeakPtr.Pin();
		if (!ClockPtr)
		{
			return {};
		}

		return ClockPtr->GetTickRate();
	}

	FQuartzTransportTimeStamp FQuartzClockProxy::GetCurrentClockTimestamp() const
	{
		TSharedPtr<FQuartzClock, ESPMode::ThreadSafe> ClockPtr = ClockWeakPtr.Pin();
		if (!ClockPtr)
		{
			return {};
		}

		return ClockPtr->GetCurrentTimestamp();
	}

	float FQuartzClockProxy::GetEstimatedClockRunTimeSeconds() const
	{
		TSharedPtr<FQuartzClock, ESPMode::ThreadSafe> ClockPtr = ClockWeakPtr.Pin();
		if (!ClockPtr)
		{
			return 0.f;
		}

		return ClockPtr->GetEstimatedRunTime();
	}


	bool FQuartzClockProxy::SendCommandToClock(TFunction<void(FQuartzClock*)> InCommand)
	{
		if (FQuartzClockCommandQueuePtr QueuePtr = SharedQueue.Pin())
		{
			QueuePtr->PushLambda<Quartz::IQuartzClock>(
				[Command = MoveTemp(InCommand)](Quartz::IQuartzClock& InListener)
				{
					Command(static_cast<FQuartzClock*>(&InListener));
				});

			return true;
		}

		return false;
	}

	// FQuartzClock Implementation
	FQuartzClock::FQuartzClock(const FName& InName, const FQuartzClockSettings& InClockSettings, FQuartzClockManager* InOwningClockManagerPtr)
		: Metronome(InClockSettings.TimeSignature, InName)
		, OwningClockManagerPtr(InOwningClockManagerPtr)
		, Name(InName)
		, bIsRunning(false)
		, bIgnoresFlush(InClockSettings.bIgnoreLevelChange)
	{
		FMixerDevice* MixerDevice = GetMixerDevice();

		if (MixerDevice)
		{
			Metronome.SetSampleRate(MixerDevice->GetSampleRate());
		}
		else
		{
			Metronome.SetSampleRate(HeadlessClockSampleRateCvar);
		}

		UpdateCachedState();
	}

	FQuartzClock::~FQuartzClock()
	{
		Shutdown();
	}

	void FQuartzClock::ChangeTickRate(FQuartzClockTickRate InNewTickRate, int32 NumFramesLeft)
	{
		FMixerDevice* MixerDevice = GetMixerDevice();

		if (MixerDevice)
		{
			InNewTickRate.SetSampleRate(MixerDevice->GetSampleRate());
		}
		else
		{
			InNewTickRate.SetSampleRate(HeadlessClockSampleRateCvar);
		}

		Metronome.SetTickRate(InNewTickRate, NumFramesLeft);
		FQuartzClockTickRate CurrentTickRate = Metronome.GetTickRate();

		// ratio between new and old rates
		const double Ratio = InNewTickRate.GetFramesPerTick() / CurrentTickRate.GetFramesPerTick();

		// adjust time-till-fire for existing commands
		for (auto& Command : PendingCommands)
		{
			if(Command.Command && !Command.Command->ShouldDeadlineIgnoresBpmChanges())
			{
				Command.NumFramesUntilExec = NumFramesLeft + Ratio * (Command.NumFramesUntilExec - NumFramesLeft);
			}
		}

		for (auto& Command : ClockAlteringPendingCommands)
		{
			if(Command.Command && !Command.Command->ShouldDeadlineIgnoresBpmChanges())
			{
				Command.NumFramesUntilExec = NumFramesLeft + Ratio * (Command.NumFramesUntilExec - NumFramesLeft);
			}
		}

		UpdateCachedState();
	}

	void FQuartzClock::ChangeTimeSignature(const FQuartzTimeSignature& InNewTimeSignature)
	{
		Metronome.SetTimeSignature(InNewTimeSignature);
		UpdateCachedState();
	}

	void FQuartzClock::Resume()
	{
		if (bIsRunning == false)
		{
			for (auto& Command : PendingCommands)
			{
				// Update countdown time to each quantized command
				Command.Command->OnClockStarted();
			}

			for (auto& Command : ClockAlteringPendingCommands)
			{
				// Update countdown time to each quantized command
				Command.Command->OnClockStarted();
			}
		}

		bIsRunning = true;
	}

	void FQuartzClock::Stop(bool CancelPendingEvents)
	{
		bIsRunning = false;
		Metronome.ResetTransport();
		TickDelayLengthInFrames = 0;

		if (CancelPendingEvents)
		{
			for (auto& Command : PendingCommands)
			{
				Command.Command->Cancel();
			}

			for (auto& Command : ClockAlteringPendingCommands)
			{
				Command.Command->Cancel();
			}

			PendingCommands.Reset();
			ClockAlteringPendingCommands.Reset();
		}
	}

	void FQuartzClock::Pause()
	{
		if (bIsRunning)
		{
			for (auto& Command : PendingCommands)
			{
				// Update countdown time to each quantized command
				Command.Command->OnClockPaused();
			}

			for (auto& Command : ClockAlteringPendingCommands)
			{
				// Update countdown time to each quantized command
				Command.Command->OnClockPaused();
			}
		}

		bIsRunning = false;
	}

	void FQuartzClock::Restart(bool bPause)
	{
		bIsRunning = !bPause;
		TickDelayLengthInFrames = 0;
	}

	void FQuartzClock::Shutdown()
	{
		for (PendingCommand& PendingCommand : PendingCommands)
		{
			PendingCommand.Command->Cancel();
		}

		for (PendingCommand& PendingCommand : ClockAlteringPendingCommands)
		{
			PendingCommand.Command->Cancel();
		}

		PendingCommands.Reset();
		ClockAlteringPendingCommands.Reset();
	}

	void FQuartzClock::LowResolutionTick(float InDeltaTimeSeconds)
	{
		TRACE_CPUPROFILER_EVENT_SCOPE(QuartzClock::Tick_LowRes);
		UE_LOG(LogAudioQuartz, Verbose, TEXT("Quartz Clock Tick (low-res): %s"), *Name.ToString());
		PreTickCommands->PumpCommandQueue(*this);
		Tick(static_cast<int32>(InDeltaTimeSeconds * Metronome.GetTickRate().GetSampleRate()));
	}

	void FQuartzClock::Tick(int32 InNumFramesUntilNextTick)
	{
		TRACE_CPUPROFILER_EVENT_SCOPE(QuartzClock::Tick);
		TRACE_CPUPROFILER_EVENT_SCOPE(QuartzClock::GameThreadCommands);

		UE_LOG(LogAudioQuartz, Verbose, TEXT("Quartz Clock Tick: %s"), *Name.ToString());

		PreTickCommands->PumpCommandQueue(*this);

		if (!bIsRunning)
		{
			return;
		}

		if (TickDelayLengthInFrames >= InNumFramesUntilNextTick)
		{
			TickDelayLengthInFrames -= InNumFramesUntilNextTick;
			return;
		}

		const int32 FramesOfLatency = (ThreadLatencyInMilliseconds / 1000) * Metronome.GetTickRate().GetSampleRate();
		int32 FramesToTick = InNumFramesUntilNextTick - TickDelayLengthInFrames;

        // commands executed in TickInternal may alter "TickDelayLengthInFrames" for the metronome's benefit
        // for the 2nd TickInternal() call we want to use the unmodified value (OriginalTickDelayLengthInFrames).
        const int32 OriginalTickDelayLengthInFrames = TickDelayLengthInFrames;
        TickInternal(FramesToTick, ClockAlteringPendingCommands, FramesOfLatency, OriginalTickDelayLengthInFrames);
        TickInternal(FramesToTick, PendingCommands, FramesOfLatency, OriginalTickDelayLengthInFrames);

		// FramesToTick may have been updated by TickInternal, recalculate
		FramesToTick = InNumFramesUntilNextTick - TickDelayLengthInFrames;
		Metronome.Tick(FramesToTick, FramesOfLatency);

		TickDelayLengthInFrames = 0;

		UpdateCachedState();
	}

	FQuartzClockCommandQueueWeakPtr FQuartzClock::GetCommandQueue() const
	{
		if (!PreTickCommands.IsValid())
		{
			PreTickCommands = MakeShared<FQuartzClockCommandQueueType>();
		}

		return PreTickCommands;
	}

	void FQuartzClock::TickInternal(int32 InNumFramesUntilNextTick, TArray<PendingCommand>& CommandsToTick, int32 FramesOfLatency, int32 FramesOfDelay)
	{
		TRACE_CPUPROFILER_EVENT_SCOPE(QuartzClock::TickInternal);
		bool bHaveCommandsToRemove = false;

		// Update all pending commands
		for (PendingCommand& PendingCommand : CommandsToTick)
		{
			// Time to notify game thread?
			if (PendingCommand.NumFramesUntilExec < FramesOfLatency)
			{
				PendingCommand.Command->AboutToStart();
			}

			// Time To execute?
			if (PendingCommand.NumFramesUntilExec < InNumFramesUntilNextTick)
			{
				PendingCommand.Command->OnFinalCallback(PendingCommand.NumFramesUntilExec + FramesOfDelay);
				PendingCommand.Command.Reset();
				bHaveCommandsToRemove = true;

			}
			else // not yet executing
			{
				PendingCommand.NumFramesUntilExec -= InNumFramesUntilNextTick;
				PendingCommand.Command->Update(PendingCommand.NumFramesUntilExec);
			}
		}

		// clean up executed commands
		if (bHaveCommandsToRemove)
		{
			for (int32 i = CommandsToTick.Num() - 1; i >= 0; --i)
			{
				if (!CommandsToTick[i].Command.IsValid())
				{
					CommandsToTick.RemoveAtSwap(i);
				}
			}
		}
	}

	void FQuartzClock::UpdateCachedState()
	{
		FScopeLock ScopeLock(&CachedClockStateCritSec);

		CachedClockState.TickRate = Metronome.GetTickRate();
		CachedClockState.TimeStamp = Metronome.GetTimeStamp();
		CachedClockState.RunTimeInSeconds = (float)Metronome.GetTimeSinceStart();

		const uint64 TempLastCacheTimestamp = CachedClockState.LastCacheTickCpuCycles64;
		CachedClockState.LastCacheTickCpuCycles64 = Metronome.GetLastTickCpuCycles64();
		CachedClockState.LastCacheTickDeltaCpuCycles64 = CachedClockState.LastCacheTickCpuCycles64 - TempLastCacheTimestamp;

		// copy previous phases (as temp values)
		FMemory::Memcpy(CachedClockState.MusicalDurationPhaseDeltas, CachedClockState.MusicalDurationPhases);
		
		// update current phases
		Metronome.CalculateDurationPhases(CachedClockState.MusicalDurationPhases);
		
		// convert temp copy to deltas
		constexpr int32 NumDurations = static_cast<int32>(EQuartzCommandQuantization::Count);
		for(int32 i = 0; i < NumDurations; ++i)
		{
			CachedClockState.MusicalDurationPhaseDeltas[i] = FMath::Wrap(CachedClockState.MusicalDurationPhases[i] - CachedClockState.MusicalDurationPhaseDeltas[i], 0.f, 1.f);
		}
	}

	void FQuartzClock::SetSampleRate(float InNewSampleRate)
	{
		if (FMath::IsNearlyEqual(InNewSampleRate, Metronome.GetTickRate().GetSampleRate()))
		{
			return;
		}

		// update Tick Rate
		Metronome.SetSampleRate(InNewSampleRate);

		UpdateCachedState();
	}

	bool FQuartzClock::IgnoresFlush() const
	{
		return bIgnoresFlush;
	}

	bool FQuartzClock::DoesMatchSettings(const FQuartzClockSettings& InClockSettings) const
	{
		return Metronome.GetTimeSignature() == InClockSettings.TimeSignature;
	}

	void FQuartzClock::SubscribeToTimeDivision(FQuartzGameThreadSubscriber InSubscriber, EQuartzCommandQuantization InQuantizationBoundary)
	{
		Metronome.SubscribeToTimeDivision(InSubscriber, InQuantizationBoundary);
	}

	void FQuartzClock::SubscribeToAllTimeDivisions(FQuartzGameThreadSubscriber InSubscriber)
	{
		Metronome.SubscribeToAllTimeDivisions(InSubscriber);
	}

	void FQuartzClock::UnsubscribeFromTimeDivision(FQuartzGameThreadSubscriber InSubscriber, EQuartzCommandQuantization InQuantizationBoundary)
	{
		Metronome.UnsubscribeFromTimeDivision(InSubscriber, InQuantizationBoundary);
	}

	void FQuartzClock::UnsubscribeFromAllTimeDivisions(FQuartzGameThreadSubscriber InSubscriber)
	{
		Metronome.UnsubscribeFromAllTimeDivisions(InSubscriber);
	}


	void FQuartzClock::AddQuantizedCommand(FQuartzQuantizationBoundary InQuantizationBondary, TSharedPtr<IQuartzQuantizedCommand> InNewEvent)
	{
		if (!ensure(InNewEvent.IsValid()))
		{
			return;
		}

		if (!bIsRunning && InQuantizationBondary.bCancelCommandIfClockIsNotRunning)
		{
			InNewEvent->Cancel();
			return;
		}

		if (InQuantizationBondary.bResetClockOnQueued)
		{
			Stop(/* clear pending events = */true);
			Restart(!bIsRunning);
		}

		if (!bIsRunning && InQuantizationBondary.bResumeClockOnQueued)
		{
			Resume();
		}

		int32 FramesUntilExec = 0;

		// if this is un-quantized, execute immediately (even if the clock is paused)
		if (InQuantizationBondary.Quantization == EQuartzCommandQuantization::None)
		{
			UE_LOG(LogAudioQuartz, Verbose, TEXT("Quartz Command:(%s) | Deadline (frames):[%i] | Boundary: [%s]")
				, *InNewEvent->GetCommandName().ToString()
				, FramesUntilExec
				, *InQuantizationBondary.ToString()
				);
			
			InNewEvent->AboutToStart();
			InNewEvent->OnFinalCallback(0);
			return;
		}

		// get number of frames until event (assuming we are at frame 0)
		FramesUntilExec = FMath::RoundToInt(Metronome.GetFramesUntilBoundary(InQuantizationBondary)); // query metronome (round result to int)
		const int32 OverriddenFramesUntilExec = FMath::Max(0, InNewEvent->OverrideFramesUntilExec(FramesUntilExec)); // allow command to override the deadline (clamp result)
		const bool bOverridden = (FramesUntilExec != OverriddenFramesUntilExec);

		UE_LOG(LogAudioQuartz, Verbose, TEXT("Quartz Command:(%s) | Deadline (frames):[%i%s] | Boundary: [%s]")
			, *InNewEvent->GetCommandName().ToString()
			, OverriddenFramesUntilExec
			, bOverridden? *FString::Printf(TEXT("(overridden from %i)"), FramesUntilExec) : TEXT("")
			, *InQuantizationBondary.ToString()
			);

		// after the log, use tho Overridden value
		FramesUntilExec = OverriddenFramesUntilExec;

		// finalize the requested subscriber offsets and notify the command of their deadline
		InNewEvent->OnScheduled(Metronome.GetTickRate());
		InNewEvent->Update(FramesUntilExec);

		// if this is going to execute on the next tick, warn Game Thread Subscribers as soon as possible
		if (FramesUntilExec == 0)
		{
			InNewEvent->AboutToStart();
		}

		// add to pending commands list, execute OnQueued()
		if (InNewEvent->IsClockAltering())
		{
			ClockAlteringPendingCommands.Emplace(PendingCommand(MoveTemp(InNewEvent), FramesUntilExec));
		}
		else
		{
			PendingCommands.Emplace(PendingCommand(MoveTemp(InNewEvent), FramesUntilExec));
		}
	}

	bool FQuartzClock::CancelQuantizedCommand(TSharedPtr<IQuartzQuantizedCommand> InCommandPtr)
	{
		if (InCommandPtr->IsClockAltering())
		{
			return CancelQuantizedCommandInternal(InCommandPtr, ClockAlteringPendingCommands);
		}

		return CancelQuantizedCommandInternal(InCommandPtr, PendingCommands);
	}

	bool FQuartzClock::HasPendingEvents() const
	{
		// if container has any events in it.
		return (NumPendingEvents() > 0);
	}

	int32 FQuartzClock::NumPendingEvents() const
	{
		return PendingCommands.Num() + ClockAlteringPendingCommands.Num();
	}

	bool FQuartzClock::IsRunning() const
	{
		return bIsRunning;
	}

	float FQuartzClock::GetDurationOfQuantizationTypeInSeconds(const EQuartzCommandQuantization& QuantizationType, float Multiplier)
	{
		FScopeLock ScopeLock(&CachedClockStateCritSec);

		// if this is unquantized, return 0
		if (QuantizationType == EQuartzCommandQuantization::None)
		{
			return 0;
		}

		// get number of frames until the relevant quantization event
		double FramesUntilExec = CachedClockState.TickRate.GetFramesPerDuration(QuantizationType);

		//Translate frames to seconds
		double SampleRate = CachedClockState.TickRate.GetSampleRate();

		if (!FMath::IsNearlyZero(SampleRate))
		{
			return (FramesUntilExec * Multiplier) / SampleRate;
		}
		else //Handle potential divide by zero
		{
			return INDEX_NONE;
		}
	}

	float FQuartzClock::GetBeatProgressPercent(const EQuartzCommandQuantization& QuantizationType) const
	{
		if(CachedClockState.LastCacheTickDeltaCpuCycles64 == 0)
		{
			return CachedClockState.MusicalDurationPhases[static_cast<int32>(QuantizationType)];
		}

		// anticipate beat progress based on the amount of wall clock time that has passed since the last audio engine update
		const float LastPhase = CachedClockState.MusicalDurationPhases[static_cast<int32>(QuantizationType)];
		const float PhaseDelta = CachedClockState.MusicalDurationPhaseDeltas[static_cast<int32>(QuantizationType)];
		const uint64 CyclesSinceLastTick = FPlatformTime::Cycles64() - CachedClockState.LastCacheTickCpuCycles64;
		const float EstimatedPercentToNextTick = static_cast<float>(CyclesSinceLastTick) / static_cast<float>(CachedClockState.LastCacheTickDeltaCpuCycles64);

		return LastPhase + PhaseDelta * EstimatedPercentToNextTick;
	}

	FQuartzTransportTimeStamp FQuartzClock::GetCurrentTimestamp()
	{
		FScopeLock ScopeLock(&CachedClockStateCritSec);
		return CachedClockState.TimeStamp;
	}

	float FQuartzClock::GetEstimatedRunTime()
	{
		FScopeLock ScopeLock(&CachedClockStateCritSec);
		return CachedClockState.RunTimeInSeconds;
	}

	FMixerDevice* FQuartzClock::GetMixerDevice()
	{
		checkSlow(OwningClockManagerPtr);
		if (OwningClockManagerPtr)
		{
			return OwningClockManagerPtr->GetMixerDevice();
		}

		return nullptr;
	}

	void FQuartzClock::AddQuantizedCommand(FQuartzQuantizedRequestData& InQuantizedRequestData)
	{
		float SampleRate = HeadlessClockSampleRateCvar;
		if (FMixerDevice* MixerDevice = GetMixerDevice())
		{
			SampleRate = MixerDevice->GetSampleRate();
		}

		FQuartzQuantizedCommandInitInfo Info(InQuantizedRequestData, SampleRate);
		AddQuantizedCommand(Info);
	}

	void FQuartzClock::AddQuantizedCommand(FQuartzQuantizedCommandInitInfo& InQuantizationCommandInitInfo)
	{
		if (!ensure(InQuantizationCommandInitInfo.QuantizedCommandPtr))
		{
			return;
		}

		// this method can't be utilized by play commands because the AudioMixerSource needs a handle in order to stop it.
		// PlayCommands must be queued via the clock manager in AudioMixerSourceManager.
		if (!ensure(EQuartzCommandType::PlaySound != InQuantizationCommandInitInfo.QuantizedCommandPtr->GetCommandType()))
		{
			return;
		}

		// Can this command run without an Audio Device?
		FMixerDevice* MixerDevice = GetMixerDevice();
		if (!MixerDevice && InQuantizationCommandInitInfo.QuantizedCommandPtr->RequiresAudioDevice())
		{
			InQuantizationCommandInitInfo.QuantizedCommandPtr->Cancel();
		}

		// this function is a friend of FQuartzClockManager, so we can use FindClock() directly
		// to access the shared ptr to "this"
		InQuantizationCommandInitInfo.SetOwningClockPtr(GetClockManager()->FindClock(GetName()));
		InQuantizationCommandInitInfo.QuantizedCommandPtr->OnQueued(InQuantizationCommandInitInfo);
		AddQuantizedCommand(InQuantizationCommandInitInfo.QuantizationBoundary, InQuantizationCommandInitInfo.QuantizedCommandPtr);
	}

	FMixerSourceManager* FQuartzClock::GetSourceManager()
	{
		FMixerDevice* MixerDevice = GetMixerDevice();

		checkSlow(MixerDevice);
		if (MixerDevice)
		{
			return MixerDevice->GetSourceManager();
		}

		return nullptr;
	}

	FQuartzClockTickRate FQuartzClock::GetTickRate()
	{
		FScopeLock ScopeLock(&CachedClockStateCritSec);
		return CachedClockState.TickRate;
	}

	FName FQuartzClock::GetName() const
	{
		return Name;
	}

	FQuartzClockManager* FQuartzClock::GetClockManager()
	{
		checkSlow(OwningClockManagerPtr);
		if (OwningClockManagerPtr)
		{
			return OwningClockManagerPtr;
		}
		return nullptr;
	}

	void FQuartzClock::ResetTransport(const int32 NumFramesToTickBeforeReset)
	{
		if (NumFramesToTickBeforeReset != 0)
		{
			Metronome.Tick(NumFramesToTickBeforeReset);
		}
		
		Metronome.ResetTransport();
	}

	void FQuartzClock::AddToTickDelay(int32 NumFramesOfDelayToAdd)
	{
		TickDelayLengthInFrames += NumFramesOfDelayToAdd;
	}

	void FQuartzClock::SetTickDelay(int32 NumFramesOfDelay)
	{
		TickDelayLengthInFrames = NumFramesOfDelay;
	}

	bool FQuartzClock::CancelQuantizedCommandInternal(TSharedPtr<IQuartzQuantizedCommand> InCommandPtr, TArray<PendingCommand>& CommandsToTick)
	{
		for (int32 i = CommandsToTick.Num() - 1; i >= 0; --i)
		{
			PendingCommand& PendingCommand = CommandsToTick[i];

			if (PendingCommand.Command == InCommandPtr)
			{
				PendingCommand.Command->Cancel();
				CommandsToTick.RemoveAtSwap(i);
				return true;
			}
		}

		return false;
	}
} // namespace Audio

===========================


=== AudioMixerClock.h ===
=========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "HAL/ThreadSafeBool.h"
#include "Sound/QuartzQuantizationUtilities.h"
#include "Quartz/QuartzMetronome.h"
#include "Sound/QuartzSubscription.h"
#include "Sound/QuartzInterfaces.h"
#include "Sound/QuartzCommandQueue.h"

namespace Audio
{
	// forwards
	class FMixerDevice;
	class FQuartzClock;
	class FMixerSourceManager;
	class FQuartzClockManager;

	using FQuartzClockCommandQueueType = Audio::Quartz::PrivateDefs::TQuartzCommandQueue<IQuartzClock>;
	using FQuartzClockCommandQueuePtr = TSharedPtr<FQuartzClockCommandQueueType, ESPMode::ThreadSafe>;
	using FQuartzClockCommandQueueWeakPtr = TWeakPtr<FQuartzClockCommandQueueType, ESPMode::ThreadSafe>;
	
	/**
	 *	FQuartzClockProxy:
	 *
	 *		This class is a C++ handle to the underlying clock.
	 *		
	 *		It is mostly a wrapper around a TWeakPtr<FQuartzClock> and
	 *		FQuartzClockCommandQueueType
	 *		
	 *		The getters query the underlying FQuartzClock directly,
	 *		which returns values updated during the last audio-engine tick
	 *
	 *		If you need to add more getters, add copies of the members in question to
	 *		FQuartzClock::FQuartzClockState and update FQuartzClock::UpdateCachedState()
	 *		for thread-safe access (or manually protect access w/ CachedClockStateCritSec)
	 *
	 *		SendCommandToClock() can be used to execute lambdas at the beginning
	 *		of the next clock tick.  These lambdas can call FQuartzClock's public methods safely.
	 *
	 *		Your lambda will take an FQuartzClock* as an argument, which will be passed in by the
	 *		FQuartzClock itself when it pumps the command queue.
	 *
	 */
	class AUDIOMIXER_API FQuartzClockProxy
	{
	public:
		// ctor
		FQuartzClockProxy() {}
		FQuartzClockProxy(const FName& Name) : ClockId(Name){ } // conv ctor from FName
		FQuartzClockProxy(TSharedPtr<FQuartzClock, ESPMode::ThreadSafe> InClock);

		FName GetClockName() const { return ClockId; }

		bool IsValid() const;
		operator bool() const { return IsValid(); }

		bool operator==(const FName& Name) const { return ClockId == Name; }

		bool DoesClockExist() const;

		bool IsClockRunning() const;

		Audio::FQuartzClockTickRate GetTickRate() const;

		float GetEstimatedClockRunTimeSeconds() const;

		FQuartzTransportTimeStamp GetCurrentClockTimestamp() const;

		float GetDurationOfQuantizationTypeInSeconds(const EQuartzCommandQuantization& QuantizationType, float Multiplier) const;

		float GetBeatProgressPercent(const EQuartzCommandQuantization& QuantizationType) const;

		// returns false if the clock is not valid or has shut down
		bool SendCommandToClock(TFunction<void(FQuartzClock*)> InCommand);

		// implicit cast to underlying ID (FName)
		operator const FName&() const { return ClockId; }

	private:
		FName ClockId;

		FQuartzClockCommandQueueWeakPtr SharedQueue;

	protected:
		TWeakPtr<FQuartzClock, ESPMode::ThreadSafe> ClockWeakPtr;

	}; // class FQuartzClockProxy


	
	/**
	 *	FQuartzClock:
	 *
	 *		This class receives, schedules, and fires quantized commands. 
	 *		The underlying FQuartzMetronome handles all counting / timing logic.
	 *
	 *		This class gets ticked externally (i.e. by some Clock Manager)
	 *		and counts down the time-to-fire the commands in audio frames.
	 *
	 *
	 *		UpdateCachedState() updates a game-thread copy of data accessed via FQuartzClockProxy
	 *		(see FQuartzClockState)
	 */

	class AUDIOMIXER_API FQuartzClock : public FQuartzClockCommandQueueType::TConsumerBase<Audio::Quartz::IQuartzClock>
	{
	public:

		// ctor
		FQuartzClock(const FName& InName, const FQuartzClockSettings& InClockSettings, FQuartzClockManager* InOwningClockManagerPtr = nullptr);

		// dtor
		virtual ~FQuartzClock() override;

		// Transport Control:
		// alter the tick rate (take by-value to make sample-rate adjustments in-place)
		void ChangeTickRate(FQuartzClockTickRate InNewTickRate, int32 NumFramesLeft = 0);

		void ChangeTimeSignature(const FQuartzTimeSignature& InNewTimeSignature);

		virtual void Resume() override;

		virtual void Pause() override;

		virtual void Restart(bool bPause = true) override;

		virtual void Stop(bool CancelPendingEvents) override;  // Pause + Restart

		void SetSampleRate(float InNewSampleRate);

		void ResetTransport(const int32 NumFramesToTickBeforeReset = 0);

		// (used for StartOtherClock command to handle the sub-tick as the target clock)
		void AddToTickDelay(int32 NumFramesOfDelayToAdd);

		// (used for StartOtherClock command to handle the sub-tick as the target clock)
		void SetTickDelay(int32 NumFramesOfDelay);

		void Shutdown();

		// Getters:
		FQuartzClockTickRate GetTickRate();

		FName GetName() const;

		bool IgnoresFlush() const;

		bool DoesMatchSettings(const FQuartzClockSettings& InClockSettings) const;

		bool HasPendingEvents() const;

		int32 NumPendingEvents() const;

		bool IsRunning() const;

		float GetDurationOfQuantizationTypeInSeconds(const EQuartzCommandQuantization& QuantizationType, float Multiplier);

		float GetBeatProgressPercent(const EQuartzCommandQuantization& QuantizationType) const;

		FQuartzTransportTimeStamp GetCurrentTimestamp();

		float GetEstimatedRunTime();

		FMixerDevice* GetMixerDevice();

		FMixerSourceManager* GetSourceManager();

		FQuartzClockManager* GetClockManager();

		FQuartzClockCommandQueueWeakPtr GetCommandQueue() const;

		// Metronome Event Subscription:
		virtual void SubscribeToTimeDivision(FQuartzGameThreadSubscriber InSubscriber, EQuartzCommandQuantization InQuantizationBoundary) override;

		virtual void SubscribeToAllTimeDivisions(FQuartzGameThreadSubscriber InSubscriber) override;

		virtual void UnsubscribeFromTimeDivision(FQuartzGameThreadSubscriber InSubscriber, EQuartzCommandQuantization InQuantizationBoundary) override;

		virtual void UnsubscribeFromAllTimeDivisions(FQuartzGameThreadSubscriber InSubscriber) override;

		// Quantized Command Management:
		virtual void AddQuantizedCommand(FQuartzQuantizedRequestData& InQuantizedRequestData) override;
		virtual void AddQuantizedCommand(FQuartzQuantizedCommandInitInfo& InQuantizationCommandInitInfo) override;

		virtual void AddQuantizedCommand(FQuartzQuantizationBoundary InQuantizationBoundary, TSharedPtr<IQuartzQuantizedCommand> InNewEvent) override;

		bool CancelQuantizedCommand(TSharedPtr<IQuartzQuantizedCommand> InCommandPtr);
		
		// low-resolution clock update
		// (not sample-accurate!, useful when running without an Audio Device)
		void LowResolutionTick(float InDeltaTimeSeconds);

		// sample accurate clock update
		void Tick(int32 InNumFramesUntilNextTick);

	private:
		// Contains the pending command and the number of frames it has to wait to fire
		struct PendingCommand
		{
			// ctor
			PendingCommand(TSharedPtr<IQuartzQuantizedCommand> InCommand, int32 InNumFramesUntilExec)
				: Command(InCommand)
				, NumFramesUntilExec(InNumFramesUntilExec)
			{
			}

			// Quantized Command Object
			TSharedPtr<IQuartzQuantizedCommand> Command;

			// Countdown to execution
			int32 NumFramesUntilExec{ 0 };
		}; // struct PendingCommand

		// mutex-protected update at the end of Tick()
		FCriticalSection CachedClockStateCritSec;
		void UpdateCachedState();

		// data is cached when an FQuartzClock is ticked
		struct FQuartzClockState
		{
			FQuartzClockTickRate TickRate;
			FQuartzTransportTimeStamp TimeStamp;
			float RunTimeInSeconds;
			float MusicalDurationPhases[static_cast<int32>(EQuartzCommandQuantization::Count)] { 0 };
			float MusicalDurationPhaseDeltas[static_cast<int32>(EQuartzCommandQuantization::Count)] { 0 };
			uint64 LastCacheTickCpuCycles64 = 0;
			uint64 LastCacheTickDeltaCpuCycles64 = 0;
			
		} CachedClockState;

		void TickInternal(int32 InNumFramesUntilNextTick, TArray<PendingCommand>& CommandsToTick, int32 FramesOfLatency = 0, int32 FramesOfDelay = 0);

		bool CancelQuantizedCommandInternal(TSharedPtr<IQuartzQuantizedCommand> InCommandPtr, TArray<PendingCommand>& CommandsToTick);

		// don't allow default ctor, a clock needs to be ready to be used
		// by the clock manager / FMixerDevice once constructed
		FQuartzClock() = delete;

		FQuartzMetronome Metronome;

		FQuartzClockManager* OwningClockManagerPtr{ nullptr };

		FName Name;

		float ThreadLatencyInMilliseconds{ 40.f };

		// Command queue handed out to GameThread objects to queue commands. These get executed at the top of Tick()
		mutable FQuartzClockCommandQueuePtr PreTickCommands; // (mutable for lazy init in GetQuartzSubscriber())

		// Container of external commands to be executed (TUniquePointer<QuantizedAudioCommand>)
		TArray<PendingCommand> ClockAlteringPendingCommands;
		TArray<PendingCommand> PendingCommands;

		FThreadSafeBool bIsRunning{ true };

		bool bIgnoresFlush{ false };

		int32 TickDelayLengthInFrames{ 0 };

	}; // class FQuartzClock
} // namespace Audio

=========================


=== AudioMixerClockHandle.cpp ===
=================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Quartz/AudioMixerClockHandle.h"
#include "Sound/QuartzQuantizationUtilities.h"
#include "AudioDevice.h"
#include "AudioMixerDevice.h"
#include "Engine/GameInstance.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioMixerClockHandle)



// Clock Handle implementation
UQuartzClockHandle::UQuartzClockHandle()
{
}

UQuartzClockHandle::~UQuartzClockHandle()
{
}

void UQuartzClockHandle::BeginDestroy()
{
	Super::BeginDestroy();

	auto Subscriber = GetQuartzSubscriber();
	RawHandle.SendCommandToClock([Subscriber](Audio::FQuartzClock* InClock) { InClock->UnsubscribeFromAllTimeDivisions(Subscriber); });
}

void UQuartzClockHandle::StartClock(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;
	ResumeClock(WorldContextObject, ClockHandle);
}

void UQuartzClockHandle::StopClock(const UObject* WorldContextObject, bool bCancelPendingEvents, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;
	RawHandle.SendCommandToClock([bCancelPendingEvents](Audio::FQuartzClock* InClock) { InClock->Stop(bCancelPendingEvents); });
}

void UQuartzClockHandle::PauseClock(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;
	RawHandle.SendCommandToClock([](Audio::FQuartzClock* InClock) { InClock->Pause(); });
}

// Begin BP interface
void UQuartzClockHandle::ResumeClock(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;
	RawHandle.SendCommandToClock([](Audio::FQuartzClock* InClock) { InClock->Resume(); });
}

void UQuartzClockHandle::QueueQuantizedSound(const UObject* WorldContextObject, UQuartzClockHandle*& InClockHandle, const FAudioComponentCommandInfo& InAudioComponentData, const FOnQuartzCommandEventBP& InDelegate, const FQuartzQuantizationBoundary& InTargetBoundary)
{
	InClockHandle = this;
	FName ClockName = GetClockName();

	//Create a Queue Command, and give it the additional data that it needs
	TSharedPtr<Audio::FQuantizedQueueCommand> QueueCommandPtr = MakeShared<Audio::FQuantizedQueueCommand>();
	QueueCommandPtr->SetQueueCommand(InAudioComponentData);

	//Set up initial command info
	Audio::FQuartzQuantizedRequestData CommandInitInfo = UQuartzSubsystem::CreateRequestDataForSchedulePlaySound(InClockHandle, InDelegate, InTargetBoundary);

	//(Queue's setup is identical to PlaySound except for the command ptr, so fix that here)
	CommandInitInfo.QuantizedCommandPtr.Reset();
	CommandInitInfo.QuantizedCommandPtr = QueueCommandPtr;

	RawHandle.SendCommandToClock([CommandInitInfo](Audio::FQuartzClock* InClock) mutable { InClock->AddQuantizedCommand(CommandInitInfo); });
}

// deprecated: use ResetTransportQuantized
void UQuartzClockHandle::ResetTransport(const UObject* WorldContextObject, const FOnQuartzCommandEventBP& InDelegate)
{
	Audio::FQuartzQuantizedRequestData Data(UQuartzSubsystem::CreateRequestDataForTransportReset(this, FQuartzQuantizationBoundary(EQuartzCommandQuantization::Bar), InDelegate));
	RawHandle.SendCommandToClock([Data](Audio::FQuartzClock* InClock) mutable { InClock->AddQuantizedCommand(Data); });
}

void UQuartzClockHandle::ResetTransportQuantized(const UObject* WorldContextObject, FQuartzQuantizationBoundary InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;
	Audio::FQuartzQuantizedRequestData Data(UQuartzSubsystem::CreateRequestDataForTransportReset(this, InQuantizationBoundary, InDelegate));
	RawHandle.SendCommandToClock([Data](Audio::FQuartzClock* InClock) mutable { InClock->AddQuantizedCommand(Data); });
}



bool UQuartzClockHandle::IsClockRunning(const UObject* WorldContextObject)
{
	return RawHandle.IsClockRunning();
}

void UQuartzClockHandle::NotifyOnQuantizationBoundary(const UObject* WorldContextObject, FQuartzQuantizationBoundary InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, float OffsetInMilliseconds)
{
	Audio::FQuartzQuantizedRequestData Data(UQuartzSubsystem::CreateRequestDataForQuantizedNotify(this, InQuantizationBoundary, InDelegate, OffsetInMilliseconds));
	RawHandle.SendCommandToClock([Data](Audio::FQuartzClock* InClock) mutable { InClock->AddQuantizedCommand(Data); });
}

float UQuartzClockHandle::GetDurationOfQuantizationTypeInSeconds(const UObject* WorldContextObject, const EQuartzCommandQuantization& QuantizationType, float Multiplier)
{
	return RawHandle.GetDurationOfQuantizationTypeInSeconds(QuantizationType, Multiplier);
}

FQuartzTransportTimeStamp UQuartzClockHandle::GetCurrentTimestamp(const UObject* WorldContextObject)
{
	return RawHandle.GetCurrentClockTimestamp();
}

float UQuartzClockHandle::GetEstimatedRunTime(const UObject* WorldContextObject)
{
	return RawHandle.GetEstimatedClockRunTimeSeconds();
}

void UQuartzClockHandle::StartOtherClock(const UObject* WorldContextObject, FName OtherClockName, FQuartzQuantizationBoundary InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate)
{
	if (OtherClockName == CurrentClockId)
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Clock: (%s) is attempting to start itself on a quantization boundary.  Ignoring command"), *CurrentClockId.ToString());
		return;
	}

	Audio::FQuartzQuantizedRequestData Data(UQuartzSubsystem::CreateRequestDataForStartOtherClock(this, OtherClockName, InQuantizationBoundary, InDelegate));
	RawHandle.SendCommandToClock([Data](Audio::FQuartzClock* InClock) mutable { InClock->AddQuantizedCommand(Data); });
}

// todo: Move the bulk of these functions to FQuartzTickableObject once lightweight clock handles are spun up.
void UQuartzClockHandle::SubscribeToQuantizationEvent(const UObject* WorldContextObject, EQuartzCommandQuantization InQuantizationBoundary, const FOnQuartzMetronomeEventBP& OnQuantizationEvent, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;

	if (InQuantizationBoundary == EQuartzCommandQuantization::None)
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Clock: (%s) is attempting to subscribe to 'NONE' as a Quantization Boundary.  Ignoring request"), *CurrentClockId.ToString());
		return;
	}

	AddMetronomeBpDelegate(InQuantizationBoundary, OnQuantizationEvent);

	auto Subscriber = GetQuartzSubscriber();
	RawHandle.SendCommandToClock([Subscriber, InQuantizationBoundary](Audio::FQuartzClock* InClock) { InClock->SubscribeToTimeDivision(Subscriber, InQuantizationBoundary); });
}

void UQuartzClockHandle::SubscribeToAllQuantizationEvents(const UObject* WorldContextObject, const FOnQuartzMetronomeEventBP& OnQuantizationEvent, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;

	for (int32 i = 0; i < static_cast<int32>(EQuartzCommandQuantization::Count) - 1; ++i)
	{
		AddMetronomeBpDelegate(static_cast<EQuartzCommandQuantization>(i), OnQuantizationEvent);
	}

	auto Subscriber = GetQuartzSubscriber();
	RawHandle.SendCommandToClock([Subscriber](Audio::FQuartzClock* InClock) { InClock->SubscribeToAllTimeDivisions(Subscriber); });
}

void UQuartzClockHandle::UnsubscribeFromTimeDivision(const UObject* WorldContextObject, EQuartzCommandQuantization InQuantizationBoundary, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;

	auto Subscriber = GetQuartzSubscriber();
	RawHandle.SendCommandToClock([Subscriber, InQuantizationBoundary](Audio::FQuartzClock* InClock) { InClock->UnsubscribeFromTimeDivision(Subscriber, InQuantizationBoundary); });
}

void UQuartzClockHandle::UnsubscribeFromAllTimeDivisions(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle)
{
	ClockHandle = this;

	auto Subscriber = GetQuartzSubscriber();
	RawHandle.SendCommandToClock([Subscriber](Audio::FQuartzClock* InClock) { InClock->UnsubscribeFromAllTimeDivisions(Subscriber); });
}

// Metronome Alteration (setters)
void UQuartzClockHandle::SetMillisecondsPerTick(const UObject* WorldContextObject, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, UQuartzClockHandle*& ClockHandle, float MillisecondsPerTick)
{
	ClockHandle = this;
	if (MillisecondsPerTick < 0 || FMath::IsNearlyZero(MillisecondsPerTick))
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Ignoring invalid request on Clock: %s: MillisecondsPerTick was %f"), *this->CurrentClockId.ToString(), MillisecondsPerTick);
		return;
	}

	Audio::FQuartzClockTickRate TickRate;
	TickRate.SetMillisecondsPerTick(MillisecondsPerTick);
	SetTickRateInternal(InQuantizationBoundary, InDelegate, TickRate);
}

void UQuartzClockHandle::SetTicksPerSecond(const UObject* WorldContextObject, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, UQuartzClockHandle*& ClockHandle, float TicksPerSecond)
{
	ClockHandle = this;
	if (TicksPerSecond < 0 || FMath::IsNearlyZero(TicksPerSecond))
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Ignoring invalid request on Clock: %s: TicksPerSecond was %f"), *this->CurrentClockId.ToString(), TicksPerSecond);
		return;
	}

	Audio::FQuartzClockTickRate TickRate;
	TickRate.SetSecondsPerTick(1.f / TicksPerSecond);
	SetTickRateInternal(InQuantizationBoundary, InDelegate, TickRate);
}

void UQuartzClockHandle::SetSecondsPerTick(const UObject* WorldContextObject, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, UQuartzClockHandle*& ClockHandle, float SecondsPerTick)
{
	ClockHandle = this;
	if (SecondsPerTick < 0 || FMath::IsNearlyZero(SecondsPerTick))
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Ignoring invalid request on Clock: %s: SecondsPerTick was %f"), *this->CurrentClockId.ToString(), SecondsPerTick);
		return;
	}

	Audio::FQuartzClockTickRate TickRate;
	TickRate.SetSecondsPerTick(SecondsPerTick);
	SetTickRateInternal(InQuantizationBoundary, InDelegate, TickRate);
}

void UQuartzClockHandle::SetThirtySecondNotesPerMinute(const UObject* WorldContextObject, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, UQuartzClockHandle*& ClockHandle, float ThirtySecondsNotesPerMinute)
{
	ClockHandle = this;
	if (ThirtySecondsNotesPerMinute < 0 || FMath::IsNearlyZero(ThirtySecondsNotesPerMinute))
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Ignoring invalid request on Clock: %s: ThirtySecondsNotesPerMinute was %f"), *this->CurrentClockId.ToString(), ThirtySecondsNotesPerMinute);
		return;
	}

	Audio::FQuartzClockTickRate TickRate;
	TickRate.SetThirtySecondNotesPerMinute(ThirtySecondsNotesPerMinute);
	SetTickRateInternal(InQuantizationBoundary, InDelegate, TickRate);
}

void UQuartzClockHandle::SetBeatsPerMinute(const UObject* WorldContextObject, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, UQuartzClockHandle*& ClockHandle, float BeatsPerMinute)
{
	ClockHandle = this;
	if (BeatsPerMinute < 0 || FMath::IsNearlyZero(BeatsPerMinute))
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Ignoring invalid request on Clock: %s: BeatsPerMinute was %f"), *this->CurrentClockId.ToString(), BeatsPerMinute);
		return;
	}

	Audio::FQuartzClockTickRate TickRate;
	TickRate.SetBeatsPerMinute(BeatsPerMinute);
	SetTickRateInternal(InQuantizationBoundary, InDelegate, TickRate);
}

void UQuartzClockHandle::SetTickRateInternal(const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, const Audio::FQuartzClockTickRate& NewTickRate)
{
	Audio::FQuartzQuantizedRequestData Data(UQuartzSubsystem::CreateRequestDataForTickRateChange(this, InDelegate, NewTickRate, InQuantizationBoundary));
	RawHandle.SendCommandToClock([Data](Audio::FQuartzClock* InClock) mutable { InClock->AddQuantizedCommand(Data); });
}

// Metronome getters
float UQuartzClockHandle::GetMillisecondsPerTick(const UObject* WorldContextObject) const
{
	Audio::FQuartzClockTickRate OutTickRate;

	if (GetCurrentTickRate(WorldContextObject, OutTickRate))
	{
		return OutTickRate.GetMillisecondsPerTick();
	}

	return 0.f;
}

float UQuartzClockHandle::GetTicksPerSecond(const UObject* WorldContextObject) const
{
	Audio::FQuartzClockTickRate OutTickRate;

	if (GetCurrentTickRate(WorldContextObject, OutTickRate))
	{
		const float SecondsPerTick = OutTickRate.GetSecondsPerTick();

		if (!FMath::IsNearlyZero(SecondsPerTick))
		{
			return 1.f / SecondsPerTick;
		}
	}

	return 0.f;
}

float UQuartzClockHandle::GetSecondsPerTick(const UObject* WorldContextObject) const
{
	Audio::FQuartzClockTickRate OutTickRate;

	if (GetCurrentTickRate(WorldContextObject, OutTickRate))
	{
		return OutTickRate.GetSecondsPerTick();
	}

	return 0.f;
}

float UQuartzClockHandle::GetThirtySecondNotesPerMinute(const UObject* WorldContextObject) const
{
	Audio::FQuartzClockTickRate OutTickRate;

	if (GetCurrentTickRate(WorldContextObject, OutTickRate))
	{
		return OutTickRate.GetThirtySecondNotesPerMinute();
	}

	return 0.f;
}

float UQuartzClockHandle::GetBeatsPerMinute(const UObject* WorldContextObject) const
{
	Audio::FQuartzClockTickRate OutTickRate;

	if (GetCurrentTickRate(WorldContextObject, OutTickRate))
	{
		return OutTickRate.GetBeatsPerMinute();
	}

	return 0.f;
}

float UQuartzClockHandle::GetBeatProgressPercent(EQuartzCommandQuantization QuantizationBoundary, float PhaseOffset, float MsOffset)
{
	if(RawHandle.IsValid() && QuantizationBoundary != EQuartzCommandQuantization::None)
	{
		constexpr float ToMilliseconds = 1000.f;
	    const float MsInQuantizationType = ToMilliseconds * RawHandle.GetDurationOfQuantizationTypeInSeconds(QuantizationBoundary, 1.f);
	    if(!FMath::IsNearlyZero(MsInQuantizationType))
	    {
		    PhaseOffset += MsOffset / MsInQuantizationType;
	    }

		return FMath::Wrap(PhaseOffset + RawHandle.GetBeatProgressPercent(QuantizationBoundary), 0.f, 1.f);
	}

	return 0.f;
}

// todo: un-comment when metronome events support the offset
// void UQuartzClockHandle::SetNotificationAnticipationAmountInMilliseconds(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle, const double Milliseconds)
// {
// 	ClockHandle = this;
// 	if(Milliseconds < 0.0)
// 	{
// 		UE_LOG(LogAudioQuartz, Warning, TEXT("Setting a negative notification anticipation amount is not supported. (request ignored)"));
// 		return;
// 	}
//
// 	SetNotificationAnticipationAmountMilliseconds(Milliseconds);
// }
//
//
// void UQuartzClockHandle::SetNotificationAnticipationAmountAsMusicalDuration(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle, const EQuartzCommandQuantization MusicalDuration, const double Multiplier)
// {
// 	ClockHandle = this;
// 	if(Multiplier < 0.0)
// 	{
// 		UE_LOG(LogAudioQuartz, Warning, TEXT("Setting a negative notification anticipation amount is not supported. (request ignored)"));
// 		return;
// 	}
//
// 	SetNotificationAnticipationAmountMusicalDuration(MusicalDuration, Multiplier);
// }

// End BP interface


UQuartzClockHandle* UQuartzClockHandle::SubscribeToClock(const UObject* WorldContextObject, FName ClockName, Audio::FQuartzClockProxy const* InHandlePtr)
{
	CurrentClockId = ClockName;

	if (InHandlePtr)
	{
		RawHandle = *InHandlePtr;
	}

	return this;
}


// returns true if OutTickRate is valid and was updated
bool UQuartzClockHandle::GetCurrentTickRate(const UObject* WorldContextObject, Audio::FQuartzClockTickRate& OutTickRate) const
{
	if (RawHandle.IsValid())
	{
		OutTickRate = RawHandle.GetTickRate();
		return true;
	}

	OutTickRate = {};
	return false;
}


=================================


=== AudioMixerClockHandle.h ===
===============================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "UObject/ObjectMacros.h"
#include "Curves/RichCurve.h"
#include "Curves/CurveBase.h"
#include "Sound/QuartzQuantizationUtilities.h"
#include "Sound/QuartzSubscription.h"
#include "Quartz/QuartzSubsystem.h"
#include "Quartz/QuartzMetronome.h"

#include "AudioMixerClockHandle.generated.h"

/**
 *  This class is a BP / Game thread wrapper around FQuartzClockProxy
 *	(to talk to the underlying clock)
 
 *  ...and inherits from FQuartzTickableObject
 *	(to listen to the underlying clock)
 *  
 *  It can subscribe to Quantized Event & Metronome delegates to synchronize
 *  gameplay & VFX to Quartz events fired from the Audio Engine
 */
UCLASS(BlueprintType, Blueprintable, Transient, ClassGroup = Quartz, meta = (BlueprintSpawnableComponent), MinimalAPI)
class UQuartzClockHandle : public UObject, public FQuartzTickableObject
{
	GENERATED_BODY()

public:
	// ctor
	AUDIOMIXER_API UQuartzClockHandle();

	// dtor
	AUDIOMIXER_API ~UQuartzClockHandle();

	// begin UObject interface
	AUDIOMIXER_API void BeginDestroy() override;
	// end UObject interface

// Begin Blueprint Interface

	// Clock manipulation
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void StartClock(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle);

	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void StopClock(const UObject* WorldContextObject, bool CancelPendingEvents, UQuartzClockHandle*& ClockHandle);

	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void PauseClock(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void ResumeClock(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "Transport, Counter"))
	AUDIOMIXER_API void ResetTransport(const UObject* WorldContextObject, const FOnQuartzCommandEventBP& InDelegate);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "Transport, Counter"))
	AUDIOMIXER_API void ResetTransportQuantized(const UObject* WorldContextObject, FQuartzQuantizationBoundary InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, UQuartzClockHandle*& ClockHandle);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject", Keywords = "Transport, Counter"))
	AUDIOMIXER_API bool IsClockRunning(const UObject* WorldContextObject);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "Transport, Counter"))
	AUDIOMIXER_API void NotifyOnQuantizationBoundary(const UObject* WorldContextObject, FQuartzQuantizationBoundary InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, float InMsOffset = 0.f);

	/** Returns the duration in seconds of the given Quantization Type
	 *
	 * @param The Quantization type to measure
	 * @param The quantity of the Quantization Type to calculate the time of
	 * @return The duration, in seconds, of a multiplier amount of the Quantization Type, or -1 in the case the clock is invalid
	 */
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetDurationOfQuantizationTypeInSeconds(const UObject* WorldContextObject, const EQuartzCommandQuantization& QuantizationType, float Multiplier = 1.0f);

	//Retrieves a timestamp for the clock
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API FQuartzTransportTimeStamp GetCurrentTimestamp(const UObject* WorldContextObject);

	// Returns the amount of time, in seconds, the clock has been running. Caution: due to latency, this will not be perfectly accurate
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetEstimatedRunTime(const UObject* WorldContextObject);

	// "other" clock manipulation
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "Transport, Counter"))
	AUDIOMIXER_API void StartOtherClock(const UObject* WorldContextObject, FName OtherClockName, FQuartzQuantizationBoundary InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate);

	// Metronome subscription
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void SubscribeToQuantizationEvent(const UObject* WorldContextObject, EQuartzCommandQuantization InQuantizationBoundary, const FOnQuartzMetronomeEventBP& OnQuantizationEvent, UQuartzClockHandle*& ClockHandle);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void SubscribeToAllQuantizationEvents(const UObject* WorldContextObject, const FOnQuartzMetronomeEventBP& OnQuantizationEvent, UQuartzClockHandle*& ClockHandle);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void UnsubscribeFromTimeDivision(const UObject* WorldContextObject, EQuartzCommandQuantization InQuantizationBoundary, UQuartzClockHandle*& ClockHandle);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void UnsubscribeFromAllTimeDivisions(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle);

	// Metronome Alteration (setters)
	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = "QuantizationBoundary, Delegate", AutoCreateRefTerm = "QuantizationBoundary, Delegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API void SetMillisecondsPerTick(const UObject* WorldContextObject, UPARAM(ref) const FQuartzQuantizationBoundary& QuantizationBoundary, const FOnQuartzCommandEventBP& Delegate, UQuartzClockHandle*& ClockHandle, float MillisecondsPerTick = 100.f);

	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = "QuantizationBoundary, Delegate", AutoCreateRefTerm = "QuantizationBoundary, Delegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API void SetTicksPerSecond(const UObject* WorldContextObject, UPARAM(ref) const FQuartzQuantizationBoundary& QuantizationBoundary, const FOnQuartzCommandEventBP& Delegate, UQuartzClockHandle*& ClockHandle, float TicksPerSecond = 10.f);

	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = "QuantizationBoundary, Delegate", AutoCreateRefTerm = "QuantizationBoundary, Delegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API void SetSecondsPerTick(const UObject* WorldContextObject, UPARAM(ref) const FQuartzQuantizationBoundary& QuantizationBoundary, const FOnQuartzCommandEventBP& Delegate, UQuartzClockHandle*& ClockHandle, float SecondsPerTick = 0.25f);

	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = "QuantizationBoundary, Delegate", AutoCreateRefTerm = "QuantizationBoundary, Delegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API void SetThirtySecondNotesPerMinute(const UObject* WorldContextObject, UPARAM(ref) const FQuartzQuantizationBoundary& QuantizationBoundary, const FOnQuartzCommandEventBP& Delegate, UQuartzClockHandle*& ClockHandle, float ThirtySecondsNotesPerMinute = 960.f);

	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = "QuantizationBoundary, Delegate", AutoCreateRefTerm = "QuantizationBoundary, Delegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API void SetBeatsPerMinute(const UObject* WorldContextObject, UPARAM(ref) const FQuartzQuantizationBoundary& QuantizationBoundary, const FOnQuartzCommandEventBP& Delegate, UQuartzClockHandle*& ClockHandle, float BeatsPerMinute = 60.f);

	// Metronome getters
	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API float GetMillisecondsPerTick(const UObject* WorldContextObject) const;

	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API float GetTicksPerSecond(const UObject* WorldContextObject) const;

	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API float GetSecondsPerTick(const UObject* WorldContextObject) const;

	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API float GetThirtySecondNotesPerMinute(const UObject* WorldContextObject) const;

	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API float GetBeatsPerMinute(const UObject* WorldContextObject) const;

	/**
	 * Returns the current progress until the next occurrence of the provided musical duration as a float value from 0 (previous beat) to 1 (next beat).
	 * This is useful for indexing into curves to animate parameters to musical time.
	 * Ms and Phase offsets are combined internally.
	 */
	UFUNCTION(BlueprintCallable, Category = "Quantization", meta = ( AutoCreateRefTerm = "PhaseOffset", Keywords = "BPM, Tempo"))
	AUDIOMIXER_API float GetBeatProgressPercent(EQuartzCommandQuantization QuantizationBoundary = EQuartzCommandQuantization::Beat, float PhaseOffset = 0.f, float MsOffset = 0.f);

	// todo: un-comment when metronome events support the offset
	// Set how early we would like to receive Metronome (not yet supported) and "About To Start" Delegates. (all other command delegates will execute as normal)
	// UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", AutoCreateRefTerm = "InDelegate", Keywords = "BPM, Tempo"))
	// void SetNotificationAnticipationAmountInMilliseconds(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle, const double Milliseconds = 0.0);

	// // Set how early we would like to receive Metronome (not yet supported) and "About To Start" Delegates. (all other command delegates will execute as normal)
	// UFUNCTION(BlueprintCallable, Category = "Quantization", meta = (WorldContext = "WorldContextObject", Keywords = "BPM, Tempo"))
	// void SetNotificationAnticipationAmountAsMusicalDuration(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle, const EQuartzCommandQuantization MusicalDuration = EQuartzCommandQuantization::QuarterNote, const double Multiplier = 1.0);

// End Blueprint Interface
	AUDIOMIXER_API void QueueQuantizedSound(const UObject* WorldContextObject, UQuartzClockHandle*& ClockHandle, const FAudioComponentCommandInfo& AudioComponentData, const FOnQuartzCommandEventBP& InDelegate, const FQuartzQuantizationBoundary& InTargetBoundary);

	AUDIOMIXER_API UQuartzClockHandle* SubscribeToClock(const UObject* WorldContextObject, FName ClockName, Audio::FQuartzClockProxy const* InHandlePtr = nullptr);

	FName GetClockName() const { return CurrentClockId; }

	bool DoesClockExist(const UObject* WorldContextObject) const
	{
		return RawHandle.DoesClockExist();
	}

	UE_DEPRECATED(5.1, "This function should not be called directly, and the original functionality has been moved into FQuartzTickable")
	virtual void ProcessCommand(const Audio::FQuartzQuantizedCommandDelegateData& Data) override {}

	UE_DEPRECATED(5.1, "This function should not be called directly, and the original functionality has been moved into FQuartzTickable")
	virtual void ProcessCommand(const Audio::FQuartzMetronomeDelegateData& Data) override {};

	AUDIOMIXER_API bool GetCurrentTickRate(const UObject* WorldContextObject, Audio::FQuartzClockTickRate& OutTickRate) const;

private:
	AUDIOMIXER_API void SetTickRateInternal(const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, const Audio::FQuartzClockTickRate& NewTickRate);

	Audio::FQuartzClockProxy RawHandle;

	FName CurrentClockId;

}; // class UQuartzClockHandle

===============================


=== AudioMixerClockManager.cpp ===
==================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Quartz/AudioMixerClockManager.h"
#include "AudioMixerDevice.h"
#include "Misc/ScopeLock.h"
#include "ProfilingDebugging/CountersTrace.h"

namespace Audio
{
	FQuartzClockManager::FQuartzClockManager(Audio::FMixerDevice* InOwner)
	: MixerDevice(InOwner)
	{
	}

	FQuartzClockManager::~FQuartzClockManager()
	{
		check(ActiveClocks.Num() == 0);
	}

	void FQuartzClockManager::Update(int32 NumFramesUntilNextUpdate)
	{
		// if this is owned by a MixerDevice, this function should only be called on the Audio Render Thread
		TRACE_CPUPROFILER_EVENT_SCOPE(QuartzClockManager::Update)
		if (MixerDevice)
		{
			check(MixerDevice->IsAudioRenderingThread());
		}

		LastUpdateSizeInFrames = NumFramesUntilNextUpdate;
		TickClocks(NumFramesUntilNextUpdate);
	}

	void FQuartzClockManager::LowResoultionUpdate(float DeltaTimeSeconds)
	{
		TRACE_CPUPROFILER_EVENT_SCOPE(QuartzClockManager::Update_LowRes)
		FScopeLock Lock(&ActiveClockCritSec);

		for (auto& Clock : ActiveClocks)
		{
			Clock->LowResolutionTick(DeltaTimeSeconds);
		}
	}

	void FQuartzClockManager::UpdateClock(FName InClockToAdvance, int32 NumFramesToAdvance)
	{
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> ClockPtr = FindClock(InClockToAdvance);

		if (ClockPtr.IsValid())
		{
			ClockPtr->Tick(NumFramesToAdvance);
		}
	}

	FQuartzClockProxy FQuartzClockManager::GetOrCreateClock(const FName& InClockName, const FQuartzClockSettings& InClockSettings, bool bOverrideTickRateIfClockExists)
	{
		FScopeLock Lock(&ActiveClockCritSec);

		// make a copy of the Settings
		FQuartzClockSettings NewSettings = InClockSettings;

		// See if this clock already exists
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);

		if (Clock)
		{
			if (bOverrideTickRateIfClockExists && !Clock->DoesMatchSettings(NewSettings))
			{
				UE_LOG(LogAudioQuartz, Display, TEXT("Overriding Tick Rate on Clock: %s"), *Clock->GetName().ToString());
				Clock->ChangeTimeSignature(NewSettings.TimeSignature);
			}

			return FQuartzClockProxy(Clock);
		}

		// doesn't exist, create new clock
		return FQuartzClockProxy(ActiveClocks.Emplace_GetRef(MakeShared<FQuartzClock>(InClockName, NewSettings, this)));
	}

	FQuartzClockProxy FQuartzClockManager::GetClock(const FName& InClockName)
	{
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> ClockPtr = FindClock(InClockName);

		if (ClockPtr)
		{
			return FQuartzClockProxy(ClockPtr);
		}

		UE_LOG(LogAudioQuartz, Warning, TEXT("Could not find Clock: %s (returning empty handle)"), *ClockPtr->GetName().ToString());
		return {};
	}

	bool FQuartzClockManager::DoesClockExist(const FName& InClockName)
	{
		FScopeLock Lock(&ActiveClockCritSec);
		return !!FindClock(InClockName);
	}

	bool FQuartzClockManager::IsClockRunning(const FName& InClockName)
	{
		FScopeLock Lock(&ActiveClockCritSec);

		// See if this clock already exists
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);

		if (Clock)
		{
			return Clock->IsRunning();
		}

		// clock doesn't exist
		return false;
	}

	float FQuartzClockManager::GetDurationOfQuantizationTypeInSeconds(const FName& InClockName, const EQuartzCommandQuantization& QuantizationType, float Multiplier)
	{
		FScopeLock Lock(&ActiveClockCritSec);

		// See if this clock already exists
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);

		if (Clock)
		{
			return Clock->GetDurationOfQuantizationTypeInSeconds(QuantizationType, Multiplier);
		}

		//Clock doesn't exist
		return INDEX_NONE;
	}

	FQuartzTransportTimeStamp FQuartzClockManager::GetCurrentTimestamp(const FName& InClockName)
	{
		FScopeLock Lock(&ActiveClockCritSec);

		// See if this clock already exists
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);

		if (Clock)
		{
			return Clock->GetCurrentTimestamp();
		}

		//Clock doesn't exist
		return FQuartzTransportTimeStamp();
	}

	float FQuartzClockManager::GetEstimatedRunTime(const FName& InClockName)
	{
		FScopeLock Lock(&ActiveClockCritSec);

		// See if this clock already exists
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);

		if (Clock)
		{
			return Clock->GetEstimatedRunTime();
		}

		//Clock doesn't exist
		return INDEX_NONE;
	}

	void FQuartzClockManager::RemoveClock(const FName& InName, bool bForceSynchronous)
	{
		if (!bForceSynchronous && MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InName]()
			{
				RemoveClock(InName);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		int32 NumClocks = ActiveClocks.Num();
		for (int32 i = NumClocks - 1; i >= 0; --i)
		{
			if (ActiveClocks[i]->GetName() == InName)
			{
				UE_LOG(LogAudioQuartz, Verbose, TEXT("Removing Clock: %s"), *InName.ToString());
				ActiveClocks.RemoveAtSwap(i);
			}
		}

	}

	FQuartzClockTickRate FQuartzClockManager::GetTickRateForClock(const FName& InName)
	{
		FScopeLock Lock(&ActiveClockCritSec);

		TSharedPtr<FQuartzClock> Clock = FindClock(InName);

		if (Clock)
		{
			return Clock->GetTickRate();
		}

		return FQuartzClockTickRate();
	}

	void FQuartzClockManager::SetTickRateForClock(const FQuartzClockTickRate& InNewTickRate, const FName& InName)
	{
		if (MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InNewTickRate, InName]()
			{
				SetTickRateForClock(InNewTickRate, InName);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InName);
		if (Clock)
		{
			Clock->ChangeTickRate(InNewTickRate);
		}
	}

	void FQuartzClockManager::ResumeClock(const FName& InName, int32 NumFramesToDelayStart)
	{
		if (MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InName]()
			{
				ResumeClock(InName);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InName);
		if (Clock)
		{
			Clock->AddToTickDelay(NumFramesToDelayStart);
			Clock->Resume();
		}
	}

	void FQuartzClockManager::StopClock(const FName& InName, bool CancelPendingEvents)
	{
		if (MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InName, CancelPendingEvents]()
			{
				StopClock(InName, CancelPendingEvents);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InName);
		if (Clock)
		{
			Clock->Stop(CancelPendingEvents);
		}
	}

	void FQuartzClockManager::PauseClock(const FName& InName)
	{
		if (MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InName]()
			{
				PauseClock(InName);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InName);
		if (Clock)
		{
			Clock->Pause();
		}
	}

	void FQuartzClockManager::Flush()
	{
		FScopeLock Lock(&ActiveClockCritSec);

		int32 NumClocks = ActiveClocks.Num();

		for (int32 i = NumClocks - 1; i >= 0; --i)
		{
			if (!MixerDevice || !ActiveClocks[i]->IgnoresFlush())
			{
				ActiveClocks.RemoveAtSwap(i);
			}
		}
	}

	void FQuartzClockManager::Shutdown()
	{
		FScopeLock Lock(&ActiveClockCritSec);
		ActiveClocks.Reset();
	}

	FQuartzQuantizedCommandHandle FQuartzClockManager::AddCommandToClock(FQuartzQuantizedCommandInitInfo& InQuantizationCommandInitInfo)
	{
		if (!ensure(InQuantizationCommandInitInfo.QuantizedCommandPtr))
		{
			return {};
		}

		FScopeLock Lock(&ActiveClockCritSec);

		// Can this command run without an Audio Device?
		if (!MixerDevice && InQuantizationCommandInitInfo.QuantizedCommandPtr->RequiresAudioDevice())
		{
			InQuantizationCommandInitInfo.QuantizedCommandPtr->Cancel();
		}
		// does the target clock exist?
		else if (TSharedPtr<FQuartzClock> Clock = FindClock(InQuantizationCommandInitInfo.ClockName))
		{
			// pass the quantized command to it's clock
			InQuantizationCommandInitInfo.SetOwningClockPtr(Clock);
			InQuantizationCommandInitInfo.QuantizedCommandPtr->OnQueued(InQuantizationCommandInitInfo);
			Clock->AddQuantizedCommand(InQuantizationCommandInitInfo.QuantizationBoundary, InQuantizationCommandInitInfo.QuantizedCommandPtr);

			// initialize the handle the audio source can use to cancel this quantized command
			FQuartzQuantizedCommandHandle Handle;
			Handle.OwningClockName = InQuantizationCommandInitInfo.ClockName;
			Handle.CommandPtr = InQuantizationCommandInitInfo.QuantizedCommandPtr;
			Handle.MixerDevice = MixerDevice;

			return Handle;
		}

		return {};
	}

	void FQuartzClockManager::SubscribeToTimeDivision(FName InClockName, MetronomeCommandQueuePtr InListenerQueue, EQuartzCommandQuantization InQuantizationBoundary)
	{
		if (MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InClockName, InListenerQueue, InQuantizationBoundary]()
			{
				SubscribeToTimeDivision(InClockName, InListenerQueue, InQuantizationBoundary);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);
		if (Clock)
		{
			Clock->SubscribeToTimeDivision(FQuartzGameThreadSubscriber(InListenerQueue), InQuantizationBoundary);
		}
	}

	void FQuartzClockManager::SubscribeToAllTimeDivisions(FName InClockName, MetronomeCommandQueuePtr InListenerQueue)
	{
		if (MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InClockName, InListenerQueue]()
			{
				SubscribeToAllTimeDivisions(InClockName, InListenerQueue);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);
		if (Clock)
		{
			Clock->SubscribeToAllTimeDivisions(FQuartzGameThreadSubscriber(InListenerQueue));
		}
	}

	void FQuartzClockManager::UnsubscribeFromTimeDivision(FName InClockName, MetronomeCommandQueuePtr InListenerQueue, EQuartzCommandQuantization InQuantizationBoundary)
	{
		if (MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InClockName, InListenerQueue, InQuantizationBoundary]()
			{
				UnsubscribeFromTimeDivision(InClockName, InListenerQueue, InQuantizationBoundary);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);
		if (Clock)
		{
			Clock->UnsubscribeFromTimeDivision(FQuartzGameThreadSubscriber(InListenerQueue), InQuantizationBoundary);
		}
	}

	void FQuartzClockManager::UnsubscribeFromAllTimeDivisions(FName InClockName, MetronomeCommandQueuePtr InListenerQueue)
	{
		if (MixerDevice && !MixerDevice->IsAudioRenderingThread())
		{
			MixerDevice->AudioRenderThreadCommand([this, InClockName, InListenerQueue]()
			{
				UnsubscribeFromAllTimeDivisions(InClockName, InListenerQueue);
			});

			return;
		}

		// Anything below is being executed on the Audio Render Thread
		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InClockName);
		if (Clock)
		{
			Clock->UnsubscribeFromAllTimeDivisions(FQuartzGameThreadSubscriber(InListenerQueue));
		}
	}

	bool FQuartzClockManager::CancelCommandOnClock(FName InOwningClockName, TSharedPtr<IQuartzQuantizedCommand> InCommandPtr)
	{
		// This function should only be called on the Audio Render Thread
		if (MixerDevice)
		{
			check(MixerDevice->IsAudioRenderingThread());
		}

		FScopeLock Lock(&ActiveClockCritSec);
		TSharedPtr<FQuartzClock> Clock = FindClock(InOwningClockName);

		if (Clock && InCommandPtr)
		{
			return Clock->CancelQuantizedCommand(InCommandPtr);
		}

		return false;
	}

	bool FQuartzClockManager::HasClockBeenTickedThisUpdate(FName InClockName)
	{
		FScopeLock Lock(&ActiveClockCritSec);
		int32 NumClocks = ActiveClocks.Num();

		for (int32 i = 0; i < NumClocks; ++i)
		{
			TSharedPtr<FQuartzClock> ClockPtr = ActiveClocks[i];
			check(ClockPtr.IsValid());

			if (ClockPtr->GetName() == InClockName)
			{
				// if this clock is earlier in the array than the last clock we ticked,
				// then it has already been ticked this update
				if (i < LastClockTickedIndex.GetValue())
				{
					return true;
				}

				return false;
			}
		}

		return false;
	}

	FMixerDevice* FQuartzClockManager::GetMixerDevice() const
	{
		return MixerDevice;
	}

	void FQuartzClockManager::TickClocks(int32 NumFramesToTick)
	{
		TRACE_CPUPROFILER_EVENT_SCOPE(QuartzClockManager::TickClocks);
		int32 TotalNumPendingCommands = 0;

		if (MixerDevice)
		{
			// This function should only be called on the Audio Render Thread
			check(MixerDevice->IsAudioRenderingThread());
		}

		FScopeLock Lock(&ActiveClockCritSec);
		for (auto& Clock : ActiveClocks)
		{
			TotalNumPendingCommands += Clock->NumPendingEvents();
			Clock->Tick(NumFramesToTick);
			LastClockTickedIndex.Increment();
		}

		TRACE_INT_VALUE(TEXT("QuartzClockManager::NumActiveClocks"), ActiveClocks.Num());
		TRACE_INT_VALUE(TEXT("QuartzClockManager::NumTotalPendingCommands"), TotalNumPendingCommands);

		LastClockTickedIndex.Reset();
	}

	TSharedPtr<FQuartzClock> FQuartzClockManager::FindClock(const FName& InName)
	{
		FScopeLock Lock(&ActiveClockCritSec);
		for (auto& Clock : ActiveClocks)
		{
			if (Clock->GetName() == InName)
			{
				return Clock;
			}
		}

		// didn't exist
		return nullptr;
	}
} // namespace Audio

==================================


=== AudioMixerClockManager.h ===
================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "AudioMixerClock.h"
#include "Sound/QuartzQuantizationUtilities.h"

namespace Audio
{
	// forwards
	class FMixerDevice;
	class FQuartzClock;
	class FQuartzClockManager;

	// Class that owns, updates, and provides access to all active clocks
	// All methods are thread-safe. The method locks if it returns a value, and stages a command if it returns void
	class FQuartzClockManager : public FQuartLatencyTracker
	{
	public:
		// ctor
		AUDIOMIXER_API FQuartzClockManager(Audio::FMixerDevice* InOwner = nullptr);

		// dtor
		AUDIOMIXER_API ~FQuartzClockManager();

		int32 GetNumClocks() const { return ActiveClocks.Num(); }

		// Called on AudioRenderThread
		AUDIOMIXER_API void Update(int32 NumFramesUntilNextUpdate);
		AUDIOMIXER_API void UpdateClock(FName InClockToAdvance, int32 NumFramesToAdvance);

		// can be called from any thread for low-resolution clock updates
		// (i.e. used when running without an audio device)
		// not sample-accurate!
		AUDIOMIXER_API void LowResoultionUpdate(float DeltaTimeSeconds);

		// add (and take ownership of) a new clock
		// safe to call from AudioThread (uses critical section)
		AUDIOMIXER_API FQuartzClockProxy GetOrCreateClock(const FName& InClockName, const FQuartzClockSettings& InClockSettings, bool bOverrideTickRateIfClockExists = false);
		AUDIOMIXER_API FQuartzClockProxy GetClock(const FName& InClockName);

		// returns true if a clock with the given name already exists.
		AUDIOMIXER_API bool DoesClockExist(const FName& InClockName);

		// returns true if the name is running
		AUDIOMIXER_API bool IsClockRunning(const FName& InClockName);

		// Returns the duration in seconds of the given Quantization Type, or -1 if the Clock is invalid or nonexistent
		AUDIOMIXER_API float GetDurationOfQuantizationTypeInSeconds(const FName& InClockName, const EQuartzCommandQuantization& QuantizationType, float Multiplier);

		// Returns the current location of the clock in the transport
		AUDIOMIXER_API FQuartzTransportTimeStamp GetCurrentTimestamp(const FName& InClockName);

		// Returns the amount of time, in seconds, the clock has been running. Caution: due to latency, this will not be perfectly accurate
		AUDIOMIXER_API float GetEstimatedRunTime(const FName& InClockName);

		// remove existing clock
		// safe to call from AudioThread (uses Audio Render Thread Command)
		AUDIOMIXER_API void RemoveClock(const FName& InName, bool bForceSynchronous = false);

		// get Tick rate for clock
		// safe to call from AudioThread (uses critical section)
		AUDIOMIXER_API FQuartzClockTickRate GetTickRateForClock(const FName& InName);

		AUDIOMIXER_API void SetTickRateForClock(const FQuartzClockTickRate& InNewTickRate, const FName& InName);

		// start the given clock
		// safe to call from AudioThread (uses Audio Render Thread command)
		AUDIOMIXER_API void ResumeClock(const FName& InName, int32 NumFramesToDelayStart = 0);

		// stop the given clock
		// safe to call from AudioThread (uses Audio Render Thread command)
		AUDIOMIXER_API void StopClock(const FName& InName, bool CancelPendingEvents);

		// stop the given clock
		// safe to call from AudioThread (uses Audio Render Thread command)
		AUDIOMIXER_API void PauseClock(const FName& InName);

		// shutdown all clocks that don't ignore Flush() (i.e. level change)
		AUDIOMIXER_API void Flush();

		// stop all clocks and cancel all pending events
		AUDIOMIXER_API void Shutdown();

		// add a new command to a given clock
		// safe to call from AudioThread (uses Audio Render Thread command)
		AUDIOMIXER_API FQuartzQuantizedCommandHandle AddCommandToClock(FQuartzQuantizedCommandInitInfo& InQuantizationCommandInitInfo);

		// subscribe to a specific time division on a clock
		// TODO: update the metronome subscription functions to take an FQuartzGameThreadSubscriber instead of the Command queue ptr
		// (to support metronome event offset)
		AUDIOMIXER_API void SubscribeToTimeDivision(FName InClockName, MetronomeCommandQueuePtr InListenerQueue, EQuartzCommandQuantization InQuantizationBoundary);

		// subscribe to all time divisions on a clock
		AUDIOMIXER_API void SubscribeToAllTimeDivisions(FName InClockName, MetronomeCommandQueuePtr InListenerQueue);

		// un-subscribe from a specific time division on a clock
		AUDIOMIXER_API void UnsubscribeFromTimeDivision(FName InClockName, MetronomeCommandQueuePtr InListenerQueue, EQuartzCommandQuantization InQuantizationBoundary);

		// un-subscribe from all time divisions on a specific clock
		AUDIOMIXER_API void UnsubscribeFromAllTimeDivisions(FName InClockName, MetronomeCommandQueuePtr InListenerQueue);

		// cancel a queued command on a clock (i.e. cancel a PlayQuantized command if the sound is stopped before it is played)
		AUDIOMIXER_API bool CancelCommandOnClock(FName InOwningClockName, TSharedPtr<IQuartzQuantizedCommand> InCommandPtr);

		AUDIOMIXER_API bool HasClockBeenTickedThisUpdate(FName InClockName);

		int32 GetLastUpdateSizeInFrames() const { return LastUpdateSizeInFrames; }

		// get access to the owning FMixerDevice
		AUDIOMIXER_API FMixerDevice* GetMixerDevice() const;

	private:
		// updates all active clocks
		AUDIOMIXER_API void TickClocks(int32 NumFramesToTick);

		// find clock with a given key
		AUDIOMIXER_API TSharedPtr<FQuartzClock> FindClock(const FName& InName);

		// pointer to owning FMixerDevice
		FMixerDevice* MixerDevice;

		// Container of active clocks
		FCriticalSection ActiveClockCritSec;

		// Our array of active clocks (mutation/access acquires clock)
		TArray<TSharedPtr<FQuartzClock>> ActiveClocks;

		FThreadSafeCounter LastClockTickedIndex{ 0 };
		int32 LastUpdateSizeInFrames{ 0 };

		// allow a clock that is queuing a command directly use FindClock() to retrieve the TSharedPtr<FQuartzClock>
		friend void FQuartzClock::AddQuantizedCommand(FQuartzQuantizedCommandInitInfo& InQuantizationCommandInitInfo);
	};

	// data that the UQuartzSubsystem needs to persist on the AudioDevice across UWorld shutdown/startup
	struct FPersistentQuartzSubsystemData
	{
		// internal clock manager for game-thread-ticked clocks
		FQuartzClockManager SubsystemClockManager;

		// array of active clock handles (update FindProxyByName() if more are added later)
		TArray<Audio::FQuartzClockProxy> ActiveExternalClockProxies;
		TArray<Audio::FQuartzClockProxy> ActiveAudioMixerClockProxies;
	};
} // namespace Audio

================================


=== AudioMixerDevice.cpp ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerDevice.h"

#include "AssetRegistry/IAssetRegistry.h"
#include "Async/Async.h"
#include "AudioAnalytics.h"
#include "AudioBusSubsystem.h"
#include "AudioDeviceNotificationSubsystem.h"
#include "AudioMixerSource.h"
#include "AudioMixerSourceManager.h"
#include "AudioMixerSourceDecode.h"
#include "AudioMixerSubmix.h"
#include "AudioMixerSourceVoice.h"
#include "AudioPluginUtilities.h"
#include "AudioMixerEffectsManager.h"
#include "DSP/Noise.h"
#include "DSP/SinOsc.h"
#include "Sound/AudioSettings.h"
#include "Sound/SoundSubmix.h"
#include "Sound/SoundSubmixSend.h"
#include "SubmixEffects/AudioMixerSubmixEffectEQ.h"
#include "SubmixEffects/AudioMixerSubmixEffectDynamicsProcessor.h"
#include "UObject/StrongObjectPtr.h"
#include "UObject/UObjectHash.h"
#include "UObject/UObjectIterator.h"
#include "IHeadMountedDisplayModule.h"
#include "ISubmixBufferListener.h"
#include "Misc/App.h"
#include "ProfilingDebugging/CsvProfiler.h"
#include "AssetRegistry/IAssetRegistry.h"
#include "Async/Async.h"
#include "AudioDeviceNotificationSubsystem.h"
#include "Sound/AudioFormatSettings.h"
#include "HAL/PlatformMisc.h"

#if WITH_EDITOR
#include "AudioEditorModule.h"
#endif // WITH_EDITOR

#ifndef CASE_ENUM_TO_TEXT
#define CASE_ENUM_TO_TEXT(X) case X: return TEXT(#X);
#endif

const TCHAR* LexToString(const ERequiredSubmixes InType)
{
	switch (InType)
	{
		FOREACH_ENUM_EREQUIREDSUBMIXES(CASE_ENUM_TO_TEXT)
	}
	return TEXT("Unknown");
}

static int32 DisableSubmixEffectEQCvar = 1;
FAutoConsoleVariableRef CVarDisableSubmixEQ(
	TEXT("au.DisableSubmixEffectEQ"),
	DisableSubmixEffectEQCvar,
	TEXT("Disables the eq submix (true by default as of 5.0).\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 DisableSubmixMutationLockCVar = 0;
FAutoConsoleVariableRef CVarDisableSubmixMutationLock(
	TEXT("au.DisableSubmixMutationLock"),
	DisableSubmixMutationLockCVar,
	TEXT("Disables the submix mutation lock.\n")
	TEXT("0: Not Disabled (Default), 1: Disabled"),
	ECVF_Default);

static int32 EnableAudibleDefaultEndpointSubmixesCVar = 0;
FAutoConsoleVariableRef CVarEnableAudibleDefaultEndpointSubmixes(
	TEXT("au.submix.audibledefaultendpoints"),
	EnableAudibleDefaultEndpointSubmixesCVar,
	TEXT("Allows audio sent to defaulted (typically silent) endpoint submixes to be audible via master. (useful for debugging)\n")
	TEXT("0: Disabled (Default), 1: Enabled"),
	ECVF_Default);

static int32 DebugGeneratorEnableCVar = 0;
FAutoConsoleVariableRef CVarDebugGeneratorEnable(
	TEXT("au.Debug.Generator"),
	DebugGeneratorEnableCVar,
	TEXT("Enables/disables debug sound generation.\n")
	TEXT("0: Disabled, 1: SinTone, 2: WhiteNoise"),
	ECVF_Default);

static float DebugGeneratorAmpCVar = 0.2f;
FAutoConsoleVariableRef CVarDebugGeneratorAmp(
	TEXT("au.Debug.Generator.Amp"),
	DebugGeneratorAmpCVar,
	TEXT("Sets.\n")
	TEXT("Default: 0.2f"),
	ECVF_Default);

static int32 DebugGeneratorChannelCVar = 0;
FAutoConsoleVariableRef CVarDebugGeneratorChannel(
	TEXT("au.Debug.Generator.Channel"),
	DebugGeneratorChannelCVar,
	TEXT("Sets channel output index of debug audio.  If number provided is above supported number, uses left.\n")
	TEXT("0: Left, 1: Right, etc."),
	ECVF_Default);

static float DebugGeneratorFreqCVar = 440.0f;
FAutoConsoleVariableRef CVarDebugGeneratorFreq(
	TEXT("au.Debug.Generator.Freq"),
	DebugGeneratorFreqCVar,
	TEXT("Sets debug sound generation frequency.\n")
	TEXT("0: Not Disabled, 1: SinTone, 2: WhiteNoise"),
	ECVF_Default);

static int32 AudioMixerPatchBufferBlocks = 3;
FAutoConsoleVariableRef CVarAudioMixerPatchBufferBlocks(
	TEXT("au.PatchBufferBlocks"),
	AudioMixerPatchBufferBlocks,
	TEXT("Determines the number of blocks that fit in a patch buffer."),
	ECVF_Default);

// Link to "Audio" profiling category
CSV_DECLARE_CATEGORY_MODULE_EXTERN(AUDIOMIXERCORE_API, Audio);

namespace Audio
{
	void FSubmixMap::Add(const FSubmixMap::FObjectId InObjectId, FMixerSubmixPtr InMixerSubmix)
	{
		if (DisableSubmixMutationLockCVar)
		{
			SubmixMap.Add(InObjectId, InMixerSubmix);
		}
		else
		{
			FScopeLock ScopeLock(&MutationLock);
			SubmixMap.Add(InObjectId, InMixerSubmix);
		}
	}

	void FSubmixMap::Iterate(FIterFunc InFunction)
	{
		if (DisableSubmixMutationLockCVar)
		{
			for (const FPair& Pair : SubmixMap)
			{
				InFunction(Pair);
			}
		}
		else
		{
			FScopeLock ScopeLock(&MutationLock);
			for (const FPair& Pair : SubmixMap)
			{
				InFunction(Pair);
			}
		}
	}

	FMixerSubmixPtr FSubmixMap::FindRef(const FSubmixMap::FObjectId InObjectId) const
	{
		if (DisableSubmixMutationLockCVar)
		{
			return SubmixMap.FindRef(InObjectId);
		}
		else
		{
			FScopeLock ScopeLock(&MutationLock);
			return SubmixMap.FindRef(InObjectId);
		}
	}

	int32 FSubmixMap::Remove(const FSubmixMap::FObjectId InObjectId)
	{
		if (DisableSubmixMutationLockCVar)
		{
			return SubmixMap.Remove(InObjectId);
		}
		else
		{
			FScopeLock ScopeLock(&MutationLock);
			return SubmixMap.Remove(InObjectId);
		}
	}

	void FSubmixMap::Reset()
	{
		if (DisableSubmixMutationLockCVar)
		{
			SubmixMap.Reset();
		}
		else
		{
			FScopeLock ScopeLock(&MutationLock);
			SubmixMap.Reset();
		}
	}

	TSet<FSubmixMap::FObjectId> FSubmixMap::GetKeys() const
	{
		FScopeLock ScopeLock(&MutationLock);
		TArray<FObjectId> Keys;
		SubmixMap.GenerateKeyArray(Keys);
		return TSet<FObjectId>(Keys);
	}


	static FAutoConsoleCommand DumpSubmixCmd(
		TEXT("au.submix.drawgraph"),
		TEXT("Draws the submix heirarchy for this world to the debug output"),
		FConsoleCommandWithWorldArgsAndOutputDeviceDelegate::CreateLambda([](const TArray<FString>& InArgs, UWorld* InWorld, FOutputDevice& OutLog)
		{
			if (InWorld)
			{
				if (const FMixerDevice* MixerDevice = static_cast<FMixerDevice*>(InWorld->GetAudioDeviceRaw()))
				{
					MixerDevice->DrawSubmixes(OutLog, InArgs);
				}
			}
		})
	);


	
	static void DrawSubmixHeirarchy(USoundSubmixBase* InSubmix, const TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe> InInstance, const FMixerDevice* InDevice, int32 InIdent, FOutputDevice& Ar, const TCHAR* GroupingText)
	{
		if (!InSubmix)
		{
			return;
		}
		
		FString Indet = FCString::Spc(InIdent*3);
		FString FxChain;
		if (USoundSubmix* Submix = Cast<USoundSubmix>(InSubmix))
		{		
			for (const TObjectPtr<USoundEffectSubmixPreset>& i: Submix->SubmixEffectChain)
			{
				FxChain += FString::Printf(TEXT("[%s]"), *GetNameSafe(i));
			}
		}

		Ar.Logf(TEXT("%sName=%s,Instance=0x%p,Id=%u,Fx=%s,[%s]"), *Indet, *InSubmix->GetName(), InInstance.Get(), InInstance ? InInstance->GetId() : 0, *FxChain, GroupingText);
		for (const auto& i : InSubmix->ChildSubmixes)
		{
			DrawSubmixHeirarchy(i, InDevice->GetSubmixInstance(i).Pin(), InDevice, InIdent+1, Ar, TEXT("Static"));
		}
		const auto& DynamicSubmixes = InSubmix->DynamicChildSubmixes.FindOrAdd(InDevice->DeviceID);
		for (const auto& i : DynamicSubmixes.ChildSubmixes)
		{
			DrawSubmixHeirarchy(i, InDevice->GetSubmixInstance(i).Pin(), InDevice, InIdent+1, Ar, TEXT("Dynamic"));
		}
	}

	static void DrawSubmixInstances(const FMixerSubmix* InRoot, const int32 InIdent, FOutputDevice& InOutput)
	{
		if (!InRoot)
		{
			return;
		}

		const FString Indent = FCString::Spc(InIdent*3);
		InOutput.Logf(TEXT("%sName=%s,Instance=0x%p,Id=%u"),
			*Indent, *InRoot->GetName(), InRoot, InRoot->GetId());

		// Go downwards.
		const TMap<uint32, FChildSubmixInfo>& Children = InRoot->GetChildren();
		for (const auto& i : Children)
		{
			if (FMixerSubmixPtr Child =  i.Value.SubmixPtr.Pin())
			{
				DrawSubmixInstances(Child.Get(), InIdent+1, InOutput);
			}
		}
	}
	
	void FMixerDevice::DrawSubmixes(FOutputDevice& InOutput, const TArray<FString>& InArgs) const
	{
		InOutput.Logf(TEXT("AudioDevice=%d, Device Instance=0x%p"), DeviceID, this);

		// Params.
		if (Algo::FindByPredicate(InArgs, [](const FString& InStr){ return FParse::Param(*InStr, TEXT("Instances")); }) != nullptr)
		{
			InOutput.Logf(TEXT("[Instance Hierarchy]"));
			for (int32 i = 0; i < RequiredSubmixes.Num(); i++)
			{
				InOutput.Logf(TEXT("SlotName=[%s]"), ToCStr(LexToString(static_cast<ERequiredSubmixes>(i))));
				DrawSubmixInstances(RequiredSubmixInstances[i].Get(), 1, InOutput);
			}
		}
		if (Algo::FindByPredicate(InArgs, [](const FString& InStr){ return FParse::Param(*InStr, TEXT("Map")); }) != nullptr)
		{
			InOutput.Logf(TEXT("[Map of UObject -> SubmixPtrs]"));

			// Map loop of unique ids from UObjects.
			TMap<uint32, USoundSubmixBase*> AllSubmixes;
			for (TObjectIterator<USoundSubmixBase> It; It; ++It)
			{
				AllSubmixes.Add(It->GetUniqueID(),*It);
			}
			for (const auto i : Submixes.GetKeys())
			{
				const auto pFound = AllSubmixes.Find(i);
				InOutput.Logf(TEXT("%u -> %s"), i, pFound ? *GetNameSafe(*pFound) : TEXT("Not found"));
			}
		}

		// USubmixMap hierarchy from slots downwards.
		InOutput.Logf(TEXT("[Map of UObject Hierarchy]"));
		for (int32 i = 0; i < RequiredSubmixes.Num(); i++)
		{
			InOutput.Logf(TEXT("SlotName=[%s]"), ToCStr(LexToString(static_cast<ERequiredSubmixes>(i))));
			DrawSubmixHeirarchy(RequiredSubmixes[i], RequiredSubmixInstances[i], this, 1, InOutput, TEXT("In Slot"));
		}
	}

	FMixerDevice::FMixerDevice(IAudioMixerPlatformInterface* InAudioMixerPlatform)
		: QuantizedEventClockManager(this)
		, AudioMixerPlatform(InAudioMixerPlatform)
		, AudioClockDelta(0.0)
		, PreviousPrimaryVolume((float)INDEX_NONE)
		, GameOrAudioThreadId(INDEX_NONE)
		, AudioPlatformThreadId(INDEX_NONE)
		, bDebugOutputEnabled(false)
		, bSubmixRegistrationDisabled(true)
	{
		// This audio device is the audio mixer
		bAudioMixerModuleLoaded = true;

		SourceManager = MakeUnique<FMixerSourceManager>(this);

		// Register AudioLink Factory. 	
		TArray<FName> Factories = IAudioLinkFactory::GetAllRegisteredFactoryNames();
		if(Factories.Num() > 0)
		{
			// Allow only a single registered factory instance for now.
			check(Factories.Num()==1);
			AudioLinkFactory=IAudioLinkFactory::FindFactory(Factories[0]);
		}
	}

	FMixerDevice::~FMixerDevice()
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(this);

		// Shutdown all pending clock events, as they may have references to 
		// the FMixerSourceManager that is about to be destroyed
		QuantizedEventClockManager.Shutdown();

		if (AudioMixerPlatform != nullptr)
		{
			delete AudioMixerPlatform;
		}
	}

	void FMixerDevice::AddReferencedObjects(FReferenceCollector& Collector)
	{
	}

	void FMixerDevice::CheckAudioThread() const
	{
#if AUDIO_MIXER_ENABLE_DEBUG_MODE
		// "Audio Thread" is the game/audio thread ID used above audio rendering thread.
		AUDIO_MIXER_CHECK(IsInAudioThread());
#endif
	}

	void FMixerDevice::OnListenerUpdated(const TArray<FListener>& InListeners)
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		ListenerTransforms.Reset(InListeners.Num());

		for (const FListener& Listener : InListeners)
		{
			ListenerTransforms.Add(Listener.Transform);
		}

		SourceManager->SetListenerTransforms(ListenerTransforms);
	}

	void FMixerDevice::ResetAudioRenderingThreadId()
	{
		AudioPlatformThreadId = INDEX_NONE;
		CheckAudioRenderingThread();
	}

	void FMixerDevice::CheckAudioRenderingThread() const
	{
		if (AudioPlatformThreadId == INDEX_NONE)
		{
			AudioPlatformThreadId = FPlatformTLS::GetCurrentThreadId();
		}
		int32 CurrentThreadId = FPlatformTLS::GetCurrentThreadId();
		AUDIO_MIXER_CHECK(CurrentThreadId == AudioPlatformThreadId);
	}

	bool FMixerDevice::IsAudioRenderingThread() const
	{
		int32 CurrentThreadId = FPlatformTLS::GetCurrentThreadId();
		return CurrentThreadId == AudioPlatformThreadId;
	}

	bool FMixerDevice::IsNonRealtime() const
	{
		return AudioMixerPlatform && AudioMixerPlatform->IsNonRealtime();
	}

	TArray<Audio::FChannelPositionInfo>* FMixerDevice::GetDefaultPositionMap(int32 NumChannels)
	{
		const Audio::FChannelPositionInfo* SpeakerPositions = GetDefaultChannelPositions();

		if (!SpeakerPositions) // speaker maps are not yet initialized
		{
			return nullptr;
		}

		switch (NumChannels)
		{
			// Mono speaker directly in front of listener:
			case 1:
			{
				// force angle on single channel if we are mono
				static TArray<Audio::FChannelPositionInfo> MonoMap = { {EAudioMixerChannel::FrontCenter, 0, 0} };
				return &MonoMap;
			}

			// Stereo speakers to front left and right of listener:
			case 2:
			{
				static TArray<Audio::FChannelPositionInfo> StereoMap = { SpeakerPositions[EAudioMixerChannel::FrontLeft], SpeakerPositions[EAudioMixerChannel::FrontRight] };
				return &StereoMap;
			}

			// Quadrophonic speakers at each corner.
			case 4:
			{
				static TArray<Audio::FChannelPositionInfo> QuadMap = {
														 SpeakerPositions[EAudioMixerChannel::FrontLeft] //left
														,SpeakerPositions[EAudioMixerChannel::FrontRight] // right
														,SpeakerPositions[EAudioMixerChannel::SideLeft] //Left Surround
														,SpeakerPositions[EAudioMixerChannel::SideRight] //Right Surround
				};
				return &QuadMap;
			}

			// 5.1 speakers.
			case 6:
			{
				static TArray<Audio::FChannelPositionInfo> FiveDotOneMap = {
														 SpeakerPositions[EAudioMixerChannel::FrontLeft] //left
														,SpeakerPositions[EAudioMixerChannel::FrontRight] // right
														,SpeakerPositions[EAudioMixerChannel::FrontCenter] //center
														,SpeakerPositions[EAudioMixerChannel::LowFrequency] //LFE
														,SpeakerPositions[EAudioMixerChannel::SideLeft] //Left Rear
														,SpeakerPositions[EAudioMixerChannel::SideRight] //Right Rear
				};
				return &FiveDotOneMap;
			}

			// 7.1 speakers.
			case 8:
			{
				static TArray<Audio::FChannelPositionInfo> SevenDotOneMap = {
														 SpeakerPositions[EAudioMixerChannel::FrontLeft] // left
														,SpeakerPositions[EAudioMixerChannel::FrontRight] // right
														,SpeakerPositions[EAudioMixerChannel::FrontCenter] //center
														,SpeakerPositions[EAudioMixerChannel::LowFrequency] //LFE
														,SpeakerPositions[EAudioMixerChannel::BackLeft] // Left Rear
														,SpeakerPositions[EAudioMixerChannel::BackRight] // Right Rear
														,SpeakerPositions[EAudioMixerChannel::SideLeft] // Left Surround
														,SpeakerPositions[EAudioMixerChannel::SideRight] // Right Surround
				};


				return &SevenDotOneMap;
			}

			case 0:
			default:
			{
				return nullptr;
			}
		}
	}

	bool FMixerDevice::IsEndpointSubmix(const USoundSubmixBase* InSubmix)
	{
		return InSubmix && (InSubmix->IsA<UEndpointSubmix>() || InSubmix->IsA<USoundfieldEndpointSubmix>());
	}

	void FMixerDevice::UpdateDeviceDeltaTime()
	{
		DeviceDeltaTime = GetGameDeltaTime();
	}

	void FMixerDevice::GetAudioDeviceList(TArray<FString>& OutAudioDeviceNames) const
	{
		if (AudioMixerPlatform && AudioMixerPlatform->IsInitialized())
		{
			uint32 NumOutputDevices;
			if (AudioMixerPlatform->GetNumOutputDevices(NumOutputDevices))
			{
				for (uint32 i = 0; i < NumOutputDevices; ++i)
				{
					FAudioPlatformDeviceInfo DeviceInfo;
					if (AudioMixerPlatform->GetOutputDeviceInfo(i, DeviceInfo))
					{
						OutAudioDeviceNames.Add(DeviceInfo.Name);
					}
				}
			}
		}
	}

	bool FMixerDevice::InitializeHardware()
	{
		ensure(IsInGameThread());
	
		LLM_SCOPE(ELLMTag::AudioMixer);


		if (AudioMixerPlatform && AudioMixerPlatform->InitializeHardware())
		{
			UE_LOG(LogAudioMixer, Display, TEXT("Initializing audio mixer using platform API: '%s'"), *AudioMixerPlatform->GetPlatformApi());

			const UAudioSettings* AudioSettings = GetDefault<UAudioSettings>();
			MonoChannelUpmixMethod = AudioSettings->MonoChannelUpmixMethod;
			PanningMethod = AudioSettings->PanningMethod;

			// Set whether we're the main audio mixer
			bIsMainAudioMixer = IsMainAudioDevice();

			AUDIO_MIXER_CHECK(SampleRate != 0.0f);

			AudioMixerPlatform->RegisterDeviceChangedListener();

			// Allow platforms to override the platform settings callback buffer frame size (i.e. restrict to particular values, etc)
			PlatformSettings.CallbackBufferFrameSize = AudioMixerPlatform->GetNumFrames(PlatformSettings.CallbackBufferFrameSize);

			OpenStreamParams.NumBuffers = PlatformSettings.NumBuffers;
			OpenStreamParams.NumFrames = PlatformSettings.CallbackBufferFrameSize;
			OpenStreamParams.OutputDeviceIndex = AUDIO_MIXER_DEFAULT_DEVICE_INDEX; // TODO: Support overriding which audio device user wants to open, not necessarily default.
			OpenStreamParams.SampleRate = SampleRate;
			OpenStreamParams.AudioMixer = this;
			OpenStreamParams.MaxSources = GetMaxSources();

			FString DefaultDeviceName = AudioMixerPlatform->GetDefaultDeviceName();

			// Allow HMD to specify audio device, if one was not specified in settings
			if (DefaultDeviceName.IsEmpty() && FAudioDevice::CanUseVRAudioDevice() && IHeadMountedDisplayModule::IsAvailable())
			{
				DefaultDeviceName = IHeadMountedDisplayModule::Get().GetAudioOutputDevice();
			}

			if (!DefaultDeviceName.IsEmpty())
			{
				uint32 NumOutputDevices = 0;
				AudioMixerPlatform->GetNumOutputDevices(NumOutputDevices);

				for (uint32 i = 0; i < NumOutputDevices; ++i)
				{
					FAudioPlatformDeviceInfo DeviceInfo;
					AudioMixerPlatform->GetOutputDeviceInfo(i, DeviceInfo);

					if (DeviceInfo.Name == DefaultDeviceName || DeviceInfo.DeviceId == DefaultDeviceName)
					{
						OpenStreamParams.OutputDeviceIndex = i;

						// If we're intentionally selecting an audio device (and not just using the default device) then 
						// lets try to restore audio to that device if it's removed and then later is restored
						OpenStreamParams.bRestoreIfRemoved = true;
						break;
					}
				}
			}

			if (AudioMixerPlatform->OpenAudioStream(OpenStreamParams))
			{
				// Get the platform device info we're using
				PlatformInfo = AudioMixerPlatform->GetPlatformDeviceInfo();
				UE_LOG(LogAudioMixer, Display, TEXT("Using Audio Hardware Device %s"), *PlatformInfo.Name);

				// Initialize some data that depends on speaker configuration, etc.
				InitializeChannelAzimuthMap(PlatformInfo.NumChannels);

				FSourceManagerInitParams SourceManagerInitParams;
				SourceManagerInitParams.NumSources = GetMaxSources();

				// TODO: Migrate this to project settings properly
				SourceManagerInitParams.NumSourceWorkers = 4;


				AudioClock = 0.0;
				AudioClockDelta = (double)OpenStreamParams.NumFrames / OpenStreamParams.SampleRate;
				AudioClockTimingData.UpdateTime = 0.0;

				PluginInitializationParams.NumSources = SourceManagerInitParams.NumSources;
				PluginInitializationParams.SampleRate = SampleRate;
				PluginInitializationParams.BufferLength = OpenStreamParams.NumFrames;
				PluginInitializationParams.AudioDevicePtr = this;

				{
					LLM_SCOPE(ELLMTag::AudioMixerPlugins);

					// Initialize any plugins if they exist
					// spatialization
					SetCurrentSpatializationPlugin(AudioPluginUtilities::GetDesiredSpatializationPluginName());

					if (OcclusionInterface.IsValid())
					{
						OcclusionInterface->Initialize(PluginInitializationParams);
					}

					if (ReverbPluginInterface.IsValid())
					{
						ReverbPluginInterface->Initialize(PluginInitializationParams);
					}

					if (SourceDataOverridePluginInterface.IsValid())
 					{
 						SourceDataOverridePluginInterface->Initialize(PluginInitializationParams);
 					}
				}

				// initialize the source manager after our plugins are spun up (cached by sources)
				SourceManager->Init(SourceManagerInitParams);

				// Need to set these up before we start the audio stream.
				InitSoundSubmixes();

				AudioMixerPlatform->PostInitializeHardware();

				// Initialize the data used for audio thread sub-frame timing.
				AudioThreadTimingData.StartTime = FPlatformTime::Seconds();
				AudioThreadTimingData.AudioThreadTime = 0.0;
				AudioThreadTimingData.AudioRenderThreadTime = 0.0;

				// Create synchronized Audio Task Queue for this device...
				CreateSynchronizedAudioTaskQueue((Audio::AudioTaskQueueId)DeviceID);

				Audio::Analytics::RecordEvent_Usage(TEXT("ProjectSettings"), MakeAnalyticsEventAttributeArray(
					TEXT("SampleRate"), PlatformSettings.SampleRate,
					TEXT("BufferSize"), PlatformSettings.CallbackBufferFrameSize,
					TEXT("NumBuffers"), PlatformSettings.NumBuffers,
					TEXT("NumSources"), PlatformSettings.MaxChannels,
					TEXT("NumOutputChannels"), PlatformInfo.NumChannels));

				// Start streaming audio
				return AudioMixerPlatform->StartAudioStream();
			}
		}
		else if (AudioMixerPlatform)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Failed to initialize audio mixer for platform API: '%s'"), *AudioMixerPlatform->GetPlatformApi());
		}

		return false;
	}

	void FMixerDevice::FadeIn()
	{
		AudioMixerPlatform->FadeIn();
	}

	void FMixerDevice::FadeOut()
	{
		// In editor builds, we aren't going to fade out the main audio device.
#if WITH_EDITOR
		if (!IsMainAudioDevice())
#endif
		{
			AudioMixerPlatform->FadeOut();
		}
	}

	void FMixerDevice::TeardownHardware()
	{
		ensure(IsInGameThread());

		if (IsInitialized())
		{
			for (TObjectIterator<USoundSubmix> It; It; ++It)
			{
				UnregisterSoundSubmix(*It, true);
			}
			
			// Destroy the synchronized Audio Task Queue for this device
			DestroySynchronizedAudioTaskQueue((Audio::AudioTaskQueueId)DeviceID);
		}
		
		// reset all the sound effect presets loaded
#if WITH_EDITOR
		for (TObjectIterator<USoundEffectPreset> It; It; ++It)
		{
			USoundEffectPreset* SoundEffectPreset = *It;
			SoundEffectPreset->Init();
		}
#endif

		if (AudioMixerPlatform)
		{
			SourceManager->Update();

			AudioMixerPlatform->UnregisterDeviceChangedListener();
			AudioMixerPlatform->StopAudioStream();
			AudioMixerPlatform->CloseAudioStream();
			AudioMixerPlatform->TeardownHardware();
		}

		// Reset existing submixes if they exist
		RequiredSubmixInstances.Reset();
		Submixes.Reset();
	}

	void FMixerDevice::UpdateHardwareTiming()
	{
		// Get the relative audio thread time (from start of audio engine)
		// Add some jitter delta to account for any audio thread timing jitter.
		const double AudioThreadJitterDelta = AudioClockDelta;
		AudioThreadTimingData.AudioThreadTime = FPlatformTime::Seconds() - AudioThreadTimingData.StartTime + AudioThreadJitterDelta;
	}

	void FMixerDevice::UpdateGameThread()
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		// Pump our command queue sending commands to the game thread
		PumpGameThreadCommandQueue();
	}

	void FMixerDevice::UpdateHardware()
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		// If we're in editor, re-query these in case they changed. 
		if (GIsEditor)
		{
			const UAudioSettings* AudioSettings = GetDefault<UAudioSettings>();
			MonoChannelUpmixMethod = AudioSettings->MonoChannelUpmixMethod;
			PanningMethod = AudioSettings->PanningMethod;
		}

		SourceManager->Update();

		AudioMixerPlatform->OnHardwareUpdate();

		if (AudioMixerPlatform->CheckAudioDeviceChange())
		{
			// Get the platform device info we're using
			PlatformInfo = AudioMixerPlatform->GetPlatformDeviceInfo();

			// Initialize some data that depends on speaker configuration, etc.
			InitializeChannelAzimuthMap(PlatformInfo.NumChannels);

			// Update the channel device count in case it changed
			SourceManager->UpdateDeviceChannelCount(PlatformInfo.NumChannels);

			// Reset rendering thread ID to this thread ID so that commands can
			// be flushed. Audio Rendering Thread ID will be reset again in call
			// to FMixerDevice::OnProcessAudio
			ResetAudioRenderingThreadId();
			
			// Cache the audio platform thread id for debugging purposes. This is
			// an attempt to narrow down the causes of UE-209237. The theory is
			// that the there are multiple threads attempting to run audio rendering
			// commands. To catch the issue we attempt to cache the thread id before
			// running audio rendering commands. We then check that the thread id
			// has not changed for the duration that render thread commands have 
			// run.
			std::atomic<int32> CurrentAudioPlatformThreadId = AudioPlatformThreadId.load();

			// Force source manager to incorporate device channel count change.
			FlushAudioRenderingCommands(true /* bPumpSynchronously */);

			if (UAudioDeviceNotificationSubsystem* AudioDeviceNotifSubsystem = UAudioDeviceNotificationSubsystem::Get())
			{
				AudioDeviceNotifSubsystem->OnDeviceSwitched(PlatformInfo.DeviceId);
			}

			// Related to earlier mention of UE-209237
			UE_CLOG(CurrentAudioPlatformThreadId != AudioPlatformThreadId, LogAudioMixer, Error, TEXT("Platform audio thread id changed while flushing render commands. Expected %d, found %d. May result in corrupt internal audio source state."), CurrentAudioPlatformThreadId.load(), AudioPlatformThreadId.load());

			// Audio rendering was suspended in CheckAudioDeviceChange if it changed.
			AudioMixerPlatform->ResumePlaybackOnNewDevice();
		}

		// Device must be initialized prior to call as submix graph may not be ready yet otherwise.
		if (IsInitialized())
		{
			// Loop through any envelope-following submixes and perform any broadcasting of envelope data if needed
			TArray<float> SubmixEnvelopeData;
			for (USoundSubmix* SoundSubmix : DelegateBoundSubmixes)
			{
				if (SoundSubmix)
				{
					// Retrieve the submix instance and the envelope data and broadcast on the audio thread.
					Audio::FMixerSubmixWeakPtr SubmixPtr = GetSubmixInstance(SoundSubmix);
					if (SubmixPtr.IsValid())
					{
						FAudioThread::RunCommandOnGameThread([this, SubmixPtr]()
							{
								Audio::FMixerSubmixPtr ThisSubmixPtr = SubmixPtr.Pin();
								if (ThisSubmixPtr.IsValid())
								{
									ThisSubmixPtr->BroadcastDelegates();
								}
							});
					}
				}
			}

			// Check if the background mute changed state and update the submixes which are enabled to do background muting.
			const float CurrentPrimaryVolume = GetPrimaryVolume();
			if (!FMath::IsNearlyEqual(PreviousPrimaryVolume, CurrentPrimaryVolume))
			{
				PreviousPrimaryVolume = CurrentPrimaryVolume;
				bool IsMuted = FMath::IsNearlyZero(CurrentPrimaryVolume);

				for (TObjectIterator<USoundSubmix> It; It; ++It)
				{
					if (It->bMuteWhenBackgrounded)
					{
						FMixerSubmixPtr SubmixInstance = GetSubmixInstance(*It).Pin();
						if (SubmixInstance.IsValid())
						{
							SubmixInstance->SetBackgroundMuted(IsMuted);
						}
					}
				}
			}
		}
	}

	double FMixerDevice::GetAudioTime() const
	{
		return AudioClock;
	}

	double FMixerDevice::GetInterpolatedAudioClock() const
	{
		return AudioClockTimingData.GetInterpolatedAudioClock(AudioClock, AudioClockDelta);
	}

	FAudioEffectsManager* FMixerDevice::CreateEffectsManager()
	{
		return new FAudioMixerEffectsManager(this);
	}

	FSoundSource* FMixerDevice::CreateSoundSource()
	{
		return new FMixerSource(this);
	}

	bool FMixerDevice::HasCompressedAudioInfoClass(USoundWave* InSoundWave)
	{
		check(InSoundWave);
		check(AudioMixerPlatform);
		// Every platform has compressed audio. 
		return true;
	}

	bool FMixerDevice::SupportsRealtimeDecompression() const
	{
		// Every platform supports realtime decompression.
		return true;
	}

	bool FMixerDevice::DisablePCMAudioCaching() const
	{
		return AudioMixerPlatform->DisablePCMAudioCaching();
	}
	
	bool FMixerDevice::ValidateAPICall(const TCHAR* Function, uint32 ErrorCode)
	{
		return false;
	}

#if UE_ALLOW_EXEC_COMMANDS
	bool FMixerDevice::Exec(UWorld* InWorld, const TCHAR* Cmd, FOutputDevice& Ar)
	{
		if (FAudioDevice::Exec(InWorld, Cmd, Ar))
		{
			return true;
		}

		return false;
	}
#endif // UE_ALLOW_EXEC_COMMANDS

	void FMixerDevice::CountBytes(FArchive& InArchive)
	{
		FAudioDevice::CountBytes(InArchive);
	}

	bool FMixerDevice::IsExernalBackgroundSoundActive()
	{
		return false;
	}

	void FMixerDevice::ResumeContext()
	{
        AudioMixerPlatform->ResumeContext();
	}

	void FMixerDevice::SuspendContext()
	{
        AudioMixerPlatform->SuspendContext();
	}

	void FMixerDevice::EnableDebugAudioOutput()
	{
		bDebugOutputEnabled = true;
	}

	bool FMixerDevice::OnProcessAudioStream(FAlignedFloatBuffer& Output)
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		// This function could be called in a task manager, which means the thread ID may change between calls.
		ResetAudioRenderingThreadId();

		// Cache the audio platform thread id for debugging purposes. This is
		// an attempt to narrow down the causes of UE-209237. The theory is
		// that the there are multiple threads attempting to run audio rendering
		// commands. To catch the issue we attempt to cache the thread id before
		// running audio rendering commands. We then check that the thread id
		// has not changed for the duration that render thread commands have 
		// run.
		std::atomic<int32> CurrentAudioPlatformThreadId = AudioPlatformThreadId.load();

		// Update the audio render thread time at the head of the render
		AudioThreadTimingData.AudioRenderThreadTime = FPlatformTime::Seconds() - AudioThreadTimingData.StartTime;

		// notify interested parties
		FAudioDeviceRenderInfo RenderInfo;
		RenderInfo.NumFrames = SourceManager->GetNumOutputFrames();
		NotifyAudioDevicePreRender(RenderInfo);

		// Pump the command queue to the audio render thread
		PumpCommandQueue();

		// update the clock manager
		QuantizedEventClockManager.Update(SourceManager->GetNumOutputFrames());

		// Compute the next block of audio in the source manager
		SourceManager->ComputeNextBlockOfSamples();

		FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
		{
			CSV_SCOPED_TIMING_STAT(Audio, Submixes);
			SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixes);

			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			if (MainSubmixPtr.IsValid())
			{
				// Process the audio output from the master submix
				MainSubmixPtr->ProcessAudio(Output);
			}
		}

		{
			CSV_SCOPED_TIMING_STAT(Audio, EndpointSubmixes);
			SCOPE_CYCLE_COUNTER(STAT_AudioMixerEndpointSubmixes);

			FScopeLock ScopeLock(&EndpointSubmixesMutationLock);
			if (EnableAudibleDefaultEndpointSubmixesCVar !=0 )
			{
				for (const FMixerSubmixPtr& Submix : DefaultEndpointSubmixes)
				{
					// If this hit, a submix was added to the default submix endpoint array
					// even though it's not an endpoint, or a parent was set on an endpoint submix
					// and it wasn't removed from DefaultEndpointSubmixes.
					ensure(Submix->IsDefaultEndpointSubmix());

					// Any endpoint submixes that don't specify an endpoint
					// are summed into our master output.
					Submix->ProcessAudio(Output);
				}
			}
			
			for (FMixerSubmixPtr& Submix : ExternalEndpointSubmixes)
			{
				// If this hit, a submix was added to the external submix endpoint array
				// even though it's not an endpoint, or a parent was set on an endpoint submix
				// and it wasn't removed from ExternalEndpointSubmixes.
				ensure(Submix->IsExternalEndpointSubmix());

				Submix->ProcessAudioAndSendToEndpoint();
			}
		}

		// Reset stopping sounds and clear their state after submixes have been mixed
		SourceManager->ClearStoppingSounds();

		// Do any debug output performing
		if (bDebugOutputEnabled || DebugGeneratorEnableCVar > 0)
		{
			if (DebugGeneratorEnableCVar < 2)
			{
				SineOscTest(Output);
			}
			else
			{
				WhiteNoiseTest(Output);
			}
		}

		// Update the audio clock
		UpdateAudioClock();

		// notify interested parties
		NotifyAudioDevicePostRender(RenderInfo);

		KickQueuedTasks((Audio::AudioTaskQueueId)DeviceID);


		// Related to earlier mention of UE-209237
		UE_CLOG(CurrentAudioPlatformThreadId != AudioPlatformThreadId, LogAudioMixer, Error, TEXT("Platform audio thread id changed while flushing render commands. Expected %d, found %d. May result in corrupt internal audio source state."), CurrentAudioPlatformThreadId.load(), AudioPlatformThreadId.load());


		return true;
	}

	void FMixerDevice::UpdateAudioClock()
	{
		AudioClock += AudioClockDelta;
		AudioClockTimingData.UpdateTime = FPlatformTime::Seconds();
	}

	void FMixerDevice::OnAudioStreamShutdown()
	{
		// Make sure the source manager pumps any final commands on shutdown. These allow for cleaning up sources, interfacing with plugins, etc.
		// Because we double buffer our command queues, we call this function twice to ensure all commands are successfully pumped.
		SourceManager->PumpCommandQueue();
		SourceManager->PumpCommandQueue();

		// Make sure we force any pending release data to happen on shutdown
		SourceManager->UpdatePendingReleaseData(true);
	}

	void FMixerDevice::LoadRequiredSubmix(ERequiredSubmixes InType, const FString& InDefaultName, bool bInDefaultMuteWhenBackgrounded, FSoftObjectPath& InObjectPath) 
	{
		check(IsInGameThread());

		const int32 RequiredSubmixCount = static_cast<int32>(ERequiredSubmixes::Count);
		if(RequiredSubmixes.Num() < RequiredSubmixCount)
		{
			RequiredSubmixes.AddZeroed(RequiredSubmixCount - RequiredSubmixes.Num());
		}

		if (RequiredSubmixInstances.Num() < RequiredSubmixCount)
		{
			RequiredSubmixInstances.AddZeroed(RequiredSubmixCount - RequiredSubmixInstances.Num());
		}

		const int32 TypeIndex = static_cast<int32>(InType);
		if (USoundSubmix* OldSubmix = RequiredSubmixes[TypeIndex])
		{
			// Don't bother swapping if new path is invalid...
			if (!InObjectPath.IsValid())
			{
				return;
			}

			// or is same object already initialized.
			if (InObjectPath.GetAssetPathString() == OldSubmix->GetPathName())
			{
				return;
			}
			OldSubmix->RemoveFromRoot();
			FMixerSubmixPtr OldSubmixPtr = RequiredSubmixInstances[TypeIndex];
			if (OldSubmixPtr.IsValid())
			{
				FMixerSubmixPtr ParentSubmixPtr = RequiredSubmixInstances[TypeIndex]->GetParentSubmix().Pin();
				if (ParentSubmixPtr.IsValid())
				{
					ParentSubmixPtr->RemoveChildSubmix(RequiredSubmixInstances[TypeIndex]);
				}
			}
		}

		// 1. Try loading from Developer Audio Settings
		USoundSubmix* NewSubmix = Cast<USoundSubmix>(InObjectPath.TryLoad());

		// 2. If Unset or not found, fallback to engine asset
		if (!NewSubmix)
		{
			static const FString EngineSubmixDir = TEXT("/Engine/EngineSounds/Submixes");

			InObjectPath = FString::Printf(TEXT("%s/%s.%s"), *EngineSubmixDir, *InDefaultName, *InDefaultName);
			NewSubmix = Cast<USoundSubmix>(InObjectPath.TryLoad());
			UE_LOG(LogAudioMixer, Display, TEXT("Submix unset or invalid in 'AudioSettings': Using engine asset '%s'"),
				*InDefaultName,
				*InObjectPath.GetAssetPathString());
		}

		// 3. If engine version not found, dynamically spawn and post error
		if (!NewSubmix)
		{
			UE_LOG(LogAudioMixer, Error, TEXT("Failed to load submix from engine asset path '%s'. Creating '%s' as a stub."),
				*InObjectPath.GetAssetPathString(),
				*InDefaultName);

			NewSubmix = NewObject<USoundSubmix>(USoundSubmix::StaticClass(), *InDefaultName);
			// Make the master reverb mute when backgrounded
			NewSubmix->bMuteWhenBackgrounded = bInDefaultMuteWhenBackgrounded;
		}

		check(NewSubmix);
		NewSubmix->AddToRoot();

		// If sharing submix with other explicitly defined MainSubmix, create
		// shared pointer directed to already existing submix instance. Otherwise,
		// create a new version.
		FMixerSubmixPtr NewMixerSubmix = GetRequiredSubmixInstance(NewSubmix);
		if (!NewMixerSubmix.IsValid())
		{
			UE_LOG(LogAudioMixer, Display, TEXT("Creating Master Submix '%s'"), *NewSubmix->GetName());
			NewMixerSubmix = MakeShared<FMixerSubmix, ESPMode::ThreadSafe>(this);
		}

		// Ensure that master submixes are ONLY tracked in master submix array.
		// RequiredSubmixes array can share instances, but should not be duplicated in Submixes Map.
		if (Submixes.Remove(NewSubmix->GetUniqueID()) > 0)
		{
			UE_LOG(LogAudioMixer, Display, TEXT("Submix '%s' has been promoted to master array."), *NewSubmix->GetName());
		}

		// Update/add new submix and instance to respective master arrays
		RequiredSubmixes[TypeIndex] = NewSubmix;
		RequiredSubmixInstances[TypeIndex] = NewMixerSubmix;

		//Note: If we support using endpoint/soundfield submixes as a master submix in the future, we will need to call NewMixerSubmix->SetSoundfieldFactory here.
		NewMixerSubmix->Init(NewSubmix, false /* bAllowReInit */);
	}

	void FMixerDevice::LoadPluginSoundSubmixes()
	{
		check(IsInGameThread());

		if (IsReverbPluginEnabled() && ReverbPluginInterface)
		{
			LLM_SCOPE(ELLMTag::AudioMixerPlugins);
			USoundSubmix* ReverbPluginSubmix = ReverbPluginInterface->LoadSubmix();
			check(ReverbPluginSubmix);
			ReverbPluginSubmix->AddToRoot();

			LoadSoundSubmix(*ReverbPluginSubmix);
			InitSoundfieldAndEndpointDataForSubmix(*ReverbPluginSubmix, GetSubmixInstance(ReverbPluginSubmix).Pin(), false);

			// Plugin must provide valid effect to enable reverb
			FSoundEffectSubmixPtr ReverbPluginEffectSubmix = ReverbPluginInterface->GetEffectSubmix();
			

			if (ReverbPluginEffectSubmix.IsValid())
			{
				if (USoundEffectPreset* Preset = ReverbPluginEffectSubmix->GetPreset())
				{
					FMixerSubmixPtr ReverbPluginMixerSubmixPtr = GetSubmixInstance(ReverbPluginSubmix).Pin();
					check(ReverbPluginMixerSubmixPtr.IsValid());

					const TWeakObjectPtr<USoundSubmix> ReverbPluginSubmixPtr = ReverbPluginSubmix;
					FMixerSubmixWeakPtr ReverbPluginMixerSubmixWeakPtr = ReverbPluginMixerSubmixPtr;
					AudioRenderThreadCommand([ReverbPluginMixerSubmixWeakPtr, ReverbPluginSubmixPtr, ReverbPluginEffectSubmix]()
					{
						FMixerSubmixPtr PluginSubmixPtr = ReverbPluginMixerSubmixWeakPtr.Pin();
						if (PluginSubmixPtr.IsValid() && ReverbPluginSubmixPtr.IsValid())
						{
							PluginSubmixPtr->ReplaceSoundEffectSubmix(0, ReverbPluginEffectSubmix);
						}
					});
				}
			}
			else
			{
				UE_LOG(LogAudioMixer, Error, TEXT("Reverb plugin failed to provide valid effect submix.  Plugin audio processing disabled."));
			}
		}
	}

	void FMixerDevice::InitSoundSubmixes()
	{
		if (IsInGameThread())
		{
			bSubmixRegistrationDisabled = true;

			UAudioSettings* AudioSettings = GetMutableDefault<UAudioSettings>();
			check(AudioSettings);

			if (RequiredSubmixes.Num() > 0)
			{
				UE_LOG(LogAudioMixer, Display, TEXT("Re-initializing Sound Submixes..."));
			}
			else
			{
				UE_LOG(LogAudioMixer, Display, TEXT("Initializing Sound Submixes..."));
			}

			// 1. Load or reload all sound submixes/instances
			LoadRequiredSubmix(ERequiredSubmixes::Main, TEXT("MasterSubmixDefault"), false /* DefaultMuteWhenBackgrounded */, AudioSettings->MasterSubmix);

			// BaseDefaultSubmix is an optional master submix type set by project settings
			if (AudioSettings->BaseDefaultSubmix.IsValid())
			{
				LoadRequiredSubmix(ERequiredSubmixes::BaseDefault, TEXT("BaseDefault"), false /* DefaultMuteWhenBackgrounded */, AudioSettings->BaseDefaultSubmix);
			}

			LoadRequiredSubmix(ERequiredSubmixes::Reverb, TEXT("MasterReverbSubmixDefault"), true /* DefaultMuteWhenBackgrounded */, AudioSettings->ReverbSubmix);

			if (!DisableSubmixEffectEQCvar)
			{
				LoadRequiredSubmix(ERequiredSubmixes::EQ, TEXT("MasterEQSubmixDefault"), false /* DefaultMuteWhenBackgrounded */, AudioSettings->EQSubmix);
			}

			LoadPluginSoundSubmixes();

			for (TObjectIterator<USoundSubmixBase> It; It; ++It)
			{
				USoundSubmixBase* SubmixToLoad = *It;
				check(SubmixToLoad);

				if (!IsRequiredSubmixType(SubmixToLoad) && !SubmixToLoad->IsDynamic( true /* bIncludeAncestors */) ) // Do not load dynamic submixes until they've been connected.
				{
					LoadSoundSubmix(*SubmixToLoad);
					InitSoundfieldAndEndpointDataForSubmix(*SubmixToLoad, GetSubmixInstance(SubmixToLoad).Pin(), false);
				}
			}
			bSubmixRegistrationDisabled = false;
		}

		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.InitSoundSubmixes"), STAT_InitSoundSubmixes, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, InitSubmix);
				InitSoundSubmixes();
			}, GET_STATID(STAT_InitSoundSubmixes));
			return;
		}

		for (int32 i = 0; i < static_cast<int32>(ERequiredSubmixes::Count); ++i)
		{
			if (DisableSubmixEffectEQCvar && i == static_cast<int32>(ERequiredSubmixes::EQ))
			{
				continue;
			}

			USoundSubmixBase* SoundSubmix = RequiredSubmixes[i];
			if (SoundSubmix && SoundSubmix != RequiredSubmixes[static_cast<int32>(ERequiredSubmixes::Main)])
			{
				FMixerSubmixPtr& MainSubmixInstance = RequiredSubmixInstances[i];

				RebuildSubmixLinks(*SoundSubmix, MainSubmixInstance);
			}
		}

		for (TObjectIterator<const USoundSubmixBase> It; It; ++It)
		{
			if (const USoundSubmixBase* SubmixBase = *It)
			{
				if (IsRequiredSubmixType(SubmixBase))
				{
					continue;
				}

				FMixerSubmixPtr SubmixPtr = Submixes.FindRef(SubmixBase->GetUniqueID());
				if (SubmixPtr.IsValid())
				{
					RebuildSubmixLinks(*SubmixBase, SubmixPtr);
				}
			}
		}
	}

	void FMixerDevice::RebuildSubmixLinks(const USoundSubmixBase& SoundSubmix, FMixerSubmixPtr& SubmixInstance)
	{
		// Setup up the submix instance's parent and add the submix instance as a child
		FMixerSubmixPtr ParentSubmixInstance;
		if (const USoundSubmixWithParentBase* SubmixWithParent = Cast<const USoundSubmixWithParentBase>(&SoundSubmix))
		{
			if (TObjectPtr<USoundSubmixBase> Parent = SubmixWithParent->GetParent(DeviceID); Parent)
			{
				ParentSubmixInstance = GetSubmixInstance(Parent).Pin();
			}
			else if (!SubmixWithParent->IsDynamic( true /*bIncludeAncestors*/ )) // Dynamic submixes do not auto connect.
			{
				// If this submix is itself the broadcast submix, set its parent to the master submix
				if (SubmixInstance == RequiredSubmixInstances[static_cast<int32>(ERequiredSubmixes::BaseDefault)])
				{
					ParentSubmixInstance = GetMasterSubmix().Pin();
				}
				else
				{
					ParentSubmixInstance = GetBaseDefaultSubmix().Pin();
				}
			}
		}

		if (ParentSubmixInstance.IsValid())
		{
			SubmixInstance->SetParentSubmix(ParentSubmixInstance);
			ParentSubmixInstance->AddChildSubmix(SubmixInstance);
		}
	}

 	FAudioPlatformSettings FMixerDevice::GetPlatformSettings() const
 	{
		FAudioPlatformSettings
			Settings;

		if (AudioMixerPlatform)
		{
			Settings = AudioMixerPlatform->GetPlatformSettings();

			const int32 DefaultMaxChannels = GetDefault<UAudioSettings>()->GetHighestMaxChannels();
			UE_LOG(LogAudioMixer, Display, TEXT("Audio Mixer Platform Settings:"));
			UE_LOG(LogAudioMixer, Display, TEXT("	Sample Rate:						  %d"), Settings.SampleRate);
			UE_LOG(LogAudioMixer, Display, TEXT("	Callback Buffer Frame Size Requested: %d"), Settings.CallbackBufferFrameSize);
			UE_LOG(LogAudioMixer, Display, TEXT("	Callback Buffer Frame Size To Use:	  %d"), AudioMixerPlatform->GetNumFrames(Settings.CallbackBufferFrameSize));
			UE_LOG(LogAudioMixer, Display, TEXT("	Number of buffers to queue:			  %d"), Settings.NumBuffers);
			UE_LOG(LogAudioMixer, Display, TEXT("	Max Channels (voices):				  %d"), (Settings.MaxChannels > 0) ? Settings.MaxChannels : DefaultMaxChannels);
			UE_LOG(LogAudioMixer, Display, TEXT("	Number of Async Source Workers:		  %d"), Settings.NumSourceWorkers);
		}

 		return Settings;
 	}

	FMixerSubmixWeakPtr FMixerDevice::GetMasterSubmix()
	{
		return GetMainSubmix();
	}

	FMixerSubmixWeakPtr FMixerDevice::GetMainSubmix()
	{
		return RequiredSubmixInstances[(int32)ERequiredSubmixes::Main];
	}

	FMixerSubmixWeakPtr FMixerDevice::GetBaseDefaultSubmix()
	{
		if (RequiredSubmixInstances[(int32)ERequiredSubmixes::BaseDefault].IsValid())
		{
			return RequiredSubmixInstances[(int32)ERequiredSubmixes::BaseDefault];
		}
		return GetMasterSubmix();
	}

	FMixerSubmixWeakPtr FMixerDevice::GetReverbSubmix()
	{
		return RequiredSubmixInstances[(int32)ERequiredSubmixes::Reverb];
	}

	FMixerSubmixWeakPtr FMixerDevice::GetEQSubmix()
	{
		return RequiredSubmixInstances[(int32)ERequiredSubmixes::EQ];
	}

	FMixerSubmixWeakPtr FMixerDevice::GetMasterReverbSubmix()
	{
		return RequiredSubmixInstances[(int32)ERequiredSubmixes::Reverb];
	}

	FMixerSubmixWeakPtr FMixerDevice::GetMasterEQSubmix()
	{
		return RequiredSubmixInstances[(int32)ERequiredSubmixes::EQ];
	}

	void FMixerDevice::AddMainSubmixEffect(FSoundEffectSubmixPtr SoundEffectSubmix)
	{
		AudioRenderThreadCommand([this, SoundEffectSubmix]()
		{
			RequiredSubmixInstances[(int32)ERequiredSubmixes::Main]->AddSoundEffectSubmix(SoundEffectSubmix);
		});
	}

	void FMixerDevice::AddMasterSubmixEffect(FSoundEffectSubmixPtr SoundEffectSubmix)
	{
		AddMainSubmixEffect(SoundEffectSubmix);
	}

	void FMixerDevice::RemoveMainSubmixEffect(uint32 SubmixEffectId)
	{
		AudioRenderThreadCommand([this, SubmixEffectId]()
		{
			RequiredSubmixInstances[(int32)ERequiredSubmixes::Main]->RemoveSoundEffectSubmix(SubmixEffectId);
		});
	}

	void FMixerDevice::RemoveMasterSubmixEffect(uint32 SubmixEffectId)
	{
		RemoveMainSubmixEffect(SubmixEffectId);
	}

	void FMixerDevice::ClearMasterSubmixEffects()
	{
		ClearMainSubmixEffects();
	}

	void FMixerDevice::ClearMainSubmixEffects()
	{
		AudioRenderThreadCommand([this]()
		{
			RequiredSubmixInstances[(int32)ERequiredSubmixes::Main]->ClearSoundEffectSubmixes();
		});
	}

	int32 FMixerDevice::AddSubmixEffect(USoundSubmix* InSoundSubmix, FSoundEffectSubmixPtr SoundEffect)
	{
		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			int32 NumEffects = MixerSubmixPtr->GetNumEffects();

			AudioRenderThreadCommand([this, MixerSubmixPtr, SoundEffect]()
				{
					MixerSubmixPtr->AddSoundEffectSubmix(SoundEffect);
				});

			return ++NumEffects;
		}
		else
		{
			UE_LOG(LogAudio, Warning, TEXT("Submix instance %s not found."), *InSoundSubmix->GetName());
		}
		return 0;
	}

	void FMixerDevice::RemoveSubmixEffect(USoundSubmix* InSoundSubmix, uint32 SubmixEffectId)
	{
		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, SubmixEffectId]()
			{
				MixerSubmixPtr->RemoveSoundEffectSubmix(SubmixEffectId);
			});
		}
	}

	void FMixerDevice::RemoveSubmixEffectAtIndex(USoundSubmix* InSoundSubmix, int32 SubmixChainIndex)
	{
		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, SubmixChainIndex]()
			{
				MixerSubmixPtr->RemoveSoundEffectSubmixAtIndex(SubmixChainIndex);
			});
		}
	}

	void FMixerDevice::ReplaceSoundEffectSubmix(USoundSubmix* InSoundSubmix, int32 InSubmixChainIndex, FSoundEffectSubmixPtr SoundEffect)
	{
		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InSubmixChainIndex, SoundEffect]()
			{
				MixerSubmixPtr->ReplaceSoundEffectSubmix(InSubmixChainIndex, SoundEffect);
			});
		}
	}

	void FMixerDevice::ClearSubmixEffects(USoundSubmix* InSoundSubmix)
	{
		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr]()
			{
				MixerSubmixPtr->ClearSoundEffectSubmixes();
			});
		}
	}

	void FMixerDevice::SetSubmixEffectChainOverride(USoundSubmix* InSoundSubmix, const TArray<FSoundEffectSubmixPtr>& InSubmixEffectPresetChain, float InFadeTimeSec)
	{
		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InSubmixEffectPresetChain, InFadeTimeSec]()
			{
				MixerSubmixPtr->SetSubmixEffectChainOverride(InSubmixEffectPresetChain, InFadeTimeSec);
			});
		}
	}

	void FMixerDevice::ClearSubmixEffectChainOverride(USoundSubmix* InSoundSubmix, float InFadeTimeSec)
	{
		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InFadeTimeSec]()
			{
				MixerSubmixPtr->ClearSubmixEffectChainOverride(InFadeTimeSec);
			});
		}
	}

	void FMixerDevice::UpdateSourceEffectChain(const uint32 SourceEffectChainId, const TArray<FSourceEffectChainEntry>& SourceEffectChain, const bool bPlayEffectChainTails)
	{
		TArray<FSourceEffectChainEntry>* ExistingOverride = SourceEffectChainOverrides.Find(SourceEffectChainId);
		if (ExistingOverride)
		{
			*ExistingOverride = SourceEffectChain;
		}
		else
		{
			SourceEffectChainOverrides.Add(SourceEffectChainId, SourceEffectChain);
		}

		FAudioThread::RunCommandOnAudioThread([MixerDeviceID = DeviceID, SourceEffectChainId, SourceEffectChain, bPlayEffectChainTails]()
		{
			if (FAudioDeviceManager* Manager = FAudioDeviceManager::Get())
			{
				if (FAudioDevice* Device = Manager->GetAudioDeviceRaw(MixerDeviceID))
				{
					FMixerDevice* MixerDevice = static_cast<FMixerDevice*>(Device);
					if (MixerDevice && MixerDevice->SourceManager)
					{
						MixerDevice->SourceManager->UpdateSourceEffectChain(SourceEffectChainId, SourceEffectChain, bPlayEffectChainTails);
					}
				}
			}
		});

		
	}

	void FMixerDevice::UpdateSubmixProperties(USoundSubmixBase* InSoundSubmix)
	{
		check(InSoundSubmix);

		// Output volume is only supported on USoundSubmixes.
		USoundSubmix* CastedSubmix = Cast<USoundSubmix>(InSoundSubmix);

		if (!CastedSubmix)
		{
			return;
		}

#if WITH_EDITOR
		check(IsInAudioThread());

		FMixerSubmixPtr MixerSubmix = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmix.IsValid())
		{
			const float NewVolume = CastedSubmix->OutputVolumeModulation.Value;
			AudioRenderThreadCommand([MixerSubmix, NewVolume]()
			{
				MixerSubmix->SetOutputVolume(NewVolume);
			});
		}
#endif // WITH_EDITOR
	}

	void FMixerDevice::SetSubmixWetDryLevel(USoundSubmix* InSoundSubmix, float InOutputVolume, float InWetLevel, float InDryLevel)
	{
		if (!IsInAudioThread())
		{
			FMixerDevice* MixerDevice = this;
			FAudioThread::RunCommandOnAudioThread([MixerDevice, InSoundSubmix, InOutputVolume, InWetLevel, InDryLevel]()
			{
				MixerDevice->SetSubmixWetDryLevel(InSoundSubmix, InOutputVolume, InWetLevel, InDryLevel);
			});
			return;
		}

		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InOutputVolume, InWetLevel, InDryLevel]()
			{
				MixerSubmixPtr->SetOutputVolume(InOutputVolume);
				MixerSubmixPtr->SetWetLevel(InWetLevel);
				MixerSubmixPtr->SetDryLevel(InDryLevel);
			});
		}
	}

	void FMixerDevice::SetSubmixOutputVolume(USoundSubmix* InSoundSubmix, float InOutputVolume)
	{
		if (!IsInAudioThread())
		{
			FMixerDevice* MixerDevice = this;
			FAudioThread::RunCommandOnAudioThread([MixerDevice, InSoundSubmix, InOutputVolume]()
			{
				MixerDevice->SetSubmixOutputVolume(InSoundSubmix, InOutputVolume);
			});
			return;
		}

		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InOutputVolume]()
			{
				MixerSubmixPtr->SetOutputVolume(InOutputVolume);
			});
		}
	}

	void FMixerDevice::SetSubmixWetLevel(USoundSubmix* InSoundSubmix, float InWetLevel)
	{
		if (!IsInAudioThread())
		{
			FMixerDevice* MixerDevice = this;
			FAudioThread::RunCommandOnAudioThread([MixerDevice, InSoundSubmix, InWetLevel]()
			{
				MixerDevice->SetSubmixWetLevel(InSoundSubmix, InWetLevel);
			});
			return;
		}

		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InWetLevel]()
			{
				MixerSubmixPtr->SetWetLevel(InWetLevel);
			});
		}
	}

	void FMixerDevice::SetSubmixDryLevel(USoundSubmix* InSoundSubmix, float InDryLevel)
	{
		if (!IsInAudioThread())
		{
			FMixerDevice* MixerDevice = this;
			FAudioThread::RunCommandOnAudioThread([MixerDevice, InSoundSubmix, InDryLevel]()
			{
				MixerDevice->SetSubmixDryLevel(InSoundSubmix, InDryLevel);
			});
			return;
		}

		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InDryLevel]()
			{
				MixerSubmixPtr->SetDryLevel(InDryLevel);
			});
		}
	}

	void FMixerDevice::SetSubmixAutoDisable(USoundSubmix* InSoundSubmix, bool bInAutoDisable)
	{
		if (!IsInAudioThread())
		{
			FMixerDevice* MixerDevice = this;
			FAudioThread::RunCommandOnAudioThread([MixerDevice, InSoundSubmix, bInAutoDisable]()
			{
				MixerDevice->SetSubmixAutoDisable(InSoundSubmix, bInAutoDisable);
			});
			return;
		}

		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, bInAutoDisable]()
			{
				MixerSubmixPtr->SetAutoDisable(bInAutoDisable);
			});
		}
	}

	void FMixerDevice::SetSubmixAutoDisableTime(USoundSubmix* InSoundSubmix, float InDisableTime)
	{
		if (!IsInAudioThread())
		{
			FMixerDevice* MixerDevice = this;
			FAudioThread::RunCommandOnAudioThread([MixerDevice, InSoundSubmix, InDisableTime]()
			{
				MixerDevice->SetSubmixAutoDisableTime(InSoundSubmix, InDisableTime);
			});
			return;
		}

		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InDisableTime]()
			{
				MixerSubmixPtr->SetAutoDisableTime(InDisableTime);
			});
		}
	}

	void FMixerDevice::UpdateSubmixModulationSettings(USoundSubmix* InSoundSubmix, const TSet<TObjectPtr<USoundModulatorBase>>& InOutputModulation, const TSet<TObjectPtr<USoundModulatorBase>>& InWetLevelModulation, const TSet<TObjectPtr<USoundModulatorBase>>& InDryLevelModulation)
	{
		TWeakObjectPtr<USoundSubmix> SubmixWeakPtr = InSoundSubmix;
		if (!IsInAudioThread())
		{
			FAudioThread::RunCommandOnAudioThread([ThisDeviceID = DeviceID, SubmixWeakPtr, OutMod = InOutputModulation, WetMod = InWetLevelModulation, DryMod = InDryLevelModulation]()
			{
				if (USoundSubmix* Submix = SubmixWeakPtr.Get())
				{
					if (FAudioDevice* Device = FAudioDeviceManager::Get()->GetAudioDeviceRaw(ThisDeviceID))
					{
						FMixerDevice* ThisMixerDevice = static_cast<FMixerDevice*>(Device);
						ThisMixerDevice->UpdateSubmixModulationSettings(Submix, OutMod, WetMod, DryMod);
					}
				}
			});
			return;
		}

		if (IsModulationPluginEnabled() && ModulationInterface.IsValid())
		{
			FMixerSubmixWeakPtr MixerSubmixWeakPtr = GetSubmixInstance(InSoundSubmix);

			if (SubmixWeakPtr.IsValid())
			{
				AudioRenderThreadCommand([MixerSubmixWeakPtr, VolumeMod = InOutputModulation, WetMod = InWetLevelModulation, DryMod = InDryLevelModulation]()
				{
					FMixerSubmixPtr MixerSubmixPtr = MixerSubmixWeakPtr.Pin();
				    if (MixerSubmixPtr.IsValid())
				    {
						MixerSubmixPtr->UpdateModulationSettings(VolumeMod, WetMod, DryMod);
					}
				});
			}
		}
	}

	void FMixerDevice::SetSubmixModulationBaseLevels(USoundSubmix* InSoundSubmix, float InVolumeModBase, float InWetModBase, float InDryModBase)
	{
		if (!IsInAudioThread())
		{
			TWeakObjectPtr<USoundSubmix> SubmixWeakPtr = InSoundSubmix;
			FAudioThread::RunCommandOnAudioThread([ThisDeviceID = DeviceID, SubmixWeakPtr, InVolumeModBase, InWetModBase, InDryModBase]()
			{
				if (USoundSubmix* Submix = SubmixWeakPtr.Get())
				{
					if (FAudioDevice* Device = FAudioDeviceManager::Get()->GetAudioDeviceRaw(ThisDeviceID))
					{
						FMixerDevice* ThisMixerDevice = static_cast<FMixerDevice*>(Device);
						ThisMixerDevice->SetSubmixModulationBaseLevels(Submix, InVolumeModBase, InWetModBase, InDryModBase);
					}
				}
			});
			return;
		}

		FMixerSubmixPtr MixerSubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();
		if (MixerSubmixPtr.IsValid())
		{
			AudioRenderThreadCommand([MixerSubmixPtr, InVolumeModBase, InWetModBase, InDryModBase]() 
			{
				MixerSubmixPtr->SetModulationBaseLevels(InVolumeModBase, InWetModBase, InDryModBase);
			});
		}
	}

	bool FMixerDevice::GetCurrentSourceEffectChain(const uint32 SourceEffectChainId, TArray<FSourceEffectChainEntry>& OutCurrentSourceEffectChainEntries)
	{
		TArray<FSourceEffectChainEntry>* ExistingOverride = SourceEffectChainOverrides.Find(SourceEffectChainId);
		if (ExistingOverride)
		{
			OutCurrentSourceEffectChainEntries = *ExistingOverride;
			return true;
		}
		return false;
	}

	void FMixerDevice::AudioRenderThreadCommand(TFunction<void()> Command)
	{
		CommandQueue.Enqueue(MoveTemp(Command));
	}

	void FMixerDevice::GameThreadMPSCCommand(TFunction<void()> InCommand)
	{
		GameThreadCommandQueue.Enqueue(MoveTemp(InCommand));
	}
	
	void FMixerDevice::PumpCommandQueue()
	{
		// Execute the pushed lambda functions
		TFunction<void()> Command;
		while (CommandQueue.Dequeue(Command))
		{
			Command();
		}
	}

	void FMixerDevice::PumpGameThreadCommandQueue()
	{
		TOptional Opt { GameThreadCommandQueue.Dequeue() };
		while (Opt.IsSet())
		{
			TFunction<void()> Command = MoveTemp(Opt.GetValue());
			Command();
				
			Opt = GameThreadCommandQueue.Dequeue();
		}
	}
	
	void FMixerDevice::FlushAudioRenderingCommands(bool bPumpSynchronously)
	{
		if (IsInitialized() && (FPlatformProcess::SupportsMultithreading() && !AudioMixerPlatform->IsNonRealtime()))
		{
			SourceManager->FlushCommandQueue(bPumpSynchronously);
		}
		else if (AudioMixerPlatform->IsNonRealtime())
		{
			SourceManager->FlushCommandQueue(true);
		}
		else
		{
			// Pump the audio device's command queue
			PumpCommandQueue();

			// And also directly pump the source manager command queue
			SourceManager->PumpCommandQueue();
			SourceManager->PumpCommandQueue();

			SourceManager->UpdatePendingReleaseData(true);
		}
	}

	bool FMixerDevice::IsRequiredSubmixType(const USoundSubmixBase* InSubmix) const
	{
		for (int32 i = 0; i < (int32)EMasterSubmixType::Count; ++i)
		{
			if (InSubmix == RequiredSubmixes[i])
			{
				return true;
			}
		}
		return false;
	}

	FMixerSubmixPtr FMixerDevice::GetRequiredSubmixInstance(uint32 InObjectId) const
	{
		check(RequiredSubmixes.Num() == (int32)ERequiredSubmixes::Count);
		for (int32 i = 0; i < (int32)ERequiredSubmixes::Count; ++i)
		{
			if (RequiredSubmixes[i] && InObjectId == RequiredSubmixes[i]->GetUniqueID())
			{
				return RequiredSubmixInstances[i];
			}
		}
		return nullptr;
	}

	FMixerSubmixPtr FMixerDevice::GetRequiredSubmixInstance(const USoundSubmixBase* InSubmix) const
	{
		check(RequiredSubmixes.Num() == (int32)ERequiredSubmixes::Count);
		for (int32 i = 0; i < (int32)ERequiredSubmixes::Count; ++i)
		{
			if (InSubmix == RequiredSubmixes[i])
			{
				return RequiredSubmixInstances[i];
			}
		}
		return nullptr;
	}

	void FMixerDevice::RegisterSoundSubmix(USoundSubmixBase* InSoundSubmix, bool bInit)
	{
		if (InSoundSubmix && bSubmixRegistrationDisabled)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Attempted register Submix %s before the submix graph was initialized."), *InSoundSubmix->GetFullName());
			return;
		}

		if (!InSoundSubmix)
		{
			return;
		}

		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.RegisterSoundSubmix"), STAT_AudioRegisterSoundSubmix, STATGROUP_AudioThreadCommands);

			FMixerDevice* MixerDevice = this;
			FAudioThread::RunCommandOnAudioThread([MixerDevice, InSoundSubmix, bInit]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, RegisterSubmix);
				MixerDevice->RegisterSoundSubmix(InSoundSubmix, bInit);
			}, GET_STATID(STAT_AudioRegisterSoundSubmix));
			return;
		}

		UE_LOG(LogAudioMixer, Display, TEXT("Registering submix %s."), *InSoundSubmix->GetFullName());

		const bool bIsMainSubmix = IsRequiredSubmixType(InSoundSubmix);

		if (!bIsMainSubmix)
		{
			// Ensure parent structure is registered prior to current submix if missing
			if (const USoundSubmixWithParentBase* SubmixWithParent = Cast<const USoundSubmixWithParentBase>(InSoundSubmix))
			{
				if (TObjectPtr<USoundSubmixBase> Parent = SubmixWithParent->GetParent(DeviceID))
				{
					FMixerSubmixPtr ParentSubmix = GetSubmixInstance(Parent).Pin();
					if (!ParentSubmix.IsValid())
					{
						RegisterSoundSubmix(Parent, bInit);
					}
				}
			}

			LoadSoundSubmix(*InSoundSubmix);
		}
		else
		{
			UE_LOG(LogAudioMixer, Display, TEXT("Submix %s was already registered as one of the master submixes."), *InSoundSubmix->GetFullName());
		}

		FMixerSubmixPtr SubmixPtr = GetSubmixInstance(InSoundSubmix).Pin();

		if (bInit)
		{
			InitSoundfieldAndEndpointDataForSubmix(*InSoundSubmix, SubmixPtr, true);
		}

		if (!bIsMainSubmix)
		{
			RebuildSubmixLinks(*InSoundSubmix, SubmixPtr);
		}
	}

	void FMixerDevice::LoadSoundSubmix(USoundSubmixBase& InSoundSubmix)
	{
		// If submix not already found, load it.
		FMixerSubmixPtr MixerSubmix = GetSubmixInstance(&InSoundSubmix).Pin();
		if (!MixerSubmix.IsValid())
		{
			InSoundSubmix.AddToRoot();

			MixerSubmix = MakeShared<FMixerSubmix, ESPMode::ThreadSafe>(this);
			Submixes.Add(InSoundSubmix.GetUniqueID(), MixerSubmix);
		}
	}

	void FMixerDevice::InitSoundfieldAndEndpointDataForSubmix(const USoundSubmixBase& InSoundSubmix, FMixerSubmixPtr MixerSubmix, bool bAllowReInit)
	{
		{
			FScopeLock ScopeLock(&EndpointSubmixesMutationLock);

			// Check to see if this is an endpoint or soundfield submix:
			if (const USoundfieldSubmix* SoundfieldSubmix = Cast<const USoundfieldSubmix>(&InSoundSubmix))
			{
				MixerSubmix->SetSoundfieldFactory(SoundfieldSubmix->GetSoundfieldFactoryForSubmix());
			}
			else if (const USoundfieldEndpointSubmix* SoundfieldEndpointSubmix = Cast<const USoundfieldEndpointSubmix>(&InSoundSubmix))
			{
				MixerSubmix->SetSoundfieldFactory(SoundfieldEndpointSubmix->GetSoundfieldEndpointForSubmix());
			}

			if (DefaultEndpointSubmixes.Contains(MixerSubmix))
			{
				DefaultEndpointSubmixes.RemoveSwap(MixerSubmix);
			}

			if (ExternalEndpointSubmixes.Contains(MixerSubmix))
			{
				ExternalEndpointSubmixes.RemoveSwap(MixerSubmix);
			}

			MixerSubmix->Init(&InSoundSubmix, bAllowReInit);

			if (IsEndpointSubmix(&InSoundSubmix) && MixerSubmix->IsDefaultEndpointSubmix())
			{
				DefaultEndpointSubmixes.Add(MixerSubmix);
			}
			else if (MixerSubmix->IsExternalEndpointSubmix())
			{
				ExternalEndpointSubmixes.Add(MixerSubmix);
			}
		}
	}

	void FMixerDevice::UnregisterSoundSubmix(const USoundSubmixBase* InSoundSubmix, const bool bReparentChildren)
	{
		if (!InSoundSubmix || bSubmixRegistrationDisabled || IsRequiredSubmixType(InSoundSubmix))
		{
			return;
		}

		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.UnregisterSoundSubmix"), STAT_AudioUnregisterSoundSubmix, STATGROUP_AudioThreadCommands);

			const TWeakObjectPtr<const USoundSubmixBase> SubmixToUnload = InSoundSubmix;
			FAudioThread::RunCommandOnAudioThread([this, SubmixToUnload, bReparentChildren]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, UnregisterSubmix);
				if (SubmixToUnload.IsValid())
				{
					UnloadSoundSubmix(*SubmixToUnload.Get(), bReparentChildren);
				}
			}, GET_STATID(STAT_AudioUnregisterSoundSubmix));
			return;
		}

		UnloadSoundSubmix(*InSoundSubmix, bReparentChildren);
	}

	void FMixerDevice::UnloadSoundSubmix(const USoundSubmixBase& InSoundSubmix, const bool bReparentChildren)
	{
		check(IsInAudioThread());

		FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();

		// Check if this is a submix type that has a parent.
		FMixerSubmixPtr ParentSubmixInstance;
		if (const USoundSubmixWithParentBase* InSoundSubmixWithParent = Cast<const USoundSubmixWithParentBase>(&InSoundSubmix))
		{
			ParentSubmixInstance = InSoundSubmixWithParent->GetParent(DeviceID)
				? GetSubmixInstance(InSoundSubmixWithParent->GetParent(DeviceID)).Pin()
				: MainSubmix.Pin();
		}

		if (ParentSubmixInstance.IsValid())
		{
			ParentSubmixInstance->RemoveChildSubmix(GetSubmixInstance(&InSoundSubmix));
		}

		if (bReparentChildren)
		{
			for (USoundSubmixBase* ChildSubmix : InSoundSubmix.ChildSubmixes)
			{
				FMixerSubmixPtr ChildSubmixPtr = GetSubmixInstance(ChildSubmix).Pin();
				if (ChildSubmixPtr.IsValid())
				{
					ChildSubmixPtr->SetParentSubmix(ParentSubmixInstance.IsValid()
						? ParentSubmixInstance
						: MainSubmix);
				}
			}
		}

		FMixerSubmixWeakPtr MixerSubmixWeakPtr = GetSubmixInstance(&InSoundSubmix);
		FMixerSubmixPtr MixerSubmix = MixerSubmixWeakPtr.Pin();

		if (MixerSubmix && MixerSubmix->IsDefaultEndpointSubmix())
		{
			FScopeLock ScopeLock(&EndpointSubmixesMutationLock);
			DefaultEndpointSubmixes.Remove(MixerSubmix);
		}
		else if (MixerSubmix && MixerSubmix->IsExternalEndpointSubmix())
		{
			FScopeLock ScopeLock(&EndpointSubmixesMutationLock);
			ExternalEndpointSubmixes.Remove(MixerSubmix);
		}

		Submixes.Remove(InSoundSubmix.GetUniqueID());
	}

	FMixerSubmixPtr FMixerDevice::FindSubmixInstanceByObjectId(uint32 InObjectId)
	{
		for (int32 i = 0; i < RequiredSubmixes.Num(); i++)
		{
			if (const USoundSubmix* MainSubmix = RequiredSubmixes[i])
			{
				if (MainSubmix->GetUniqueID() == InObjectId)
				{
					return GetRequiredSubmixInstance(MainSubmix);
				}
			}
			else
			{
				const ERequiredSubmixes SubmixType = static_cast<ERequiredSubmixes>(i);
				ensureAlwaysMsgf(ERequiredSubmixes::Main != SubmixType,
					TEXT("Top-level main submix has to be registered before anything else, and is required for the lifetime of the application.")
				);

				if (!DisableSubmixEffectEQCvar && ERequiredSubmixes::EQ == SubmixType)
				{
					UE_LOG(LogAudioMixer, Warning, TEXT("Failed to query EQ Submix when it was expected to be loaded."));
				}
			}
		}

		return Submixes.FindRef(InObjectId);
	}

	FMixerSubmixWeakPtr FMixerDevice::GetSubmixInstance(const USoundSubmixBase* SoundSubmix) const
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		FMixerSubmixPtr MixerSubmix = GetRequiredSubmixInstance(SoundSubmix);
		if (MixerSubmix.IsValid())
		{
			return MixerSubmix;
		}
		
		if (SoundSubmix)
		{
			return Submixes.FindRef(SoundSubmix->GetUniqueID());
		}

		return nullptr;
	}

	ISoundfieldFactory* FMixerDevice::GetFactoryForSubmixInstance(USoundSubmix* SoundSubmix)
	{
		FMixerSubmixWeakPtr WeakSubmixPtr = GetSubmixInstance(SoundSubmix);
		return GetFactoryForSubmixInstance(WeakSubmixPtr);
	}

	ISoundfieldFactory* FMixerDevice::GetFactoryForSubmixInstance(FMixerSubmixWeakPtr& SoundSubmixPtr)
	{
		FMixerSubmixPtr SubmixPtr = SoundSubmixPtr.Pin();
		if (SubmixPtr.IsValid())
		{
			return SubmixPtr->GetSoundfieldFactory();
		}
		else
		{
			return nullptr;
		}
	}

	FMixerSourceVoice* FMixerDevice::GetMixerSourceVoice()
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		FMixerSourceVoice* Voice = nullptr;
		if (!SourceVoices.Dequeue(Voice))
		{
			Voice = new FMixerSourceVoice();
		}

		Voice->Reset(this);
		return Voice;
	}

	void FMixerDevice::ReleaseMixerSourceVoice(FMixerSourceVoice* InSourceVoice)
	{
		SourceVoices.Enqueue(InSourceVoice);
	}

	int32 FMixerDevice::GetNumSources() const
	{
		return Sources.Num();
	}

	IAudioLinkFactory* FMixerDevice::GetAudioLinkFactory() const
	{
		return AudioLinkFactory;
	}

	int32 FMixerDevice::GetNumActiveSources() const
	{
		return SourceManager->GetNumActiveSources();
	}

	void FMixerDevice::Get3DChannelMap(const int32 InSubmixNumChannels, const FWaveInstance* InWaveInstance, float EmitterAzimith, float InNonSpatializedAmount, const TMap<EAudioMixerChannel::Type, float>* InOmniMap, float InDefaultOmniValue, Audio::FAlignedFloatBuffer& OutChannelMap)
	{
		// If we're center-channel only, then no need for spatial calculations, but need to build a channel map
		if (InWaveInstance->bCenterChannelOnly)
		{
			int32 NumOutputChannels = InSubmixNumChannels;
			const TArray<EAudioMixerChannel::Type>& ChannelArray = GetChannelArray();

			// If we are only spatializing to stereo output
			if (NumOutputChannels == 2)
			{
				// Equal volume in left + right channel with equal power panning
				static const float Pan = 1.0f / FMath::Sqrt(2.0f);
				OutChannelMap.Add(Pan);
				OutChannelMap.Add(Pan);
			}
			else
			{
				for (EAudioMixerChannel::Type Channel : ChannelArray)
				{
					float Pan = (Channel == EAudioMixerChannel::FrontCenter) ? 1.0f : 0.0f;
					OutChannelMap.Add(Pan);
				}
			}

			return;
		}

		float Azimuth = EmitterAzimith;

		const FChannelPositionInfo* PrevChannelInfo = nullptr;
		const FChannelPositionInfo* NextChannelInfo = nullptr;

		for (int32 i = 0; i < DeviceChannelAzimuthPositions.Num(); ++i)
		{
			const FChannelPositionInfo& ChannelPositionInfo = DeviceChannelAzimuthPositions[i];

			if (Azimuth <= ChannelPositionInfo.Azimuth)
			{
				NextChannelInfo = &DeviceChannelAzimuthPositions[i];

				int32 PrevIndex = i - 1;
				if (PrevIndex < 0)
				{
					PrevIndex = DeviceChannelAzimuthPositions.Num() - 1;
				}

				PrevChannelInfo = &DeviceChannelAzimuthPositions[PrevIndex];
				break;
			}
		}

		// If we didn't find anything, that means our azimuth position is at the top of the mapping
		if (PrevChannelInfo == nullptr)
		{
			PrevChannelInfo = &DeviceChannelAzimuthPositions[DeviceChannelAzimuthPositions.Num() - 1];
			NextChannelInfo = &DeviceChannelAzimuthPositions[0];
			AUDIO_MIXER_CHECK(PrevChannelInfo != NextChannelInfo);
		}

		float NextChannelAzimuth = NextChannelInfo->Azimuth;
		float PrevChannelAzimuth = PrevChannelInfo->Azimuth;

		if (NextChannelAzimuth < PrevChannelAzimuth)
		{
			NextChannelAzimuth += 360.0f;
		}

		if (Azimuth < PrevChannelAzimuth)
		{
			Azimuth += 360.0f;
		}

		AUDIO_MIXER_CHECK(NextChannelAzimuth > PrevChannelAzimuth);
		AUDIO_MIXER_CHECK(Azimuth > PrevChannelAzimuth);
		float Fraction = (Azimuth - PrevChannelAzimuth) / (NextChannelAzimuth - PrevChannelAzimuth);
		AUDIO_MIXER_CHECK(Fraction >= 0.0f && Fraction <= 1.0f);

		// Compute the panning values using equal-power panning law
		float PrevChannelPan; 
		float NextChannelPan;

		if (PanningMethod == EPanningMethod::EqualPower)
		{
			FMath::SinCos(&NextChannelPan, &PrevChannelPan, Fraction * 0.5f * PI);

			// Note that SinCos can return values slightly greater than 1.0 when very close to PI/2
			NextChannelPan = FMath::Clamp(NextChannelPan, 0.0f, 1.0f);
			PrevChannelPan = FMath::Clamp(PrevChannelPan, 0.0f, 1.0f);
		}
		else
		{
			NextChannelPan = Fraction;
			PrevChannelPan = 1.0f - Fraction;
		}

		float OmniAmount = InNonSpatializedAmount;

		// Build the output channel map based on the current platform device output channel array 

		int32 NumSpatialChannels = DeviceChannelAzimuthPositions.Num();
		if (DeviceChannelAzimuthPositions.Num() > 4)
		{
			NumSpatialChannels--;
		}

		const TArray<EAudioMixerChannel::Type>& ChannelArray = GetChannelArray();

		if (OmniAmount > 0.0f)
		{
			for (EAudioMixerChannel::Type Channel : ChannelArray)
			{
				float OmniPanFactor = InDefaultOmniValue;

				if (InOmniMap)
				{
					const float* MappedOmniPanFactor = InOmniMap->Find(Channel);
					if (MappedOmniPanFactor)
					{
						OmniPanFactor = *MappedOmniPanFactor;
					}
				}

				float EffectivePan = 0.0f;

				// Check for manual channel mapping parameters (LFE and Front Center)
				if (Channel == EAudioMixerChannel::LowFrequency)
				{
					EffectivePan = InWaveInstance->LFEBleed;
				}
				else if (Channel == PrevChannelInfo->Channel)
				{
					EffectivePan = FMath::Lerp(PrevChannelPan, OmniPanFactor, OmniAmount);
				}
				else if (Channel == NextChannelInfo->Channel)
				{
					EffectivePan = FMath::Lerp(NextChannelPan, OmniPanFactor, OmniAmount);
				}
				else if (Channel == EAudioMixerChannel::FrontCenter)
				{
					EffectivePan = FMath::Lerp(0.0f, OmniPanFactor, OmniAmount);
					EffectivePan = FMath::Max(InWaveInstance->VoiceCenterChannelVolume, EffectivePan);
				}
				else
				{
					EffectivePan = FMath::Lerp(0.0f, OmniPanFactor, OmniAmount);
				}

				AUDIO_MIXER_CHECK(EffectivePan >= 0.0f && EffectivePan <= 1.0f);
				OutChannelMap.Add(EffectivePan);
			}
		}
		else
		{
			for (EAudioMixerChannel::Type Channel : ChannelArray)
			{
				float EffectivePan = 0.0f;

				// Check for manual channel mapping parameters (LFE and Front Center)
				if (Channel == EAudioMixerChannel::LowFrequency)
				{
					EffectivePan = InWaveInstance->LFEBleed;
				}
				else if (Channel == PrevChannelInfo->Channel)
				{
					EffectivePan = PrevChannelPan;
				}
				else if (Channel == NextChannelInfo->Channel)
				{
					EffectivePan = NextChannelPan;
				}
				else if (Channel == EAudioMixerChannel::FrontCenter)
				{
					EffectivePan = FMath::Max(InWaveInstance->VoiceCenterChannelVolume, EffectivePan);
				}

				AUDIO_MIXER_CHECK(EffectivePan >= 0.0f && EffectivePan <= 1.0f);
				OutChannelMap.Add(EffectivePan);
			}
		}
	}

	const TArray<FTransform>* FMixerDevice::GetListenerTransforms()
	{
		return SourceManager->GetListenerTransforms();
	}

	void FMixerDevice::StartRecording(USoundSubmix* InSubmix, float ExpectedRecordingDuration)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.PauseRecording"), STAT_StartRecording, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix, ExpectedRecordingDuration]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, StartRecording);
				StartRecording(InSubmix, ExpectedRecordingDuration);
			}, GET_STATID(STAT_StartRecording));
			return;
		}

		// if we can find the submix here, record that submix. Otherwise, just record the master submix.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->OnStartRecordingOutput(ExpectedRecordingDuration);
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->OnStartRecordingOutput(ExpectedRecordingDuration);
		}
	}

	Audio::FAlignedFloatBuffer& FMixerDevice::StopRecording(USoundSubmix* InSubmix, float& OutNumChannels, float& OutSampleRate)
	{
		// if we can find the submix here, record that submix. Otherwise, just record the master submix.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			return FoundSubmix->OnStopRecordingOutput(OutNumChannels, OutSampleRate);
		}
		else
		{
			FMixerSubmixPtr MainSubmixPtr = GetMasterSubmix().Pin();
			check(MainSubmixPtr.IsValid());

			return MainSubmixPtr->OnStopRecordingOutput(OutNumChannels, OutSampleRate);
		}
	}

	void FMixerDevice::PauseRecording(USoundSubmix* InSubmix)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.PauseRecording"), STAT_PauseRecording, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, PauseRecording);
				PauseRecording(InSubmix);
			}, GET_STATID(STAT_PauseRecording));
			return;
		}

		// if we can find the submix here, pause that submix. Otherwise, just pause the master submix.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->PauseRecordingOutput();
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->PauseRecordingOutput();
		}
	}

	void FMixerDevice::ResumeRecording(USoundSubmix* InSubmix)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.ResumeRecording"), STAT_ResumeRecording, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, ResumeRecording);
				ResumeRecording(InSubmix);
			}, GET_STATID(STAT_ResumeRecording));
			return;
		}

		// if we can find the submix here, resume that submix. Otherwise, just resume the master submix.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->ResumeRecordingOutput();
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->ResumeRecordingOutput();
		}
	}

	void FMixerDevice::StartEnvelopeFollowing(USoundSubmix* InSubmix)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.StartEnvelopeFollowing"), STAT_StartEnvelopeFollowing, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, StartEnvelopeFollowing);
				StartEnvelopeFollowing(InSubmix);
			}, GET_STATID(STAT_StartEnvelopeFollowing));
			return;
		}

		// if we can find the submix here, record that submix. Otherwise, just record the master submix.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->StartEnvelopeFollowing(InSubmix->EnvelopeFollowerAttackTime, InSubmix->EnvelopeFollowerReleaseTime);
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->StartEnvelopeFollowing(InSubmix->EnvelopeFollowerAttackTime, InSubmix->EnvelopeFollowerReleaseTime);
		}

		DelegateBoundSubmixes.AddUnique(InSubmix);
	}

	void FMixerDevice::StopEnvelopeFollowing(USoundSubmix* InSubmix)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.StopEnvelopeFollowing"), STAT_StopEnvelopeFollowing, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, StopEnvelopeFollowing);
				StopEnvelopeFollowing(InSubmix);
			}, GET_STATID(STAT_StopEnvelopeFollowing));
			return;
		}

		// if we can find the submix here, record that submix. Otherwise, just record the master submix.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->StopEnvelopeFollowing();
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->StopEnvelopeFollowing();
		}

		DelegateBoundSubmixes.RemoveSingleSwap(InSubmix);
	}

	void FMixerDevice::AddEnvelopeFollowerDelegate(USoundSubmix* InSubmix, const FOnSubmixEnvelopeBP& OnSubmixEnvelopeBP)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.AddEnvelopeFollowerDelegate"), STAT_AddEnvelopeFollowerDelegate, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix, OnSubmixEnvelopeBP]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, AddEnvelopeFollowerDelegate);
				AddEnvelopeFollowerDelegate(InSubmix, OnSubmixEnvelopeBP);
			}, GET_STATID(STAT_AddEnvelopeFollowerDelegate));
			return;
		}

		// if we can find the submix here, record that submix. Otherwise, just record the master submix.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->AddEnvelopeFollowerDelegate(OnSubmixEnvelopeBP);
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->AddEnvelopeFollowerDelegate(OnSubmixEnvelopeBP);
		}
	}

	void FMixerDevice::RemoveEnvelopeFollowerDelegate(USoundSubmix* InSubmix, const FOnSubmixEnvelopeBP& OnSubmixEnvelopeBP)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.RemoveEnvelopeFollowerDelegate"), STAT_RemoveEnvelopeFollowerDelegate, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix, OnSubmixEnvelopeBP]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, RemoveEnvelopeFollowerDelegate);
				RemoveEnvelopeFollowerDelegate(InSubmix, OnSubmixEnvelopeBP);
			}, GET_STATID(STAT_RemoveEnvelopeFollowerDelegate));
			return;
		}

		// Fallback to the master submix if the provided submix isn't found to match behavior from ::AddEnvelopeFollowerDelegate
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->RemoveEnvelopeFollowerDelegate(OnSubmixEnvelopeBP);
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->RemoveEnvelopeFollowerDelegate(OnSubmixEnvelopeBP);
		}
	}

	void FMixerDevice::StartSpectrumAnalysis(USoundSubmix* InSubmix, const FSoundSpectrumAnalyzerSettings& InSettings)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.StartSpectrumAnalysis"), STAT_StartSpectrumAnalysis, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix, InSettings]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, StartSpectrumAnalysis);
				StartSpectrumAnalysis(InSubmix, InSettings);
			}, GET_STATID(STAT_StartSpectrumAnalysis));
			return;
		}

		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->StartSpectrumAnalysis(InSettings);
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->StartSpectrumAnalysis(InSettings);
		}

		DelegateBoundSubmixes.AddUnique(InSubmix);
	}

	void FMixerDevice::StopSpectrumAnalysis(USoundSubmix* InSubmix)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.StopSpectrumAnalysis"), STAT_StopSpectrumAnalysis, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, StopSpectrumAnalysis);
				StopSpectrumAnalysis(InSubmix);
			}, GET_STATID(STAT_StopSpectrumAnalysis));
			return;
		}

		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->StopSpectrumAnalysis();
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->StopSpectrumAnalysis();
		}

		DelegateBoundSubmixes.RemoveSingleSwap(InSubmix);

	}

	void FMixerDevice::GetMagnitudesForFrequencies(USoundSubmix* InSubmix, const TArray<float>& InFrequencies, TArray<float>& OutMagnitudes)
	{
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->GetMagnitudeForFrequencies(InFrequencies, OutMagnitudes);
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->GetMagnitudeForFrequencies(InFrequencies, OutMagnitudes);
		}
	}

	void FMixerDevice::GetPhasesForFrequencies(USoundSubmix* InSubmix, const TArray<float>& InFrequencies, TArray<float>& OutPhases)
	{
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();
		if (FoundSubmix.IsValid())
		{
			FoundSubmix->GetPhaseForFrequencies(InFrequencies, OutPhases);
		}
		else
		{
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FMixerSubmixPtr MainSubmixPtr = MainSubmix.Pin();
			check(MainSubmixPtr.IsValid());

			MainSubmixPtr->GetPhaseForFrequencies(InFrequencies, OutPhases);
		}
	}

	void FMixerDevice::AddSpectralAnalysisDelegate(USoundSubmix* InSubmix, const FSoundSpectrumAnalyzerDelegateSettings& InDelegateSettings, const FOnSubmixSpectralAnalysisBP& OnSubmixSpectralAnalysisBP)
	{

		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.AddSpectralAnalysisDelegate"), STAT_AddSpectralAnalysisDelegate, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix, InDelegateSettings, OnSubmixSpectralAnalysisBP]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, AddSpectralAnalysisDelegate);
				AddSpectralAnalysisDelegate(InSubmix, InDelegateSettings, OnSubmixSpectralAnalysisBP);
			}, GET_STATID(STAT_AddSpectralAnalysisDelegate));
			return;
		}

		// get submix if it is available.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();

		if (!FoundSubmix.IsValid())
		{
			// If can't find the submix isntance, use master submix.
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FoundSubmix = MainSubmix.Pin();
		}

		if (ensure(FoundSubmix.IsValid()))
		{
			FoundSubmix->AddSpectralAnalysisDelegate(InDelegateSettings, OnSubmixSpectralAnalysisBP);
		}
	}

	void FMixerDevice::RemoveSpectralAnalysisDelegate(USoundSubmix* InSubmix, const FOnSubmixSpectralAnalysisBP& InDelegate)
	{
		if (!IsInAudioThread())
		{
			DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.RemoveSpectralAnalysisDelegate"), STAT_RemoveSpectralAnalysisDelegate, STATGROUP_AudioThreadCommands);

			FAudioThread::RunCommandOnAudioThread([this, InSubmix, InDelegate]()
			{
				CSV_SCOPED_TIMING_STAT(Audio, RemoveSpectralAnalysisDelegate);
				RemoveSpectralAnalysisDelegate(InSubmix, InDelegate);
			}, GET_STATID(STAT_RemoveSpectralAnalysisDelegate));
			return;
		}

		// get submix if it is available.
		FMixerSubmixPtr FoundSubmix = GetSubmixInstance(InSubmix).Pin();

		if (!FoundSubmix.IsValid())
		{
			// If can't find the submix isntance, use master submix.
			FMixerSubmixWeakPtr MainSubmix = GetMasterSubmix();
			FoundSubmix = MainSubmix.Pin();
		}

		if (ensure(FoundSubmix.IsValid()))
		{
			FoundSubmix->RemoveSpectralAnalysisDelegate(InDelegate);
		}
	}

	USoundSubmix& FMixerDevice::GetMainSubmixObject() const
	{
		const int32 SubmixIndex = static_cast<int32>(ERequiredSubmixes::Main);
		USoundSubmix* MainSubmix = RequiredSubmixes[SubmixIndex];
		check(MainSubmix);
		return *MainSubmix;
	}

	void FMixerDevice::RegisterSubmixBufferListener(ISubmixBufferListener* InSubmixBufferListener, USoundSubmix* InSubmix)
	{
		DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.RegisterSubmixBufferListener"), STAT_RegisterSubmixBufferListener, STATGROUP_AudioThreadCommands);

		const bool bUseMaster = InSubmix == nullptr;
		const TWeakObjectPtr<USoundSubmix> SubmixPtr(InSubmix);

		auto RegisterLambda = [this, InSubmixBufferListener, bUseMaster, SubmixPtr]()
		{
			CSV_SCOPED_TIMING_STAT(Audio, RegisterSubmixBufferListener);

			FMixerSubmixPtr FoundSubmix = bUseMaster
				? GetMasterSubmix().Pin()
				: GetSubmixInstance(SubmixPtr.Get()).Pin();

			// Attempt to register submix if instance not found and is not master (i.e. default) submix
			if (!bUseMaster && !FoundSubmix.IsValid() && SubmixPtr.IsValid())
			{
				RegisterSoundSubmix(SubmixPtr.Get(), true /* bInit */);
				FoundSubmix = GetSubmixInstance(SubmixPtr.Get()).Pin();
			}

			if (FoundSubmix.IsValid())
			{
				PRAGMA_DISABLE_DEPRECATION_WARNINGS
				FoundSubmix->RegisterBufferListener(InSubmixBufferListener);
				PRAGMA_ENABLE_DEPRECATION_WARNINGS
			}
			else
			{
				UE_LOG(LogAudioMixer, Warning, TEXT("Submix buffer listener not registered. Submix not loaded."));
			}
		};

		FAudioThread::RunCommandOnAudioThread(MoveTemp(RegisterLambda));
	}

	void FMixerDevice::RegisterSubmixBufferListener(TSharedRef<ISubmixBufferListener, ESPMode::ThreadSafe> InSubmixBufferListener, USoundSubmix& InSubmix)
	{
		DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.RegisterSubmixBufferListener"), STAT_RegisterSubmixBufferListener, STATGROUP_AudioThreadCommands);

		const TWeakObjectPtr<USoundSubmix> SubmixPtr(&InSubmix);

		// Pass the name vs. reconciling it inline with the command lambda, as occasionally
		// deprecated submix buffer listeners are not constructed as a shared pointer and
		// therefore getting destroyed before the lambda is executed on the AudioThread.
		// This means no name is provided and thus not apparent who the caller is. If
		// the Buffer Listener is invalid here, at least the callstack will show the
		// requesting client directly.
		const FString ListenerName = InSubmixBufferListener->GetListenerName();
		auto RegisterLambda = [this, InSubmixBufferListener, ListenerName, SubmixPtr]()
		{
			CSV_SCOPED_TIMING_STAT(Audio, RegisterSubmixBufferListener);

			FMixerSubmixPtr FoundSubmix = GetSubmixInstance(SubmixPtr.Get()).Pin();

			// Attempt to register submix if instance not found and is not master (i.e. default) submix
			if (!FoundSubmix.IsValid() && SubmixPtr.IsValid())
			{
				RegisterSoundSubmix(SubmixPtr.Get(), true /* bInit */);
				FoundSubmix = GetSubmixInstance(SubmixPtr.Get()).Pin();
			}

			if (FoundSubmix.IsValid())
			{
				FoundSubmix->RegisterBufferListener(InSubmixBufferListener);
				UE_LOG(LogAudioMixer, Display, TEXT("Submix buffer listener '%s' registered with submix '%s'"), *ListenerName, *FoundSubmix->SubmixName);
			}
			else
			{
				UE_LOG(LogAudioMixer, Warning, TEXT("Submix buffer listener '%s' not registered. Submix not loaded."), *ListenerName);
			}
		};

		UE_LOG(LogAudioMixer, Display, TEXT("Sending SubmixBufferListener '%s' register command..."), *ListenerName);
		FAudioThread::RunCommandOnAudioThread(MoveTemp(RegisterLambda));
	}

	void FMixerDevice::UnregisterSubmixBufferListener(ISubmixBufferListener* InSubmixBufferListener, USoundSubmix* InSubmix)
	{
		DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.UnregisterSubmixBufferListener"), STAT_UnregisterSubmixBufferListener, STATGROUP_AudioThreadCommands);

		const bool bUseMaster = InSubmix == nullptr;
		const TWeakObjectPtr<USoundSubmix> SubmixPtr(InSubmix);

		auto UnregisterLambda = [this, InSubmixBufferListener, bUseMaster, SubmixPtr]()
		{
			CSV_SCOPED_TIMING_STAT(Audio, UnregisterSubmixBufferListener);

			FMixerSubmixPtr FoundSubmix = bUseMaster
				? GetMasterSubmix().Pin()
				: GetSubmixInstance(SubmixPtr.Get()).Pin();

			if (FoundSubmix.IsValid())
			{
				PRAGMA_DISABLE_DEPRECATION_WARNINGS
				FoundSubmix->UnregisterBufferListener(InSubmixBufferListener);
				PRAGMA_ENABLE_DEPRECATION_WARNINGS
			}
			else
			{
				UE_LOG(LogAudioMixer, Display, TEXT("Submix buffer listener not unregistered. Submix not loaded."));
			}
		};

		FAudioThread::RunCommandOnAudioThread(MoveTemp(UnregisterLambda));
	}

	void FMixerDevice::UnregisterSubmixBufferListener(TSharedRef<ISubmixBufferListener, ESPMode::ThreadSafe> InSubmixBufferListener, USoundSubmix& InSubmix)
	{
		DECLARE_CYCLE_STAT(TEXT("FAudioThreadTask.UnregisterSubmixBufferListener"), STAT_UnregisterSubmixBufferListener, STATGROUP_AudioThreadCommands);

		const TWeakObjectPtr<USoundSubmix> SubmixPtr(&InSubmix);
		UPTRINT ListenerPtr = reinterpret_cast<UPTRINT>(&InSubmixBufferListener.Get());
		FString ListenerName = InSubmixBufferListener->GetListenerName();
		
		auto UnregisterLambda = [this, SubmixPtr, ListenerPtr, ListenerName]()
		{
			CSV_SCOPED_TIMING_STAT(Audio, UnregisterSubmixBufferListener);

			FMixerSubmixPtr FoundSubmix = GetSubmixInstance(SubmixPtr.Get()).Pin();
			if (FoundSubmix.IsValid())
			{
				UE_LOG(LogAudioMixer, Display, TEXT("Unregistering submix buffer listener '%s' from submix '%s'"), *ListenerName, *FoundSubmix->SubmixName);
				FoundSubmix->UnregisterBufferListenerInternal(ListenerPtr);
			}
			else
			{
				UE_LOG(LogAudioMixer, Display, TEXT("Submix buffer listener '%s' not unregistered. Submix not loaded."), *ListenerName);
			}
		};

		FAudioThread::RunCommandOnAudioThread(MoveTemp(UnregisterLambda));
	}

	void FMixerDevice::FlushExtended(UWorld* WorldToFlush, bool bClearActivatedReverb)
	{
		QuantizedEventClockManager.Flush();
	}

	FPatchOutputStrongPtr FMixerDevice::MakePatch(int32 InFrames, int32 InChannels, float InGain) const
	{
		// Assume the mixer will consume SourceManager->GetNumOutputFrames() per iteration and an input patch will generate InFrames per iteration.
		// An input patch must have adequate space to contain as many frames as the mixer might consume, as well as as many as might be pushed to the patch.
		// This should be twice the ceiling of the ratio of the larger number of frames to the smaller number, times InFrames.
		// An output patch must have adequate space to contain as many frames as the mixer might generate, as well as as many as might be consumed from the patch.
		// This should be the same number.
		int32 MaxSizeFrames = FMath::Max(InFrames, SourceManager->GetNumOutputFrames()), MinSizeFrames = FMath::Min(InFrames, SourceManager->GetNumOutputFrames());
		return MakeShared<Audio::FPatchOutput, ESPMode::ThreadSafe>(AudioMixerPatchBufferBlocks * InFrames * FMath::DivideAndRoundUp(MaxSizeFrames, MinSizeFrames) * InChannels, InGain);
	}

	FPatchOutputStrongPtr FMixerDevice::AddPatchForSubmix(uint32 InObjectId, float InPatchGain)
	{
		if (!ensure(IsAudioRenderingThread()))
		{
			return nullptr;
		}

		FMixerSubmixPtr SubmixPtr = FindSubmixInstanceByObjectId(InObjectId);
		if (SubmixPtr.IsValid())
		{
			return SubmixPtr->AddPatch(InPatchGain);
		}

		return nullptr;
	}

	int32 FMixerDevice::GetDeviceSampleRate() const
	{
		return SampleRate;
	}

	int32 FMixerDevice::GetDeviceOutputChannels() const
	{
		return PlatformInfo.NumChannels;
	}

	FMixerSourceManager* FMixerDevice::GetSourceManager()
	{
		return SourceManager.Get();
	}

	const FMixerSourceManager* FMixerDevice::GetSourceManager() const
	{
		return SourceManager.Get();
	}

	bool FMixerDevice::IsMainAudioDevice() const
	{
		bool bIsMain = (this == FAudioDeviceManager::Get()->GetMainAudioDeviceRaw());
		return bIsMain;
	}

	void FMixerDevice::WhiteNoiseTest(FAlignedFloatBuffer& Output)
	{
		const int32 NumFrames = OpenStreamParams.NumFrames;
		const int32 NumChannels = PlatformInfo.NumChannels;

		static FWhiteNoise WhiteNoise;

		for (int32 FrameIndex = 0; FrameIndex < NumFrames; ++FrameIndex)
		{
			for (int32 ChannelIndex = 0; ChannelIndex < NumChannels; ++ChannelIndex)
			{
				int32 Index = FrameIndex * NumChannels + ChannelIndex;
				Output[Index] += WhiteNoise.Generate(DebugGeneratorAmpCVar, 0.f);
			}
		}
	}

	void FMixerDevice::SineOscTest(FAlignedFloatBuffer& Output)
	{
		const int32 NumFrames = OpenStreamParams.NumFrames;
		const int32 NumChannels = PlatformInfo.NumChannels;

		check(NumChannels > 0);

		// Constrain user setting if channel index not supported
		const int32 ChannelIndex = FMath::Clamp(DebugGeneratorChannelCVar, 0, NumChannels - 1);

		static FSineOsc SineOscLeft(PlatformInfo.SampleRate, DebugGeneratorFreqCVar, DebugGeneratorAmpCVar);
		static FSineOsc SineOscRight(PlatformInfo.SampleRate, DebugGeneratorFreqCVar / 2.0f, DebugGeneratorAmpCVar);

		SineOscLeft.SetFrequency(DebugGeneratorFreqCVar);
		SineOscLeft.SetScale(DebugGeneratorAmpCVar);

		if (!DebugGeneratorEnableCVar)
		{
			SineOscRight.SetFrequency(DebugGeneratorFreqCVar / 2.0f);
			SineOscRight.SetScale(DebugGeneratorAmpCVar);
		}

		for (int32 FrameIndex = 0; FrameIndex < NumFrames; ++FrameIndex)
		{
			int32 Index = FrameIndex * NumChannels;

			Output[Index + ChannelIndex] += SineOscLeft.ProcessAudio();

			// Using au. commands for debug only supports discrete channel
			if (!DebugGeneratorEnableCVar)
			{
				if (NumChannels > 1 && DebugGeneratorChannelCVar == 0)
				{
					Output[Index + 1] += SineOscRight.ProcessAudio();
				}
			}
		}
	}

	void FMixerDevice::CreateSynchronizedAudioTaskQueue(AudioTaskQueueId QueueId)
	{
		Audio::CreateSynchronizedAudioTaskQueue(QueueId);
	}

	void FMixerDevice::DestroySynchronizedAudioTaskQueue(AudioTaskQueueId QueueId, bool RunCurrentQueue)
	{
		Audio::DestroySynchronizedAudioTaskQueue(QueueId, RunCurrentQueue);
	}

	int FMixerDevice::KickQueuedTasks(AudioTaskQueueId QueueId)
	{
		return Audio::KickQueuedTasks(QueueId);
	}

	double FAudioClockTimingData::GetInterpolatedAudioClock(const double InAudioClock, const double InAudioClockDelta) const
	{
		if (UpdateTime > 0.0)
		{
			const double TargetClock = InAudioClock + InAudioClockDelta;
			const double CurrentDeltaSeconds = FPlatformTime::Seconds() - UpdateTime;
			const double Alpha = FMath::Clamp(CurrentDeltaSeconds / InAudioClockDelta, 0.0f, 1.0f);

			const double InterpolatedClock = FMath::Lerp(InAudioClock, TargetClock, Alpha);

			return InterpolatedClock;
		}

		// Fall back to quantized clock if no timing data is available
		return InAudioClock;
	}
}

============================


=== AudioMixerDevice.h ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "Audio.h"
#include "AudioMixer.h"
#include "AudioDevice.h"
#include "Containers/MpscQueue.h"
#include "Sound/SoundSubmix.h"
#include "Sound/SoundGenerator.h"
#include "DSP/BufferVectorOperations.h"
#include "DSP/MultithreadedPatching.h"
#include "Quartz/AudioMixerClockManager.h"
#include "UObject/GCObject.h"
#include "UObject/StrongObjectPtr.h"

// Forward Declarations
class FOnSubmixEnvelopeBP;
class IAudioMixerPlatformInterface;
class USoundModulatorBase;
class IAudioLinkFactory;

#include "AudioMixerDevice.generated.h"

UENUM()
enum class ERequiredSubmixes : uint8
{
	Main = 0,
	BaseDefault = 1,
	Reverb = 2,
	EQ = 3,
	Count = 4 UMETA(Hidden)
};


namespace Audio
{
	// Audio Namespace Forward Declarations
	class FMixerSourceManager;
	class FMixerSourceVoice;
	class FMixerSubmix;
	class FAudioFormatSettings;

	typedef TSharedPtr<FMixerSubmix, ESPMode::ThreadSafe> FMixerSubmixPtr;
	typedef TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> FMixerSubmixWeakPtr;

	/** Data used to schedule events automatically in the audio renderer in audio mixer. */
	struct FAudioThreadTimingData
	{
		/** The time since audio device started. */
		double StartTime;

		/** The clock of the audio thread, periodically synced to the audio render thread time. */
		double AudioThreadTime;

		/** The clock of the audio render thread. */
		double AudioRenderThreadTime;

		/** The current audio thread fraction for audio events relative to the render thread. */
		double AudioThreadTimeJitterDelta;

		FAudioThreadTimingData()
			: StartTime(0.0)
			, AudioThreadTime(0.0)
			, AudioRenderThreadTime(0.0)
			, AudioThreadTimeJitterDelta(0.05)
		{}
	};	

	/** Data used to interpolate the audio clock in between buffer callbacks */
	struct FAudioClockTimingData
	{
		/** Time in secods of previous audio clock update */
		double UpdateTime = 0.0;

		/** Interpolates the given clock based on the amount of platform time that has passed since last update */
		double GetInterpolatedAudioClock(const double InAudioClock, const double InAudioClockDelta) const;
	};

	// Deprecated, use ERequiredSubmixes above
	namespace EMasterSubmixType
	{
		enum Type
		{
			Master = static_cast<uint8>(ERequiredSubmixes::Main),
			BaseDefault = static_cast<uint8>(ERequiredSubmixes::BaseDefault),
			Reverb = static_cast<uint8>(ERequiredSubmixes::Reverb),
			EQ = static_cast<uint8>(ERequiredSubmixes::EQ),
			Count = static_cast<uint8>(ERequiredSubmixes::Count)
		};
	}

	struct FSubmixMap
	{
	public:
		using FObjectId = uint32;
		using FPair = TPair<FObjectId, FMixerSubmixPtr>;
		using FIterFunc = TUniqueFunction<void(const FPair&)>;

		void Add(const FObjectId InObjectId, FMixerSubmixPtr InMixerSubmix);
		void Iterate(FIterFunc InFunction);
		FMixerSubmixPtr FindRef(FObjectId InObjectId) const;
		int32 Remove(const FObjectId InObjectId);
		void Reset();
		TSet<FSubmixMap::FObjectId> GetKeys() const;
	private:
		TMap<FObjectId, FMixerSubmixPtr> SubmixMap;

		mutable FCriticalSection MutationLock;
	};


	class FMixerDevice :	public FAudioDevice,
							public IAudioMixer,
							public FGCObject
	{
	public:
		AUDIOMIXER_API FMixerDevice(IAudioMixerPlatformInterface* InAudioMixerPlatform);
		AUDIOMIXER_API ~FMixerDevice();

		//~ Begin FAudioDevice
		AUDIOMIXER_API virtual void UpdateDeviceDeltaTime() override;
		AUDIOMIXER_API virtual void GetAudioDeviceList(TArray<FString>& OutAudioDeviceNames) const override;
		AUDIOMIXER_API virtual bool InitializeHardware() override;
		AUDIOMIXER_API virtual void FadeIn() override;
		AUDIOMIXER_API virtual void FadeOut() override;
		AUDIOMIXER_API virtual void TeardownHardware() override;
		AUDIOMIXER_API virtual void UpdateHardwareTiming() override;
		AUDIOMIXER_API virtual void UpdateGameThread() override;
		AUDIOMIXER_API virtual void UpdateHardware() override;
		AUDIOMIXER_API virtual double GetAudioTime() const override;
		AUDIOMIXER_API virtual double GetInterpolatedAudioClock() const override;
		AUDIOMIXER_API virtual FAudioEffectsManager* CreateEffectsManager() override;
		AUDIOMIXER_API virtual FSoundSource* CreateSoundSource() override;
		AUDIOMIXER_API virtual bool HasCompressedAudioInfoClass(USoundWave* SoundWave) override;
		AUDIOMIXER_API virtual bool SupportsRealtimeDecompression() const override;
		AUDIOMIXER_API virtual bool DisablePCMAudioCaching() const override;
		AUDIOMIXER_API virtual bool ValidateAPICall(const TCHAR* Function, uint32 ErrorCode) override;
#if UE_ALLOW_EXEC_COMMANDS
		AUDIOMIXER_API virtual bool Exec(UWorld* InWorld, const TCHAR* Cmd, FOutputDevice& Ar) override;
#endif
		AUDIOMIXER_API virtual void CountBytes(class FArchive& Ar) override;
		AUDIOMIXER_API virtual bool IsExernalBackgroundSoundActive() override;
		AUDIOMIXER_API virtual void ResumeContext() override;
		AUDIOMIXER_API virtual void SuspendContext() override;
		AUDIOMIXER_API virtual void EnableDebugAudioOutput() override;
		AUDIOMIXER_API virtual FAudioPlatformSettings GetPlatformSettings() const override;
		AUDIOMIXER_API virtual void RegisterSoundSubmix(USoundSubmixBase* SoundSubmix, bool bInit = true) override;
		AUDIOMIXER_API virtual void UnregisterSoundSubmix(const USoundSubmixBase* SoundSubmix, const bool bReparentChildren) override;

		AUDIOMIXER_API virtual int32 GetNumActiveSources() const override;

		// Updates the source effect chain (using unique object id). 
		AUDIOMIXER_API virtual void UpdateSourceEffectChain(const uint32 SourceEffectChainId, const TArray<FSourceEffectChainEntry>& SourceEffectChain, const bool bPlayEffectChainTails) override;
		AUDIOMIXER_API virtual bool GetCurrentSourceEffectChain(const uint32 SourceEffectChainId, TArray<FSourceEffectChainEntry>& OutCurrentSourceEffectChainEntries) override;

		// Submix dry/wet settings
		AUDIOMIXER_API virtual void UpdateSubmixProperties(USoundSubmixBase* InSubmix) override;
		AUDIOMIXER_API virtual void SetSubmixWetDryLevel(USoundSubmix* InSoundSubmix, float InOutputVolume, float InWetLevel, float InDryLevel) override;
		AUDIOMIXER_API virtual void SetSubmixOutputVolume(USoundSubmix* InSoundSubmix, float InOutputVolume) override;
		AUDIOMIXER_API virtual void SetSubmixWetLevel(USoundSubmix* InSoundSubmix, float InWetLevel) override;
		AUDIOMIXER_API virtual void SetSubmixDryLevel(USoundSubmix* InSoundSubmix, float InDryLevel) override;

		// Submix auto-disable setteings
		AUDIOMIXER_API virtual void SetSubmixAutoDisable(USoundSubmix* InSoundSubmix, bool bInAutoDisable) override;
		AUDIOMIXER_API virtual void SetSubmixAutoDisableTime(USoundSubmix* InSoundSubmix, float InDisableTime) override;

		// Submix Modulation Settings
		AUDIOMIXER_API virtual void UpdateSubmixModulationSettings(USoundSubmix* InSoundSubmix, const TSet<TObjectPtr<USoundModulatorBase>>& InOutputModulation, const TSet<TObjectPtr<USoundModulatorBase>>& InWetLevelModulation, const TSet<TObjectPtr<USoundModulatorBase>>& InDryLevelModulation) override;
		AUDIOMIXER_API virtual void SetSubmixModulationBaseLevels(USoundSubmix* InSoundSubmix, float InVolumeModBase, float InWetModBase, float InDryModBase) override;

		// Submix effect chain override settings
		AUDIOMIXER_API virtual void SetSubmixEffectChainOverride(USoundSubmix* InSoundSubmix, const TArray<FSoundEffectSubmixPtr>& InSubmixEffectPresetChain, float InFadeTimeSec) override;
		AUDIOMIXER_API virtual void ClearSubmixEffectChainOverride(USoundSubmix* InSoundSubmix, float InFadeTimeSec) override;

		// Submix recording callbacks:
		AUDIOMIXER_API virtual void StartRecording(USoundSubmix* InSubmix, float ExpectedRecordingDuration) override;
		AUDIOMIXER_API virtual Audio::FAlignedFloatBuffer& StopRecording(USoundSubmix* InSubmix, float& OutNumChannels, float& OutSampleRate) override;

		AUDIOMIXER_API virtual void PauseRecording(USoundSubmix* InSubmix);
		AUDIOMIXER_API virtual void ResumeRecording(USoundSubmix* InSubmix);

		// Submix envelope following
		AUDIOMIXER_API virtual void StartEnvelopeFollowing(USoundSubmix* InSubmix) override;
		AUDIOMIXER_API virtual void StopEnvelopeFollowing(USoundSubmix* InSubmix) override;
		AUDIOMIXER_API virtual void AddEnvelopeFollowerDelegate(USoundSubmix* InSubmix, const FOnSubmixEnvelopeBP& OnSubmixEnvelopeBP) override;
		AUDIOMIXER_API virtual void RemoveEnvelopeFollowerDelegate(USoundSubmix* InSubmix, const FOnSubmixEnvelopeBP& OnSubmixEnvelopeBP) override;

		// Submix Spectrum Analysis
		AUDIOMIXER_API virtual void StartSpectrumAnalysis(USoundSubmix* InSubmix, const FSoundSpectrumAnalyzerSettings& InSettings) override;
		AUDIOMIXER_API virtual void StopSpectrumAnalysis(USoundSubmix* InSubmix) override;
		AUDIOMIXER_API virtual void GetMagnitudesForFrequencies(USoundSubmix* InSubmix, const TArray<float>& InFrequencies, TArray<float>& OutMagnitudes) override;
		AUDIOMIXER_API virtual void GetPhasesForFrequencies(USoundSubmix* InSubmix, const TArray<float>& InFrequencies, TArray<float>& OutPhases) override;
		AUDIOMIXER_API virtual void AddSpectralAnalysisDelegate(USoundSubmix* InSubmix, const FSoundSpectrumAnalyzerDelegateSettings& InDelegateSettings, const FOnSubmixSpectralAnalysisBP& OnSubmixSpectralAnalysisBP) override;
		AUDIOMIXER_API virtual void RemoveSpectralAnalysisDelegate(USoundSubmix* InSubmix, const FOnSubmixSpectralAnalysisBP& OnSubmixSpectralAnalysisBP) override;

		// Submix buffer listener callbacks
		UE_DEPRECATED(5.4, "Use RegisterSubmixBufferListener version that requires a shared reference to a listener and provide explicit reference to a submix: use GetMainSubmixObject to register with the Main Output Submix (rather than nullptr for safety), and instantiate buffer listener via the shared pointer API.")
		AUDIOMIXER_API virtual void RegisterSubmixBufferListener(ISubmixBufferListener* InSubmixBufferListener, USoundSubmix* InSubmix = nullptr) override;

		UE_DEPRECATED(5.4, "Use UnregisterSubmixBufferListener version that requires a shared reference to a listener and provide explicit reference to a submix: use GetMainSubmixObject to unregister from the Main Output Submix (rather than nullptr for safety), and instantiate buffer listener via the shared pointer API.")
		AUDIOMIXER_API virtual void UnregisterSubmixBufferListener(ISubmixBufferListener* InSubmixBufferListener, USoundSubmix* InSubmix = nullptr) override;

		AUDIOMIXER_API virtual void RegisterSubmixBufferListener(TSharedRef<ISubmixBufferListener, ESPMode::ThreadSafe> InSubmixBufferListener, USoundSubmix& InSubmix) override;

		// This is optional, and should only be used to manually unregister before the ISubmixBufferListener is getting destroyed
		// (do not call this in the destructor of ISubmixBufferListener or derived classes)
		AUDIOMIXER_API virtual void UnregisterSubmixBufferListener(TSharedRef<ISubmixBufferListener, ESPMode::ThreadSafe> InSubmixBufferListener, USoundSubmix& InSubmix) override;

		AUDIOMIXER_API virtual FPatchOutputStrongPtr AddPatchForSubmix(uint32 InObjectId, float InPatchGain) override;

		AUDIOMIXER_API virtual void FlushExtended(UWorld* WorldToFlush, bool bClearActivatedReverb);
		AUDIOMIXER_API virtual void FlushAudioRenderingCommands(bool bPumpSynchronously = false) override;

		// Audio Device Properties
		AUDIOMIXER_API virtual bool IsNonRealtime() const override;

		//~ End FAudioDevice

		//~ Begin IAudioMixer
		AUDIOMIXER_API virtual bool OnProcessAudioStream(FAlignedFloatBuffer& OutputBuffer) override;
		AUDIOMIXER_API virtual void OnAudioStreamShutdown() override;
		//~ End IAudioMixer

		//~ Begin FGCObject
		AUDIOMIXER_API virtual void AddReferencedObjects(FReferenceCollector& Collector) override;
		virtual FString GetReferencerName() const override
		{
			return TEXT("Audio::FMixerDevice");
		}
		//~End FGCObject

		AUDIOMIXER_API FMixerSubmixPtr FindSubmixInstanceByObjectId(uint32 InObjectId);

		AUDIOMIXER_API FMixerSubmixWeakPtr GetSubmixInstance(const USoundSubmixBase* SoundSubmix) const;

		// If SoundSubmix is a soundfield submix, this will return the factory used to encode 
		// source audio to it's soundfield format.
		// Otherwise, returns nullptr.
		AUDIOMIXER_API ISoundfieldFactory* GetFactoryForSubmixInstance(USoundSubmix* SoundSubmix);
		AUDIOMIXER_API ISoundfieldFactory* GetFactoryForSubmixInstance(FMixerSubmixWeakPtr& SoundSubmixPtr);

		// Functions which check the thread it's called on and helps make sure functions are called from correct threads
		AUDIOMIXER_API void CheckAudioThread() const;
		AUDIOMIXER_API void CheckAudioRenderingThread() const;
		AUDIOMIXER_API bool IsAudioRenderingThread() const;

		// Public Functions
		AUDIOMIXER_API FMixerSourceVoice* GetMixerSourceVoice();
		AUDIOMIXER_API void ReleaseMixerSourceVoice(FMixerSourceVoice* InSourceVoice);
		AUDIOMIXER_API int32 GetNumSources() const;

		// AudioLink
		AUDIOMIXER_API IAudioLinkFactory* GetAudioLinkFactory() const;

		const FAudioPlatformDeviceInfo& GetPlatformDeviceInfo() const { return PlatformInfo; };

		FORCEINLINE int32 GetNumDeviceChannels() const { return PlatformInfo.NumChannels; }
		FORCEINLINE int32 GetNumDirectOutChannels() const { return PlatformInfo.NumDirectOutChannels; }

		int32 GetNumOutputFrames() const { return PlatformSettings.CallbackBufferFrameSize; }

		int32 GetNumOutputBuffers() const { return PlatformSettings.NumBuffers; }

		// Retrieve a pointer to the currently active platform. Only use this if you know what you are doing. The returned IAudioMixerPlatformInterface will only be alive as long as this FMixerDevice is alive.
		IAudioMixerPlatformInterface* GetAudioMixerPlatform() const { return AudioMixerPlatform; }

		// Builds a 3D channel map for a spatialized source.
		AUDIOMIXER_API void Get3DChannelMap(const int32 InSubmixNumChannels, const FWaveInstance* InWaveInstance, const float EmitterAzimuth, const float NonSpatiliazedFactor, const TMap<EAudioMixerChannel::Type, float>* InOmniMap, float InDefaultOmniValue, Audio::FAlignedFloatBuffer& OutChannelMap);

		// Builds a channel gain matrix for a non-spatialized source. The non-static variation of this function queries AudioMixerDevice->NumOutputChannels directly which may not be thread safe.
		AUDIOMIXER_API void Get2DChannelMap(bool bIsVorbis, const int32 NumSourceChannels, const bool bIsCenterChannelOnly, Audio::FAlignedFloatBuffer& OutChannelMap) const;
		AUDIOMIXER_API static void Get2DChannelMap(bool bIsVorbis, const int32 NumSourceChannels, const int32 NumOutputChannels, const bool bIsCenterChannelOnly, Audio::FAlignedFloatBuffer& OutChannelMap);

		AUDIOMIXER_API int32 GetDeviceSampleRate() const;
		AUDIOMIXER_API int32 GetDeviceOutputChannels() const;

		AUDIOMIXER_API FMixerSourceManager* GetSourceManager();
		AUDIOMIXER_API const FMixerSourceManager* GetSourceManager() const;

		AUDIOMIXER_API virtual USoundSubmix& GetMainSubmixObject() const override;

		AUDIOMIXER_API FMixerSubmixWeakPtr GetBaseDefaultSubmix();
		AUDIOMIXER_API FMixerSubmixWeakPtr GetMainSubmix();
		AUDIOMIXER_API FMixerSubmixWeakPtr GetReverbSubmix();
		AUDIOMIXER_API FMixerSubmixWeakPtr GetEQSubmix();

		// Renamed Main submix: these functions will be deprecated in a future release
		AUDIOMIXER_API void AddMasterSubmixEffect(FSoundEffectSubmixPtr SoundEffect);
		AUDIOMIXER_API void RemoveMasterSubmixEffect(uint32 SubmixEffectId);
		AUDIOMIXER_API void ClearMasterSubmixEffects();
		AUDIOMIXER_API FMixerSubmixWeakPtr GetMasterSubmix();
		AUDIOMIXER_API FMixerSubmixWeakPtr GetMasterReverbSubmix();
		AUDIOMIXER_API FMixerSubmixWeakPtr GetMasterEQSubmix();

		// Add submix effect to main submix
		AUDIOMIXER_API void AddMainSubmixEffect(FSoundEffectSubmixPtr SoundEffect);

		// Remove submix effect from main submix
		AUDIOMIXER_API void RemoveMainSubmixEffect(uint32 SubmixEffectId);

		// Clear all submix effects from main submix
		AUDIOMIXER_API void ClearMainSubmixEffects();

		// Add submix effect to given submix
		AUDIOMIXER_API int32 AddSubmixEffect(USoundSubmix* InSoundSubmix, FSoundEffectSubmixPtr SoundEffect);

		// Remove submix effect to given submix
		AUDIOMIXER_API void RemoveSubmixEffect(USoundSubmix* InSoundSubmix, uint32 SubmixEffectId);

		// Remove submix effect at the given submix chain index
		AUDIOMIXER_API void RemoveSubmixEffectAtIndex(USoundSubmix* InSoundSubmix, int32 SubmixChainIndex);

		// Replace the submix effect of the given submix at the submix chain index with the new submix effect id and submix instance
		AUDIOMIXER_API void ReplaceSoundEffectSubmix(USoundSubmix* InSoundSubmix, int32 InSubmixChainIndex, FSoundEffectSubmixPtr SoundEffect);

		// Clear all submix effects from given submix
		AUDIOMIXER_API void ClearSubmixEffects(USoundSubmix* InSoundSubmix);

		// Returns the channel array for the given submix channel type
		AUDIOMIXER_API const TArray<EAudioMixerChannel::Type>& GetChannelArray() const;

		// Retrieves the listener transforms
		AUDIOMIXER_API const TArray<FTransform>* GetListenerTransforms();

		// Retrieves spherical locations of channels for a given submix format
		AUDIOMIXER_API const FChannelPositionInfo* GetDefaultChannelPositions() const;

		// Audio thread tick timing relative to audio render thread timing
		double GetAudioThreadTime() const { return AudioThreadTimingData.AudioThreadTime; }
		double GetAudioRenderThreadTime() const { return AudioThreadTimingData.AudioRenderThreadTime; }
		double GetAudioClockDelta() const { return AudioClockDelta; }

		EMonoChannelUpmixMethod GetMonoChannelUpmixMethod() const { return MonoChannelUpmixMethod; }

		AUDIOMIXER_API TArray<Audio::FChannelPositionInfo>* GetDefaultPositionMap(int32 NumChannels);

		static AUDIOMIXER_API bool IsEndpointSubmix(const USoundSubmixBase* InSubmix);

		AUDIOMIXER_API FPatchOutputStrongPtr MakePatch(int32 InFrames, int32 InChannels, float InGain) const;

		// Clock Manager for quantized event handling on Audio Render Thread
		FQuartzClockManager QuantizedEventClockManager;

		// Keep a reference alive to UQuartzSubsystem state that needs to persist across level transitions (UWorld destruction
		TSharedPtr<FPersistentQuartzSubsystemData, ESPMode::ThreadSafe> QuartzSubsystemData { nullptr };

		// Technically, in editor, multiple UQuartz(World)Subsystem's will reference the same FMixerDevice object.
		// We need to protect around mutation/access of the "shared" state.
		// (in practice this should be low/zero contention)
		FCriticalSection QuartzPersistentStateCritSec;

		// Pushes the command to a audio render thread command queue to be executed on render thread
		AUDIOMIXER_API void AudioRenderThreadCommand(TFunction<void()> Command);

		// Pushes the command to a MPSC queue to be executed on the game thread
		AUDIOMIXER_API void GameThreadMPSCCommand(TFunction<void()> InCommand);

		// Debug Commands
		AUDIOMIXER_API void DrawSubmixes(FOutputDevice& InOutput, const TArray<FString>& InArgs) const;

	protected:
		AUDIOMIXER_API virtual void InitSoundSubmixes() override;

		AUDIOMIXER_API virtual void OnListenerUpdated(const TArray<FListener>& InListeners) override;

		TArray<FTransform> ListenerTransforms;

	private:
		// Resets the thread ID used for audio rendering
		void ResetAudioRenderingThreadId();

		void RebuildSubmixLinks(const USoundSubmixBase& SoundSubmix, FMixerSubmixPtr& SubmixInstance);

		void InitializeChannelMaps();
		static int32 GetChannelMapCacheId(const int32 NumSourceChannels, const int32 NumOutputChannels, const bool bIsCenterChannelOnly);
		void CacheChannelMap(const int32 NumSourceChannels, const int32 NumOutputChannels, const bool bIsCenterChannelOnly);
		void InitializeChannelAzimuthMap(const int32 NumChannels);

		void WhiteNoiseTest(FAlignedFloatBuffer& Output);
		void SineOscTest(FAlignedFloatBuffer& Output);

		bool IsMainAudioDevice() const;

		void LoadRequiredSubmix(ERequiredSubmixes InType, const FString& InDefaultName, bool bInDefaultMuteWhenBackgrounded, FSoftObjectPath& InOutObjectPath);
		void LoadPluginSoundSubmixes();
		void LoadSoundSubmix(USoundSubmixBase& SoundSubmix);

		void InitSoundfieldAndEndpointDataForSubmix(const USoundSubmixBase& InSoundSubmix, FMixerSubmixPtr MixerSubmix, bool bAllowReInit);

		void UnloadSoundSubmix(const USoundSubmixBase& SoundSubmix, const bool bReparentChildren);

		bool IsRequiredSubmixType(const USoundSubmixBase* InSubmix) const;
		FMixerSubmixPtr GetRequiredSubmixInstance(uint32 InSubmixId) const;
		FMixerSubmixPtr GetRequiredSubmixInstance(const USoundSubmixBase* InSubmix) const;
		
		// Pumps the audio render thread command queue
		void PumpCommandQueue();
		void PumpGameThreadCommandQueue();

		/** Updates the audio clock and the associated timing data */
		void UpdateAudioClock();
		
		TArray<USoundSubmix*> RequiredSubmixes;
		TArray<FMixerSubmixPtr> RequiredSubmixInstances;

		TArray<TStrongObjectPtr<UAudioBus>> DefaultAudioBuses;
		/** Ptr to the platform interface, which handles streaming audio to the hardware device. */
		IAudioMixerPlatformInterface* AudioMixerPlatform;
		
		/** Contains a map of channel/speaker azimuth positions. */
		FChannelPositionInfo DefaultChannelAzimuthPositions[EAudioMixerChannel::MaxSupportedChannel];

		/** The azimuth positions for submix channel types. */
		TArray<FChannelPositionInfo> DeviceChannelAzimuthPositions;

		int32 DeviceOutputChannels;

		/** What upmix method to use for mono channel upmixing. */
		EMonoChannelUpmixMethod MonoChannelUpmixMethod;

		/** What panning method to use for panning. */
		EPanningMethod PanningMethod;

		/** The audio output stream parameters used to initialize the audio hardware. */
		FAudioMixerOpenStreamParams OpenStreamParams;

		/** The time delta for each callback block. */
		double AudioClockDelta;

		/** The timing data used to interpolate the audio clock */
		FAudioClockTimingData AudioClockTimingData;

		/** What the previous master volume was. */
		float PreviousPrimaryVolume;

		/** Timing data for audio thread. */
		FAudioThreadTimingData AudioThreadTimingData;

		/** The platform device info for this mixer device. */
		FAudioPlatformDeviceInfo PlatformInfo;

		/** Map of USoundSubmix static data objects to the dynamic audio mixer submix. */
		FSubmixMap Submixes;

		// Submixes that will sum their audio and send it directly to AudioMixerPlatform.
		// Submixes are added to this list in RegisterSoundSubmix, and removed in UnregisterSoundSubmix.
		TArray<FMixerSubmixPtr> DefaultEndpointSubmixes;

		// Submixes that need to be processed, but will be sending their audio to external sends.
		// Submixes are added to this list in RegisterSoundSubmix and removed in UnregisterSoundSubmix.
		TArray<FMixerSubmixPtr> ExternalEndpointSubmixes;

		// Contended between RegisterSoundSubmix/UnregisterSoundSubmix on the audio thread and OnProcessAudioStream on the audio mixer thread.
		FCriticalSection EndpointSubmixesMutationLock;

		/** Which submixes have been told to envelope follow with this audio device. */
		TArray<USoundSubmix*> DelegateBoundSubmixes;

		/** Queue of mixer source voices. */
		TQueue<FMixerSourceVoice*> SourceVoices;

		TMap<uint32, TArray<FSourceEffectChainEntry>> SourceEffectChainOverrides;

		/** The mixer source manager. */
		TUniquePtr<FMixerSourceManager> SourceManager;

		/** ThreadId for the game thread (or if audio is running a separate thread, that ID) */
		mutable int32 GameOrAudioThreadId;

		/** ThreadId for the low-level platform audio mixer. */
		mutable std::atomic<int32> AudioPlatformThreadId;

		/** Command queue to send commands to audio render thread from game thread or audio thread. */
		TQueue<TFunction<void()>> CommandQueue;

		/** MPSC command queue to send commands to the game thread */
		TMpscQueue<TFunction<void()>> GameThreadCommandQueue;

		IAudioLinkFactory* AudioLinkFactory = nullptr;
		
		/** Whether or not we generate output audio to test multi-platform mixer. */
		bool bDebugOutputEnabled;

		/** Whether or not initialization of the submix system is underway and submixes can be registered */
		bool bSubmixRegistrationDisabled;

	public:

		// Creates a queue for audio decode requests with a specific Id. Tasks
		// created with this Id will not be started immediately upon creation,
		// but will instead be queued up to await a start "kick" later.
		AUDIOMIXER_API static void CreateSynchronizedAudioTaskQueue(AudioTaskQueueId QueueId);

		// Destroys an audio decode task queue. Tasks currently queued up are 
		// optionally started.
		AUDIOMIXER_API static void DestroySynchronizedAudioTaskQueue(AudioTaskQueueId QueueId, bool RunCurrentQueue = false);

		// "Kicks" all of the audio decode tasks currentlyt in the queue.
		AUDIOMIXER_API static int KickQueuedTasks(AudioTaskQueueId QueueId);
	};
}


==========================


=== AudioMixerEffectsManager.cpp ===
====================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerEffectsManager.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSubmix.h"

namespace Audio
{
	FAudioMixerEffectsManager::FAudioMixerEffectsManager(FAudioDevice* InDevice)
		: FAudioEffectsManager(InDevice)
	{
	}

	FAudioMixerEffectsManager::~FAudioMixerEffectsManager()
	{}

	void FAudioMixerEffectsManager::SetReverbEffectParameters(const FAudioEffectParameters& InEffectParameters)
	{
		FMixerDevice* MixerDevice = (FMixerDevice*)AudioDevice;

		FMixerSubmixWeakPtr MasterReverbSubmix = MixerDevice->GetMasterReverbSubmix();
		FMixerSubmixPtr MasterReverbSubmixPtr = MasterReverbSubmix.Pin();
		
		if (MasterReverbSubmixPtr.IsValid())
		{
			bool bReportFailure = false;

			FSoundEffectSubmixPtr SoundEffectSubmix = MasterReverbSubmixPtr->GetSubmixEffect(0);
			if (SoundEffectSubmix.IsValid())
			{
				InEffectParameters.PrintSettings();

				if (!SoundEffectSubmix->SupportsDefaultReverb() || !SoundEffectSubmix->SetParameters(InEffectParameters))
				{
					bReportFailure = true;
				}
				else
				{
					InvalidReverbEffect.Reset();
				}
			}
			else
			{
				bReportFailure = true;
			}

			if (bReportFailure && InvalidReverbEffect != SoundEffectSubmix)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to update reverb parameters on Default Reverb Submix. Ensure first submix effect is supported type"));
				InvalidReverbEffect = SoundEffectSubmix;
			}
		}
	}

	void FAudioMixerEffectsManager::SetEQEffectParameters(const FAudioEffectParameters& InEffectParameters)
	{
		FMixerDevice* MixerDevice = (FMixerDevice*)AudioDevice;

		FMixerSubmixWeakPtr MasterEQSubmix = MixerDevice->GetMasterEQSubmix();
		FMixerSubmixPtr MasterEQSubmixPtr = MasterEQSubmix.Pin();

		if (MasterEQSubmixPtr.IsValid())
		{
			bool bReportFailure = false;
			FSoundEffectSubmixPtr SoundEffectSubmix = MasterEQSubmixPtr->GetSubmixEffect(0);
			if (SoundEffectSubmix.IsValid())
			{
				InEffectParameters.PrintSettings();

				if (!SoundEffectSubmix->SupportsDefaultEQ() || !SoundEffectSubmix->SetParameters(InEffectParameters))
				{
					bReportFailure = true;
				}
				else
				{
					InvalidEQEffect.Reset();
				}
			}
			else
			{
				bReportFailure = true;
			}

			if (bReportFailure && InvalidEQEffect != SoundEffectSubmix)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to update EQ parameters on legacy Default EQ Submix. Ensure first submix effect is supported type"));
				InvalidEQEffect = SoundEffectSubmix;
			}
		}
	}

	void FAudioMixerEffectsManager::SetRadioEffectParameters(const FAudioEffectParameters& InEffectParameters)
	{
		// Effect system deprecated
	}
}

====================================


=== AudioMixerEffectsManager.h ===
==================================

// Copyright Epic Games, Inc. All Rights Reserved.

/*=============================================================================
AudioMixerEffectsManager.h: Implementation of backwards compatible effects
manager for the multi-platform audio mixer device.
=============================================================================*/

#pragma once

#include "AudioEffect.h"
#include "Curves/CurveFloat.h"
#include "Sound/SoundEffectSubmix.h"


namespace Audio
{
	class FAudioMixerEffectsManager : public FAudioEffectsManager
	{
	public:
		FAudioMixerEffectsManager(FAudioDevice* InDevice);
		~FAudioMixerEffectsManager() override;

		//~ Begin FAudioEffectsManager
		virtual void SetReverbEffectParameters(const FAudioEffectParameters& InEffectParameters) override;
		virtual void SetEQEffectParameters(const FAudioEffectParameters& InEffectParameters) override;
		virtual void SetRadioEffectParameters(const FAudioEffectParameters& InEffectParameters) override;
		//~ End FAudioEffectsManager

	protected:
		FRuntimeFloatCurve MasterReverbWetLevelCurve;

	private:
		FSoundEffectSubmixPtr InvalidReverbEffect;
		FSoundEffectSubmixPtr InvalidEQEffect;
	};
} // namespace Audio

==================================


=== AudioMixerModule.cpp ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerModule.h"
#include "Modules/ModuleManager.h"

class FAudioMixerModule : public IModuleInterface
{
public:

	virtual void StartupModule() override
	{
		FModuleManager::Get().LoadModuleChecked(TEXT("AudioMixerCore"));
		FModuleManager::Get().LoadModuleChecked(TEXT("SignalProcessing"));
	}
};

IMPLEMENT_MODULE(FAudioMixerModule, AudioMixer);

============================


=== AudioMixerModule.h ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once


/* Public dependencies
*****************************************************************************/

#include "CoreMinimal.h"


/* Public includes
*****************************************************************************/

#include "AudioDecompress.h"
#include "AudioEffect.h"



==========================


=== AudioMixerQuantizedCommands.cpp ===
=======================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Quartz/AudioMixerQuantizedCommands.h"
#include "AudioMixerSourceManager.h"

namespace Audio
{
	
	FQuantizedPlayCommand::FQuantizedPlayCommand()
	{
	}

	TSharedPtr<IQuartzQuantizedCommand> FQuantizedPlayCommand::GetDeepCopyOfDerivedObject() const
	{
		TSharedPtr<FQuantizedPlayCommand> NewCopy = MakeShared<FQuantizedPlayCommand>();

		NewCopy->OwningClockPtr = OwningClockPtr;
		NewCopy->SourceID = SourceID;

		return NewCopy;
	}

	void FQuantizedPlayCommand::OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo)
	{
		OwningClockPtr = InCommandInitInfo.OwningClockPointer;
		SourceID = InCommandInitInfo.SourceID;
		bIsCanceled = false;

		// access source manager through owning clock (via clock manager)
		FMixerSourceManager* SourceManager = OwningClockPtr->GetSourceManager();
		if (SourceManager)
		{
			SourceManager->PauseSoundForQuantizationCommand(SourceID);
		}
		else
		{
			// cancel ourselves (no source manager may mean we are running without an audio device)
			if (ensure(OwningClockPtr))
			{
				OwningClockPtr->CancelQuantizedCommand(TSharedPtr<IQuartzQuantizedCommand>(this));
			}
		}
		
	}

	// TODO: think about playback progress of a sound source
	// TODO: AudioComponent "waiting to play" state (cancel-able)
	void FQuantizedPlayCommand::OnFinalCallbackCustom(int32 InNumFramesLeft)
	{
		// Access source manager through owning clock (via clock manager)
		check(OwningClockPtr && OwningClockPtr->GetSourceManager());

		// This was canceled before the active sound hit the source manager.
		// Calling CancelCustom() make sure we stop the associated sound.
		if (bIsCanceled)
		{
			CancelCustom();
			return;
		}

		// access source manager through owning clock (via clock manager)
		// Owning Clock Ptr may be nullptr if this command was canceled.
		if (OwningClockPtr)
		{
			FMixerSourceManager* SourceManager = OwningClockPtr->GetSourceManager();
			if (SourceManager)
			{
				SourceManager->SetSubBufferDelayForSound(SourceID, InNumFramesLeft);
				SourceManager->UnPauseSoundForQuantizationCommand(SourceID);
			}
			else
			{
				// cancel ourselves (no source manager may mean we are running without an audio device)
				OwningClockPtr->CancelQuantizedCommand(TSharedPtr<IQuartzQuantizedCommand>(this));
			}
		}

	}

	void FQuantizedPlayCommand::CancelCustom()
	{
		bIsCanceled = true;

		if (OwningClockPtr)
		{
			FMixerSourceManager* SourceManager = OwningClockPtr->GetSourceManager();
			FMixerDevice* MixerDevice = OwningClockPtr->GetMixerDevice();

			if (MixerDevice && SourceManager && MixerDevice->IsAudioRenderingThread())
			{
				// if we don't UnPause first, this function will be called by FMixerSourceManager::StopInternal()
				SourceManager->UnPauseSoundForQuantizationCommand(SourceID); // (avoid infinite recursion)
				SourceManager->CancelQuantizedSound(SourceID);
			}
		}
	}

	static const FName PlayCommandName("Play Command");
	FName FQuantizedPlayCommand::GetCommandName() const
	{
		return PlayCommandName;
	}

	int32 FQuantizedPlayCommand::OverrideFramesUntilExec(int32 NumFramesUntilExec)
	{
//		if (OwningClockPtr)
//		{
//				if(const FMixerDevice* MixerDevice = OwningClockPtr->GetMixerDevice())
//				{
//					return NumFramesUntilExec + 2 * MixerDevice->GetBufferLength();
//				}
//		}
//		
		return NumFramesUntilExec;
	}

	void FQuantizedQueueCommand::SetQueueCommand(const FAudioComponentCommandInfo& InAudioComponentData)
	{
		AudioComponentData = InAudioComponentData;
	}

	TSharedPtr<IQuartzQuantizedCommand> FQuantizedQueueCommand::GetDeepCopyOfDerivedObject() const
	{
		return MakeShared<FQuantizedQueueCommand>(*this);
	}

	void FQuantizedQueueCommand::OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo)
	{
		OwningClockPtr = InCommandInitInfo.OwningClockPointer;
	}

	int32 FQuantizedQueueCommand::OverrideFramesUntilExec(int32 NumFramesUntilExec)
	{
		// Calculate the amount of time before taking up a voice slot
		int32 NumFramesBeforeVoiceSlot = NumFramesUntilExec - static_cast<int32>(OwningClockPtr->GetTickRate().GetFramesPerDuration(AudioComponentData.AnticipatoryBoundary.Quantization));

		//If NumFramesBeforeVoiceSlot is less than 0, change the boundary back to the original, and mark this command as having 0 frames till exec
		if (NumFramesBeforeVoiceSlot < 0)
		{
			return 0;
		}
	
		return NumFramesBeforeVoiceSlot;
	}

	void FQuantizedQueueCommand::OnFinalCallbackCustom(int32 InNumFramesLeft)
	{
		if (OwningClockPtr)
		{
			FName ClockName = OwningClockPtr->GetName();
			Audio::FQuartzQueueCommandData CommandData(AudioComponentData, ClockName);

			AudioComponentData.Subscriber.PushEvent(CommandData);
		}
	}

	static const FName QueueCommandName("Queue Command");
	FName FQuantizedQueueCommand::GetCommandName() const
	{
		return QueueCommandName;
	}
	
	TSharedPtr<IQuartzQuantizedCommand> FQuantizedTickRateChange::GetDeepCopyOfDerivedObject() const
	{
		TSharedPtr<FQuantizedTickRateChange> NewCopy = MakeShared<FQuantizedTickRateChange>();

		NewCopy->OwningClockPtr = OwningClockPtr;
		NewCopy->TickRate = TickRate;

		return NewCopy;
	}
	
	void FQuantizedTickRateChange::OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo)
	{
		OwningClockPtr = InCommandInitInfo.OwningClockPointer;
	}
	
	void FQuantizedTickRateChange::OnFinalCallbackCustom(int32 InNumFramesLeft)
	{
		OwningClockPtr->ChangeTickRate(TickRate, InNumFramesLeft);
	}

	static const FName TickRateChangeCommandName("Tick Rate Change Command");
	FName FQuantizedTickRateChange::GetCommandName() const
	{
		return TickRateChangeCommandName;
	}

	TSharedPtr<IQuartzQuantizedCommand> FQuantizedTransportReset::GetDeepCopyOfDerivedObject() const
	{
		TSharedPtr<FQuantizedTransportReset> NewCopy = MakeShared<FQuantizedTransportReset>();

		NewCopy->OwningClockPtr = OwningClockPtr;

		return NewCopy;
	}

	void FQuantizedTransportReset::OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo)
	{
		OwningClockPtr = InCommandInitInfo.OwningClockPointer;
	}

	void FQuantizedTransportReset::OnFinalCallbackCustom(int32 InNumFramesLeft)
	{
		// todo: guard against multiple reset commands executing in the same clock tick
		// OwningClockPtr->ResetTransport(InNumFramesLeft - 1); // - 1 to triggering events w/o double trigger of events on the last frame
		OwningClockPtr->ResetTransport(0);
		OwningClockPtr->AddToTickDelay(InNumFramesLeft); // next metronome tick will be less by InNumFramesLeft
	}

	static const FName TransportResetCommandName("Transport Reset Command");
	FName FQuantizedTransportReset::GetCommandName() const
	{
		return TransportResetCommandName;
	}


	TSharedPtr<IQuartzQuantizedCommand> FQuantizedOtherClockStart::GetDeepCopyOfDerivedObject() const
	{
		TSharedPtr<FQuantizedOtherClockStart> NewCopy = MakeShared<FQuantizedOtherClockStart>();

		NewCopy->OwningClockPtr = OwningClockPtr;
		NewCopy->NameOfClockToStart = NameOfClockToStart;

		return NewCopy;
	}

	void FQuantizedOtherClockStart::OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo)
	{
		OwningClockPtr = InCommandInitInfo.OwningClockPointer;
		check(OwningClockPtr.IsValid());

		NameOfClockToStart = InCommandInitInfo.OtherClockName;
	}

	void FQuantizedOtherClockStart::OnFinalCallbackCustom(int32 InNumFramesLeft)
	{
		if (!ensureMsgf(OwningClockPtr.IsValid(), TEXT("Quantized Other Clock Start is early exiting (invalid/missing Owning Clock Pointer)")))
		{
			return;
		}

		// get access to the clock manager
		FQuartzClockManager* ClockManager = OwningClockPtr->GetClockManager();

		bool bShouldStart = ClockManager && !ClockManager->IsClockRunning(NameOfClockToStart);

		if (bShouldStart)
		{
			// ...start the clock
			ClockManager->ResumeClock(NameOfClockToStart, InNumFramesLeft);

			if (ClockManager->HasClockBeenTickedThisUpdate(NameOfClockToStart))
			{
				ClockManager->UpdateClock(NameOfClockToStart, ClockManager->GetLastUpdateSizeInFrames());
			}
		}
	}

	static const FName StartOtherClockName("Start Other Clock Command");
	FName FQuantizedOtherClockStart::GetCommandName() const
	{
		return StartOtherClockName;
	}


	FQuantizedNotify::FQuantizedNotify(float InMsOffset)  : OffsetInMs(InMsOffset)
	{
	}

	int32 FQuantizedNotify::OverrideFramesUntilExec(int32 NumFramesUntilExec)
	{
		constexpr float MsToSec = 1000.f;
		return FMath::Max(0, NumFramesUntilExec + (OffsetInMs / MsToSec) * SampleRate);
	}

	void FQuantizedNotify::OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo)
	{
		SampleRate = InCommandInitInfo.SampleRate;
	}

	TSharedPtr<IQuartzQuantizedCommand> FQuantizedNotify::GetDeepCopyOfDerivedObject() const
	{
		return MakeShared<FQuantizedNotify>();
	}

	static const FName FQuantizedNotifyName("Notify Command");
	FName FQuantizedNotify::GetCommandName() const
	{
		return FQuantizedNotifyName;
	}

} // namespace Audio

=======================================


=== AudioMixerQuantizedCommands.h ===
=====================================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "AudioMixerClock.h"

namespace Audio
{
	// QuartzQuantizedCommand that plays a sound on a sample-accurate boundary
	class FQuantizedPlayCommand : public IQuartzQuantizedCommand
	{
	public:
		// ctor
		AUDIOMIXER_API FQuantizedPlayCommand();

		// dtor
		~FQuantizedPlayCommand() {}

		AUDIOMIXER_API virtual TSharedPtr<IQuartzQuantizedCommand> GetDeepCopyOfDerivedObject() const override;

		AUDIOMIXER_API virtual void OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo) override;

		AUDIOMIXER_API virtual void OnFinalCallbackCustom(int32 InNumFramesLeft) override;

		AUDIOMIXER_API virtual void CancelCustom() override;

		virtual bool RequiresAudioDevice() const override { return true; }

		AUDIOMIXER_API virtual FName GetCommandName() const override;
		
		// for your implementation, a new EQuartzCommandType needs to be defined in QuartzQuantizationUtilities.h
		virtual EQuartzCommandType GetCommandType() const { return EQuartzCommandType::PlaySound; };

		virtual int32 OverrideFramesUntilExec(int32 NumFramesUntilExec);

	protected:
		TSharedPtr<FQuartzClock> OwningClockPtr{ nullptr };

		int32 SourceID{ -1 };

		bool bIsCanceled = false;

	}; // class FQuantizedPlayCommand 


	class FQuantizedQueueCommand : public IQuartzQuantizedCommand
	{
	public:
		AUDIOMIXER_API virtual TSharedPtr<IQuartzQuantizedCommand> GetDeepCopyOfDerivedObject() const override;

		AUDIOMIXER_API virtual void OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo) override;

		AUDIOMIXER_API virtual int32 OverrideFramesUntilExec(int32 NumFramesUntilExec) override;

		AUDIOMIXER_API virtual void OnFinalCallbackCustom(int32 InNumFramesLeft) override;

		virtual bool RequiresAudioDevice() const override { return true; }

		AUDIOMIXER_API virtual FName GetCommandName() const override;
		virtual EQuartzCommandType GetCommandType() const { return EQuartzCommandType::QueueSoundToPlay; };

		AUDIOMIXER_API void SetQueueCommand(const FAudioComponentCommandInfo& InAudioCommandData);

		FQuantizedQueueCommand() {}

	private:
		TSharedPtr<FQuartzClock> OwningClockPtr{ nullptr };

		//Data for the quantization event
		FAudioComponentCommandInfo AudioComponentData;
	}; // class FQuantizedQueueCommand 
	
	// QuartzQuantizedCommand that changes the TickRate of a clock on a sample-accurate boundary (i.e. BPM changes)
	class FQuantizedTickRateChange : public IQuartzQuantizedCommand
	{
	public:
		void SetTickRate(const FQuartzClockTickRate& InTickRate)
		{
			TickRate = InTickRate;
		}

		AUDIOMIXER_API virtual TSharedPtr<IQuartzQuantizedCommand> GetDeepCopyOfDerivedObject() const override;

		AUDIOMIXER_API virtual void OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo) override;

		AUDIOMIXER_API virtual void OnFinalCallbackCustom(int32 InNumFramesLeft) override;

		virtual bool IsClockAltering() override { return true; }

		AUDIOMIXER_API virtual FName GetCommandName() const override;
		virtual EQuartzCommandType GetCommandType() const { return EQuartzCommandType::TickRateChange; };

	private:
		FQuartzClockTickRate TickRate;
		TSharedPtr<FQuartzClock> OwningClockPtr{ nullptr };

	}; // class FQuantizedTickRateChange 


	// QuartzQuantizedCommand that resets the transport of a clock's metronome on a sample-accurate boundary
	class FQuantizedTransportReset : public IQuartzQuantizedCommand
	{
	public:
		AUDIOMIXER_API virtual TSharedPtr<IQuartzQuantizedCommand> GetDeepCopyOfDerivedObject() const override;

		AUDIOMIXER_API virtual void OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo) override;

		AUDIOMIXER_API virtual void OnFinalCallbackCustom(int32 InNumFramesLeft) override;

		virtual bool IsClockAltering() override { return true; }

		AUDIOMIXER_API virtual FName GetCommandName() const override;
		virtual EQuartzCommandType GetCommandType() const { return EQuartzCommandType::TransportReset; };

	private:
		TSharedPtr<FQuartzClock> OwningClockPtr{ nullptr };

	}; // class FQuantizedTransportReset 


	// QuartzQuantizedCommand that starts a second clock on a sample-accurate boundary
	class FQuantizedOtherClockStart : public IQuartzQuantizedCommand
	{
	public:
		AUDIOMIXER_API virtual TSharedPtr<IQuartzQuantizedCommand> GetDeepCopyOfDerivedObject() const override;

		AUDIOMIXER_API virtual void OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo) override;

		AUDIOMIXER_API virtual void OnFinalCallbackCustom(int32 InNumFramesLeft) override;

		virtual bool IsClockAltering() override { return true; }

		AUDIOMIXER_API virtual FName GetCommandName() const override;
		virtual EQuartzCommandType GetCommandType() const { return EQuartzCommandType::StartOtherClock; };

	private:
		TSharedPtr<FQuartzClock> OwningClockPtr{ nullptr };
		FName NameOfClockToStart;

	}; // class FQuantizedOtherClockStart


	// QuartzQuantizedCommand that basically no-ops, so the game thread can get notified on a musical boundary
	class FQuantizedNotify : public IQuartzQuantizedCommand
	{
	public:
		// ctor
		AUDIOMIXER_API FQuantizedNotify(float InMsOffset = 0.f);

		// dtor
		virtual ~FQuantizedNotify() override = default;

		AUDIOMIXER_API virtual TSharedPtr<IQuartzQuantizedCommand> GetDeepCopyOfDerivedObject() const override;

		virtual bool RequiresAudioDevice() const override { return true; }

		AUDIOMIXER_API virtual FName GetCommandName() const override;

		virtual EQuartzCommandType GetCommandType() const override { return EQuartzCommandType::Notify; };

		AUDIOMIXER_API virtual void OnQueuedCustom(const FQuartzQuantizedCommandInitInfo& InCommandInitInfo) override;

		AUDIOMIXER_API virtual int32 OverrideFramesUntilExec(int32 NumFramesUntilExec) override;

	protected:
		TSharedPtr<FQuartzClock> OwningClockPtr{ nullptr };
		float OffsetInMs = 0.f;
		float SampleRate = 0.f;
		bool bIsCanceled = false;

	}; // class FQuantizedNotify

} // namespace Audio

=====================================


=== AudioMixerSource.cpp ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.
#include "AudioMixerSource.h"

#include "AudioDefines.h"
#include "AudioMixerSourceBuffer.h"
#include "ActiveSound.h"
#include "AudioMixerSourceBuffer.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSourceVoice.h"
#include "AudioMixerTrace.h"
#include "ContentStreaming.h"
#include "IAudioExtensionPlugin.h"
#include "IAudioModulation.h"
#include "ProfilingDebugging/CsvProfiler.h"
#include "Sound/AudioSettings.h"
#include "Sound/SoundModulationDestination.h"
#include "Misc/ScopeRWLock.h"
#include "Templates/Function.h"
#include "Trace/Trace.h"
#include "Engine/Engine.h"


CSV_DECLARE_CATEGORY_MODULE_EXTERN(AUDIOMIXERCORE_API, Audio);

#if UE_AUDIO_PROFILERTRACE_ENABLED
UE_TRACE_EVENT_BEGIN(Audio, MixerSourceStart)
	UE_TRACE_EVENT_FIELD(uint32, DeviceId)
	UE_TRACE_EVENT_FIELD(uint64, Timestamp)
	UE_TRACE_EVENT_FIELD(uint32, PlayOrder)
	UE_TRACE_EVENT_FIELD(int32, SourceId)
	UE_TRACE_EVENT_FIELD(uint64, ComponentId)
	UE_TRACE_EVENT_FIELD(UE::Trace::WideString, Name)
UE_TRACE_EVENT_END()

UE_TRACE_EVENT_BEGIN(Audio, MixerSourceStop)
	UE_TRACE_EVENT_FIELD(uint32, DeviceId)
	UE_TRACE_EVENT_FIELD(uint64, Timestamp)
	UE_TRACE_EVENT_FIELD(uint32, PlayOrder)
UE_TRACE_EVENT_END()
#endif // UE_AUDIO_PROFILERTRACE_ENABLED


static int32 UseListenerOverrideForSpreadCVar = 0;
FAutoConsoleVariableRef CVarUseListenerOverrideForSpread(
	TEXT("au.UseListenerOverrideForSpread"),
	UseListenerOverrideForSpreadCVar,
	TEXT("Zero attenuation override distance stereo panning\n")
	TEXT("0: Use actual distance, 1: use listener override"),
	ECVF_Default);

static uint32 AudioMixerSourceFadeMinCVar = 512;
static FAutoConsoleCommand GSetAudioMixerSourceFadeMin(
	TEXT("au.SourceFadeMin"),
	TEXT("Sets the length (in samples) of minimum fade when a sound source is stopped. Must be divisible by 4 (vectorization requirement). Ignored for some procedural source types. (Default: 512, Min: 4). \n"),
	FConsoleCommandWithArgsDelegate::CreateStatic(
		[](const TArray<FString>& Args)
		{
			if (Args.Num() > 0)
			{
				const int32 SourceFadeMin = FMath::Max(FCString::Atoi(*Args[0]), 4);
				AudioMixerSourceFadeMinCVar = AlignArbitrary(SourceFadeMin, 4);
			}
		}
	)
);

namespace Audio
{
	namespace MixerSourcePrivate
	{
		EMixerSourceSubmixSendStage SubmixSendStageToMixerSourceSubmixSendStage(ESubmixSendStage InSendStage)
		{
			switch(InSendStage)
			{
				case ESubmixSendStage::PreDistanceAttenuation:
					return EMixerSourceSubmixSendStage::PreDistanceAttenuation;

				case ESubmixSendStage::PostDistanceAttenuation:
				default:
					return EMixerSourceSubmixSendStage::PostDistanceAttenuation;
			}
		}

		const USoundClass* GetFallbackSoundClass(const FActiveSound& InActiveSound, const FWaveInstance& InWaveInstance)
		{
			const USoundClass* SoundClass = InActiveSound.GetSoundClass();
			if (InWaveInstance.SoundClass)
			{
				SoundClass = InWaveInstance.SoundClass;
			}

			return SoundClass;
		}
		
	} // namespace MixerSourcePrivate

	namespace ModulationUtils
	{
		void MixInRoutedValue(const FModulationParameter& InParam, float& InOutValueA, float InValueB)
		{
			if (InParam.bRequiresConversion)
			{
				InParam.NormalizedFunction(InOutValueA);
				InParam.NormalizedFunction(InValueB);
			}
			InParam.MixFunction(InOutValueA, InValueB);
			if (InParam.bRequiresConversion)
			{
				InParam.UnitFunction(InOutValueA);
			}
		}

		FSoundModulationDestinationSettings InitRoutedDestinationSettings(
			const EModulationRouting& InActiveSoundRouting,
			const FSoundModulationDestinationSettings& InActiveSoundSettings,
			const EModulationRouting& InWaveRouting,
			const FSoundModulationDestinationSettings& InWaveSettings,
			const USoundClass* InSoundClass,
			const FModulationParameter& InParam,
			TFunctionRef<const FSoundModulationDestinationSettings* (const USoundClass&)> InGetSoundClassDestinationFunction)
		{
			auto UnionSoundClassSettings = [&](FSoundModulationDestinationSettings& InOutSettings)
			{
				if (InSoundClass)
				{
					const FSoundModulationDestinationSettings& ClassSettings = *InGetSoundClassDestinationFunction(*InSoundClass);
					MixInRoutedValue(InParam, InOutSettings.Value, ClassSettings.Value);
					InOutSettings.Modulators = InOutSettings.Modulators.Union(ClassSettings.Modulators);
				}
			};

			switch (InActiveSoundRouting)
			{
				case EModulationRouting::Union:
				{
					FSoundModulationDestinationSettings UnionSettings = InActiveSoundSettings;
					switch (InWaveRouting)
					{
						case EModulationRouting::Union:
						{
							MixInRoutedValue(InParam, UnionSettings.Value, InWaveSettings.Value);
							UnionSettings.Modulators = UnionSettings.Modulators.Union(InWaveSettings.Modulators);
							UnionSoundClassSettings(UnionSettings);
							return UnionSettings;
						}
						break;

						case EModulationRouting::Inherit:
						{
							UnionSoundClassSettings(UnionSettings);
						}
						break;

						case EModulationRouting::Override:
						{
							MixInRoutedValue(InParam, UnionSettings.Value, InWaveSettings.Value);
							UnionSettings.Modulators = UnionSettings.Modulators.Union(InWaveSettings.Modulators);
						}
						break;

						case EModulationRouting::Disable:
						default:
						break;
					}

					return UnionSettings;
				}
				break;

				case EModulationRouting::Inherit:
				{
					switch (InWaveRouting)
					{
						case EModulationRouting::Union:
						{
							FSoundModulationDestinationSettings UnionSettings = InWaveSettings;
							UnionSoundClassSettings(UnionSettings);
							return UnionSettings;
						}
						break;

						case EModulationRouting::Inherit:
						{
							if (InSoundClass)
							{
								return *InGetSoundClassDestinationFunction(*InSoundClass);
							}
						}
						break;

						case EModulationRouting::Override:
						{
							return InWaveSettings;
						}
						break;

						case EModulationRouting::Disable:
						default:
						break;
					}
				}
				break;

				case EModulationRouting::Override:
				{
					return InActiveSoundSettings;
				}
				break;

				case EModulationRouting::Disable:
				default:
				break;
			}

			return { };
		}

		float GetRoutedDestinationValue(
			const EModulationRouting& InActiveSoundRouting,
			const FSoundModulationDestinationSettings& InActiveSoundSettings,
			const EModulationRouting& InWaveRouting,
			const FSoundModulationDestinationSettings& InWaveSettings,
			const USoundClass* InSoundClass,
			const FModulationParameter& InParam,
			TFunctionRef<const FSoundModulationDestinationSettings* (const USoundClass&)> InGetSoundClassDestinationFunction)
		{
			auto MixInSoundClassValue = [&](float& InOutValue)
			{
				if (InSoundClass)
				{
					const FSoundModulationDestinationSettings& ClassSettings = *InGetSoundClassDestinationFunction(*InSoundClass);
					MixInRoutedValue(InParam, InOutValue, ClassSettings.Value);
				}
			};

			switch (InActiveSoundRouting)
			{
				case EModulationRouting::Union:
				{
					float UnionValue = InActiveSoundSettings.Value;
					switch (InWaveRouting)
					{
						case EModulationRouting::Union:
						{
							MixInRoutedValue(InParam, UnionValue, InWaveSettings.Value);
							MixInSoundClassValue(UnionValue);
							return UnionValue;
						}
						break;

						case EModulationRouting::Inherit:
						{
							MixInSoundClassValue(UnionValue);
						}
						break;

						case EModulationRouting::Override:
						{
							MixInRoutedValue(InParam, UnionValue, InWaveSettings.Value);
						}
						break;

						case EModulationRouting::Disable:
						default:
						break;
					}

					return UnionValue;
				}
				break;

				case EModulationRouting::Inherit:
				{
					switch (InWaveRouting)
					{
						case EModulationRouting::Union:
						{
							float UnionValue = InWaveSettings.Value;
							MixInSoundClassValue(UnionValue);
							return UnionValue;
						}
						break;

						case EModulationRouting::Inherit:
						{
							if (InSoundClass)
							{
								return InGetSoundClassDestinationFunction(*InSoundClass)->Value;
							}
						}
						break;

						case EModulationRouting::Override:
						{
							return InWaveSettings.Value;
						}
						break;

						case EModulationRouting::Disable:
						default:
						break;
					}
				}
				break;

				case EModulationRouting::Override:
				{
					return InActiveSoundSettings.Value;
				}
				break;

				case EModulationRouting::Disable:
				default:
				break;
			}

			return 1.0f;
		}

		FSoundModulationDestinationSettings InitRoutedVolumeModulation(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, const FActiveSound& InActiveSound)
		{
			const EModulationRouting& ActiveSoundRouting = InActiveSound.ModulationRouting.VolumeRouting;
			const FSoundModulationDestinationSettings& ActiveSoundSettings = InActiveSound.ModulationRouting.VolumeModulationDestination;

			const EModulationRouting& WaveRouting = InWaveData.ModulationSettings.VolumeRouting;
			const FSoundModulationDestinationSettings& WaveSettings = InWaveData.ModulationSettings.VolumeModulationDestination;

			return InitRoutedDestinationSettings(
				ActiveSoundRouting,
				ActiveSoundSettings,
				WaveRouting,
				WaveSettings,
				MixerSourcePrivate::GetFallbackSoundClass(InActiveSound, InWaveInstance),
				Audio::GetModulationParameter("Volume"),
				[](const USoundClass& InSoundClass) { return &InSoundClass.Properties.ModulationSettings.VolumeModulationDestination; }
			);
		}

		float GetRoutedVolume(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, const FActiveSound& InActiveSound)
		{
			const EModulationRouting& ActiveSoundRouting = InActiveSound.ModulationRouting.VolumeRouting;
			const FSoundModulationDestinationSettings& ActiveSoundSettings = InActiveSound.ModulationRouting.VolumeModulationDestination;

			const EModulationRouting& WaveRouting = InWaveData.ModulationSettings.VolumeRouting;
			const FSoundModulationDestinationSettings& WaveSettings = InWaveData.ModulationSettings.VolumeModulationDestination;

			return GetRoutedDestinationValue(
				ActiveSoundRouting,
				ActiveSoundSettings,
				WaveRouting,
				WaveSettings,
				MixerSourcePrivate::GetFallbackSoundClass(InActiveSound, InWaveInstance),
				Audio::GetModulationParameter("Volume"),
				[](const USoundClass& InSoundClass) { return &InSoundClass.Properties.ModulationSettings.VolumeModulationDestination; }
			);
		}

		FSoundModulationDestinationSettings InitRoutedPitchModulation(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, const FActiveSound& InActiveSound)
		{
			const EModulationRouting& ActiveSoundRouting = InActiveSound.ModulationRouting.PitchRouting;
			const FSoundModulationDestinationSettings& ActiveSoundSettings = InActiveSound.ModulationRouting.PitchModulationDestination;

			const EModulationRouting& WaveRouting = InWaveData.ModulationSettings.PitchRouting;
			const FSoundModulationDestinationSettings& WaveSettings = InWaveData.ModulationSettings.PitchModulationDestination;

			return InitRoutedDestinationSettings(
				ActiveSoundRouting,
				ActiveSoundSettings,
				WaveRouting,
				WaveSettings,
				MixerSourcePrivate::GetFallbackSoundClass(InActiveSound, InWaveInstance),
				Audio::GetModulationParameter("Pitch"),
				[](const USoundClass& InSoundClass) { return &InSoundClass.Properties.ModulationSettings.PitchModulationDestination; }
			);
		}

		float GetRoutedPitch(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, const FActiveSound& InActiveSound)
		{
			const EModulationRouting& ActiveSoundRouting = InActiveSound.ModulationRouting.PitchRouting;
			const FSoundModulationDestinationSettings& ActiveSoundSettings = InActiveSound.ModulationRouting.PitchModulationDestination;

			const EModulationRouting& WaveRouting = InWaveData.ModulationSettings.PitchRouting;
			const FSoundModulationDestinationSettings& WaveSettings = InWaveData.ModulationSettings.PitchModulationDestination;

			return GetRoutedDestinationValue(
				ActiveSoundRouting,
				ActiveSoundSettings,
				WaveRouting,
				WaveSettings,
				MixerSourcePrivate::GetFallbackSoundClass(InActiveSound, InWaveInstance),
				Audio::GetModulationParameter("Pitch"),
				[](const USoundClass& InSoundClass) { return &InSoundClass.Properties.ModulationSettings.PitchModulationDestination; }
			);
		}

		FSoundModulationDestinationSettings InitRoutedHighpassModulation(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, const FActiveSound& InActiveSound)
		{
			const EModulationRouting& ActiveSoundRouting = InActiveSound.ModulationRouting.HighpassRouting;
			const FSoundModulationDestinationSettings& ActiveSoundSettings = InActiveSound.ModulationRouting.HighpassModulationDestination;

			const EModulationRouting& WaveRouting = InWaveData.ModulationSettings.HighpassRouting;
			const FSoundModulationDestinationSettings& WaveSettings = InWaveData.ModulationSettings.HighpassModulationDestination;

			return InitRoutedDestinationSettings(
				ActiveSoundRouting,
				ActiveSoundSettings,
				WaveRouting,
				WaveSettings,
				MixerSourcePrivate::GetFallbackSoundClass(InActiveSound, InWaveInstance),
				Audio::GetModulationParameter("HPFCutoffFrequency"),
				[](const USoundClass& InSoundClass) { return &InSoundClass.Properties.ModulationSettings.HighpassModulationDestination; }
			);
		}

		float GetRoutedHighpass(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, const FActiveSound& InActiveSound)
		{
			const EModulationRouting& ActiveSoundRouting = InActiveSound.ModulationRouting.HighpassRouting;
			const FSoundModulationDestinationSettings& ActiveSoundSettings = InActiveSound.ModulationRouting.HighpassModulationDestination;

			const EModulationRouting& WaveRouting = InWaveData.ModulationSettings.HighpassRouting;
			const FSoundModulationDestinationSettings& WaveSettings = InWaveData.ModulationSettings.HighpassModulationDestination;

			return GetRoutedDestinationValue(
				ActiveSoundRouting,
				ActiveSoundSettings,
				WaveRouting,
				WaveSettings,
				MixerSourcePrivate::GetFallbackSoundClass(InActiveSound, InWaveInstance),
				Audio::GetModulationParameter("HPFCutoffFrequency"),
				[](const USoundClass& InSoundClass) { return &InSoundClass.Properties.ModulationSettings.HighpassModulationDestination; }
			);
		}

		FSoundModulationDestinationSettings InitRoutedLowpassModulation(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, const FActiveSound& InActiveSound)
		{
			const EModulationRouting& ActiveSoundRouting = InActiveSound.ModulationRouting.LowpassRouting;
			const FSoundModulationDestinationSettings& ActiveSoundSettings = InActiveSound.ModulationRouting.LowpassModulationDestination;

			const EModulationRouting& WaveRouting = InWaveData.ModulationSettings.LowpassRouting;
			const FSoundModulationDestinationSettings& WaveSettings = InWaveData.ModulationSettings.LowpassModulationDestination;

			return InitRoutedDestinationSettings(
				ActiveSoundRouting,
				ActiveSoundSettings,
				WaveRouting,
				WaveSettings,
				MixerSourcePrivate::GetFallbackSoundClass(InActiveSound, InWaveInstance),
				Audio::GetModulationParameter("LPFCutoffFrequency"),
				[](const USoundClass& InSoundClass) { return &InSoundClass.Properties.ModulationSettings.LowpassModulationDestination; }
			);
		}

		float GetRoutedLowpass(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, const FActiveSound& InActiveSound)
		{
			const EModulationRouting& ActiveSoundRouting = InActiveSound.ModulationRouting.LowpassRouting;
			const FSoundModulationDestinationSettings& ActiveSoundSettings = InActiveSound.ModulationRouting.LowpassModulationDestination;

			const EModulationRouting& WaveRouting = InWaveData.ModulationSettings.LowpassRouting;
			const FSoundModulationDestinationSettings& WaveSettings = InWaveData.ModulationSettings.LowpassModulationDestination;

			return GetRoutedDestinationValue(
				ActiveSoundRouting,
				ActiveSoundSettings,
				WaveRouting,
				WaveSettings,
				MixerSourcePrivate::GetFallbackSoundClass(InActiveSound, InWaveInstance),
				Audio::GetModulationParameter("LPFCutoffFrequency"),
				[](const USoundClass& InSoundClass) { return &InSoundClass.Properties.ModulationSettings.LowpassModulationDestination; }
			);
		}

		FSoundModulationDefaultSettings InitRoutedModulation(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, FActiveSound* InActiveSound)
		{
			FSoundModulationDefaultSettings Settings;
			if (InActiveSound)
			{
				Settings.VolumeModulationDestination = InitRoutedVolumeModulation(InWaveInstance, InWaveData, *InActiveSound);
				Settings.PitchModulationDestination = InitRoutedPitchModulation(InWaveInstance, InWaveData, *InActiveSound);
				Settings.HighpassModulationDestination = InitRoutedHighpassModulation(InWaveInstance, InWaveData, *InActiveSound);
				Settings.LowpassModulationDestination = InitRoutedLowpassModulation(InWaveInstance, InWaveData, *InActiveSound);
			}

			return Settings;
		}

		FSoundModulationDefaultRoutingSettings UpdateRoutedModulation(const FWaveInstance& InWaveInstance, const USoundWave& InWaveData, FActiveSound* InActiveSound)
		{
			FSoundModulationDefaultRoutingSettings NewRouting;

			if (InActiveSound)
			{
				NewRouting.VolumeModulationDestination = InitRoutedVolumeModulation(InWaveInstance, InWaveData, *InActiveSound);
				NewRouting.PitchModulationDestination = InitRoutedPitchModulation(InWaveInstance, InWaveData, *InActiveSound);
				NewRouting.HighpassModulationDestination = InitRoutedHighpassModulation(InWaveInstance, InWaveData, *InActiveSound);
				NewRouting.LowpassModulationDestination = InitRoutedLowpassModulation(InWaveInstance, InWaveData, *InActiveSound);
			}

			return NewRouting;
		}

	} // namespace ModulationUtils

	FMixerSource::FMixerSource(FAudioDevice* InAudioDevice)
		: FSoundSource(InAudioDevice)
		, MixerDevice(static_cast<FMixerDevice*>(InAudioDevice))
		, MixerBuffer(nullptr)
		, MixerSourceVoice(nullptr)
		, bBypassingSubmixModulation(false)
		, bPreviousBusEnablement(false)
		, bPreviousBaseSubmixEnablement(false)
		, PreviousAzimuth(-1.0f)
		, PreviousPlaybackPercent(0.0f)
		, InitializationState(EMixerSourceInitializationState::NotInitialized)
		, bPlayedCachedBuffer(false)
		, bPlaying(false)
		, bLoopCallback(false)
		, bIsDone(false)
		, bIsEffectTailsDone(false)
		, bIsPlayingEffectTails(false)
		, bEditorWarnedChangedSpatialization(false)
		, bIs3D(false)
		, bDebugMode(false)
		, bIsVorbis(false)
		, bIsStoppingVoicesEnabled(InAudioDevice->IsStoppingVoicesEnabled())
		, bSendingAudioToBuses(false)
		, bPrevAllowedSpatializationSetting(false)		
	{
	}

	FMixerSource::~FMixerSource()
	{
		FreeResources();
	}

	bool FMixerSource::Init(FWaveInstance* InWaveInstance)
	{
		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(AudioMixerSource::Init);
		AUDIO_MIXER_CHECK(MixerBuffer);
		AUDIO_MIXER_CHECK(MixerBuffer->IsRealTimeSourceReady());

		// We've already been passed the wave instance in PrepareForInitialization, make sure we have the same one
		AUDIO_MIXER_CHECK(WaveInstance && WaveInstance == InWaveInstance);
		AUDIO_MIXER_CHECK(WaveInstance->WaveData);
		LLM_SCOPE(ELLMTag::AudioMixer);
		
		FSoundSource::InitCommon();

		NumChannels = WaveInstance->WaveData->NumChannels;
		if (!ensure(InWaveInstance))
		{
			return false;
		}

		USoundWave* WaveData = WaveInstance->WaveData;
		check(WaveData);

		if (WaveData->NumChannels == 0)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Soundwave %s has invalid compressed data."), *(WaveData->GetName()));
			FreeResources();
			return false;
		}

		// Get the number of frames before creating the buffer
		int32 NumFrames = INDEX_NONE;
		if (WaveData->DecompressionType != DTYPE_Procedural)
		{
			check(!WaveData->RawPCMData || WaveData->RawPCMDataSize);
			const int32 NumBytes = WaveData->RawPCMDataSize;
			if (NumChannels > 0)
			{
				NumFrames = NumBytes / (WaveData->NumChannels * sizeof(int16));
			}
		}

		// Reset all 'previous' state.
		PreviousSubmixResolved.Reset();
		bPreviousBusEnablement = false;
		bPreviousBaseSubmixEnablement = false;
		PreviousAzimuth = -1.f;
		PreviousPlaybackPercent = 0.f;
		PreviousSubmixSends.Reset();

		// Unfortunately, we need to know if this is a vorbis source since channel maps are different for 5.1 vorbis files
		bIsVorbis = WaveData->bDecompressedFromOgg;

		bIsStoppingVoicesEnabled = AudioDevice->IsStoppingVoicesEnabled();

		bIsStopping = false;
		bIsEffectTailsDone = true;
		bIsDone = false;

		bBypassingSubmixModulation = false;

		FSoundBuffer* SoundBuffer = static_cast<FSoundBuffer*>(MixerBuffer);
		if (SoundBuffer->NumChannels > 0)
		{
			CSV_SCOPED_TIMING_STAT(Audio, InitSources);
			SCOPE_CYCLE_COUNTER(STAT_AudioSourceInitTime);

			AUDIO_MIXER_CHECK(MixerDevice);
			MixerSourceVoice = MixerDevice->GetMixerSourceVoice();
			if (!MixerSourceVoice)
			{
				FreeResources();
				UE_LOG(LogAudioMixer, Warning, TEXT("Failed to get a mixer source voice for sound %s."), *InWaveInstance->GetName());
				return false;
			}

			// Initialize the source voice with the necessary format information
			FMixerSourceVoiceInitParams InitParams;
			InitParams.SourceListener = this;
			InitParams.NumInputChannels = WaveData->NumChannels;
			InitParams.NumInputFrames = NumFrames;
			InitParams.SourceVoice = MixerSourceVoice;
			InitParams.bUseHRTFSpatialization = UseObjectBasedSpatialization();

			// in this file once spat override is implemented
			InitParams.bIsExternalSend = MixerDevice->GetCurrentSpatializationPluginInterfaceInfo().bSpatializationIsExternalSend;
			InitParams.bIsSoundfield = WaveInstance->bIsAmbisonics && (WaveData->NumChannels == 4);

			FActiveSound* ActiveSound = WaveInstance->ActiveSound;
			InitParams.ModulationSettings = ModulationUtils::InitRoutedModulation(*WaveInstance, *WaveData, ActiveSound);

			// Copy quantization request data
			if (WaveInstance->QuantizedRequestData)
			{
				InitParams.QuantizedRequestData = *WaveInstance->QuantizedRequestData;
			}

			if (WaveInstance->bIsAmbisonics && (WaveData->NumChannels != 4))
			{
				UE_LOG(LogAudioMixer, Warning, TEXT("Sound wave %s was flagged as being ambisonics but had a channel count of %d. Currently the audio engine only supports FOA sources that have four channels."), *InWaveInstance->GetName(), WaveData->NumChannels);
			}
			if (ActiveSound)
			{
				InitParams.AudioComponentUserID = WaveInstance->ActiveSound->GetAudioComponentUserID();
#if AUDIO_MIXER_ENABLE_DEBUG_MODE
				if (InitParams.AudioComponentUserID.IsNone())
				{
					InitParams.AudioComponentUserID = ActiveSound->GetSound()->GetFName();

				}
#endif // AUDIO_MIXER_ENABLE_DEBUG_MODE
				InitParams.AudioComponentID = WaveInstance->ActiveSound->GetAudioComponentID();
			}

			InitParams.EnvelopeFollowerAttackTime = WaveInstance->EnvelopeFollowerAttackTime;
			InitParams.EnvelopeFollowerReleaseTime = WaveInstance->EnvelopeFollowerReleaseTime;

			InitParams.SourceEffectChainId = 0;

			InitParams.SourceBufferListener = WaveInstance->SourceBufferListener;
			InitParams.bShouldSourceBufferListenerZeroBuffer = WaveInstance->bShouldSourceBufferListenerZeroBuffer;

			if (WaveInstance->bShouldUseAudioLink)
			{
				if (IAudioLinkFactory* LinkFactory = MixerDevice->GetAudioLinkFactory())
				{				
					IAudioLinkFactory::FAudioLinkSourcePushedCreateArgs CreateArgs;					
					if (WaveInstance->AudioLinkSettingsOverride)
					{
						CreateArgs.Settings = WaveInstance->AudioLinkSettingsOverride->GetProxy();
					}
					else
					{
						CreateArgs.Settings = GetDefault<UAudioLinkSettingsAbstract>(LinkFactory->GetSettingsClass())->GetProxy();
					}
					
					CreateArgs.OwnerName = *WaveInstance->GetName();			// <-- FIXME: String FName conversion.
					CreateArgs.NumChannels = SoundBuffer->NumChannels;
					CreateArgs.NumFramesPerBuffer = MixerDevice->GetBufferLength();
					CreateArgs.SampleRate = MixerDevice->GetSampleRate();
					CreateArgs.TotalNumFramesInSource = NumTotalFrames;
					AudioLink = LinkFactory->CreateSourcePushedAudioLink(CreateArgs);
					InitParams.AudioLink = AudioLink;
				}
			}

			// Source manager needs to know if this is a vorbis source for rebuilding speaker maps
			InitParams.bIsVorbis = bIsVorbis;

			// Support stereo by default
			// Check the min number of channels the source effect chain supports
			// We don't want to instantiate the effect chain if it has an effect that doesn't support its channel count
			// E.g. we shouldn't instantiate a chain on a quad source if there is an effect that only supports stereo
			InitParams.SourceEffectChainMaxSupportedChannels = WaveInstance->SourceEffectChain ? 
				WaveInstance->SourceEffectChain->GetSupportedChannelCount() :
				USoundEffectSourcePreset::DefaultSupportedChannels;

			if (InitParams.NumInputChannels <= InitParams.SourceEffectChainMaxSupportedChannels)
			{
				if (WaveInstance->SourceEffectChain)
				{
					InitParams.SourceEffectChainId = WaveInstance->SourceEffectChain->GetUniqueID();

					for (int32 i = 0; i < WaveInstance->SourceEffectChain->Chain.Num(); ++i)
					{
						InitParams.SourceEffectChain.Add(WaveInstance->SourceEffectChain->Chain[i]);
						InitParams.bPlayEffectChainTails = WaveInstance->SourceEffectChain->bPlayEffectChainTails;
					}
				}

				// Only need to care about effect chain tails finishing if we're told to play them
				if (InitParams.bPlayEffectChainTails)
				{
					bIsEffectTailsDone = false;
				}

				// Setup the bus Id if this source is a bus
				if (WaveData->bIsSourceBus)
				{
					// We need to check if the source bus has an audio bus specified
					USoundSourceBus* SoundSourceBus = CastChecked<USoundSourceBus>(WaveData);

					// If it does, we will use that audio bus as the source of the audio data for the source bus
					if (SoundSourceBus->AudioBus)
					{
						InitParams.AudioBusId = SoundSourceBus->AudioBus->GetUniqueID();
						InitParams.AudioBusChannels = (int32)SoundSourceBus->AudioBus->GetNumChannels();
					}
					else
					{
						InitParams.AudioBusId = WaveData->GetUniqueID();
						InitParams.AudioBusChannels = WaveData->NumChannels;
					}

					if (!WaveData->IsLooping())
					{
						InitParams.SourceBusDuration = WaveData->GetDuration();
					}
				}
			}

			// Toggle muting the source if sending only to output bus.
			// This can get set even if the source doesn't have bus sends since bus sends can be dynamically enabled.
			InitParams.bEnableBusSends = WaveInstance->bEnableBusSends;
			InitParams.bEnableBaseSubmix = WaveInstance->bEnableBaseSubmix;
			InitParams.bEnableSubmixSends = WaveInstance->bEnableSubmixSends;
			InitParams.PlayOrder = WaveInstance->GetPlayOrder();
			bPreviousBusEnablement = WaveInstance->bEnableBusSends;
			DynamicBusSendInfos.Reset();

			SetupBusData(InitParams.AudioBusSends, InitParams.bEnableBusSends);

			// Don't set up any submixing if we're set to output to bus only
	
			// If we're spatializing using HRTF and its an external send, don't need to setup a default/base submix send to master or EQ submix
			// We'll only be using non-default submix sends (e.g. reverb).
			if (!(InitParams.bUseHRTFSpatialization && InitParams.bIsExternalSend))
			{
				FMixerSubmixWeakPtr SubmixPtr;
				// If a sound specifies a base submix manually, always use that
				if (WaveInstance->SoundSubmix)
				{
					SubmixPtr = MixerDevice->GetSubmixInstance(WaveInstance->SoundSubmix);
				}
				else
				{
					// Retrieve the base default submix if one is not explicitly set
					SubmixPtr = MixerDevice->GetBaseDefaultSubmix();
				}

				FMixerSourceSubmixSend SubmixSend;
				SubmixSend.Submix = SubmixPtr;
				SubmixSend.SubmixSendStage = EMixerSourceSubmixSendStage::PostDistanceAttenuation;
				SubmixSend.SendLevel = InitParams.bEnableBaseSubmix;
				SubmixSend.bIsMainSend = true;
				SubmixSend.SoundfieldFactory = MixerDevice->GetFactoryForSubmixInstance(SubmixSend.Submix);
				InitParams.SubmixSends.Add(SubmixSend);
				bPreviousBaseSubmixEnablement = InitParams.bEnableBaseSubmix;
			}
			else
			{
				// Warn about sending a source marked as Binaural directly to a soundfield submix:
				// This is a bit of a gray area as soundfield submixes are intended to be their own spatial format
				// So to send a source to this, and also flagging the source as Binaural are probably conflicting forms of spatialazition.
				FMixerSubmixWeakPtr SubmixWeakPtr = MixerDevice->GetSubmixInstance(WaveInstance->SoundSubmix);

				if (FMixerSubmixPtr SubmixPtr = SubmixWeakPtr.Pin())
				{
					if ((SubmixPtr->IsSoundfieldSubmix() || SubmixPtr->IsSoundfieldEndpointSubmix()))
					{
						UE_LOG(LogAudioMixer, Warning, TEXT("Ignoring soundfield Base Submix destination being set on SoundWave (%s) because spatialization method is set to Binaural.")
							, *InWaveInstance->GetName());
					}
					
					bBypassingSubmixModulation = true;
				}
			}

			// Add submix sends for this source
			for (FSoundSubmixSendInfo& SendInfo : WaveInstance->SoundSubmixSends)
			{
				if (SendInfo.SoundSubmix != nullptr)
				{
					FMixerSourceSubmixSend SubmixSend;
					SubmixSend.Submix = MixerDevice->GetSubmixInstance(SendInfo.SoundSubmix);

					SubmixSend.SubmixSendStage = EMixerSourceSubmixSendStage::PostDistanceAttenuation;
					if (SendInfo.SendStage == ESubmixSendStage::PreDistanceAttenuation)
					{
						SubmixSend.SubmixSendStage = EMixerSourceSubmixSendStage::PreDistanceAttenuation;
					}
					if (!WaveInstance->bEnableSubmixSends)
					{
						SubmixSend.SendLevel = 0.0f;
					}
					else
					{
						SubmixSend.SendLevel = SendInfo.SendLevel;
					}
					
					SubmixSend.bIsMainSend = false;
					SubmixSend.SoundfieldFactory = MixerDevice->GetFactoryForSubmixInstance(SubmixSend.Submix);
					InitParams.SubmixSends.Add(SubmixSend);
				}
			}

			// Loop through all submix sends to figure out what speaker maps this source is using
			for (FMixerSourceSubmixSend& Send : InitParams.SubmixSends)
			{
				FMixerSubmixPtr SubmixPtr = Send.Submix.Pin();
				if (SubmixPtr.IsValid())
				{
					FRWScopeLock Lock(ChannelMapLock, SLT_Write);
					ChannelMap.Reset();
				}
			}

			// Check to see if this sound has been flagged to be in debug mode
#if AUDIO_MIXER_ENABLE_DEBUG_MODE
			InitParams.DebugName = WaveInstance->GetName();

			bool bIsDebug = false;
			FString WaveInstanceName = WaveInstance->GetName(); //-V595
			FString TestName = GEngine->GetAudioDeviceManager()->GetDebugger().GetAudioMixerDebugSoundName();
			if (!TestName.IsEmpty() && WaveInstanceName.Contains(TestName))
			{
				bDebugMode = true;
				InitParams.bIsDebugMode = bDebugMode;
			}
#endif

			// Whether or not we're 3D
			bIs3D = !UseObjectBasedSpatialization() && WaveInstance->GetUseSpatialization() && SoundBuffer->NumChannels < 3;

			// Pass on the fact that we're 3D to the init params
			InitParams.bIs3D = bIs3D;

			// Grab the source's reverb plugin settings
			InitParams.SpatializationPluginSettings = UseSpatializationPlugin() ? WaveInstance->SpatializationPluginSettings : nullptr;

			// Grab the source's occlusion plugin settings
			InitParams.OcclusionPluginSettings = UseOcclusionPlugin() ? WaveInstance->OcclusionPluginSettings : nullptr;

			// Grab the source's reverb plugin settings
			InitParams.ReverbPluginSettings = UseReverbPlugin() ? WaveInstance->ReverbPluginSettings : nullptr;

			// Grab the source's source data override plugin settings
			InitParams.SourceDataOverridePluginSettings = UseSourceDataOverridePlugin() ? WaveInstance->SourceDataOverridePluginSettings : nullptr;

			// Update the buffer sample rate to the wave instance sample rate in case it was serialized incorrectly
			MixerBuffer->InitSampleRate(WaveData->GetSampleRateForCurrentPlatform());

			// Retrieve the raw pcm buffer data and the precached buffers before initializing so we can avoid having USoundWave ptrs in audio renderer thread
			EBufferType::Type BufferType = MixerBuffer->GetType();
			if (BufferType == EBufferType::PCM || BufferType == EBufferType::PCMPreview)
			{
				FRawPCMDataBuffer RawPCMDataBuffer;
				MixerBuffer->GetPCMData(&RawPCMDataBuffer.Data, &RawPCMDataBuffer.DataSize);
				MixerSourceBuffer->SetPCMData(RawPCMDataBuffer);
			}
#if PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS > 0
			else if (BufferType == EBufferType::PCMRealTime || BufferType == EBufferType::Streaming)
			{
				if (WaveData->CachedRealtimeFirstBuffer)
				{
					const uint32 NumPrecacheSamples = (uint32)(WaveData->NumPrecacheFrames * WaveData->NumChannels);
					const uint32 BufferSize = NumPrecacheSamples * sizeof(int16) * PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS;

					TArray<uint8> PrecacheBufferCopy;
					PrecacheBufferCopy.AddUninitialized(BufferSize);

					FMemory::Memcpy(PrecacheBufferCopy.GetData(), WaveData->CachedRealtimeFirstBuffer, BufferSize);

					MixerSourceBuffer->SetCachedRealtimeFirstBuffers(MoveTemp(PrecacheBufferCopy));
				}
			}
#endif

			// Pass the decompression state off to the mixer source buffer if it hasn't already done so
			ICompressedAudioInfo* Decoder = MixerBuffer->GetDecompressionState(true);
			MixerSourceBuffer->SetDecoder(Decoder);

			// Hand off the mixer source buffer decoder
			InitParams.MixerSourceBuffer = MixerSourceBuffer;
			MixerSourceBuffer = nullptr;

			if (MixerSourceVoice->Init(InitParams))
			{
				// Initialize the propagation interface as soon as we have a valid source id
				if (AudioDevice->SourceDataOverridePluginInterface)
				{
					uint32 SourceId = MixerSourceVoice->GetSourceId();
					AudioDevice->SourceDataOverridePluginInterface->OnInitSource(SourceId, InitParams.AudioComponentUserID, InitParams.SourceDataOverridePluginSettings);
				}

				InitializationState = EMixerSourceInitializationState::Initialized;

				Update();

				return true;
			}
			else
			{
				InitializationState = EMixerSourceInitializationState::NotInitialized;
				UE_LOG(LogAudioMixer, Warning, TEXT("Failed to initialize mixer source voice '%s'."), *InWaveInstance->GetName());
			}
		}
		else
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Num channels was 0 for sound buffer '%s'."), *InWaveInstance->GetName());
		}

		FreeResources();
		return false;
	}

	void FMixerSource::SetupBusData(TArray<FInitAudioBusSend>* OutAudioBusSends, bool bEnableBusSends)
	{
		for (int32 BusSendType = 0; BusSendType < (int32)EBusSendType::Count; ++BusSendType)
		{
			// And add all the source bus sends
			for (FSoundSourceBusSendInfo& SendInfo : WaveInstance->BusSends[BusSendType])
			{
				// Avoid redoing duplicate code for sending audio to source bus or audio bus. Most of it is the same other than the bus id.
				auto SetupBusSend = [this](TArray<FInitAudioBusSend>* AudioBusSends, const FSoundSourceBusSendInfo& InSendInfo, int32 InBusSendType, uint32 InBusId, bool bEnableBusSends, int32 InBusChannels)
				{
					FInitAudioBusSend BusSend;
					BusSend.AudioBusId = InBusId;
					BusSend.BusChannels = InBusChannels;
					
					if(bEnableBusSends)
					{
						BusSend.SendLevel = InSendInfo.SendLevel;
					}
					else
					{
						BusSend.SendLevel = 0;
					}
					
					if (AudioBusSends)
					{
						AudioBusSends[InBusSendType].Add(BusSend);
					}

					FDynamicBusSendInfo NewDynamicBusSendInfo;
					NewDynamicBusSendInfo.SendLevel = InSendInfo.SendLevel;
					NewDynamicBusSendInfo.BusId = BusSend.AudioBusId;
					NewDynamicBusSendInfo.BusSendLevelControlMethod = InSendInfo.SourceBusSendLevelControlMethod;
					NewDynamicBusSendInfo.BusSendType = (EBusSendType)InBusSendType;
					NewDynamicBusSendInfo.MinSendLevel = InSendInfo.MinSendLevel;
					NewDynamicBusSendInfo.MaxSendLevel = InSendInfo.MaxSendLevel;
					NewDynamicBusSendInfo.MinSendDistance = InSendInfo.MinSendDistance;
					NewDynamicBusSendInfo.MaxSendDistance = InSendInfo.MaxSendDistance;
					NewDynamicBusSendInfo.CustomSendLevelCurve = InSendInfo.CustomSendLevelCurve;

					// Copy the bus SourceBusSendInfo structs to a local copy so we can update it in the update tick
					bool bIsNew = true;
					for (FDynamicBusSendInfo& BusSendInfo : DynamicBusSendInfos)
					{
						if (BusSendInfo.BusId == NewDynamicBusSendInfo.BusId)
						{
							BusSendInfo = NewDynamicBusSendInfo;
							BusSendInfo.bIsInit = false;
							bIsNew = false;
							break;
						}
					}

					if (bIsNew)
					{
						DynamicBusSendInfos.Add(NewDynamicBusSendInfo);
					}

					// Flag that we're sending audio to buses so we can check for updates to send levels
					bSendingAudioToBuses = true;
				};

				// Retrieve bus id of the audio bus to use
				if (SendInfo.SoundSourceBus)
				{						
					uint32 BusId;
					int32 BusChannels;

					// Either use the bus id of the source bus's audio bus id if it was specified
					if (SendInfo.SoundSourceBus->AudioBus)
					{
						BusId = SendInfo.SoundSourceBus->AudioBus->GetUniqueID();
						BusChannels = (int32)SendInfo.SoundSourceBus->AudioBus->GetNumChannels();
					}
					else
					{
						// otherwise, use the id of the source bus itself (for an automatic source bus)
						BusId = SendInfo.SoundSourceBus->GetUniqueID();
						BusChannels = SendInfo.SoundSourceBus->NumChannels;
					}

					// Call lambda w/ the correctly derived bus id
					SetupBusSend(OutAudioBusSends, SendInfo, BusSendType, BusId, bEnableBusSends, BusChannels);
				}

				if (SendInfo.AudioBus)
				{
					// Only need to send audio to just the specified audio bus
					uint32 BusId = SendInfo.AudioBus->GetUniqueID();
					int32 BusChannels = (int32)SendInfo.AudioBus->AudioBusChannels + 1;

					// Note we will be sending audio to both the specified source bus and the audio bus with the same send level
					SetupBusSend(OutAudioBusSends, SendInfo, BusSendType, BusId, bEnableBusSends, BusChannels);
				}
			}
		}
	}

	void FMixerSource::Update()
	{
		CSV_SCOPED_TIMING_STAT(Audio, UpdateSources);
		SCOPE_CYCLE_COUNTER(STAT_AudioUpdateSources);

		LLM_SCOPE(ELLMTag::AudioMixer);

		if (!WaveInstance || !MixerSourceVoice || Paused || InitializationState == EMixerSourceInitializationState::NotInitialized)
		{
			return;
		}

		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(FMixerSource::Update);

		// if MarkAsGarbage() was called, WaveInstance->WaveData is null
		if (!WaveInstance->WaveData)
		{
			StopNow();
			return;
		}

		++TickCount;

		// Allow plugins to override any data in a waveinstance
		if (AudioDevice->SourceDataOverridePluginInterface && WaveInstance->bEnableSourceDataOverride)
		{
			uint32 SourceId = MixerSourceVoice->GetSourceId();
			int32 ListenerIndex = WaveInstance->ActiveSound->GetClosestListenerIndex();

			FTransform ListenerTransform;
			AudioDevice->GetListenerTransform(ListenerIndex, ListenerTransform);

			AudioDevice->SourceDataOverridePluginInterface->GetSourceDataOverrides(SourceId, ListenerTransform, WaveInstance);
		}

		// AudioLink, push state if we're enabled and 3d.
		if (bIs3D && AudioLink.IsValid())
		{
			IAudioLinkSourcePushed::FOnUpdateWorldStateParams Params;
			Params.WorldTransform = WaveInstance->ActiveSound->Transform;
			AudioLink->OnUpdateWorldState(Params);
		}

		UpdateModulation();

		UpdatePitch();

		UpdateVolume();

		UpdateSpatialization();

		UpdateEffects();

		UpdateSourceBusSends();

		UpdateChannelMaps();

		UpdateRelativeRenderCost();

#if ENABLE_AUDIO_DEBUG
		UpdateCPUCoreUtilization();

		Audio::FAudioDebugger::DrawDebugInfo(*this);
#endif // ENABLE_AUDIO_DEBUG
	}

	bool FMixerSource::PrepareForInitialization(FWaveInstance* InWaveInstance)
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		if (!ensure(InWaveInstance))
		{
			return false;
		}

		// We are currently not supporting playing audio on a controller
		if (InWaveInstance->OutputTarget == EAudioOutputTarget::Controller)
		{
			return false;
		}

		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(AudioMixerSource::PrepareForInitialization);

		// We are not initialized yet. We won't be until the sound file finishes loading and parsing the header.
		InitializationState = EMixerSourceInitializationState::Initializing;

		//  Reset so next instance will warn if algorithm changes in-flight
		bEditorWarnedChangedSpatialization = false;

		const bool bIsSeeking = InWaveInstance->StartTime > 0.0f;

		check(InWaveInstance);
		check(AudioDevice);

		check(!MixerBuffer);
		MixerBuffer = FMixerBuffer::Init(AudioDevice, InWaveInstance->WaveData, bIsSeeking /* bForceRealtime */);

		if (!MixerBuffer)
		{
			FreeResources(); // APM: maybe need to call this here too? 
			return false;
		}

		// WaveData must be valid beyond this point, otherwise MixerBuffer
		// would have failed to init.
		check(InWaveInstance->WaveData);
		USoundWave& SoundWave = *InWaveInstance->WaveData;

		WaveInstance = InWaveInstance;

		LPFFrequency = MAX_FILTER_FREQUENCY;
		LastLPFFrequency = FLT_MAX;

		HPFFrequency = 0.0f;
		LastHPFFrequency = FLT_MAX;

		bIsDone = false;

		// Not all wave data types have a non-zero duration
		if (SoundWave.Duration > 0.0f)
		{
			if (!SoundWave.bIsSourceBus)
			{
				NumTotalFrames = SoundWave.Duration * SoundWave.GetSampleRateForCurrentPlatform();
				check(NumTotalFrames > 0);
			}
			else if (!SoundWave.IsLooping())
			{
				NumTotalFrames = SoundWave.Duration * AudioDevice->GetSampleRate();
				check(NumTotalFrames > 0);
			}

			StartFrame = FMath::Clamp<int32>((InWaveInstance->StartTime / SoundWave.Duration) * NumTotalFrames, 0, NumTotalFrames);
		}

		check(!MixerSourceBuffer.IsValid());

		// Active sound instance ID is the audio component ID of active sound.
		uint64 InstanceID = 0;
		uint32 PlayOrder = 0;
		bool bActiveSoundIsPreviewSound = false;
		TArray<FAudioParameter> DefaultParameters;
		FActiveSound* ActiveSound = WaveInstance->ActiveSound;
		if (ActiveSound)
		{
			InstanceID = ActiveSound->GetAudioComponentID();
			PlayOrder = ActiveSound->GetPlayOrder();
			bActiveSoundIsPreviewSound = ActiveSound->bIsPreviewSound;
			if (Audio::IParameterTransmitter* Transmitter = ActiveSound->GetTransmitter())
			{
				DefaultParameters = Transmitter->GetParameters();
				SoundWave.InitParameters(DefaultParameters);
			}
		}

		FMixerSourceBufferInitArgs BufferInitArgs;
		BufferInitArgs.AudioDeviceID = AudioDevice->DeviceID;
		BufferInitArgs.AudioComponentID = InstanceID;
		BufferInitArgs.InstanceID = GetTransmitterID(InstanceID, WaveInstance->WaveInstanceHash, PlayOrder);
		BufferInitArgs.SampleRate = AudioDevice->GetSampleRate();
		BufferInitArgs.AudioMixerNumOutputFrames = MixerDevice->GetNumOutputFrames();
		BufferInitArgs.Buffer = MixerBuffer;
		BufferInitArgs.SoundWave = &SoundWave;
		BufferInitArgs.LoopingMode = InWaveInstance->LoopingMode;
		BufferInitArgs.bIsSeeking = bIsSeeking;
		BufferInitArgs.bIsPreviewSound = bActiveSoundIsPreviewSound;
		BufferInitArgs.StartTime = InWaveInstance->StartTime;

		MixerSourceBuffer = FMixerSourceBuffer::Create(BufferInitArgs, MoveTemp(DefaultParameters));
		
		if (!MixerSourceBuffer.IsValid())
		{
			FreeResources();

			// Guarantee that this wave instance does not try to replay by disabling looping.
			WaveInstance->LoopingMode = LOOP_Never;

			if (ensure(ActiveSound))
			{
				ActiveSound->bShouldRemainActiveIfDropped = false;
			}
		}
		
		return MixerSourceBuffer.IsValid();
	}

	bool FMixerSource::IsPreparedToInit()
	{
		LLM_SCOPE(ELLMTag::AudioMixer);
		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(AudioMixerSource::IsPreparedToInit);

		if (MixerBuffer && MixerBuffer->IsRealTimeSourceReady())
		{
			check(MixerSourceBuffer.IsValid());

			// Check if we have a realtime audio task already (doing first decode)
			if (MixerSourceBuffer->IsAsyncTaskInProgress())
			{
				// not ready
				return MixerSourceBuffer->IsAsyncTaskDone();
			}
			else if (WaveInstance)
			{
				if (WaveInstance->WaveData->bIsSourceBus)
				{
					// Buses don't need to do anything to play audio
					return true;
				}
				else
				{
					// Now check to see if we need to kick off a decode the first chunk of audio
					const EBufferType::Type BufferType = MixerBuffer->GetType();
					if ((BufferType == EBufferType::PCMRealTime || BufferType == EBufferType::Streaming) && WaveInstance->WaveData)
					{
						// If any of these conditions meet, we need to do an initial async decode before we're ready to start playing the sound
						if (WaveInstance->StartTime > 0.0f || WaveInstance->WaveData->bProcedural || WaveInstance->WaveData->bIsSourceBus || !WaveInstance->WaveData->CachedRealtimeFirstBuffer)
						{
							// Before reading more PCMRT data, we first need to seek the buffer
							if (WaveInstance->IsSeekable())
							{
								MixerBuffer->Seek(WaveInstance->StartTime);
							}

							check(MixerSourceBuffer.IsValid());

							ICompressedAudioInfo* Decoder = MixerBuffer->GetDecompressionState(false);
							MixerSourceBuffer->ReadMoreRealtimeData(Decoder, 0, EBufferReadMode::Asynchronous);

							// not ready
							return false;
						}
					}
				}
			}

			return true;
		}

		return false;
	}

	bool FMixerSource::IsInitialized() const
	{
		return InitializationState == EMixerSourceInitializationState::Initialized;
	}

	void FMixerSource::Play()
	{
		if (!WaveInstance)
		{
			return;
		}

		// Don't restart the sound if it was stopping when we paused, just stop it.
		if (Paused && (bIsStopping || bIsDone))
		{
			StopNow();
			return;
		}

		if (bIsStopping)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Restarting a source which was stopping. Stopping now."));
			return;
		}

		AUDIO_MIXER_TRACE_CPUPROFILER_EVENT_SCOPE(AudioMixerSource::Play);

		// It's possible if Pause and Play are called while a sound is async initializing. In this case
		// we'll just not actually play the source here. Instead we'll call play when the sound finishes loading.
		if (MixerSourceVoice && InitializationState == EMixerSourceInitializationState::Initialized)
		{
			MixerSourceVoice->Play();

#if UE_AUDIO_PROFILERTRACE_ENABLED
			const bool bChannelEnabled = UE_TRACE_CHANNELEXPR_IS_ENABLED(AudioMixerChannel);
			if (bChannelEnabled && WaveInstance)
			{
				if (const FActiveSound* ActiveSound = WaveInstance->ActiveSound)
				{
					int32 TraceSourceId = INDEX_NONE;
					if (MixerSourceVoice)
					{
						TraceSourceId = MixerSourceVoice->GetSourceId();
					}

					UE_TRACE_LOG(Audio, MixerSourceStart, AudioMixerChannel)
						<< MixerSourceStart.DeviceId(MixerDevice->DeviceID)
						<< MixerSourceStart.Timestamp(FPlatformTime::Cycles64())
						<< MixerSourceStart.PlayOrder(WaveInstance->GetPlayOrder())
						<< MixerSourceStart.SourceId(TraceSourceId)
						<< MixerSourceStart.ComponentId(ActiveSound->GetAudioComponentID())
						<< MixerSourceStart.Name(*WaveInstance->WaveData->GetPathName());
				}
			}
#endif // UE_AUDIO_PROFILERTRACE_ENABLED
		}

		bIsStopping = false;
		Paused = false;
		Playing = true;
		bLoopCallback = false;
		bIsDone = false;
	}

	void FMixerSource::Stop()
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		if (InitializationState == EMixerSourceInitializationState::NotInitialized)
		{
			return;
		}

		if (!MixerSourceVoice)
		{
			StopNow();
			return;
		}

		USoundWave* SoundWave = WaveInstance ? WaveInstance->WaveData : nullptr;

		// If MarkAsGarbage() was called, SoundWave can be null
		if (!SoundWave)
		{
			StopNow();
			return;
		}

		// Stop procedural sounds immediately that don't require fade
		if (SoundWave->bProcedural && !SoundWave->bRequiresStopFade)
		{
			StopNow();
			return;
		}

		if (bIsDone)
		{
			StopNow();
			return;
		}

		if (Playing && !bIsStoppingVoicesEnabled)
		{
			StopNow();
			return;
		}

		// Otherwise, we need to do a quick fade-out of the sound and put the state
		// of the sound into "stopping" mode. This prevents this source from
		// being put into the "free" pool and prevents the source from freeing its resources
		// until the sound has finished naturally (i.e. faded all the way out)

		// Let the wave instance know it's stopping
		if (!bIsStopping)
		{
			WaveInstance->SetStopping(true);

			MixerSourceVoice->StopFade(AudioMixerSourceFadeMinCVar);
			bIsStopping = true;
			Paused = false;
		}
	}

	void FMixerSource::StopNow()
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		// Immediately stop the sound source

		InitializationState = EMixerSourceInitializationState::NotInitialized;

		bIsStopping = false;

		if (WaveInstance)
		{
			if (MixerSourceVoice && Playing)
			{
#if UE_AUDIO_PROFILERTRACE_ENABLED
				const bool bChannelEnabled = UE_TRACE_CHANNELEXPR_IS_ENABLED(AudioMixerChannel);
				if (bChannelEnabled)
				{
					int32 TraceSourceId = INDEX_NONE;
					if (MixerSourceVoice)
					{
						TraceSourceId = MixerSourceVoice->GetSourceId();
					}

					UE_TRACE_LOG(Audio, MixerSourceStop, AudioMixerChannel)
						<< MixerSourceStop.DeviceId(MixerDevice->DeviceID)
						<< MixerSourceStop.Timestamp(FPlatformTime::Cycles64())
						<< MixerSourceStop.PlayOrder(WaveInstance->GetPlayOrder());
				}
#endif // UE_AUDIO_PROFILERTRACE_ENABLED

				MixerSourceVoice->Stop();
			}

			Paused = false;
			Playing = false;

			FreeResources();
		}

		FSoundSource::Stop();
	}

	void FMixerSource::Pause()
	{
		if (!WaveInstance)
		{
			return;
		}

		if (bIsStopping)
		{
			return;
		}

		if (MixerSourceVoice)
		{
			MixerSourceVoice->Pause();
		}

		Paused = true;
	}

	bool FMixerSource::IsFinished()
	{
		// A paused source is not finished.
		if (Paused)
		{
			return false;
		}

		if (InitializationState == EMixerSourceInitializationState::NotInitialized)
		{
			return true;
		}

		if (InitializationState == EMixerSourceInitializationState::Initializing)
		{
			return false;
		}

		if (WaveInstance && MixerSourceVoice)
		{
			if (bIsDone && bIsEffectTailsDone)
			{
				WaveInstance->NotifyFinished();
				bIsStopping = false;
				return true;
			}
			else if (bLoopCallback && WaveInstance->LoopingMode == LOOP_WithNotification)
			{
				WaveInstance->NotifyFinished();
				bLoopCallback = false;
			}

			return false;
		}
		return true;
	}

	float FMixerSource::GetPlaybackPercent() const
	{
		if (InitializationState != EMixerSourceInitializationState::Initialized)
		{
			return PreviousPlaybackPercent;
		}

		if (MixerSourceVoice && NumTotalFrames > 0)
		{
			int64 NumFrames = StartFrame + MixerSourceVoice->GetNumFramesPlayed();
			AUDIO_MIXER_CHECK(NumTotalFrames > 0);
			PreviousPlaybackPercent = (float)NumFrames / NumTotalFrames;
			if (WaveInstance->LoopingMode == LOOP_Never)
			{
				PreviousPlaybackPercent = FMath::Min(PreviousPlaybackPercent, 1.0f);
			}
			return PreviousPlaybackPercent;
		}
		else
		{
			// If we don't have any frames, that means it's a procedural sound wave, which means
			// that we're never going to have a playback percentage.
			return 1.0f;
		}
	}

	int64 FMixerSource::GetNumFramesPlayed() const
	{
		if (InitializationState == EMixerSourceInitializationState::Initialized && MixerSourceVoice != nullptr)
		{
			return MixerSourceVoice->GetNumFramesPlayed();
		}

		return 0;
	}

	float FMixerSource::GetEnvelopeValue() const
	{
		if (MixerSourceVoice)
		{
			return MixerSourceVoice->GetEnvelopeValue();
		}
		return 0.0f;
	}

	float FMixerSource::GetRelativeRenderCost() const
	{
		if (MixerSourceVoice)
		{
			return MixerSourceVoice->GetRelativeRenderCost();
		}
		return 1.0f;
	}

	void FMixerSource::OnBeginGenerate()
	{
	}

	void FMixerSource::OnDone()
	{
		bIsDone = true;
	}

	void FMixerSource::OnEffectTailsDone()
	{
		bIsEffectTailsDone = true;
	}

	void FMixerSource::FreeResources()
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		if (MixerBuffer)
		{
			MixerBuffer->EnsureHeaderParseTaskFinished();
		}

		check(!bIsStopping);
		check(!Playing);

		if (AudioLink.IsValid())
		{
			AudioLink.Reset();
		}

		// Make a new pending release data ptr to pass off release data
		if (MixerSourceVoice)
		{
			// Release the source using the propagation interface
			if (AudioDevice->SourceDataOverridePluginInterface)
			{
				uint32 SourceId = MixerSourceVoice->GetSourceId();
				AudioDevice->SourceDataOverridePluginInterface->OnReleaseSource(SourceId);
			}

			// We're now "releasing" so don't recycle this voice until we get notified that the source has finished
			bIsReleasing = true;

			// This will trigger FMixerSource::OnRelease from audio render thread.
			MixerSourceVoice->Release();
			MixerSourceVoice = nullptr;
		}

		MixerSourceBuffer.Reset();
		bLoopCallback = false;
		NumTotalFrames = 0;

		if (MixerBuffer)
		{
			EBufferType::Type BufferType = MixerBuffer->GetType();
			if (BufferType == EBufferType::PCMRealTime || BufferType == EBufferType::Streaming)
			{
				delete MixerBuffer;
			}

			MixerBuffer = nullptr;
		}

		// Reset the source's channel maps
		FRWScopeLock Lock(ChannelMapLock, SLT_Write);
		ChannelMap.Reset();

		InitializationState = EMixerSourceInitializationState::NotInitialized;
	}

	void FMixerSource::UpdatePitch()
	{
		AUDIO_MIXER_CHECK(MixerBuffer);

		check(WaveInstance);

		FActiveSound* ActiveSound = WaveInstance->ActiveSound;
		check(ActiveSound);

		Pitch = WaveInstance->GetPitch();

		// Don't apply global pitch scale to UI sounds
		if (!WaveInstance->bIsUISound)
		{
			Pitch *= AudioDevice->GetGlobalPitchScale().GetValue();
		}

		Pitch = AudioDevice->ClampPitch(Pitch);

		// Scale the pitch by the ratio of the audio buffer sample rate and the actual sample rate of the hardware
		if (MixerBuffer)
		{
			const float MixerBufferSampleRate = MixerBuffer->GetSampleRate();
			const float AudioDeviceSampleRate = AudioDevice->GetSampleRate();
			Pitch *= MixerBufferSampleRate / AudioDeviceSampleRate;

			MixerSourceVoice->SetPitch(Pitch);
		}

		USoundWave* WaveData = WaveInstance->WaveData;
		check(WaveData);
		const float ModPitchBase = ModulationUtils::GetRoutedPitch(*WaveInstance, *WaveData, *ActiveSound);
		MixerSourceVoice->SetModPitch(ModPitchBase);
	}

	float FMixerSource::GetInheritedSubmixVolumeModulation() const
	{
		if (!MixerDevice)
		{
			return 1.0f;
		}

		FAudioDevice::FAudioSpatializationInterfaceInfo SpatializationInfo = MixerDevice->GetCurrentSpatializationPluginInterfaceInfo();
		// We only hit this condition if, while the sound is playing, the spatializer changes from an external send to a non-external one.
		// If that happens, the submix will catch all modulation so this function's logic is not needed.
		if (!SpatializationInfo.bSpatializationIsExternalSend)
		{
			return 1.0f;
		}

		// if there is a return submix, we need to figure out where to stop manually attenuating
		// Because the submix will modulate itself later
		// Since the graph has tree-like structure, we can create a list of the return submix's ancestors
		// to use while traversing the other submix's ancestors
		TArray<uint32> ReturnSubmixAncestors;
		if (SpatializationInfo.bReturnsToSubmixGraph)
		{
			if (MixerDevice && MixerDevice->ReverbPluginInterface)
			{
				USoundSubmix* ReturnSubmix = MixerDevice->ReverbPluginInterface->GetSubmix();
				if (ReturnSubmix)
				{
					FMixerSubmixWeakPtr CurrReturnSubmixWeakPtr = MixerDevice->GetSubmixInstance(ReturnSubmix);
					FMixerSubmixPtr CurrReturnSubmixPtr = CurrReturnSubmixWeakPtr.Pin();
					while (CurrReturnSubmixPtr && CurrReturnSubmixPtr->IsValid())
					{
						ReturnSubmixAncestors.Add(CurrReturnSubmixPtr->GetId());

						CurrReturnSubmixWeakPtr = CurrReturnSubmixPtr->GetParent();
						CurrReturnSubmixPtr = CurrReturnSubmixWeakPtr.Pin();
					}
				}
			}
		}

		float SubmixModVolume = 1.0f;

		FMixerSubmixWeakPtr CurrSubmixWeakPtr = MixerDevice->GetSubmixInstance(WaveInstance->SoundSubmix);
		FMixerSubmixPtr CurrSubmixPtr = CurrSubmixWeakPtr.Pin();
		// Check the submix and all its parents in the graph for active modulation
		while (CurrSubmixPtr && CurrSubmixPtr->IsValid())
		{
			// Matching ID means the external spatializer has returned to the submix graph at this point,
			// so we no longer need to manually apply volume modulation
			if (SpatializationInfo.bReturnsToSubmixGraph && ReturnSubmixAncestors.Contains(CurrSubmixPtr->GetId()))
			{
				break;
			}

			FModulationDestination* SubmixOutVolDest = CurrSubmixPtr->GetOutputVolumeDestination();
			FModulationDestination* SubmixWetVolDest = CurrSubmixPtr->GetWetVolumeDestination();
			if (SubmixOutVolDest)
			{
				SubmixModVolume *= SubmixOutVolDest->GetValue();
			}
			if (SubmixWetVolDest)
			{
				SubmixModVolume *= SubmixWetVolDest->GetValue();
			}

			CurrSubmixWeakPtr = CurrSubmixPtr->GetParent();
			CurrSubmixPtr = CurrSubmixWeakPtr.Pin();
		}

		return SubmixModVolume;
	}

	void FMixerSource::UpdateVolume()
	{
		// TODO: investigate if occlusion should be split from raw distance attenuation
		MixerSourceVoice->SetDistanceAttenuation(WaveInstance->GetDistanceAndOcclusionAttenuation());

		float CurrentVolume = 0.0f;
		if (!AudioDevice->IsAudioDeviceMuted())
		{
			// 1. Apply device gain stage(s)
			CurrentVolume = WaveInstance->ActiveSound->bIsPreviewSound ? 1.0f : AudioDevice->GetPrimaryVolume();
			CurrentVolume *= AudioDevice->GetPlatformAudioHeadroom();

			// 2. Apply instance gain stage(s)
			CurrentVolume *= WaveInstance->GetVolume();
			CurrentVolume *= WaveInstance->GetDynamicVolume();

			// 3. Submix Volume Modulation (this only happens if the asset is binaural and we're sending to an external submix)
			if (bBypassingSubmixModulation)
			{
				CurrentVolume *= GetInheritedSubmixVolumeModulation();
			}

			// 4. Apply editor gain stage(s)
			CurrentVolume = FMath::Clamp<float>(GetDebugVolume(CurrentVolume), 0.0f, MAX_VOLUME);

			FActiveSound* ActiveSound = WaveInstance->ActiveSound;
			check(ActiveSound);

			USoundWave* WaveData = WaveInstance->WaveData;
			check(WaveData);
			const float ModVolumeBase = ModulationUtils::GetRoutedVolume(*WaveInstance, *WaveData, *ActiveSound);
			MixerSourceVoice->SetModVolume(ModVolumeBase);
		}
		MixerSourceVoice->SetVolume(CurrentVolume);
	}

	void FMixerSource::UpdateSpatialization()
	{
		FQuat LastEmitterWorldRotation = SpatializationParams.EmitterWorldRotation;
		SpatializationParams = GetSpatializationParams();
		SpatializationParams.LastEmitterWorldRotation = LastEmitterWorldRotation;

		if (WaveInstance->GetUseSpatialization() || WaveInstance->bIsAmbisonics)
		{
			MixerSourceVoice->SetSpatializationParams(SpatializationParams);
		}
	}
	
	void FMixerSource::UpdateSubmixSendLevels(const FSoundSubmixSendInfoBase& InSendInfo, const EMixerSourceSubmixSendStage InSendStage, TSet<FMixerSubmixWeakPtr>& OutTouchedSubmixes)
	{
		if (InSendInfo.SoundSubmix != nullptr)
		{
			const FMixerSubmixWeakPtr SubmixInstance = MixerDevice->GetSubmixInstance(InSendInfo.SoundSubmix);
			float SendLevel = 1.0f;

			// Add it to our touched submix list.
			OutTouchedSubmixes.Add(SubmixInstance);

			// calculate send level based on distance if that method is enabled
			if (!WaveInstance->bEnableSubmixSends)
			{
				SendLevel = 0.0f;
			}
			else if (InSendInfo.SendLevelControlMethod == ESendLevelControlMethod::Manual)
			{
				if (InSendInfo.DisableManualSendClamp)
				{
					SendLevel = InSendInfo.SendLevel;
				}
				else
				{
					SendLevel = FMath::Clamp(InSendInfo.SendLevel, 0.0f, 1.0f);
				}
			}
			else
			{
				// The alpha value is determined identically between manual and custom curve methods
				const FVector2D SendRadialRange = { InSendInfo.MinSendDistance, InSendInfo.MaxSendDistance};
				const FVector2D SendLevelRange = { InSendInfo.MinSendLevel, InSendInfo.MaxSendLevel };
				const float Denom = FMath::Max(SendRadialRange.Y - SendRadialRange.X, 1.0f);
				const float Alpha = FMath::Clamp((WaveInstance->ListenerToSoundDistance - SendRadialRange.X) / Denom, 0.0f, 1.0f);

				if (InSendInfo.SendLevelControlMethod == ESendLevelControlMethod::Linear)
				{
					SendLevel = FMath::Clamp(FMath::Lerp(SendLevelRange.X, SendLevelRange.Y, Alpha), 0.0f, 1.0f);
				}
				else // use curve
				{
					SendLevel = FMath::Clamp(InSendInfo.CustomSendLevelCurve.GetRichCurveConst()->Eval(Alpha), 0.0f, 1.0f);
				}
			}

			// set the level and stage for this send
			MixerSourceVoice->SetSubmixSendInfo(SubmixInstance, SendLevel, InSendStage);
		}
	}

	void FMixerSource::UpdateEffects()
	{
		// Update the default LPF filter frequency
		SetFilterFrequency();

		if (LastLPFFrequency != LPFFrequency)
		{
			MixerSourceVoice->SetLPFFrequency(LPFFrequency);
			LastLPFFrequency = LPFFrequency;
		}

		if (LastHPFFrequency != HPFFrequency)
		{
			MixerSourceVoice->SetHPFFrequency(HPFFrequency);
			LastHPFFrequency = HPFFrequency;
		}

		check(WaveInstance);
		FActiveSound* ActiveSound = WaveInstance->ActiveSound;
		check(ActiveSound);

		USoundWave* WaveData = WaveInstance->WaveData;
		check(WaveData);

		float ModHighpassBase = ModulationUtils::GetRoutedHighpass(*WaveInstance, *WaveData, *ActiveSound);
		MixerSourceVoice->SetModHPFFrequency(ModHighpassBase);

		float ModLowpassBase = ModulationUtils::GetRoutedLowpass(*WaveInstance, *WaveData, *ActiveSound);
		MixerSourceVoice->SetModLPFFrequency(ModLowpassBase);

		// If reverb is applied, figure out how of the source to "send" to the reverb.
		if (WaveInstance->bReverb)
		{
			// Send the source audio to the reverb plugin if enabled
			if (UseReverbPlugin() && AudioDevice->ReverbPluginInterface)
			{
				check(MixerDevice);
				FMixerSubmixPtr ReverbPluginSubmixPtr = MixerDevice->GetSubmixInstance(AudioDevice->ReverbPluginInterface->GetSubmix()).Pin();
				if (ReverbPluginSubmixPtr.IsValid())
				{
					MixerSourceVoice->SetSubmixSendInfo(ReverbPluginSubmixPtr, WaveInstance->ReverbSendLevel);
				}
			}

			// Send the source audio to the master reverb
			MixerSourceVoice->SetSubmixSendInfo(MixerDevice->GetMasterReverbSubmix(), WaveInstance->ReverbSendLevel);
		}

		// Safely track if the submix has changed between updates.
		bool bSubmixHasChanged = false;
		TObjectKey<USoundSubmixBase> SubmixKey(WaveInstance->SoundSubmix);
		if (SubmixKey != PrevousSubmix )
		{
			bSubmixHasChanged = true;
		}

		// This will reattempt to resolve a submix each update if there's a valid input
		if ((!WaveInstance->SoundSubmix && PreviousSubmixResolved.IsValid()) || 
		     (WaveInstance->SoundSubmix && !PreviousSubmixResolved.IsValid()) )
		{
			bSubmixHasChanged = true;
		}

		//Check whether the base submix send has been enabled or disabled since the last update
		//Or if the submix has now been registered with the world.
		if (WaveInstance->bEnableBaseSubmix != bPreviousBaseSubmixEnablement || bSubmixHasChanged)
		{
			// set the level for this send
			FMixerSubmixWeakPtr SubmixPtr;
			if (WaveInstance->SoundSubmix)
			{
				SubmixPtr = MixerDevice->GetSubmixInstance(WaveInstance->SoundSubmix);
			}
			else if (!WaveInstance->bIsDynamic) // Dynamic submixes don't auto connect.
			{
				SubmixPtr = MixerDevice->GetBaseDefaultSubmix(); // This will try base default and fall back to master if that fails.
			}

			MixerSourceVoice->SetSubmixSendInfo(SubmixPtr, WaveInstance->bEnableBaseSubmix);
			bPreviousBaseSubmixEnablement = WaveInstance->bEnableBaseSubmix;
			PreviousSubmixResolved = SubmixPtr;
			PrevousSubmix = SubmixKey;
		}

		// We clear sends that aren't used between updates. So tally up the ones that are used.
		// Including the submix itself. 
		// It's okay to use "previous" submix here as it's set above or from a previous setting.
		TSet<FMixerSubmixWeakPtr> TouchedSubmixes;
		TouchedSubmixes.Add(PreviousSubmixResolved);
	

		// Attenuation Submix Sends. (these come from Attenuation assets).
		// These are largely identical to SoundSubmix Sends, but don't specify a send stage, so we pass one here.		
		for (const FAttenuationSubmixSendSettings& SendSettings : WaveInstance->AttenuationSubmixSends)
		{
			UpdateSubmixSendLevels(SendSettings, EMixerSourceSubmixSendStage::PostDistanceAttenuation, TouchedSubmixes);
		}
		
		// Sound submix Sends. (these come from SoundBase derived assets).
		for (FSoundSubmixSendInfo& SendInfo : WaveInstance->SoundSubmixSends)
		{
			UpdateSubmixSendLevels(SendInfo, MixerSourcePrivate::SubmixSendStageToMixerSourceSubmixSendStage(SendInfo.SendStage), TouchedSubmixes);
		}
		
		// Anything we haven't touched this update we should now clear.
		const TSet<FMixerSubmixWeakPtr> ToClear = PreviousSubmixSends.Difference(TouchedSubmixes);
		PreviousSubmixSends = TouchedSubmixes;

		// Clear sends that aren't touched.	
		for (FMixerSubmixWeakPtr i : ToClear)
		{
			MixerSourceVoice->ClearSubmixSendInfo(i);
		}
	
		MixerSourceVoice->SetEnablement(WaveInstance->bEnableBusSends, WaveInstance->bEnableBaseSubmix, WaveInstance->bEnableSubmixSends);

		MixerSourceVoice->SetSourceBufferListener(WaveInstance->SourceBufferListener, WaveInstance->bShouldSourceBufferListenerZeroBuffer);
	}

	void FMixerSource::UpdateModulation()
	{
		check(WaveInstance);

		FActiveSound* ActiveSound = WaveInstance->ActiveSound;
		check(ActiveSound);

		if (ActiveSound->bModulationRoutingUpdated)
		{
			if (WaveInstance->WaveData)
			{
				FSoundModulationDefaultRoutingSettings UpdatedRouting = ModulationUtils::UpdateRoutedModulation(*WaveInstance, *(WaveInstance->WaveData), ActiveSound);
				MixerSourceVoice->SetModulationRouting(UpdatedRouting);
			}
			else
			{
				MixerSourceVoice->SetModulationRouting(ActiveSound->ModulationRouting);
			}
		}

		ActiveSound->bModulationRoutingUpdated = false;
	}

	void FMixerSource::UpdateSourceBusSends()
	{
		// 1) loop through all bus sends
		// 2) check for any bus sends that are set to update non-manually
		// 3) Cache previous send level and only do update if it's changed in any significant amount

		SetupBusData();

		FActiveSound* ActiveSound = WaveInstance->ActiveSound;
		check(ActiveSound);

		// Check if the user actively called a function that alters bus sends since the last update
		bool bHasNewBusSends = ActiveSound->HasNewBusSends();

		if (!bSendingAudioToBuses && !bHasNewBusSends && !DynamicBusSendInfos.Num())
		{
			return;
		}

		if (bHasNewBusSends)
		{
			TArray<TTuple<EBusSendType, FSoundSourceBusSendInfo>> NewBusSends = ActiveSound->GetNewBusSends();
			for (TTuple<EBusSendType, FSoundSourceBusSendInfo>& NewSend : NewBusSends)
			{
				if (NewSend.Value.SoundSourceBus)
				{
					MixerSourceVoice->SetAudioBusSendInfo(NewSend.Key, NewSend.Value.SoundSourceBus->GetUniqueID(), NewSend.Value.SendLevel);
					bSendingAudioToBuses = true;
				}

				if (NewSend.Value.AudioBus)
				{
					MixerSourceVoice->SetAudioBusSendInfo(NewSend.Key, NewSend.Value.AudioBus->GetUniqueID(), NewSend.Value.SendLevel);
					bSendingAudioToBuses = true;
				}
			}

			ActiveSound->ResetNewBusSends();
		}

		// If this source is sending its audio to a bus, we need to check if it needs to be updated
		for (FDynamicBusSendInfo& DynamicBusSendInfo : DynamicBusSendInfos)
		{
			float SendLevel = 0.0f;

			if (DynamicBusSendInfo.BusSendLevelControlMethod == ESourceBusSendLevelControlMethod::Manual)
			{
				SendLevel = FMath::Clamp(DynamicBusSendInfo.SendLevel, 0.0f, 1.0f);
			}
			else
			{
				// The alpha value is determined identically between linear and custom curve methods
				const FVector2D SendRadialRange = { DynamicBusSendInfo.MinSendDistance, DynamicBusSendInfo.MaxSendDistance };
				const FVector2D SendLevelRange = { DynamicBusSendInfo.MinSendLevel, DynamicBusSendInfo.MaxSendLevel };
				const float Denom = FMath::Max(SendRadialRange.Y - SendRadialRange.X, 1.0f);
				const float Alpha = FMath::Clamp((WaveInstance->ListenerToSoundDistance - SendRadialRange.X) / Denom, 0.0f, 1.0f);

				if (DynamicBusSendInfo.BusSendLevelControlMethod == ESourceBusSendLevelControlMethod::Linear)
				{
					SendLevel = FMath::Clamp(FMath::Lerp(SendLevelRange.X, SendLevelRange.Y, Alpha), 0.0f, 1.0f);
				}
				else // use curve
				{
					SendLevel = FMath::Clamp(DynamicBusSendInfo.CustomSendLevelCurve.GetRichCurveConst()->Eval(Alpha), 0.0f, 1.0f);
				}
			}

			// If the send level changed, then we need to send an update to the audio render thread
			const bool bSendLevelChanged = !FMath::IsNearlyEqual(SendLevel, DynamicBusSendInfo.SendLevel);
			const bool bBusEnablementChanged = bPreviousBusEnablement != WaveInstance->bEnableBusSends;

			if (bSendLevelChanged || bBusEnablementChanged)
			{
				DynamicBusSendInfo.SendLevel = SendLevel;
				DynamicBusSendInfo.bIsInit = false;

				MixerSourceVoice->SetAudioBusSendInfo(DynamicBusSendInfo.BusSendType, DynamicBusSendInfo.BusId, SendLevel);

				bPreviousBusEnablement = WaveInstance->bEnableBusSends;
			}

		}
	}

	void FMixerSource::UpdateChannelMaps()
	{
		SetLFEBleed();

		int32 NumOutputDeviceChannels = MixerDevice->GetNumDeviceChannels();
		const FAudioPlatformDeviceInfo& DeviceInfo = MixerDevice->GetPlatformDeviceInfo();

		// Compute a new speaker map for each possible output channel mapping for the source
		bool bShouldSetMap = false;
		{
			FRWScopeLock Lock(ChannelMapLock, SLT_Write);
			bShouldSetMap = ComputeChannelMap(GetNumChannels(), ChannelMap);
		}
		if(bShouldSetMap)
		{			
			FRWScopeLock Lock(ChannelMapLock, SLT_ReadOnly);
			MixerSourceVoice->SetChannelMap(NumChannels, ChannelMap, bIs3D, WaveInstance->bCenterChannelOnly);
		}

		bPrevAllowedSpatializationSetting = IsSpatializationCVarEnabled();
	}

	void FMixerSource::UpdateRelativeRenderCost()
	{
		if (MixerSourceVoice)
		{
			const float RelativeRenderCost = MixerSourceVoice->GetRelativeRenderCost();
			check(WaveInstance);
			WaveInstance->SetRelativeRenderCost(RelativeRenderCost);
#if ENABLE_AUDIO_DEBUG
			if (DebugInfo.IsValid())
			{
				FScopeLock DebugInfoLock(&DebugInfo->CS);
				DebugInfo->RelativeRenderCost = RelativeRenderCost;
			}
#endif // if ENABLE_AUDIO_DEBUG
		}
	}

#if ENABLE_AUDIO_DEBUG
	void FMixerSource::UpdateCPUCoreUtilization()
	{
		if (MixerSourceVoice)
		{
			if (DebugInfo.IsValid())
			{
				FScopeLock DebugInfoLock(&DebugInfo->CS);
				DebugInfo->CPUCoreUtilization = MixerSourceVoice->GetCPUCoreUtilization();
			}
		}
	}
#endif // if ENABLE_AUDIO_DEBUG

	bool FMixerSource::ComputeMonoChannelMap(Audio::FAlignedFloatBuffer& OutChannelMap)
	{
		if (IsUsingObjectBasedSpatialization())
		{
			if (WaveInstance->SpatializationMethod != ESoundSpatializationAlgorithm::SPATIALIZATION_HRTF && !bEditorWarnedChangedSpatialization)
			{
				bEditorWarnedChangedSpatialization = true;
				UE_LOG(LogAudioMixer, Warning, TEXT("Changing the spatialization method on a playing sound is not supported (WaveInstance: %s)"), *WaveInstance->WaveData->GetFullName());
			}

			// Treat the source as if it is a 2D stereo source:
			return ComputeStereoChannelMap(OutChannelMap);
		}
		else if (WaveInstance->GetUseSpatialization() && (!FMath::IsNearlyEqual(WaveInstance->AbsoluteAzimuth, PreviousAzimuth, 0.01f) || MixerSourceVoice->NeedsSpeakerMap()))
		{
			// Don't need to compute the source channel map if the absolute azimuth hasn't changed much
			PreviousAzimuth = WaveInstance->AbsoluteAzimuth;
			OutChannelMap.Reset();

			int32 NumDeviceChannels = MixerDevice->GetNumDeviceChannels();
			float DefaultOmniAmount = 1.0f / NumDeviceChannels;
			MixerDevice->Get3DChannelMap(NumDeviceChannels, WaveInstance, WaveInstance->AbsoluteAzimuth, SpatializationParams.NonSpatializedAmount, nullptr, DefaultOmniAmount, OutChannelMap);
			return true;
		}
		else if (!OutChannelMap.Num() || (IsSpatializationCVarEnabled() != bPrevAllowedSpatializationSetting))
		{
			// Only need to compute the 2D channel map once
			MixerDevice->Get2DChannelMap(bIsVorbis, 1, WaveInstance->bCenterChannelOnly, OutChannelMap);
			return true;
		}

		// Return false means the channel map hasn't changed
		return false;
	}

	bool FMixerSource::ComputeStereoChannelMap(Audio::FAlignedFloatBuffer& OutChannelMap)
	{
		// Only recalculate positional data if the source has moved a significant amount:
		if (WaveInstance->GetUseSpatialization() && (!FMath::IsNearlyEqual(WaveInstance->AbsoluteAzimuth, PreviousAzimuth, 0.01f) || MixerSourceVoice->NeedsSpeakerMap()))
		{
			// Make sure our stereo emitter positions are updated relative to the sound emitter position
			if (GetNumChannels() == 2)
			{
				UpdateStereoEmitterPositions();
			}

			// Check whether voice is currently using 
			if (!IsUsingObjectBasedSpatialization())
			{
				float AzimuthOffset = 0.0f;

				float LeftAzimuth = 90.0f;
				float RightAzimuth = 270.0f;

				const float DistanceToUse = UseListenerOverrideForSpreadCVar ? WaveInstance->ListenerToSoundDistance : WaveInstance->ListenerToSoundDistanceForPanning;

				if (DistanceToUse > KINDA_SMALL_NUMBER)
				{
					AzimuthOffset = FMath::Atan(0.5f * WaveInstance->StereoSpread / DistanceToUse);
					AzimuthOffset = FMath::RadiansToDegrees(AzimuthOffset);

					LeftAzimuth = WaveInstance->AbsoluteAzimuth - AzimuthOffset;
					if (LeftAzimuth < 0.0f)
					{
						LeftAzimuth += 360.0f;
					}

					RightAzimuth = WaveInstance->AbsoluteAzimuth + AzimuthOffset;
					if (RightAzimuth > 360.0f)
					{
						RightAzimuth -= 360.0f;
					}
				}

				// Reset the channel map, the stereo spatialization channel mapping calls below will append their mappings
				OutChannelMap.Reset();

				int32 NumOutputChannels = MixerDevice->GetNumDeviceChannels();

				if (WaveInstance->NonSpatializedRadiusMode == ENonSpatializedRadiusSpeakerMapMode::OmniDirectional)
				{
					float DefaultOmniAmount = 1.0f / NumOutputChannels;
					MixerDevice->Get3DChannelMap(NumOutputChannels, WaveInstance, LeftAzimuth, SpatializationParams.NonSpatializedAmount, nullptr, DefaultOmniAmount, OutChannelMap);
					MixerDevice->Get3DChannelMap(NumOutputChannels, WaveInstance, RightAzimuth, SpatializationParams.NonSpatializedAmount, nullptr, DefaultOmniAmount, OutChannelMap);
				}
				else if (WaveInstance->NonSpatializedRadiusMode == ENonSpatializedRadiusSpeakerMapMode::Direct2D)
				{
					// Create some omni maps for left and right channels
					auto CreateLeftOmniMap = []() -> TMap<EAudioMixerChannel::Type, float>
					{
						TMap<EAudioMixerChannel::Type, float> LeftOmniMap;
						LeftOmniMap.Add(EAudioMixerChannel::FrontLeft, 1.0f);
						return LeftOmniMap;
					};

					auto CreateRightOmniMap = []() -> TMap<EAudioMixerChannel::Type, float>
					{
						TMap<EAudioMixerChannel::Type, float> RightOmniMap;
						RightOmniMap.Add(EAudioMixerChannel::FrontRight, 1.0f);
						return RightOmniMap;
					};

					static const TMap<EAudioMixerChannel::Type, float> LeftOmniMap = CreateLeftOmniMap();
					static const TMap<EAudioMixerChannel::Type, float> RightOmniMap = CreateRightOmniMap();

					MixerDevice->Get3DChannelMap(NumOutputChannels, WaveInstance, LeftAzimuth, SpatializationParams.NonSpatializedAmount, &LeftOmniMap, 0.0f, OutChannelMap);
					MixerDevice->Get3DChannelMap(NumOutputChannels, WaveInstance, RightAzimuth, SpatializationParams.NonSpatializedAmount, &RightOmniMap, 0.0f, OutChannelMap);
				}
				else
				{
					// If we are in 5.1, we need to use the side-channel speakers
					if (NumOutputChannels == 6)
					{
						// Create some omni maps for left and right channels
						auto CreateLeftOmniMap = []() -> TMap<EAudioMixerChannel::Type, float>
						{
							TMap<EAudioMixerChannel::Type, float> LeftOmniMap;
							LeftOmniMap.Add(EAudioMixerChannel::FrontLeft, 1.0f);
							LeftOmniMap.Add(EAudioMixerChannel::SideLeft, 1.0f);

							return LeftOmniMap;
						};

						auto CreateRightOmniMap = []() -> TMap<EAudioMixerChannel::Type, float>
						{
							TMap<EAudioMixerChannel::Type, float> RightOmniMap;
							RightOmniMap.Add(EAudioMixerChannel::FrontRight, 1.0f);
							RightOmniMap.Add(EAudioMixerChannel::SideRight, 1.0f);

							return RightOmniMap;
						};

						static const TMap<EAudioMixerChannel::Type, float> LeftOmniMap = CreateLeftOmniMap();
						static const TMap<EAudioMixerChannel::Type, float> RightOmniMap = CreateRightOmniMap();

						MixerDevice->Get3DChannelMap(NumOutputChannels, WaveInstance, LeftAzimuth, SpatializationParams.NonSpatializedAmount, &LeftOmniMap, 0.0f, OutChannelMap);
						MixerDevice->Get3DChannelMap(NumOutputChannels, WaveInstance, RightAzimuth, SpatializationParams.NonSpatializedAmount, &RightOmniMap, 0.0f, OutChannelMap);

					}
					// If we are in 7.1 we need to use the back-channel speakers
					else if (NumOutputChannels == 8)
					{
						// Create some omni maps for left and right channels
						auto CreateLeftOmniMap = []() -> TMap<EAudioMixerChannel::Type, float>
						{
							TMap<EAudioMixerChannel::Type, float> LeftOmniMap;
							LeftOmniMap.Add(EAudioMixerChannel::FrontLeft, 1.0f);
							LeftOmniMap.Add(EAudioMixerChannel::BackLeft, 1.0f);

							return LeftOmniMap;
						};

						auto CreateRightOmniMap = []() -> TMap<EAudioMixerChannel::Type, float>
						{
							TMap<EAudioMixerChannel::Type, float> RightOmniMap;
							RightOmniMap.Add(EAudioMixerChannel::FrontRight, 1.0f);
							RightOmniMap.Add(EAudioMixerChannel::BackRight, 1.0f);

							return RightOmniMap;
						};

						static const TMap<EAudioMixerChannel::Type, float> LeftOmniMap = CreateLeftOmniMap();
						static const TMap<EAudioMixerChannel::Type, float> RightOmniMap = CreateRightOmniMap();

						MixerDevice->Get3DChannelMap(NumOutputChannels, WaveInstance, LeftAzimuth, SpatializationParams.NonSpatializedAmount, &LeftOmniMap, 0.0f, OutChannelMap);
						MixerDevice->Get3DChannelMap(NumOutputChannels, WaveInstance, RightAzimuth, SpatializationParams.NonSpatializedAmount, &RightOmniMap, 0.0f, OutChannelMap);
					}
				}		

				return true;
			}
		}

		if (!OutChannelMap.Num() || (IsSpatializationCVarEnabled() != bPrevAllowedSpatializationSetting))
		{
			MixerDevice->Get2DChannelMap(bIsVorbis, 2, WaveInstance->bCenterChannelOnly, OutChannelMap);
			return true;
		}

		return false;
	}

	bool FMixerSource::ComputeChannelMap(const int32 NumSourceChannels, Audio::FAlignedFloatBuffer& OutChannelMap)
	{
		if (NumSourceChannels == 1)
		{
			return ComputeMonoChannelMap(OutChannelMap);
		}
		else if (NumSourceChannels == 2)
		{
			return ComputeStereoChannelMap(OutChannelMap);
		}
		else if (!OutChannelMap.Num())
		{
			MixerDevice->Get2DChannelMap(bIsVorbis, NumSourceChannels, WaveInstance->bCenterChannelOnly, OutChannelMap);
			return true;
		}
		return false;
	}

	bool FMixerSource::UseObjectBasedSpatialization() const
	{
		return (GetNumChannels() <= MixerDevice->GetCurrentSpatializationPluginInterfaceInfo().MaxChannelsSupportedBySpatializationPlugin &&
				AudioDevice->IsSpatializationPluginEnabled() &&
				WaveInstance->SpatializationMethod == ESoundSpatializationAlgorithm::SPATIALIZATION_HRTF);
	}

	bool FMixerSource::IsUsingObjectBasedSpatialization() const
	{
		bool bIsUsingObjectBaseSpatialization = UseObjectBasedSpatialization();

		if (MixerSourceVoice)
		{
			// If it is currently playing, check whether it actively uses HRTF spatializer.
			// HRTF spatialization cannot be altered on currently playing source. So this handles
			// the case where the source was initialized without HRTF spatialization before HRTF
			// spatialization is enabled. 
			bool bDefaultIfNoSourceId = true;
			bIsUsingObjectBaseSpatialization &= MixerSourceVoice->IsUsingHRTFSpatializer(bDefaultIfNoSourceId);
		}
		return bIsUsingObjectBaseSpatialization;
	}

	bool FMixerSource::UseSpatializationPlugin() const
	{
		return (GetNumChannels() <= MixerDevice->GetCurrentSpatializationPluginInterfaceInfo().MaxChannelsSupportedBySpatializationPlugin) &&  
			AudioDevice->IsSpatializationPluginEnabled() &&
			WaveInstance->SpatializationPluginSettings != nullptr;
	}

	bool FMixerSource::UseOcclusionPlugin() const
	{
		return (GetNumChannels() == 1 || GetNumChannels() == 2) && 
			AudioDevice->IsOcclusionPluginEnabled() &&
			WaveInstance->OcclusionPluginSettings != nullptr;
	}

	bool FMixerSource::UseReverbPlugin() const
	{
		return (GetNumChannels() == 1 || GetNumChannels() == 2) && 
			AudioDevice->IsReverbPluginEnabled() &&
			WaveInstance->ReverbPluginSettings != nullptr;
	}

	bool FMixerSource::UseSourceDataOverridePlugin() const
	{
		return (GetNumChannels() == 1 || GetNumChannels() == 2) && 
			AudioDevice->IsSourceDataOverridePluginEnabled() &&
			WaveInstance->SourceDataOverridePluginSettings != nullptr;
	}
}

============================


=== AudioMixerSource.h ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "AudioMixerBuffer.h"
#include "AudioMixerSourceManager.h"

namespace Audio
{
	class FMixerDevice;
	class FMixerSourceVoice;
	class FMixerSource;
	class FMixerBuffer;
	class ISourceListener;

	/** State to track initialization stages. */
	enum class EMixerSourceInitializationState : uint8
	{
		NotInitialized,
		Initializing,
		Initialized
	};

	/** 
	 * FMixerSource
	 * Class which implements a sound source object for the audio mixer module.
	 */
	class FMixerSource :	public FSoundSource, 
							public ISourceListener
	{
	public:
		/** Constructor. */
		FMixerSource(FAudioDevice* InAudioDevice);

		/** Destructor. */
		~FMixerSource();

		//~ Begin FSoundSource Interface
		virtual bool Init(FWaveInstance* InWaveInstance) override;
		virtual void Update() override;
		virtual bool PrepareForInitialization(FWaveInstance* InWaveInstance) override;
		virtual bool IsPreparedToInit() override;
		virtual bool IsInitialized() const override;
		virtual void Play() override;
		virtual void Stop() override;
		virtual void StopNow() override;
		virtual bool IsStopping() override { return bIsStopping; }
		virtual void Pause() override;
		virtual bool IsFinished() override;
		virtual float GetPlaybackPercent() const override;
		virtual int64 GetNumFramesPlayed() const override;
		virtual float GetEnvelopeValue() const override;
		virtual float GetRelativeRenderCost() const override;
		//~ End FSoundSource Interface

		//~ Begin ISourceListener
		virtual void OnBeginGenerate() override;
		virtual void OnDone() override;
		virtual void OnEffectTailsDone() override;
		virtual void OnLoopEnd() override { bLoopCallback = true; };
		//~ End ISourceListener

	private:

		/** Initializes the bus sends. */
		void SetupBusData(TArray<FInitAudioBusSend>* OutAudioBusSends = nullptr, bool bEnableBusSends = true);

		/** Frees any resources for this sound source. */
		void FreeResources();

		/** Updates the pitch parameter set from the game thread. */
		void UpdatePitch();
		
		/** Updates the volume parameter set from the game thread. */
		void UpdateVolume();

		/** Gets updated spatialization information for the voice. */
		void UpdateSpatialization();

		/** Updates and source effect on this voice. */
		void UpdateEffects();

		/** Updates the Modulation Routing settings on this voice. */
		void UpdateModulation();

		/** Updates source bus send levels based on game data. */
		void UpdateSourceBusSends();

		/** Updates the channel map of the sound if its a 3d sound.*/
		void UpdateChannelMaps();

		/** Updates the relative render cost estimate of the playing sound source. */
		void UpdateRelativeRenderCost();

#if ENABLE_AUDIO_DEBUG
		void UpdateCPUCoreUtilization();
#endif // ENABLE_AUDIO_DEBUG

		/** Computes the mono-channel map. */
		bool ComputeMonoChannelMap(Audio::FAlignedFloatBuffer& OutChannelMap);

		/** Computes the stereo-channel map. */
		bool ComputeStereoChannelMap(Audio::FAlignedFloatBuffer& OutChannelMap);

		/** Compute the channel map based on the number of output and source channels. */
		bool ComputeChannelMap(const int32 NumSourceChannels, Audio::FAlignedFloatBuffer& OutChannelMap);

		/** Whether or not we should create the source voice with the HRTF spatializer. */
		bool UseObjectBasedSpatialization() const;
		
		/** Whether or not existing or new sources will use the HRTF spatializer. */
		bool IsUsingObjectBasedSpatialization() const;

		/** Whether or not to use the spatialization plugin. */
		bool UseSpatializationPlugin() const;

		/** Whether or not to use the occlusion plugin. */
		bool UseOcclusionPlugin() const;

		/** Whether or not to use the reverb plugin. */
		bool UseReverbPlugin() const;

		/** Whether or not to use the source data override plugin */
		bool UseSourceDataOverridePlugin() const;

		/** Gets an accumulated volume value based on the Modulation Destination data of the WaveInstance's submix and all of the submix's ancestors */
		float GetInheritedSubmixVolumeModulation() const;

	private:
		void UpdateSubmixSendLevels(const FSoundSubmixSendInfoBase& InSendInfo, EMixerSourceSubmixSendStage InSendStage, TSet<FMixerSubmixWeakPtr>& OutTouchedSubmixes);

		FMixerDevice* MixerDevice;
		FMixerBuffer* MixerBuffer;
		TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe> MixerSourceBuffer;
		FMixerSourceVoice* MixerSourceVoice;
		IAudioLinkFactory::FAudioLinkSourcePushedSharedPtr AudioLink;
		FMixerSubmixWeakPtr PreviousSubmixResolved;
		TObjectKey<USoundSubmixBase> PrevousSubmix;

		// These modulators are obtained from the submix and used only on binaural assets
		bool bBypassingSubmixModulation;

		uint32 bPreviousBusEnablement;
		uint32 bPreviousBaseSubmixEnablement;

		// This holds data copied from FSoundSourceBusSendInfo when a new sound starts playing
		// so that distance-based level control can be calculated during rendering
		struct FDynamicBusSendInfo
		{
			float SendLevel = 0.0f;
			uint32 BusId = 0;
			ESourceBusSendLevelControlMethod BusSendLevelControlMethod = ESourceBusSendLevelControlMethod::Manual;
			EBusSendType BusSendType = EBusSendType::PreEffect;
			float MinSendLevel = 0.0f;
			float MaxSendLevel = 0.0f;
			float MinSendDistance = 0.0f;
			float MaxSendDistance = 0.0f;
			FRuntimeFloatCurve CustomSendLevelCurve;
			bool bIsInit = true;
		};

		// Mapping of channel map types to channel maps. Determined by what submixes this source sends its audio to.
		Audio::FAlignedFloatBuffer ChannelMap;
		FRWLock ChannelMapLock;

		float PreviousAzimuth;
		mutable float PreviousPlaybackPercent;

		FSpatializationParams SpatializationParams;

		EMixerSourceInitializationState InitializationState;

		FThreadSafeBool bPlayedCachedBuffer;
		FThreadSafeBool bPlaying;
		FThreadSafeBool bIsStopping;
		FThreadSafeBool bLoopCallback;
		FThreadSafeBool bIsDone;
		FThreadSafeBool bIsEffectTailsDone;
		FThreadSafeBool bIsPlayingEffectTails;
		FThreadSafeBool bFreeAsyncTask;

		// Array of copied FSoundSourceBusSendInfo data for all the bus sends this
		// source may need to live-update during its lifespan
		TArray<FDynamicBusSendInfo> DynamicBusSendInfos;

		// An array of submixes from previous update. Allows us to clear out submix sends if they are no longer being sent.
		TSet<FMixerSubmixWeakPtr> PreviousSubmixSends;
		
		// Whether or not we're currently releasing our resources. Prevents recycling the source until release is finished.
		FThreadSafeBool bIsReleasing;

		uint32 bEditorWarnedChangedSpatialization : 1;
		uint32 bIs3D : 1;
		uint32 bDebugMode : 1;
		uint32 bIsVorbis : 1;
		uint32 bIsStoppingVoicesEnabled : 1;
		uint32 bSendingAudioToBuses : 1;
		uint32 bPrevAllowedSpatializationSetting : 1;
	};
}

==========================


=== AudioMixerSourceBuffer.cpp ===
==================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerSourceBuffer.h"
#include "AudioMixerSourceDecode.h"
#include "ContentStreaming.h"
#include "AudioDecompress.h"
#include "Misc/ScopeTryLock.h"
#include "DSP/FloatArrayMath.h"

namespace Audio
{
	bool FRawPCMDataBuffer::GetNextBuffer(FMixerSourceVoiceBuffer* OutSourceBufferPtr, const uint32 NumSampleToGet)
	{
		// TODO: support loop counts
		float* OutBufferPtr = OutSourceBufferPtr->AudioData.GetData();
		int16* DataPtr = (int16*)Data;

		if (LoopCount == Audio::LOOP_FOREVER)
		{
			bool bIsFinishedOrLooped = false;
			for (uint32 Sample = 0; Sample < NumSampleToGet; ++Sample)
			{
				OutBufferPtr[Sample] = DataPtr[CurrentSample++] / 32768.0f;

				// Loop around if we're looping
				if (CurrentSample >= NumSamples)
				{
					CurrentSample = 0;
					bIsFinishedOrLooped = true;
				}
			}
			return bIsFinishedOrLooped;
		}
		else if (CurrentSample < NumSamples)
		{
			uint32 Sample = 0;
			while (Sample < NumSampleToGet && CurrentSample < NumSamples)
			{
				OutBufferPtr[Sample++] = (float)DataPtr[CurrentSample++] / 32768.0f;
			}

			// Zero out the rest of the buffer
			FMemory::Memzero(&OutBufferPtr[Sample], (NumSampleToGet - Sample) * sizeof(float));
		}
		else
		{
			FMemory::Memzero(OutBufferPtr, NumSampleToGet * sizeof(float));
		}

		// If the current sample is greater or equal to num samples we hit the end of the buffer
		return CurrentSample >= NumSamples;
	}

	TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe> FMixerSourceBuffer::Create(FMixerSourceBufferInitArgs& InArgs, TArray<FAudioParameter>&& InDefaultParams)
	{
		LLM_SCOPE(ELLMTag::AudioMixer);

		// Fail if the Wave has been flagged to contain an error
		if (InArgs.SoundWave && InArgs.SoundWave->HasError())
		{
			UE_LOG(LogAudioMixer, VeryVerbose, TEXT("FMixerSourceBuffer::Create failed as '%s' is flagged as containing errors"), *InArgs.SoundWave->GetName());
			return {};
		}

		TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe> NewSourceBuffer = MakeShareable(new FMixerSourceBuffer(InArgs, MoveTemp(InDefaultParams)));

		return NewSourceBuffer;
	}

	FMixerSourceBuffer::FMixerSourceBuffer(FMixerSourceBufferInitArgs& InArgs, TArray<FAudioParameter>&& InDefaultParams)
		: NumBuffersQeueued(0)
		, CurrentBuffer(0)
		, SoundWave(InArgs.SoundWave)
		, AsyncRealtimeAudioTask(nullptr)
		, DecompressionState(nullptr)
		, LoopingMode(InArgs.LoopingMode)
		, NumChannels(InArgs.Buffer->NumChannels)
		, BufferType(InArgs.Buffer->GetType())
		, NumPrecacheFrames(InArgs.SoundWave->NumPrecacheFrames)
		, AuioDeviceID(InArgs.AudioDeviceID)
		, InstanceID(InArgs.InstanceID)
		, WaveName(InArgs.SoundWave->GetFName())
#if ENABLE_AUDIO_DEBUG
		, SampleRate(InArgs.SampleRate)
#endif // ENABLE_AUDIO_DEBUG
		, bInitialized(false)
		, bBufferFinished(false)
		, bPlayedCachedBuffer(false)
		, bIsSeeking(InArgs.bIsSeeking)
		, bLoopCallback(false)
		, bProcedural(InArgs.SoundWave->bProcedural)
		, bIsBus(InArgs.SoundWave->bIsSourceBus)
		, bForceSyncDecode(InArgs.bForceSyncDecode)
		, bHasError(false)
	{
		// TODO: remove the need to do this here. 1) remove need for decoders to depend on USoundWave and 2) remove need for procedural sounds to use USoundWaveProcedural
		InArgs.SoundWave->AddPlayingSource(this);

		// Retrieve a sound generator if this is a procedural sound wave
		if (bProcedural)
		{
			FSoundGeneratorInitParams InitParams;
			InitParams.AudioDeviceID = InArgs.AudioDeviceID;
			InitParams.AudioComponentId = InArgs.AudioComponentID;
			InitParams.SampleRate = InArgs.SampleRate;
			InitParams.AudioMixerNumOutputFrames = InArgs.AudioMixerNumOutputFrames;
			InitParams.NumChannels = NumChannels;
			InitParams.NumFramesPerCallback = MONO_PCM_BUFFER_SAMPLES;
			InitParams.InstanceID = InArgs.InstanceID;
			InitParams.bIsPreviewSound = InArgs.bIsPreviewSound;
			InitParams.StartTime = InArgs.StartTime;

			SoundGenerator = InArgs.SoundWave->CreateSoundGenerator(InitParams, MoveTemp(InDefaultParams));

			// In the case of procedural audio generation, the mixer source buffer will never "loop" -- i.e. when it's done, it's done
			LoopingMode = LOOP_Never;
		}

		const uint32 TotalSamples = MONO_PCM_BUFFER_SAMPLES * NumChannels;
		for (int32 BufferIndex = 0; BufferIndex < Audio::MAX_BUFFERS_QUEUED; ++BufferIndex)
		{
			SourceVoiceBuffers.Add(MakeShared<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe>());

			// Prepare the memory to fit the max number of samples
			SourceVoiceBuffers[BufferIndex]->AudioData.Reset(TotalSamples);
			SourceVoiceBuffers[BufferIndex]->bRealTimeBuffer = true;
			SourceVoiceBuffers[BufferIndex]->LoopCount = 0;
		}
	}

	FMixerSourceBuffer::~FMixerSourceBuffer()
	{
		// GC methods may get called from the game thread during the destructor
		// These methods will trylock and early exit if we have this lock
		FScopeLock Lock(&SoundWaveCritSec);

		// OnEndGenerate calls EnsureTaskFinishes,
		// which will make sure we have completed our async realtime task before deleting the decompression state
		OnEndGenerate();

		// Clean up decompression state after things have been finished using it
		DeleteDecoder();

		if (SoundWave)
		{
			SoundWave->RemovePlayingSource(this);
		}
	}

	void FMixerSourceBuffer::SetDecoder(ICompressedAudioInfo* InCompressedAudioInfo)
	{
		if (DecompressionState == nullptr)
		{
			DecompressionState = InCompressedAudioInfo;
		}
	}

	void FMixerSourceBuffer::SetPCMData(const FRawPCMDataBuffer& InPCMDataBuffer)
	{
		check(BufferType == EBufferType::PCM || BufferType == EBufferType::PCMPreview);
		RawPCMDataBuffer = InPCMDataBuffer;
	}

	void FMixerSourceBuffer::SetCachedRealtimeFirstBuffers(TArray<uint8>&& InPrecachedBuffers)
	{
		CachedRealtimeFirstBuffer = MoveTemp(InPrecachedBuffers);
	}

	bool FMixerSourceBuffer::Init()
	{
		// We have successfully initialized which means our SoundWave has been flagged as bIsActive
		// GC can run between PreInit and Init so when cleaning up FMixerSourceBuffer, we don't want to touch SoundWave unless bInitailized is true.
		// SoundWave->bIsSoundActive will prevent GC until it is released in audio render thread
		bInitialized = true;

		switch (BufferType)
		{
		case EBufferType::PCM:
		case EBufferType::PCMPreview:
			SubmitInitialPCMBuffers();
			break;

		case EBufferType::PCMRealTime:
		case EBufferType::Streaming:
			SubmitInitialRealtimeBuffers();
			break;

		case EBufferType::Invalid:
			break;
		}

		return true;
	}

	void FMixerSourceBuffer::OnBufferEnd()
	{
		FScopeTryLock Lock(&SoundWaveCritSec);

		// If the buffer is flagged as complete and there's nothing queued remaining.
		const bool bBufferCompleted = (NumBuffersQeueued == 0 && bBufferFinished);
		
		// If we're procedural we must have a procedural SoundWave pointer to continue.
		const bool bProceduralStateBad = (bProcedural && !SoundWave);
		
		// If we're non-procedural and we don't have a decoder, bail. This can happen when the wave is GC'd.
		// The Decoder and SoundWave is deleted on the GameThread via FMixerSourceBuffer::OnBeginDestroy
		// Although this is bad state it's not an error, so just bail here.
		const bool bDecompressionStateBad = (!bProcedural && DecompressionState == nullptr);

		if (!Lock.IsLocked() || bBufferCompleted || bProceduralStateBad || bDecompressionStateBad || bHasError )
		{
			return;
		}

		ProcessRealTimeSource();
	}

	int32 FMixerSourceBuffer::GetNumBuffersQueued() const
	{
		FScopeTryLock Lock(&SoundWaveCritSec);
		if (Lock.IsLocked())
		{
			return NumBuffersQeueued;
		}

		return 0;
	}

	TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe> FMixerSourceBuffer::GetNextBuffer()
	{
		FScopeTryLock Lock(&SoundWaveCritSec);
		if (!Lock.IsLocked())
		{
			return nullptr;
		}

		TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe> NewBufferPtr;
		BufferQueue.Dequeue(NewBufferPtr);
		--NumBuffersQeueued;
		return NewBufferPtr;
	}

	void FMixerSourceBuffer::SubmitInitialPCMBuffers()
	{
		CurrentBuffer = 0;

		RawPCMDataBuffer.NumSamples = RawPCMDataBuffer.DataSize / sizeof(int16);
		RawPCMDataBuffer.CurrentSample = 0;

		// Only submit data if we've successfully loaded it
		if (!RawPCMDataBuffer.Data || !RawPCMDataBuffer.DataSize)
		{
			return;
		}

		RawPCMDataBuffer.LoopCount = (LoopingMode != LOOP_Never) ? Audio::LOOP_FOREVER : 0;

		// Submit the first two format-converted chunks to the source voice
		const uint32 NumSamplesPerBuffer = MONO_PCM_BUFFER_SAMPLES * NumChannels;
		int16* RawPCMBufferDataPtr = (int16*)RawPCMDataBuffer.Data;

		// Prepare the buffer for the PCM submission
		SourceVoiceBuffers[0]->AudioData.Reset(NumSamplesPerBuffer);
		SourceVoiceBuffers[0]->AudioData.AddZeroed(NumSamplesPerBuffer);

		RawPCMDataBuffer.GetNextBuffer(SourceVoiceBuffers[0].Get(), NumSamplesPerBuffer);

		SubmitBuffer(SourceVoiceBuffers[0]);

		CurrentBuffer = 1;
	}

	void FMixerSourceBuffer::SubmitInitialRealtimeBuffers()
	{
		static_assert(PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS <= 2 && PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS >= 0, "Unsupported number of precache buffers.");

		CurrentBuffer = 0;

		bPlayedCachedBuffer = false;
		if (!bIsSeeking && CachedRealtimeFirstBuffer.Num() > 0)
		{
			bPlayedCachedBuffer = true;

			const uint32 NumSamples = NumPrecacheFrames * NumChannels;
			const uint32 BufferSize = NumSamples * sizeof(int16);

			// Format convert the first cached buffers
#if (PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS == 2)
			{
				// Prepare the precache buffer memory
				for (int32 i = 0; i < 2; ++i)
				{
					SourceVoiceBuffers[i]->AudioData.Reset();
					SourceVoiceBuffers[i]->AudioData.AddZeroed(NumSamples);
				}

				int16* CachedBufferPtr0 = (int16*)CachedRealtimeFirstBuffer.GetData();
				int16* CachedBufferPtr1 = (int16*)(CachedRealtimeFirstBuffer.GetData() + BufferSize);
				float* AudioData0 = SourceVoiceBuffers[0]->AudioData.GetData();
				float* AudioData1 = SourceVoiceBuffers[1]->AudioData.GetData();

				Audio::ArrayPcm16ToFloat(MakeArrayView(CachedBufferPtr0, NumSamples), MakeArrayView(AudioData0, NumSamples));
				Audio::ArrayPcm16ToFloat(MakeArrayView(CachedBufferPtr1, NumSamples), MakeArrayView(AudioData1, NumSamples));

				// Submit the already decoded and cached audio buffers
				SubmitBuffer(SourceVoiceBuffers[0]);
				SubmitBuffer(SourceVoiceBuffers[1]);

				CurrentBuffer = 2;
			}
#elif (PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS == 1)
			{
				SourceVoiceBuffers[0]->AudioData.Reset();
				SourceVoiceBuffers[0]->AudioData.AddZeroed(NumSamples);

				int16* CachedBufferPtr0 = (int16*)CachedRealtimeFirstBuffer.GetData();
				float* AudioData0 = SourceVoiceBuffers[0]->AudioData.GetData();
				Audio::ArrayPcm16ToFloat(MakeArrayView(CachedBufferPtr0, NumSamples), MakeArrayView(AudioData0, NumSamples));

				// Submit the already decoded and cached audio buffers
				SubmitBuffer(SourceVoiceBuffers[0]);

				CurrentBuffer = 1;
			}
#endif
		}
		else if (!bIsBus)
		{
			ProcessRealTimeSource();
		}
	}

	bool FMixerSourceBuffer::ReadMoreRealtimeData(ICompressedAudioInfo* InDecoder, const int32 BufferIndex, EBufferReadMode BufferReadMode)
	{
		const int32 MaxSamples = MONO_PCM_BUFFER_SAMPLES * NumChannels;

		SourceVoiceBuffers[BufferIndex]->AudioData.Reset();
		SourceVoiceBuffers[BufferIndex]->AudioData.AddUninitialized(MaxSamples);

		if (bProcedural)
		{
			FScopeTryLock Lock(&SoundWaveCritSec);
			
			if (Lock.IsLocked() && SoundWave)
			{
				FProceduralAudioTaskData NewTaskData;

				// Pass the generator instance to the async task
				if (SoundGenerator.IsValid())
				{
					NewTaskData.SoundGenerator = SoundGenerator;
				}
				else
				{
					// Otherwise pass the raw sound wave procedural ptr.
					check(SoundWave && SoundWave->bProcedural);
					NewTaskData.ProceduralSoundWave = SoundWave;
				}

				NewTaskData.AudioData = SourceVoiceBuffers[BufferIndex]->AudioData.GetData();
				NewTaskData.NumSamples = MaxSamples;
				NewTaskData.NumChannels = NumChannels;
				AsyncTaskStartTimeInCycles = FPlatformTime::Cycles64();
				check(!AsyncRealtimeAudioTask);
				AsyncRealtimeAudioTask = CreateAudioTask(AuioDeviceID, NewTaskData);
			}

			return false;
		}
		else if (BufferType != EBufferType::PCMRealTime && BufferType != EBufferType::Streaming)
		{
			check(RawPCMDataBuffer.Data != nullptr);

			// Read the next raw PCM buffer into the source buffer index. This converts raw PCM to float.
			return RawPCMDataBuffer.GetNextBuffer(SourceVoiceBuffers[BufferIndex].Get(), MaxSamples);
		}

		// Handle the case that the decoder has an error and can't continue.
		if (InDecoder && InDecoder->HasError())
		{
			FMemory::Memzero(SourceVoiceBuffers[BufferIndex]->AudioData.GetData(), MaxSamples * sizeof(float));

			FScopeTryLock Lock(&SoundWaveCritSec);
			if (Lock.IsLocked() && SoundWave)
			{
				SoundWave->SetError(TEXT("ICompressedAudioInfo::HasError() flagged on the Decoder"));
			}

			bHasError = true;
			bBufferFinished = true;
			return false;	
		}

		check(InDecoder != nullptr);

		FDecodeAudioTaskData NewTaskData;
		NewTaskData.AudioData = SourceVoiceBuffers[BufferIndex]->AudioData.GetData();
		NewTaskData.DecompressionState = InDecoder;
		NewTaskData.BufferType = BufferType;
		NewTaskData.NumChannels = NumChannels;
		NewTaskData.bLoopingMode = LoopingMode != LOOP_Never;
		NewTaskData.bSkipFirstBuffer = (BufferReadMode == EBufferReadMode::AsynchronousSkipFirstFrame);
		NewTaskData.NumFramesToDecode = MONO_PCM_BUFFER_SAMPLES;
		NewTaskData.NumPrecacheFrames = NumPrecacheFrames;
		NewTaskData.bForceSyncDecode = bForceSyncDecode;

		AsyncTaskStartTimeInCycles = FPlatformTime::Cycles64();
		FScopeLock Lock(&DecodeTaskCritSec);		
		check(!AsyncRealtimeAudioTask);
		AsyncRealtimeAudioTask = CreateAudioTask(AuioDeviceID, NewTaskData);

		return false;
	}

	void FMixerSourceBuffer::SubmitRealTimeSourceData(const bool bInIsFinishedOrLooped)
	{
		// Have we reached the end of the sound
		if (bInIsFinishedOrLooped)
		{
			switch (LoopingMode)
			{
				case LOOP_Never:
					// Play out any queued buffers - once there are no buffers left, the state check at the beginning of IsFinished will fire
					bBufferFinished = true;
					break;

				case LOOP_WithNotification:
					// If we have just looped, and we are looping, send notification
					// This will trigger a WaveInstance->NotifyFinished() in the FXAudio2SoundSournce::IsFinished() function on main thread.
					bLoopCallback = true;
					break;

				case LOOP_Forever:
					// Let the sound loop indefinitely
					break;
			}
		}

		if (SourceVoiceBuffers[CurrentBuffer]->AudioData.Num() > 0)
		{
			SubmitBuffer(SourceVoiceBuffers[CurrentBuffer]);
		}
	}

	void FMixerSourceBuffer::ProcessRealTimeSource()
	{
		FScopeLock Lock(&DecodeTaskCritSec);
		if (AsyncRealtimeAudioTask)
		{
			AsyncRealtimeAudioTask->EnsureCompletion();

			bool bIsFinishedOrLooped = false;

			switch (AsyncRealtimeAudioTask->GetType())
			{
				case EAudioTaskType::Decode:
				{
					FDecodeAudioTaskResults TaskResult;
					AsyncRealtimeAudioTask->GetResult(TaskResult);
					bIsFinishedOrLooped = TaskResult.bIsFinishedOrLooped;
#if ENABLE_AUDIO_DEBUG
					double AudioDuration = static_cast<double>(MONO_PCM_BUFFER_SAMPLES) / FMath::Max(1., static_cast<double>(SampleRate));
					UpdateCPUCoreUtilization(TaskResult.CPUDuration, AudioDuration);
#endif // ENABLE_AUDIO_DEBUG
				}
				break;

				case EAudioTaskType::Procedural:
				{
					FProceduralAudioTaskResults TaskResult;
					AsyncRealtimeAudioTask->GetResult(TaskResult);

					SourceVoiceBuffers[CurrentBuffer]->AudioData.SetNum(TaskResult.NumSamplesWritten);
					bIsFinishedOrLooped = TaskResult.bIsFinished;
#if ENABLE_AUDIO_DEBUG
					double AudioDuration = static_cast<double>(TaskResult.NumSamplesWritten) / static_cast<double>(FMath::Max(1, NumChannels * SampleRate));
					UpdateCPUCoreUtilization(TaskResult.CPUDuration, AudioDuration);
#endif // ENABLE_AUDIO_DEBUG

					// Set the render cost encountered during the last render
					SetRelativeRenderCost(TaskResult.RelativeRenderCost);
				}
				break;
			}

			delete AsyncRealtimeAudioTask;
			AsyncRealtimeAudioTask = nullptr;
			AsyncTaskStartTimeInCycles = 0;

			SubmitRealTimeSourceData(bIsFinishedOrLooped);
		}

		if (FAudioDeviceManager* ADM = FAudioDeviceManager::Get())
		{
			if (FAudioDevice* AudioDevice = ADM->GetAudioDeviceRaw(AuioDeviceID))
			{
				UAudioBusSubsystem* AudioBusSubsystem = AudioDevice->GetSubsystem<UAudioBusSubsystem>();
				check(AudioBusSubsystem);
				AudioBusSubsystem->ConnectPatches(InstanceID);
			}
		}

		if (!AsyncRealtimeAudioTask)
		{
			// Update the buffer index
			if (++CurrentBuffer > 2)
			{
				CurrentBuffer = 0;
			}

			EBufferReadMode DataReadMode;
			if (bPlayedCachedBuffer)
			{
				bPlayedCachedBuffer = false;
				DataReadMode = EBufferReadMode::AsynchronousSkipFirstFrame;
			}
			else
			{
				DataReadMode = EBufferReadMode::Asynchronous;
			}

			const bool bIsFinishedOrLooped = ReadMoreRealtimeData(DecompressionState, CurrentBuffer, DataReadMode);

			// If this was a synchronous read, then immediately write it
			if (AsyncRealtimeAudioTask == nullptr && !bHasError)
			{
				SubmitRealTimeSourceData(bIsFinishedOrLooped);
			}
		}
	}

	void FMixerSourceBuffer::SubmitBuffer(TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe> InSourceVoiceBuffer)
	{
		NumBuffersQeueued++;
		BufferQueue.Enqueue(InSourceVoiceBuffer);
	}

	void FMixerSourceBuffer::DeleteDecoder()
	{
		// Clean up decompression state after things have been finished using it
		if (DecompressionState)
		{
			delete DecompressionState;
			DecompressionState = nullptr;
		}
	}

	bool FMixerSourceBuffer::OnBeginDestroy(USoundWave* /*Wave*/)
	{
		FScopeTryLock Lock(&SoundWaveCritSec);

		// if we don't have the lock, it means we are in ~FMixerSourceBuffer() on another thread
		if (Lock.IsLocked() && SoundWave)
		{
			EnsureAsyncTaskFinishes();
			DeleteDecoder();
			ClearWave();
			return true;
		}

		return false;
	}

	bool FMixerSourceBuffer::OnIsReadyForFinishDestroy(USoundWave* /*Wave*/) const
	{
		return false;
	}

	void FMixerSourceBuffer::OnFinishDestroy(USoundWave* /*Wave*/)
	{
		EnsureAsyncTaskFinishes();
		FScopeTryLock Lock(&SoundWaveCritSec);

		// if we don't have the lock, it means we are in ~FMixerSourceBuffer() on another thread
		if (Lock.IsLocked() && SoundWave)
		{
			DeleteDecoder();
			ClearWave();
		}
	}

	bool FMixerSourceBuffer::IsAsyncTaskInProgress() const
	{ 
		FScopeLock Lock(&DecodeTaskCritSec);
		return AsyncRealtimeAudioTask != nullptr;
	}

	bool FMixerSourceBuffer::IsAsyncTaskDone() const
	{
		FScopeLock Lock(&DecodeTaskCritSec);
		if (AsyncRealtimeAudioTask)
		{
			return AsyncRealtimeAudioTask->IsDone();
		}
		return true;
	}

	bool FMixerSourceBuffer::IsGeneratorFinished() const
	{
		return bProcedural && SoundGenerator.IsValid() && SoundGenerator->IsFinished();
	}

	float FMixerSourceBuffer::GetRelativeRenderCost() const
	{
		return RelativeRenderCost.load(std::memory_order_relaxed);
	}

	void FMixerSourceBuffer::SetRelativeRenderCost(float InRelativeRenderCost)
	{
		RelativeRenderCost.store(InRelativeRenderCost, std::memory_order_relaxed);
	}

#if ENABLE_AUDIO_DEBUG
	double FMixerSourceBuffer::GetCPUCoreUtilization() const
	{
		return CPUCoreUtilization.load(std::memory_order_relaxed);
	}

	void FMixerSourceBuffer::UpdateCPUCoreUtilization(double InCPUTime, double InAudioTime) 
	{
		constexpr double AnalysisTime = 1.0;

		if (InAudioTime > 0.0)
		{
			double NewUtilization = InCPUTime / InAudioTime;
			
			// Determine smoothing coefficients based upon duration of audio being rendered.
			const double DigitalCutoff = 1.0 / FMath::Max(1., AnalysisTime / InAudioTime);
			const double SmoothingBeta = FMath::Clamp(FMath::Exp(-UE_PI * DigitalCutoff), 0.0, 1.0 - UE_DOUBLE_SMALL_NUMBER);

			double PriorUtilization = CPUCoreUtilization.load(std::memory_order_relaxed);
			
			// Smooth value if utilization has been initialized.
			if (PriorUtilization > 0.0)
			{
				NewUtilization = (1.0 - SmoothingBeta) * NewUtilization + SmoothingBeta * PriorUtilization;
			}
			CPUCoreUtilization.store(NewUtilization, std::memory_order_relaxed);
		}
	}
#endif // ENABLE_AUDIO_DEBUG

	void FMixerSourceBuffer::GetDiagnosticState(FDiagnosticState& OutState)
	{
		// Query without a lock!
		OutState.bInFlight = AsyncRealtimeAudioTask != nullptr;
		OutState.WaveName = WaveName;
		OutState.bProcedural = bProcedural;
		OutState.RunTimeInSecs = OutState.bInFlight ?
			FPlatformTime::ToSeconds(FPlatformTime::Cycles64() - this->AsyncTaskStartTimeInCycles) :
			0.f;
	}

	void FMixerSourceBuffer::EnsureAsyncTaskFinishes()
	{
		FScopeLock Lock(&DecodeTaskCritSec);
		if (AsyncRealtimeAudioTask)
		{
			AsyncRealtimeAudioTask->CancelTask();

			delete AsyncRealtimeAudioTask;
			AsyncRealtimeAudioTask = nullptr;
		}
	}

	void FMixerSourceBuffer::OnBeginGenerate()
	{
		FScopeTryLock Lock(&SoundWaveCritSec);
		if (!Lock.IsLocked())
		{
			return;
		}

		if (SoundGenerator.IsValid())
		{
			SoundGenerator->OnBeginGenerate();
		}
		else
		{
			if (SoundWave && bProcedural)
			{
				check(SoundWave && SoundWave->bProcedural);
				SoundWave->OnBeginGenerate();
			}
		}
	}

	void FMixerSourceBuffer::OnEndGenerate()
	{
		// Make sure the async task finishes!
		EnsureAsyncTaskFinishes();

		FScopeTryLock Lock(&SoundWaveCritSec);
		if (!Lock.IsLocked())
		{
			return;
		}

		if (SoundGenerator.IsValid())
		{
			SoundGenerator->OnEndGenerate();
			if (SoundWave)
			{
				SoundWave->OnEndGenerate(SoundGenerator);
			}

			if (FAudioDeviceManager* ADM = FAudioDeviceManager::Get())
			{
				if (FAudioDevice* AudioDevice = ADM->GetAudioDeviceRaw(AuioDeviceID))
				{
					UAudioBusSubsystem* AudioBusSubsystem = AudioDevice->GetSubsystem<UAudioBusSubsystem>();
					check(AudioBusSubsystem);
					AudioBusSubsystem->RemoveSound(InstanceID);
				}
			}
		}
		else
		{
			// Only need to call OnEndGenerate and access SoundWave here if we successfully initialized
			if (SoundWave && bInitialized && bProcedural)
			{
				check(SoundWave && SoundWave->bProcedural);
				SoundWave->OnEndGenerate();
			}
		}
	}

}

==================================


=== AudioMixerSourceBuffer.h ===
================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "AudioMixerBuffer.h"
#include "AudioMixerSourceManager.h"
#include "Sound/SoundWave.h"
#include "Sound/SoundGenerator.h"

namespace Audio
{
	struct FMixerSourceVoiceBuffer;

	static const int32 MAX_BUFFERS_QUEUED = 3;
	static const int32 LOOP_FOREVER = -1;

	struct FRawPCMDataBuffer
	{
		uint8* Data;
		uint32 DataSize;
		int32 LoopCount;
		uint32 CurrentSample;
		uint32 NumSamples;

		bool GetNextBuffer(FMixerSourceVoiceBuffer* OutSourceBufferPtr, const uint32 NumSampleToGet);

		FRawPCMDataBuffer()
			: Data(nullptr)
			, DataSize(0)
			, LoopCount(0)
			, CurrentSample(0)
			, NumSamples(0)
		{}
	};

	/** Enum describing the data-read mode of an audio buffer. */
	enum class EBufferReadMode : uint8
	{
		/** Read the next buffer asynchronously. */
		Asynchronous,

		/** Read the next buffer asynchronously but skip the first chunk of audio. */
		AsynchronousSkipFirstFrame
	};

	using FMixerSourceBufferPtr = TSharedPtr<class FMixerSourceBuffer, ESPMode::ThreadSafe>;

	struct FMixerSourceBufferInitArgs
	{
		FDeviceId AudioDeviceID = 0;
		uint64 AudioComponentID = 0;
		uint64 InstanceID = 0;
		int32 SampleRate = 0;
		int32 AudioMixerNumOutputFrames = 0;
		FMixerBuffer* Buffer = nullptr;
		USoundWave* SoundWave = nullptr;
		ELoopingMode LoopingMode = ELoopingMode::LOOP_Never;
		float StartTime = 0.0f;
		bool bIsSeeking = false;
		bool bForceSyncDecode = false;
		bool bIsPreviewSound = false;
	};

	/** Class which handles decoding audio for a particular source buffer. */
	class FMixerSourceBuffer : public ISoundWaveClient
	{
	public:
		static FMixerSourceBufferPtr Create(FMixerSourceBufferInitArgs& InArgs, TArray<FAudioParameter>&& InDefaultParams=TArray<FAudioParameter>());

		~FMixerSourceBuffer();

		bool Init();

		// Sets the decoder to use for realtime async decoding
		void SetDecoder(ICompressedAudioInfo* InCompressedAudioInfo);

		// Sets the raw PCM data buffer to use for the source buffer
		void SetPCMData(const FRawPCMDataBuffer& InPCMDataBuffer);

		// Sets the precached buffers
		void SetCachedRealtimeFirstBuffers(TArray<uint8>&& InPrecachedBuffer);

		// Called by source manager when needing more buffers
		void OnBufferEnd();

		// Return the number of buffers enqueued on the mixer source buffer
		int32 GetNumBuffersQueued() const;

		// Returns the next enqueued buffer, returns nullptr if no buffers enqueued
		TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe> GetNextBuffer();

		// Returns if buffer looped
		bool DidBufferLoop() const { return bLoopCallback; }

		// Returns true if buffer finished
		bool DidBufferFinish() const { return bBufferFinished; }

		// Called to start an async task to read more data
		bool ReadMoreRealtimeData(ICompressedAudioInfo* InDecoder, int32 BufferIndex, EBufferReadMode BufferReadMode);

		// Returns true if async task is in progress
		bool IsAsyncTaskInProgress() const;

		// Returns true if the async task is done
		bool IsAsyncTaskDone() const;

		// Returns some diagnostic state
		struct FDiagnosticState
		{
			FName WaveName;
			float RunTimeInSecs=0.f;
			bool bInFlight=false;
			bool bProcedural=false;
		};
		void GetDiagnosticState(FDiagnosticState& OutState);

		// Ensures the async task finishes
		void EnsureAsyncTaskFinishes();

		// Begin and end generation on the audio render thread (audio mixer only)
		void OnBeginGenerate();
		void OnEndGenerate();
		void ClearWave() { SoundWave = nullptr; }

		// Returns whether or not generator is finished (returns false if generator is invalid)
		bool IsGeneratorFinished() const;
#if ENABLE_AUDIO_DEBUG
		double GetCPUCoreUtilization() const;
#endif // ENABLE_AUDIO_DEBUG

		// Returns the runtime render cost
		float GetRelativeRenderCost() const;

	private:
		FMixerSourceBuffer(FMixerSourceBufferInitArgs& InArgs, TArray<FAudioParameter>&& InDefaultParams);

		void SubmitInitialPCMBuffers();
		void SubmitInitialRealtimeBuffers();
		void SubmitRealTimeSourceData(const bool bFinishedOrLooped);
		void ProcessRealTimeSource();
		void SubmitBuffer(TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe> InSourceVoiceBuffer);
		void DeleteDecoder();


		int32 NumBuffersQeueued;
		FRawPCMDataBuffer RawPCMDataBuffer;

		TArray<TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe>> SourceVoiceBuffers;
		TQueue<TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe>> BufferQueue;
		int32 CurrentBuffer;
		// SoundWaves are only set for procedural sound waves
		USoundWave* SoundWave;
		ISoundGeneratorPtr SoundGenerator;
		IAudioTask* AsyncRealtimeAudioTask;
		ICompressedAudioInfo* DecompressionState;
		ELoopingMode LoopingMode;
		int32 NumChannels;
		Audio::EBufferType::Type BufferType;
		int32 NumPrecacheFrames;
		Audio::FDeviceId AuioDeviceID;
		uint64 InstanceID;
		TArray<uint8> CachedRealtimeFirstBuffer;
		FName WaveName;
		uint64 AsyncTaskStartTimeInCycles=0;

#if ENABLE_AUDIO_DEBUG
		int32 SampleRate = 0;
		std::atomic<double> CPUCoreUtilization = 0.0;
		void UpdateCPUCoreUtilization(double InCPUTime, double InAudioTime);
#endif // ENABLE_AUDIO_DEBUG

		std::atomic<float> RelativeRenderCost = 1.0f;
		void SetRelativeRenderCost(float InRelativeRenderCost);

		mutable FCriticalSection SoundWaveCritSec;
		mutable FCriticalSection DecodeTaskCritSec;

		uint32 bInitialized : 1;
		uint32 bBufferFinished : 1;
		uint32 bPlayedCachedBuffer : 1;
		uint32 bIsSeeking : 1;
		uint32 bLoopCallback : 1;
		uint32 bProcedural : 1;
		uint32 bIsBus : 1;
		uint32 bForceSyncDecode : 1;
		uint32 bHasError : 1;
		
		virtual bool OnBeginDestroy(class USoundWave* Wave) override;
		virtual bool OnIsReadyForFinishDestroy(class USoundWave* Wave) const override;
		virtual void OnFinishDestroy(class USoundWave* Wave) override;
	};
}

================================


=== AudioMixerSourceDecode.cpp ===
==================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerSourceDecode.h"
#include "CoreMinimal.h"
#include "Stats/Stats.h"
#include "AudioMixer.h"
#include "Sound/SoundWaveProcedural.h"
#include "HAL/RunnableThread.h"
#include "AudioMixerBuffer.h"
#include "Async/Async.h"
#include "AudioDecompress.h"
#include "Sound/SoundGenerator.h"
#include "DSP/FloatArrayMath.h"

static int32 ForceSyncAudioDecodesCvar = 0;
FAutoConsoleVariableRef CVarForceSyncAudioDecodes(
	TEXT("au.ForceSyncAudioDecodes"),
	ForceSyncAudioDecodesCvar,
	TEXT("Disables using async tasks for processing sources.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 ForceSynchronizedAudioTaskKickCvar = 0;
FAutoConsoleVariableRef CVarForceSynchronizedAudioTaskKick(
	TEXT("au.ForceSynchronizedAudioTaskKick"),
	ForceSynchronizedAudioTaskKickCvar,
	TEXT("Force all Audio Tasks created in one \"audio render frame\" to be queued until they can all be \"kicked\" at once at the end of the frame.\n")
	TEXT("0: Don't Force, 1: Force"),
	ECVF_Default);

namespace Audio
{

class FAsyncDecodeWorker : public FNonAbandonableTask
{
#if ENABLE_AUDIO_DEBUG
	struct FScopeDecodeTimer
	{
		FScopeDecodeTimer(double* OutResultSeconds)
		: Result(OutResultSeconds)
		{
			StartCycle = FPlatformTime::Cycles64();
		}
		~FScopeDecodeTimer()
		{
			uint64 EndCycle = FPlatformTime::Cycles64();
			if (Result)
			{
				*Result = static_cast<double>(EndCycle - StartCycle) * FPlatformTime::GetSecondsPerCycle64();
			}
		}

		double* Result = nullptr;
		uint64 StartCycle = 0;
	};

#endif // if ENABLE_AUDIO_DEBUG

public:
	FAsyncDecodeWorker(const FHeaderParseAudioTaskData& InTaskData)
		: HeaderParseAudioData(InTaskData)
		, TaskType(EAudioTaskType::Header)
		, bIsDone(false)
	{
	}

	FAsyncDecodeWorker(const FProceduralAudioTaskData& InTaskData)
		: ProceduralTaskData(InTaskData)
		, TaskType(EAudioTaskType::Procedural)
		, bIsDone(false)
	{
	}

	FAsyncDecodeWorker(const FDecodeAudioTaskData& InTaskData)
		: DecodeTaskData(InTaskData)
		, TaskType(EAudioTaskType::Decode)
		, bIsDone(false)
	{
	}

	~FAsyncDecodeWorker()
	{
	}

	void DoWork()
	{
		FScopedFTZFloatMode FTZ;

		switch (TaskType)
		{
			case EAudioTaskType::Procedural:
			{
#if ENABLE_AUDIO_DEBUG
				FScopeDecodeTimer Timer(&ProceduralResult.CPUDuration);
#endif // if ENABLE_AUDIO_DEBUG
				QUICK_SCOPE_CYCLE_COUNTER(STAT_FAsyncDecodeWorker_Procedural);
				if (ProceduralTaskData.SoundGenerator.IsValid())
				{
					// Generators are responsible to zero memory in case they can't generate the requested amount of samples
					ProceduralResult.NumSamplesWritten = ProceduralTaskData.SoundGenerator->GetNextBuffer(ProceduralTaskData.AudioData, ProceduralTaskData.NumSamples);
					ProceduralResult.bIsFinished = ProceduralTaskData.SoundGenerator->IsFinished();
					ProceduralResult.RelativeRenderCost = ProceduralTaskData.SoundGenerator->GetRelativeRenderCost();
				}
				else
				{
					// Make sure we've been flagged as active
					if (!ProceduralTaskData.ProceduralSoundWave || !ProceduralTaskData.ProceduralSoundWave->IsGeneratingAudio())
					{
						// Act as if we generated audio, but return silence.
						FMemory::Memzero(ProceduralTaskData.AudioData, ProceduralTaskData.NumSamples * sizeof(float));
						ProceduralResult.NumSamplesWritten = ProceduralTaskData.NumSamples;
						return;
					}

					// If we're not a float format, we need to convert the format to float
					const EAudioMixerStreamDataFormat::Type FormatType = ProceduralTaskData.ProceduralSoundWave->GetGeneratedPCMDataFormat();
					if (FormatType != EAudioMixerStreamDataFormat::Float)
					{
						check(FormatType == EAudioMixerStreamDataFormat::Int16);

						int32 NumChannels = ProceduralTaskData.NumChannels;
						int32 ByteSize = NumChannels * ProceduralTaskData.NumSamples * sizeof(int16);

						TArray<uint8> DecodeBuffer;
						DecodeBuffer.AddUninitialized(ByteSize);

						const int32 NumBytesWritten = ProceduralTaskData.ProceduralSoundWave->GeneratePCMData(DecodeBuffer.GetData(), ProceduralTaskData.NumSamples);

						check(NumBytesWritten <= ByteSize);

						ProceduralResult.NumSamplesWritten = NumBytesWritten / sizeof(int16);
						Audio::ArrayPcm16ToFloat(MakeArrayView((int16*)DecodeBuffer.GetData(), ProceduralResult.NumSamplesWritten)
							, MakeArrayView(ProceduralTaskData.AudioData, ProceduralResult.NumSamplesWritten));
					}
					else
					{
						const int32 NumBytesWritten = ProceduralTaskData.ProceduralSoundWave->GeneratePCMData((uint8*)ProceduralTaskData.AudioData, ProceduralTaskData.NumSamples);
						ProceduralResult.NumSamplesWritten = NumBytesWritten / sizeof(float);
					}
				}
			}
			break;

			case EAudioTaskType::Header:
			{
				QUICK_SCOPE_CYCLE_COUNTER(STAT_FAsyncDecodeWorker_Header);
				HeaderParseAudioData.MixerBuffer->ReadCompressedInfo(HeaderParseAudioData.SoundWave);
			}
			break;

			case EAudioTaskType::Decode:
			{
#if ENABLE_AUDIO_DEBUG
				FScopeDecodeTimer Timer(&DecodeResult.CPUDuration);
#endif // if ENABLE_AUDIO_DEBUG
				QUICK_SCOPE_CYCLE_COUNTER(STAT_FAsyncDecodeWorker_Decode);
				int32 NumChannels = DecodeTaskData.NumChannels;
				int32 ByteSize = NumChannels * DecodeTaskData.NumFramesToDecode * sizeof(int16);

				// Create a buffer to decode into that's of the appropriate size
				TArray<uint8> DecodeBuffer;
				DecodeBuffer.AddZeroed(ByteSize);

#if PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS
				// skip the first buffers if we've already decoded them during Precache:
				if (DecodeTaskData.bSkipFirstBuffer)
				{
					const int32 kPCMBufferSize = NumChannels * DecodeTaskData.NumPrecacheFrames * sizeof(int16);
					int32 NumBytesStreamed = kPCMBufferSize;
					if (DecodeTaskData.BufferType == EBufferType::Streaming)
					{
						for (int32 NumberOfBuffersToSkip = 0; NumberOfBuffersToSkip < PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS; NumberOfBuffersToSkip++)
						{
							DecodeTaskData.DecompressionState->StreamCompressedData(DecodeBuffer.GetData(), DecodeTaskData.bLoopingMode, kPCMBufferSize, NumBytesStreamed);
						}
					}
					else
					{
						for (int32 NumberOfBuffersToSkip = 0; NumberOfBuffersToSkip < PLATFORM_NUM_AUDIODECOMPRESSION_PRECACHE_BUFFERS; NumberOfBuffersToSkip++)
						{
							DecodeTaskData.DecompressionState->ReadCompressedData(DecodeBuffer.GetData(), DecodeTaskData.bLoopingMode, kPCMBufferSize);
						}
					}
				}
#endif

				const int32 kPCMBufferSize = NumChannels * DecodeTaskData.NumFramesToDecode * sizeof(int16);
				int32 NumBytesStreamed = kPCMBufferSize;
				if (DecodeTaskData.BufferType == EBufferType::Streaming)
				{
					DecodeResult.bIsFinishedOrLooped = DecodeTaskData.DecompressionState->StreamCompressedData(DecodeBuffer.GetData(), DecodeTaskData.bLoopingMode, kPCMBufferSize, NumBytesStreamed);
				}
				else
				{
					DecodeResult.bIsFinishedOrLooped = DecodeTaskData.DecompressionState->ReadCompressedData(DecodeBuffer.GetData(), DecodeTaskData.bLoopingMode, kPCMBufferSize);
				}

				// Convert the decoded PCM data into a float buffer while still in the async task
				Audio::ArrayPcm16ToFloat(MakeArrayView((int16*)DecodeBuffer.GetData(), DecodeTaskData.NumFramesToDecode * NumChannels)
					, MakeArrayView(DecodeTaskData.AudioData, DecodeTaskData.NumFramesToDecode* NumChannels));
			}
			break;
		}
		bIsDone = true;
	}

	FORCEINLINE TStatId GetStatId() const
	{
		RETURN_QUICK_DECLARE_CYCLE_STAT(FAsyncDecodeWorker, STATGROUP_ThreadPoolAsyncTasks);
	}

	FHeaderParseAudioTaskData HeaderParseAudioData;
	FDecodeAudioTaskData DecodeTaskData;
	FDecodeAudioTaskResults DecodeResult;
	FProceduralAudioTaskData ProceduralTaskData;
	FProceduralAudioTaskResults ProceduralResult;
	EAudioTaskType TaskType;
	FThreadSafeBool bIsDone;
};

class FDecodeHandleBase : public IAudioTask
{
public:
	FDecodeHandleBase()
		: Task(nullptr)
	{}

	virtual ~FDecodeHandleBase()
	{
		if (Task)
		{
			Task->EnsureCompletion(/*bIsLatencySensitive =*/ true);
			delete Task;
		}
	}

	virtual bool IsDone() const override
	{
		if (Task)
		{
			return Task->IsDone();
		}
		return true;
	}

	virtual void EnsureCompletion() override
	{
		if (Task)
		{
			Task->EnsureCompletion(/*bIsLatencySensitive =*/ true);
		}
	}

	virtual void CancelTask() override
	{
		if (Task)
		{
			// If Cancel returns false, it means we weren't able to cancel. So lets then fallback to ensure complete.
			if (!Task->Cancel())
			{
				Task->EnsureCompletion(/*bIsLatencySensitive =*/ true);
			}
		}
	}

protected:

	FAsyncTask<FAsyncDecodeWorker>* Task;
};

class FHeaderDecodeHandle : public FDecodeHandleBase
{
public:
	FHeaderDecodeHandle(const FHeaderParseAudioTaskData& InJobData)
	{
		Task = new FAsyncTask<FAsyncDecodeWorker>(InJobData);
        if (ForceSyncAudioDecodesCvar)
        {
            Task->StartSynchronousTask();
            return;
        }
        
		Task->StartBackgroundTask();
	}

	virtual EAudioTaskType GetType() const override
	{
		return EAudioTaskType::Header;
	}
};

class FProceduralDecodeHandle : public FDecodeHandleBase
{
public:
	FProceduralDecodeHandle(const FProceduralAudioTaskData& InJobData)
	{
		Task = new FAsyncTask<FAsyncDecodeWorker>(InJobData);
        if (ForceSyncAudioDecodesCvar || InJobData.bForceSyncDecode)
        {
            Task->StartSynchronousTask();
            return;
        }
        
		// We tried using the background priority thread pool
		// like other async audio decodes
		// but that resulted in underruns, see FORT-700578
		Task->StartBackgroundTask();
	}

	virtual EAudioTaskType GetType() const override
	{ 
		return EAudioTaskType::Procedural; 
	}

	virtual void GetResult(FProceduralAudioTaskResults& OutResult) override
	{
		Task->EnsureCompletion();
		const FAsyncDecodeWorker& DecodeWorker = Task->GetTask();
		OutResult = DecodeWorker.ProceduralResult;
	}
};

class FSynchronizedProceduralDecodeHandle : public FDecodeHandleBase
{
public:
	FSynchronizedProceduralDecodeHandle(const FProceduralAudioTaskData& InJobData, AudioTaskQueueId InQueueId)
	{
		Task = new FAsyncTask<FAsyncDecodeWorker>(InJobData);
		QueueId = InQueueId; 
		{
			FScopeLock Lock(&SynchronizationQuequesLockCs);
			TArray<FAsyncTask<FAsyncDecodeWorker>*>* Queue = ProceduralRenderingSynchronizationQueues.Find(QueueId);
			if (Queue)
			{
				Queue->Add(Task);
				return;
			}
		}

		// failed to queue it up, so do a normal start...
		QueueId = 0;
		if (ForceSyncAudioDecodesCvar || InJobData.bForceSyncDecode)
		{
			Task->StartSynchronousTask();
			return;
		}
		Task->StartBackgroundTask();
	}

	virtual EAudioTaskType GetType() const override
	{
		return EAudioTaskType::Procedural;
	}

	virtual bool IsDone() const override
	{
		if (IsQueued())
		{
			return false;
		}
		return FDecodeHandleBase::IsDone();
	}

	bool IsQueued() const
	{
		if (!QueueId)
		{
			return false;
		}
		FScopeLock Lock(&SynchronizationQuequesLockCs);
		TArray<FAsyncTask<FAsyncDecodeWorker>*>* Queue = ProceduralRenderingSynchronizationQueues.Find(QueueId);
		return (Queue && Queue->Find(Task) != INDEX_NONE);
	}

	bool Dequeue(bool Run)
	{
		FScopeLock Lock(&SynchronizationQuequesLockCs);
		TArray<FAsyncTask<FAsyncDecodeWorker>*>* Queue = ProceduralRenderingSynchronizationQueues.Find(QueueId);
		if (!Queue)
		{
			return false;
		}
		int NumRemoved = Queue->Remove(Task);
		if (NumRemoved > 0)
		{
			if (Run)
			{
				Task->StartBackgroundTask();
			}
			return true;
		}
		return false;
	}

	virtual void EnsureCompletion() override
	{
		{
			FScopeLock Lock(&SynchronizationQuequesLockCs);
			// For now, if this is in the queue still (not kicked)
			// we're going to pull it out of the queue and run it now.
			// This seems to only happen when first starting a sound as 
			// the system tries to decode the first chunk of audio 
			// asynchronously to the audio thread. 
			Dequeue(/* Run */ true);
			// Now we can wait on it to complete...
		}
		if (Task)
		{
			Task->EnsureCompletion(/*bIsLatencySensitive =*/ true);
		}
	}

	virtual void CancelTask() override
	{
		{
			FScopeLock Lock(&SynchronizationQuequesLockCs);
			// If we dequeue it then it never ran and we are done. Otherwise...
			if (!Dequeue(/* Run */ false))
			{
				FDecodeHandleBase::CancelTask();
			}
		}
	}

	virtual void GetResult(FProceduralAudioTaskResults& OutResult) override
	{
		Task->EnsureCompletion();
		const FAsyncDecodeWorker& DecodeWorker = Task->GetTask();
		OutResult = DecodeWorker.ProceduralResult;
	}

	static void CreateSynchronizedRenderQueued(AudioTaskQueueId QueueId)
	{
		FScopeLock Lock(&SynchronizationQuequesLockCs);
		TArray<FAsyncTask<FAsyncDecodeWorker>*>* Queue = ProceduralRenderingSynchronizationQueues.Find(QueueId);
		if (!Queue)
		{
			ProceduralRenderingSynchronizationQueues.Add(QueueId);
			ProceduralRenderingSynchronizationQueues[QueueId].Reserve(128);
		}
	}

	static void DestroySynchronizedRenderQueued(AudioTaskQueueId QueueId, bool RunCurrentQueue = false)
	{
		FScopeLock Lock(&SynchronizationQuequesLockCs);
		
		if (RunCurrentQueue)
		{
			KickQueuedTasks(QueueId);
		}

		TArray<FAsyncTask<FAsyncDecodeWorker>*>* Queue = ProceduralRenderingSynchronizationQueues.Find(QueueId);
		if (Queue)
		{
			ProceduralRenderingSynchronizationQueues.Remove(QueueId);
		}
	}

	static int KickQueuedTasks(AudioTaskQueueId QueueId)
	{
		FScopeLock Lock(&SynchronizationQuequesLockCs);
		int NumStarted = 0;
		TArray<FAsyncTask<FAsyncDecodeWorker>*>* Queue = ProceduralRenderingSynchronizationQueues.Find(QueueId);
		if (Queue)
		{
			for (auto Task : *Queue)
			{ 
				Task->StartBackgroundTask();
			}
			NumStarted = Queue->Num();
			Queue->Empty();
		}
		return NumStarted;
	}
private:
	AudioTaskQueueId QueueId = 0;

	static TMap <AudioTaskQueueId, TArray<FAsyncTask<FAsyncDecodeWorker>*>> ProceduralRenderingSynchronizationQueues;
	static FCriticalSection SynchronizationQuequesLockCs;
};

TMap <AudioTaskQueueId, TArray<FAsyncTask<FAsyncDecodeWorker>*>> FSynchronizedProceduralDecodeHandle::ProceduralRenderingSynchronizationQueues;
FCriticalSection FSynchronizedProceduralDecodeHandle::SynchronizationQuequesLockCs;

class FDecodeHandle : public FDecodeHandleBase
{
public:
	FDecodeHandle(const FDecodeAudioTaskData& InJobData)
	{
		Task = new FAsyncTask<FAsyncDecodeWorker>(InJobData);
        if (ForceSyncAudioDecodesCvar || InJobData.bForceSyncDecode)
        {
            Task->StartSynchronousTask();
            return;
        }
        
		const bool bUseBackground = ShouldUseBackgroundPoolFor_FAsyncRealtimeAudioTask();
		Task->StartBackgroundTask(bUseBackground ? GBackgroundPriorityThreadPool : GThreadPool);
	}

	virtual EAudioTaskType GetType() const override
	{ 
		return EAudioTaskType::Decode; 
	}

	virtual void GetResult(FDecodeAudioTaskResults& OutResult) override
	{
		Task->EnsureCompletion();
		const FAsyncDecodeWorker& DecodeWorker = Task->GetTask();
		OutResult = DecodeWorker.DecodeResult;
	}
};

IAudioTask* CreateAudioTask(Audio::FDeviceId InDeviceId, const FProceduralAudioTaskData& InJobData)
{
	if (ForceSynchronizedAudioTaskKickCvar || (InJobData.SoundGenerator && InJobData.SoundGenerator->GetSynchronizedRenderQueueId()))
	{
		AudioTaskQueueId QueueId = InJobData.SoundGenerator->GetSynchronizedRenderQueueId();
		if (!QueueId)
		{
			// Only use the audio device ID as the task queue id if both 
			// ForceSynchronizedAudioTaskKickCvar is true AND the caller has
			// not specified a specific task queue id in their SoundGenerator.
			QueueId = (AudioTaskQueueId)InDeviceId;
		}
		return new FSynchronizedProceduralDecodeHandle(InJobData, QueueId);
	}

	return new FProceduralDecodeHandle(InJobData);
}

IAudioTask* CreateAudioTask(Audio::FDeviceId InDeviceId, const FHeaderParseAudioTaskData& InJobData)
{
	return new FHeaderDecodeHandle(InJobData);
}

IAudioTask* CreateAudioTask(Audio::FDeviceId InDeviceId, const FDecodeAudioTaskData& InJobData)
{
	return new FDecodeHandle(InJobData);
}

void CreateSynchronizedAudioTaskQueue(AudioTaskQueueId QueueId)
{
	FSynchronizedProceduralDecodeHandle::CreateSynchronizedRenderQueued(QueueId);
}

void DestroySynchronizedAudioTaskQueue(AudioTaskQueueId QueueId, bool RunCurrentQueue)
{
	FSynchronizedProceduralDecodeHandle::DestroySynchronizedRenderQueued(QueueId, RunCurrentQueue);
}

int KickQueuedTasks(AudioTaskQueueId QueueId)
{
	return FSynchronizedProceduralDecodeHandle::KickQueuedTasks(QueueId);
}

}

==================================


=== AudioMixerSourceDecode.h ===
================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "Containers/Queue.h"
#include "Sound/SoundWaveProcedural.h"
#include "Sound/SoundGenerator.h"
#include "AudioDecompress.h"
#include "AudioMixerBuffer.h"

class USoundWave;

namespace Audio
{
	class FMixerBuffer;

	// Data needed for a procedural audio task
	struct FProceduralAudioTaskData
	{
		// The procedural sound wave ptr to use to generate audio with
		// TODO: remove the need for this
		USoundWave* ProceduralSoundWave;

		// The sound generator to use to generate audio
		ISoundGeneratorPtr SoundGenerator;

		// The audio buffer to fill from the results of the generation
		float* AudioData;

		// The size of the audio buffer
		int32 NumSamples;

		// The number of channels of the procedural buffer
		int32 NumChannels;

		// Force decodes to execute synchronously
		bool bForceSyncDecode;

		FProceduralAudioTaskData()
			: ProceduralSoundWave(nullptr)
			, AudioData(nullptr)
			, NumSamples(0)
			, NumChannels(0)
			, bForceSyncDecode(false)
		{}
	};

	// Data needed for a decode audio task
	struct FDecodeAudioTaskData
	{
		// A pointer to a buffer of audio which will be decoded to
		float* AudioData;

		// Decompression state for decoder
		ICompressedAudioInfo* DecompressionState;

		// The buffer type for the decoder
		Audio::EBufferType::Type BufferType;

		// Number of channels of the decoder
		int32 NumChannels;

		// The number of frames which are precached
		int32 NumPrecacheFrames;

		// The number of frames to decode
		int32 NumFramesToDecode;

		// Whether or not this sound is intending to be looped
		bool bLoopingMode;

		// Whether or not to skip the first buffer
		bool bSkipFirstBuffer;

		// Force this decoding operation to occur synchronously,
		// regardless of the value of au.ForceSyncAudioDecodes. (used by time synth)
		bool bForceSyncDecode;

		FDecodeAudioTaskData()
			: AudioData(nullptr)
			, DecompressionState(nullptr)
			, BufferType(Audio::EBufferType::Invalid)
			, NumChannels(0)
			, NumPrecacheFrames(0)
			, NumFramesToDecode(0)
			, bLoopingMode(false)
			, bSkipFirstBuffer(false)
			, bForceSyncDecode(false)
		{}
	};

	// Data needed for a header parse audio task
	struct FHeaderParseAudioTaskData
	{
		// The mixer buffer object which results will be written to
		FMixerBuffer* MixerBuffer;

		// The sound wave object which contains the encoded file
		USoundWave* SoundWave;

		FHeaderParseAudioTaskData()
			: MixerBuffer(nullptr)
			, SoundWave(nullptr)
		{}
	};

	// Results from procedural audio task
	struct FProceduralAudioTaskResults
	{
		int32 NumSamplesWritten;
		bool bIsFinished;
		float RelativeRenderCost = 1.f;

#if ENABLE_AUDIO_DEBUG
		double CPUDuration = 0.0;
#endif // if ENABLE_AUDIO_DEBUG

		FProceduralAudioTaskResults()
			: NumSamplesWritten(0)
			, bIsFinished(false)
		{}
	};

	// Results from decode audio task
	struct FDecodeAudioTaskResults
	{

		// Whether or not the audio buffer looped
		bool bIsFinishedOrLooped;

#if ENABLE_AUDIO_DEBUG
		double CPUDuration = 0;
#endif // if ENABLE_AUDIO_DEBUG

		FDecodeAudioTaskResults()
			: bIsFinishedOrLooped(false)
		{}
	};

	// The types of audio tasks
	enum class EAudioTaskType
	{
		// The job is a procedural sound wave job to generate more audio
		Procedural,

		// The job is a header decode job
		Header,

		// The job is a decode job
		Decode,

		// The job is invalid (or unknown)
		Invalid,
	};

	// Handle to an in-flight decode job. Can be queried and used on any thread.
	class IAudioTask
	{
	public:
		virtual ~IAudioTask() {}

		// Queries if the decode job has finished.
		virtual bool IsDone() const = 0;

		// Returns the job type of the handle.
		virtual EAudioTaskType GetType() const = 0;

		// Ensures the completion of the decode operation.
		virtual void EnsureCompletion() = 0;

		// Cancel the decode operation
		virtual void CancelTask() = 0;

		// Returns the result of a procedural sound generate job
		virtual void GetResult(FProceduralAudioTaskResults& OutResult) {};

		// Returns the result of a decode job
		virtual void GetResult(FDecodeAudioTaskResults& OutResult) {};
	};

	// Creates a task to decode a decoded file header
	IAudioTask* CreateAudioTask(Audio::FDeviceId InDeviceId, const FHeaderParseAudioTaskData& InJobData);

	// Creates a task for a procedural sound wave generation
	IAudioTask* CreateAudioTask(Audio::FDeviceId InDeviceId, const FProceduralAudioTaskData& InJobData);

	// Creates a task to decode a chunk of audio
	IAudioTask* CreateAudioTask(Audio::FDeviceId InDeviceId, const FDecodeAudioTaskData& InJobData);

	// Creates a queue for audio decode requests with a specific Id. Tasks
	// created with this Id will not be started immediately upon creation,
	// but will instead be queued up to await a start "kick" later. NOTE:
	// "kicking" the queue is the responsibility of the system that creates 
	// the queue, typically someplace like in a FOnAudioDevicePostRender delegate! 
	void CreateSynchronizedAudioTaskQueue(AudioTaskQueueId QueueId);

	// Destroys an audio decode task queue. Tasks currently queued up are 
	// optionally started.
	void DestroySynchronizedAudioTaskQueue(AudioTaskQueueId QueueId, bool RunCurrentQueue = false);

	// "Kicks" all of the audio decode tasks currentlyt in the specified queue.
	int KickQueuedTasks(AudioTaskQueueId QueueId);

}

================================


=== AudioMixerSourceManager.cpp ===
===================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerSourceManager.h"

#include "AudioDefines.h"
#include "AudioMixerSourceBuffer.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSourceVoice.h"
#include "AudioMixerSubmix.h"
#include "AudioMixerTrace.h"
#include "AudioThread.h"
#include "DSP/FloatArrayMath.h"
#include "IAudioExtensionPlugin.h"
#include "AudioMixer.h"
#include "Sound/SoundModulationDestination.h"
#include "SoundFieldRendering.h"
#include "ProfilingDebugging/CsvProfiler.h"
#include "Async/Async.h"
#include "ProfilingDebugging/CountersTrace.h"
#include "HAL/PlatformStackWalk.h"
#include "Stats/Stats.h"
#include "Trace/Trace.h"

#if WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
	#define AUDIO_MIXER_THREAD_COMMAND_STRING(X) (X)
#else //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
	#define AUDIO_MIXER_THREAD_COMMAND_STRING(X) ("")
#endif //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG

// Link to "Audio" profiling category
CSV_DECLARE_CATEGORY_MODULE_EXTERN(AUDIOMIXERCORE_API, Audio);
static int32 DisableParallelSourceProcessingCvar = 1;
FAutoConsoleVariableRef CVarDisableParallelSourceProcessing(
	TEXT("au.DisableParallelSourceProcessing"),
	DisableParallelSourceProcessingCvar,
	TEXT("Disables using async tasks for processing sources.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 DisableFilteringCvar = 0;
FAutoConsoleVariableRef CVarDisableFiltering(
	TEXT("au.DisableFiltering"),
	DisableFilteringCvar,
	TEXT("Disables using the per-source lowpass and highpass filter.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 DisableHPFilteringCvar = 0;
FAutoConsoleVariableRef CVarDisableHPFiltering(
	TEXT("au.DisableHPFiltering"),
	DisableHPFilteringCvar,
	TEXT("Disables using the per-source highpass filter.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 DisableEnvelopeFollowingCvar = 0;
FAutoConsoleVariableRef CVarDisableEnvelopeFollowing(
	TEXT("au.DisableEnvelopeFollowing"),
	DisableEnvelopeFollowingCvar,
	TEXT("Disables using the envlope follower for source envelope tracking.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 DisableSourceEffectsCvar = 0;
FAutoConsoleVariableRef CVarDisableSourceEffects(
	TEXT("au.DisableSourceEffects"),
	DisableSourceEffectsCvar,
	TEXT("Disables using any source effects.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 DisableDistanceAttenuationCvar = 0;
FAutoConsoleVariableRef CVarDisableDistanceAttenuation(
	TEXT("au.DisableDistanceAttenuation"),
	DisableDistanceAttenuationCvar,
	TEXT("Disables using any Distance Attenuation.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 BypassAudioPluginsCvar = 0;
FAutoConsoleVariableRef CVarBypassAudioPlugins(
	TEXT("au.BypassAudioPlugins"),
	BypassAudioPluginsCvar,
	TEXT("Bypasses any audio plugin processing.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 FlushCommandBufferOnTimeoutCvar = 0;
FAutoConsoleVariableRef CVarFlushCommandBufferOnTimeout(
	TEXT("au.FlushCommandBufferOnTimeout"),
	FlushCommandBufferOnTimeoutCvar,
	TEXT("When set to 1, flushes audio render thread synchronously when our fence has timed out.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);

static int32 CommandBufferFlushWaitTimeMsCvar = 1000;
FAutoConsoleVariableRef CVarCommandBufferFlushWaitTimeMs(
	TEXT("au.CommandBufferFlushWaitTimeMs"),
	CommandBufferFlushWaitTimeMsCvar,
	TEXT("How long to wait for the command buffer flush to complete.\n"),
	ECVF_Default);

static int32 CommandBufferMaxSizeInMbCvar = 10;
FAutoConsoleVariableRef CVarCommandBufferMaxSizeMb(
	TEXT("au.CommandBufferMaxSizeInMb"),
	CommandBufferMaxSizeInMbCvar,
	TEXT("How big to allow the command buffer to grow before ignoring more commands"),
	ECVF_Default);

static int32 CommandBufferInitialCapacityCvar = 500;
FAutoConsoleVariableRef CVarCommandBufferInitialCapacity(
	TEXT("au.CommandBufferInitialCapacity"),
	CommandBufferInitialCapacityCvar,
	TEXT("How many elements to initialize the command buffer capacity with"),
	ECVF_Default);

static float AudioCommandExecTimeMsWarningThresholdCvar = 500.f;
FAutoConsoleVariableRef CVarAudioCommandExecTimeMsWarningThreshold(
	TEXT("au.AudioThreadCommand.ExecutionTimeWarningThresholdInMs"),
	AudioCommandExecTimeMsWarningThresholdCvar,
	TEXT("If a command took longer to execute than this number (in milliseconds) then we log a warning"),
	ECVF_Default);

static int32 LogEveryAudioThreadCommandCvar = 0;
FAutoConsoleVariableRef LogEveryAudioThreadCommand(
	TEXT("au.AudioThreadCommand.LogEveryExecution"),
	LogEveryAudioThreadCommandCvar,
	TEXT("Extremely verbose logging of each Audio Thread command caller and it's execution time"),
	ECVF_Default);

// +/- 4 Octaves (default)
static float MaxModulationPitchRangeFreqCVar = 16.0f;
static float MinModulationPitchRangeFreqCVar = 0.0625f;
static FAutoConsoleCommand GModulationSetMaxPitchRange(
	TEXT("au.Modulation.SetPitchRange"),
	TEXT("Sets max final modulation range of pitch (in semitones). Default: 96 semitones (+/- 4 octaves)"),
	FConsoleCommandWithArgsDelegate::CreateStatic(
		[](const TArray<FString>& Args)
		{
			if (Args.Num() < 1)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to set max modulation pitch range: Range not provided"));
				return;
			}

			const float Range = FCString::Atof(*Args[0]);
			MaxModulationPitchRangeFreqCVar = Audio::GetFrequencyMultiplier(Range * 0.5f);
			MaxModulationPitchRangeFreqCVar = Audio::GetFrequencyMultiplier(Range * -0.5f);
		}
	)
);

#define ENVELOPE_TAIL_THRESHOLD (1.58489e-5f) // -96 dB

#define VALIDATE_SOURCE_MIXER_STATE 1

#if AUDIO_MIXER_ENABLE_DEBUG_MODE

// Macro which checks if the source id is in debug mode, avoids having a bunch of #ifdefs in code
#define AUDIO_MIXER_DEBUG_LOG(SourceId, Format, ...)																							\
	if (SourceInfos[SourceId].bIsDebugMode)																													\
	{																																			\
		FString CustomMessage = FString::Printf(Format, ##__VA_ARGS__);																			\
		FString LogMessage = FString::Printf(TEXT("<Debug Sound Log> [Id=%d][Name=%s]: %s"), SourceId, *SourceInfos[SourceId].DebugName, *CustomMessage);	\
		UE_LOG(LogAudioMixer, Log, TEXT("%s"), *LogMessage);																								\
	}

#else

#define AUDIO_MIXER_DEBUG_LOG(SourceId, Message)

#endif

// Disable subframe timing logic
#define AUDIO_SUBFRAME_ENABLED 0

// Define profiling for source manager. 
DEFINE_STAT(STAT_AudioMixerHRTF);
DEFINE_STAT(STAT_AudioMixerSourceBuffers);
DEFINE_STAT(STAT_AudioMixerSourceEffectBuffers);
DEFINE_STAT(STAT_AudioMixerSourceManagerUpdate);
DEFINE_STAT(STAT_AudioMixerSourceOutputBuffers);

#if UE_AUDIO_PROFILERTRACE_ENABLED
UE_TRACE_EVENT_BEGIN(Audio, MixerSourceVolume)
	UE_TRACE_EVENT_FIELD(uint32, DeviceId)
	UE_TRACE_EVENT_FIELD(uint64, Timestamp)
	UE_TRACE_EVENT_FIELD(uint32, PlayOrder)
	UE_TRACE_EVENT_FIELD(float, Volume)
UE_TRACE_EVENT_END()

UE_TRACE_EVENT_BEGIN(Audio, MixerSourceDistanceAttenuation)
	UE_TRACE_EVENT_FIELD(uint32, DeviceId)
	UE_TRACE_EVENT_FIELD(uint64, Timestamp)
	UE_TRACE_EVENT_FIELD(uint32, PlayOrder)
	UE_TRACE_EVENT_FIELD(float, DistanceAttenuation)
UE_TRACE_EVENT_END()

UE_TRACE_EVENT_BEGIN(Audio, MixerSourcePitch)
	UE_TRACE_EVENT_FIELD(uint32, DeviceId)
	UE_TRACE_EVENT_FIELD(uint64, Timestamp)
	UE_TRACE_EVENT_FIELD(uint32, PlayOrder)
	UE_TRACE_EVENT_FIELD(float, Pitch)
UE_TRACE_EVENT_END()

UE_TRACE_EVENT_BEGIN(Audio, MixerSourceFilters)
	UE_TRACE_EVENT_FIELD(uint32, DeviceId)
	UE_TRACE_EVENT_FIELD(uint64, Timestamp)
	UE_TRACE_EVENT_FIELD(uint32, PlayOrder)
	UE_TRACE_EVENT_FIELD(float, LPFFrequency)
	UE_TRACE_EVENT_FIELD(float, HPFFrequency)
UE_TRACE_EVENT_END()

UE_TRACE_EVENT_BEGIN(Audio, MixerSourceEnvelope)
	UE_TRACE_EVENT_FIELD(uint32, DeviceId)
	UE_TRACE_EVENT_FIELD(uint64, Timestamp)
	UE_TRACE_EVENT_FIELD(uint32, PlayOrder)
	UE_TRACE_EVENT_FIELD(float, Envelope)
UE_TRACE_EVENT_END()
#endif // UE_AUDIO_PROFILERTRACE_ENABLED


#ifndef CASE_ENUM_TO_TEXT
	#define CASE_ENUM_TO_TEXT(TXT) case TXT: return TEXT(#TXT);
#endif

const TCHAR* LexToString(ESourceManagerRenderThreadPhase InPhase)
{
	switch(InPhase)
	{
		FOREACH_ENUM_ESOURCEMANAGERRENDERTHREADPHASE(CASE_ENUM_TO_TEXT)
	} 
	return TEXT("Unknown");
}

namespace Audio
{
	int32 GetCommandBufferInitialCapacity()
	{
		return FMath::Clamp(CommandBufferInitialCapacityCvar, 0, 10000);
	}
	/*************************************************************************
	* FMixerSourceManager
	**************************************************************************/

	FMixerSourceManager::FMixerSourceManager(FMixerDevice* InMixerDevice)
		: MixerDevice(InMixerDevice)
		, NumActiveSources(0)
		, NumTotalSources(0)
		, NumOutputFrames(0)
		, NumOutputSamples(0)
		, NumSourceWorkers(4)
		, bInitialized(false)
		, bUsingSpatializationPlugin(false)
		, bUsingSourceDataOverridePlugin(false)
	{
		// Get a manual resetable event
		const bool bIsManualReset = true;
		CommandsProcessedEvent = FPlatformProcess::GetSynchEventFromPool(bIsManualReset);
		check(CommandsProcessedEvent != nullptr);

		// Immediately trigger the command processed in case a flush happens before the audio thread swaps command buffers
		CommandsProcessedEvent->Trigger();

		// reserve the first buffer with the initial capacity
		CommandBuffers[0].SourceCommandQueue.Reserve(GetCommandBufferInitialCapacity());
	}

	FMixerSourceManager::~FMixerSourceManager()
	{
		if (SourceWorkers.Num() > 0)
		{
			for (int32 i = 0; i < SourceWorkers.Num(); ++i)
			{
				delete SourceWorkers[i];
				SourceWorkers[i] = nullptr;
			}

			SourceWorkers.Reset();
		}

		FPlatformProcess::ReturnSynchEventToPool(CommandsProcessedEvent);
	}

	void FMixerSourceManager::Init(const FSourceManagerInitParams& InitParams)
	{
		AUDIO_MIXER_CHECK(InitParams.NumSources > 0);

		if (bInitialized || !MixerDevice)
		{
			return;
		}

		AUDIO_MIXER_CHECK(MixerDevice->GetSampleRate() > 0);

		NumTotalSources = InitParams.NumSources;

		NumOutputFrames = MixerDevice->PlatformSettings.CallbackBufferFrameSize;
		NumOutputSamples = NumOutputFrames * MixerDevice->GetNumDeviceChannels();

		MixerSources.Init(nullptr, NumTotalSources);

		// Populate output sources array with default data
		SourceSubmixOutputBuffers.Reset();
		for (int32 Index = 0; Index < NumTotalSources; Index++)
		{
			SourceSubmixOutputBuffers.Emplace(MixerDevice, 2, MixerDevice->GetNumDeviceChannels(), NumOutputFrames);
		}

		SourceInfos.AddDefaulted(NumTotalSources);

		for (int32 i = 0; i < NumTotalSources; ++i)
		{
			FSourceInfo& SourceInfo = SourceInfos[i];

			SourceInfo.MixerSourceBuffer = nullptr;

			SourceInfo.VolumeSourceStart = -1.0f;
			SourceInfo.VolumeSourceDestination = -1.0f;
			SourceInfo.VolumeFadeSlope = 0.0f;
			SourceInfo.VolumeFadeStart = 0.0f;
			SourceInfo.VolumeFadeFramePosition = 0;
			SourceInfo.VolumeFadeNumFrames = 0;

			SourceInfo.DistanceAttenuationSourceStart = -1.0f;
			SourceInfo.DistanceAttenuationSourceDestination = -1.0f;

			SourceInfo.LowPassFreq = MAX_FILTER_FREQUENCY;
			SourceInfo.HighPassFreq = MIN_FILTER_FREQUENCY;

			SourceInfo.SourceListener = nullptr;
			SourceInfo.CurrentPCMBuffer = nullptr;	
			SourceInfo.CurrentAudioChunkNumFrames = 0;
			SourceInfo.CurrentFrameAlpha = 0.0f;
			SourceInfo.CurrentFrameIndex = 0;
			SourceInfo.NumFramesPlayed = 0;
			SourceInfo.StartTime = 0.0;
			SourceInfo.SubmixSends.Reset();
			SourceInfo.AudioBusId = INDEX_NONE;
			SourceInfo.SourceBusDurationFrames = INDEX_NONE;
		
			SourceInfo.AudioBusSends[(int32)EBusSendType::PreEffect].Reset();
			SourceInfo.AudioBusSends[(int32)EBusSendType::PostEffect].Reset();

			SourceInfo.SourceEffectChainId = INDEX_NONE;

			Audio::FInlineEnvelopeFollowerInitParams EnvelopeFollowerInitParams;
			EnvelopeFollowerInitParams.SampleRate = MixerDevice->SampleRate;
			EnvelopeFollowerInitParams.AttackTimeMsec = 10.f;
			EnvelopeFollowerInitParams.ReleaseTimeMsec = 100.f;
			EnvelopeFollowerInitParams.Mode = EPeakMode::Peak;
			SourceInfo.SourceEnvelopeFollower = Audio::FInlineEnvelopeFollower(EnvelopeFollowerInitParams);

			SourceInfo.SourceEnvelopeValue = 0.0f;
			SourceInfo.bEffectTailsDone = false;
		
			SourceInfo.ResetModulators(MixerDevice->DeviceID);

			SourceInfo.bIs3D = false;
			SourceInfo.bIsCenterChannelOnly = false;
			SourceInfo.bIsActive = false;
			SourceInfo.bIsPlaying = false;
			SourceInfo.bIsPaused = false;
			SourceInfo.bIsPausedForQuantization = false;
			SourceInfo.bDelayLineSet = false;
			SourceInfo.bIsStopping = false;
			SourceInfo.bIsDone = false;
			SourceInfo.bIsLastBuffer = false;
			SourceInfo.bIsBusy = false;
			SourceInfo.bUseHRTFSpatializer = false;
			SourceInfo.bUseOcclusionPlugin = false;
			SourceInfo.bUseReverbPlugin = false;
			SourceInfo.bHasStarted = false;
			SourceInfo.bEnableBusSends = false;
			SourceInfo.bEnableBaseSubmix = false;
			SourceInfo.bEnableSubmixSends = false;
			SourceInfo.bIsVorbis = false;
			SourceInfo.bHasPreDistanceAttenuationSend = false;
			SourceInfo.bModFiltersUpdated = false;

#if AUDIO_MIXER_ENABLE_DEBUG_MODE
			SourceInfo.bIsDebugMode = false;
#endif // AUDIO_MIXER_ENABLE_DEBUG_MODE

			SourceInfo.NumInputChannels = 0;
			SourceInfo.NumPostEffectChannels = 0;
			SourceInfo.NumInputFrames = 0;
		}
		
		GameThreadInfo.bIsBusy.AddDefaulted(NumTotalSources);
		GameThreadInfo.bNeedsSpeakerMap.AddDefaulted(NumTotalSources);
		GameThreadInfo.bIsDebugMode.AddDefaulted(NumTotalSources);
		GameThreadInfo.bIsUsingHRTFSpatializer.AddDefaulted(NumTotalSources);
#if ENABLE_AUDIO_DEBUG
		GameThreadInfo.CPUCoreUtilization.AddZeroed(NumTotalSources);
#endif // if ENABLE_AUDIO_DEBUG

		GameThreadInfo.RelativeRenderCost.Reset(NumTotalSources);
		GameThreadInfo.FreeSourceIndices.Reset(NumTotalSources);
		for (int32 i = NumTotalSources - 1; i >= 0; --i)
		{
			GameThreadInfo.RelativeRenderCost.Add(1.0f);
			GameThreadInfo.FreeSourceIndices.Add(i);
		}

		// Initialize the source buffer memory usage to max source scratch buffers (num frames times max source channels)
		for (int32 SourceId = 0; SourceId < NumTotalSources; ++SourceId)
		{
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			SourceInfo.SourceBuffer.Reset(NumOutputFrames * 8);
			SourceInfo.PreDistanceAttenuationBuffer.Reset(NumOutputFrames * 8);
			SourceInfo.SourceEffectScratchBuffer.Reset(NumOutputFrames * 8);
			SourceInfo.AudioPluginOutputData.AudioBuffer.Reset(NumOutputFrames * 2);
		}

		// Setup the source workers
		SourceWorkers.Reset();
		if (NumSourceWorkers > 0)
		{
			const int32 NumSourcesPerWorker = FMath::Max(NumTotalSources / NumSourceWorkers, 1);
			int32 StartId = 0;
			int32 EndId = 0;
			while (EndId < NumTotalSources)
			{
				EndId = FMath::Min(StartId + NumSourcesPerWorker, NumTotalSources);
				SourceWorkers.Add(new FAsyncTask<FAudioMixerSourceWorker>(this, StartId, EndId));
				StartId = EndId;
			}
		}
		NumSourceWorkers = SourceWorkers.Num();

		// Cache the spatialization plugin
		bUsingSpatializationPlugin = false;
		SpatialInterfaceInfo = MixerDevice->GetCurrentSpatializationPluginInterfaceInfo();
		const auto& SpatializationPlugin = SpatialInterfaceInfo.SpatializationPlugin;
		if (SpatialInterfaceInfo.SpatializationPlugin.IsValid())
		{
			bUsingSpatializationPlugin = true;
		}
		// Cache the source data override plugin
		SourceDataOverridePlugin = MixerDevice->SourceDataOverridePluginInterface;
		if (SourceDataOverridePlugin.IsValid())
		{
			bUsingSourceDataOverridePlugin = true;
		}

		// Spam command queue with nops.
		static FAutoConsoleCommand SpamNopsCmd(
			TEXT("au.AudioThreadCommand.SpamCommandQueue"),
			TEXT(""),
			FConsoleCommandDelegate::CreateLambda([this]() 
			{				
				struct FSpamPayload
				{
					uint8 JunkBytes[1024];
				} Payload;
				for (int32 i = 0; i < 65536; ++i)
				{
					AudioMixerThreadCommand([Payload] {}, AUDIO_MIXER_THREAD_COMMAND_STRING("SpamNopsCmd() -- Console command"));
				}
			})
		);


		// submit a command that has an endless loop
		static FAutoConsoleCommand SpamEndlessCmd(
			TEXT("au.AudioThreadCommand.ChokeCommandQueue"),
			TEXT(""),
			FConsoleCommandDelegate::CreateLambda([this]()
			{
				AudioMixerThreadCommand([] {while(true){}}, AUDIO_MIXER_THREAD_COMMAND_STRING("ChokeCommandQueue() -- Console command"));
			})
		);

		// submit a MPSC command that has an endless loop
		static FAutoConsoleCommand SpamEndlessCmdMPSC(
			TEXT("au.AudioThreadCommand.ChokeMPSCCommandQueue"),
			TEXT(""),
			FConsoleCommandDelegate::CreateLambda([this]()
				{
					AudioMixerThreadMPSCCommand([] {while (true) {}}, AUDIO_MIXER_THREAD_COMMAND_STRING("ChokeMPSCCommandQueue() -- Console command"));
				})
		);

		// Test stall diagnostics.
		static FAutoConsoleCommand StallDiagnostics(
			TEXT("au.AudioSourceManager.HangDiagnostics"),
			TEXT(""),
			FConsoleCommandDelegate::CreateLambda([this]() { DoStallDiagnostics(); })
		);

		bInitialized = true;
		bPumpQueue = false;
	}

	void FMixerSourceManager::Update(bool bTimedOut)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

#if VALIDATE_SOURCE_MIXER_STATE
		for (int32 i = 0; i < NumTotalSources; ++i)
		{
			if (!GameThreadInfo.bIsBusy[i])
			{
				// Make sure that our bIsFree and FreeSourceIndices are correct
				AUDIO_MIXER_CHECK(GameThreadInfo.FreeSourceIndices.Contains(i) == true);
			}
		}
#endif

		if (FPlatformProcess::SupportsMultithreading())
		{
			// If the command was triggered, then we want to do a swap of command buffers
			if (CommandsProcessedEvent->Wait(0))
			{
				int32 CurrentGameIndex = !RenderThreadCommandBufferIndex.GetValue();

				// This flags the audio render thread to be able to pump the next batch of commands
				// And will allow the audio thread to write to a new command slot
				const int32 NextIndex = (CurrentGameIndex + 1) & 1;

				FCommands& NextCommandBuffer = CommandBuffers[NextIndex];

				// Make sure we've actually emptied the command queue from the render thread before writing to it
				if (FlushCommandBufferOnTimeoutCvar && NextCommandBuffer.SourceCommandQueue.Num() != 0)
				{
					UE_LOG(LogAudioMixer, Warning, TEXT("Audio render callback stopped. Flushing %d commands."), NextCommandBuffer.SourceCommandQueue.Num());

					// Pop and execute all the commands that came since last update tick
					for (int32 Id = 0; Id < NextCommandBuffer.SourceCommandQueue.Num(); ++Id)
					{
						FAudioMixerThreadCommand AudioCommand = NextCommandBuffer.SourceCommandQueue[Id];

						AudioCommand();
						NumCommands.Decrement();
					}

					NextCommandBuffer.SourceCommandQueue.Reset();
				}

				// Here we ensure that we block for any pending calls to AudioMixerThreadCommand.
				FScopeLock ScopeLock(&CommandBufferIndexCriticalSection);
				RenderThreadCommandBufferIndex.Set(CurrentGameIndex);

				CommandsProcessedEvent->Reset();
			}
		}
		else
		{
			int32 CurrentRenderIndex = RenderThreadCommandBufferIndex.GetValue();
			int32 CurrentGameIndex = !RenderThreadCommandBufferIndex.GetValue();
			check(CurrentGameIndex == 0 || CurrentGameIndex == 1);
			check(CurrentRenderIndex == 0 || CurrentRenderIndex == 1);

			// If these values are the same, that means the audio render thread has finished the last buffer queue so is ready for the next block
			if (CurrentRenderIndex == CurrentGameIndex)
			{
				// This flags the audio render thread to be able to pump the next batch of commands
				// And will allow the audio thread to write to a new command slot
				const int32 NextIndex = !CurrentGameIndex;

				// Make sure we've actually emptied the command queue from the render thread before writing to it
				if (CommandBuffers[NextIndex].SourceCommandQueue.Num() != 0)
				{
					UE_LOG(LogAudioMixer, Warning, TEXT("Source command queue not empty: %d"), CommandBuffers[NextIndex].SourceCommandQueue.Num());
				}
				bPumpQueue = true;
			}
		}

	}

	void FMixerSourceManager::ReleaseSource(const int32 SourceId)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(bInitialized);

		if (MixerSources[SourceId] == nullptr)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Ignoring double release of SourceId: %i"), SourceId);
			return;
		}

		AUDIO_MIXER_DEBUG_LOG(SourceId, TEXT("Is releasing"));
		
		FSourceInfo& SourceInfo = SourceInfos[SourceId];

#if AUDIO_MIXER_ENABLE_DEBUG_MODE
		if (SourceInfo.bIsDebugMode)
		{
			DebugSoloSources.Remove(SourceId);
		}
#endif
		// Remove from list of active bus or source ids depending on what type of source this is
		if (SourceInfo.AudioBusId != INDEX_NONE)
		{
			// Remove this bus from the registry of bus instances
			TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(SourceInfo.AudioBusId);
			if (AudioBusPtr.IsValid())
			{
				// If this audio bus was automatically created via source bus playback, this this audio bus can be removed
				if (AudioBusPtr->RemoveInstanceId(SourceId))
				{
					// Only automatic buses will be getting removed here. Otherwise they need to be manually removed from the source manager.
					ensure(AudioBusPtr->IsAutomatic());
					AudioBuses.Remove(SourceInfo.AudioBusId);
				}
			}
		}

		// Remove this source's send list from the bus data registry
		for (int32 AudioBusSendType = 0; AudioBusSendType < (int32)EBusSendType::Count; ++AudioBusSendType)
		{
			for (uint32 AudioBusId : SourceInfo.AudioBusSends[AudioBusSendType])
			{
				// we should have a bus registration entry still since the send hasn't been cleaned up yet
				TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(AudioBusId);
				if (AudioBusPtr.IsValid())
				{
					if (AudioBusPtr->RemoveSend((EBusSendType)AudioBusSendType, SourceId))
					{
						ensure(AudioBusPtr->IsAutomatic());
						AudioBuses.Remove(AudioBusId);
					}
				}
			}

			SourceInfo.AudioBusSends[AudioBusSendType].Reset();
		}

		SourceInfo.AudioBusId = INDEX_NONE;
		SourceInfo.SourceBusDurationFrames = INDEX_NONE;

		// Free the mixer source buffer data
		if (SourceInfo.MixerSourceBuffer.IsValid())
		{
			PendingSourceBuffers.Add(SourceInfo.MixerSourceBuffer);
			SourceInfo.MixerSourceBuffer = nullptr;
		}

		SourceInfo.SourceListener = nullptr;

		// Remove the mixer source from its submix sends
		for (FMixerSourceSubmixSend& SubmixSendItem : SourceInfo.SubmixSends)
		{
			FMixerSubmixPtr SubmixPtr = SubmixSendItem.Submix.Pin();
			if (SubmixPtr.IsValid())
			{
				SubmixPtr->RemoveSourceVoice(MixerSources[SourceId]);
			}
		}
		SourceInfo.SubmixSends.Reset();

		// Notify plugin effects
		if (SourceInfo.bUseHRTFSpatializer)
		{
			AUDIO_MIXER_CHECK(bUsingSpatializationPlugin);
			LLM_SCOPE(ELLMTag::AudioMixerPlugins);
			SpatialInterfaceInfo.SpatializationPlugin->OnReleaseSource(SourceId);
		}

		if (SourceInfo.bUseOcclusionPlugin)
		{
			MixerDevice->OcclusionInterface->OnReleaseSource(SourceId);
		}

		if (SourceInfo.bUseReverbPlugin)
		{
			MixerDevice->ReverbPluginInterface->OnReleaseSource(SourceId);
		}

		if (SourceInfo.AudioLink)
		{
			SourceInfo.AudioLink->OnSourceReleased(SourceId);
			SourceInfo.AudioLink.Reset();
		}

		// Delete the source effects
		SourceInfo.SourceEffectChainId = INDEX_NONE;
		ResetSourceEffectChain(SourceId);

		SourceInfo.SourceEnvelopeFollower.Reset();
		SourceInfo.bEffectTailsDone = true;

		// Release the source voice back to the mixer device. This is pooled.
		MixerDevice->ReleaseMixerSourceVoice(MixerSources[SourceId]);
		MixerSources[SourceId] = nullptr;

		// Reset all state and data
		SourceInfo.PitchSourceParam.Init();
		SourceInfo.VolumeSourceStart = -1.0f;
		SourceInfo.VolumeSourceDestination = -1.0f;
		SourceInfo.VolumeFadeSlope = 0.0f;
		SourceInfo.VolumeFadeStart = 0.0f;
		SourceInfo.VolumeFadeFramePosition = 0;
		SourceInfo.VolumeFadeNumFrames = 0;

		SourceInfo.DistanceAttenuationSourceStart = -1.0f;
		SourceInfo.DistanceAttenuationSourceDestination = -1.0f;

		SourceInfo.LowPassFreq = MAX_FILTER_FREQUENCY;
		SourceInfo.HighPassFreq = MIN_FILTER_FREQUENCY;

		if (SourceInfo.SourceBufferListener)
		{
			SourceInfo.SourceBufferListener->OnSourceReleased(SourceId);
			SourceInfo.SourceBufferListener.Reset();
		}

		SourceInfo.ResetModulators(MixerDevice->DeviceID);

		SourceInfo.LowPassFilter.Reset();
		SourceInfo.HighPassFilter.Reset();
		SourceInfo.CurrentPCMBuffer = nullptr;
		SourceInfo.CurrentAudioChunkNumFrames = 0;
		SourceInfo.SourceBuffer.Reset();
		SourceInfo.PreDistanceAttenuationBuffer.Reset();
		SourceInfo.SourceEffectScratchBuffer.Reset();
		SourceInfo.AudioPluginOutputData.AudioBuffer.Reset();
		SourceInfo.CurrentFrameValues.Reset();
		SourceInfo.NextFrameValues.Reset();
		SourceInfo.CurrentFrameAlpha = 0.0f;
		SourceInfo.CurrentFrameIndex = 0;
		SourceInfo.NumFramesPlayed = 0;
		SourceInfo.StartTime = 0.0;
		SourceInfo.bIs3D = false;
		SourceInfo.bIsCenterChannelOnly = false;
		SourceInfo.bIsActive = false;
		SourceInfo.bIsPlaying = false;
		SourceInfo.bIsDone = true;
		SourceInfo.bIsLastBuffer = false;
		SourceInfo.bIsPaused = false;
		SourceInfo.bIsPausedForQuantization = false;
		SourceInfo.bDelayLineSet = false;
		SourceInfo.bIsStopping = false;
		SourceInfo.bIsBusy = false;
		SourceInfo.bUseHRTFSpatializer = false;
		SourceInfo.bIsExternalSend = false;
		SourceInfo.bUseOcclusionPlugin = false;
		SourceInfo.bUseReverbPlugin = false;
		SourceInfo.bHasStarted = false;
		SourceInfo.bEnableBusSends = false;
		SourceInfo.bEnableBaseSubmix = false;
		SourceInfo.bEnableSubmixSends = false;
		SourceInfo.bHasPreDistanceAttenuationSend = false;
		SourceInfo.bModFiltersUpdated = false;

		SourceInfo.AudioComponentID = 0;
		SourceInfo.PlayOrder = INDEX_NONE;

		SourceInfo.QuantizedCommandHandle.Reset();

#if AUDIO_MIXER_ENABLE_DEBUG_MODE
		SourceInfo.bIsDebugMode = false;
		SourceInfo.DebugName = FString();
#endif //AUDIO_MIXER_ENABLE_DEBUG_MODE

		SourceInfo.NumInputChannels = 0;
		SourceInfo.NumPostEffectChannels = 0;

		GameThreadInfo.bNeedsSpeakerMap[SourceId] = false;
	}

	void FMixerSourceManager::BuildSourceEffectChain(const int32 SourceId, FSoundEffectSourceInitData& InitData, const TArray<FSourceEffectChainEntry>& InSourceEffectChain, TArray<TSoundEffectSourcePtr>& OutSourceEffects)
	{
		// Create new source effects. The memory will be owned by the source manager.
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
		for (const FSourceEffectChainEntry& ChainEntry : InSourceEffectChain)
		{
			// Presets can have null entries
			if (!ChainEntry.Preset)
			{
				continue;
			}

			// Get this source effect presets unique id so instances can identify their originating preset object
			const uint32 PresetUniqueId = ChainEntry.Preset->GetUniqueID();
			InitData.ParentPresetUniqueId = PresetUniqueId;

			TSoundEffectSourcePtr NewEffect = USoundEffectPreset::CreateInstance<FSoundEffectSourceInitData, FSoundEffectSource>(InitData, *ChainEntry.Preset);
			NewEffect->SetEnabled(!ChainEntry.bBypass);

			OutSourceEffects.Add(NewEffect);
		}
	}

	void FMixerSourceManager::ResetSourceEffectChain(const int32 SourceId)
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
		{
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// Unregister these source effect instances from their owning USoundEffectInstance on the audio thread.
			// Have to pass to Game Thread prior to processing on AudioThread to avoid race condition with GC.
			// (RunCommandOnAudioThread is not safe to call from any thread other than the GameThread).
			if (!SourceInfo.SourceEffects.IsEmpty())
			{
				AsyncTask(ENamedThreads::GameThread, [GTSourceEffects = MoveTemp(SourceInfo.SourceEffects)]() mutable
				{
					FAudioThread::RunCommandOnAudioThread([ATSourceEffects = MoveTemp(GTSourceEffects)]() mutable
					{
						for (const TSoundEffectSourcePtr& EffectPtr : ATSourceEffects)
						{
							USoundEffectPreset::UnregisterInstance(EffectPtr);
						}
					});
				});

				SourceInfo.SourceEffects.Reset();
			}
			SourceInfo.SourceEffectPresets.Reset();
		}
	}

	bool FMixerSourceManager::GetFreeSourceId(int32& OutSourceId)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (GameThreadInfo.FreeSourceIndices.Num())
		{
			OutSourceId = GameThreadInfo.FreeSourceIndices.Pop();

			AUDIO_MIXER_CHECK(OutSourceId < NumTotalSources);
			AUDIO_MIXER_CHECK(!GameThreadInfo.bIsBusy[OutSourceId]);

			AUDIO_MIXER_CHECK(!GameThreadInfo.bIsDebugMode[OutSourceId]);
			AUDIO_MIXER_CHECK(NumActiveSources < NumTotalSources);
			++NumActiveSources;

			GameThreadInfo.bIsBusy[OutSourceId] = true;
			return true;
		}
		AUDIO_MIXER_CHECK(false);
		return false;
	}

	int32 FMixerSourceManager::GetNumActiveSources() const
	{
		return NumActiveSources;
	}

	int32 FMixerSourceManager::GetNumActiveAudioBuses() const
	{
		return AudioBuses.Num();
	}

	void FMixerSourceManager::InitSource(const int32 SourceId, const FMixerSourceVoiceInitParams& InitParams)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK(!GameThreadInfo.bIsDebugMode[SourceId]);
		AUDIO_MIXER_CHECK(InitParams.SourceListener != nullptr);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

#if AUDIO_MIXER_ENABLE_DEBUG_MODE
		GameThreadInfo.bIsDebugMode[SourceId] = InitParams.bIsDebugMode;
#endif 

		// Make sure we flag that this source needs a speaker map to at least get one
		GameThreadInfo.bNeedsSpeakerMap[SourceId] = true;

		GameThreadInfo.bIsUsingHRTFSpatializer[SourceId] = InitParams.bUseHRTFSpatialization;

		// Need to build source effect instances on the audio thread
		FSoundEffectSourceInitData InitData;
		InitData.SampleRate = MixerDevice->SampleRate;
		InitData.NumSourceChannels = InitParams.NumInputChannels;
		InitData.AudioClock = MixerDevice->GetAudioTime();
		InitData.AudioDeviceId = MixerDevice->DeviceID;

		TArray<TSoundEffectSourcePtr> SourceEffectChain;
		BuildSourceEffectChain(SourceId, InitData, InitParams.SourceEffectChain, SourceEffectChain);

		FModulationDestination VolumeMod;
		VolumeMod.Init(MixerDevice->DeviceID, FName("Volume"), false /* bInIsBuffered */, true /* bInValueLinear */);
		VolumeMod.UpdateModulators(InitParams.ModulationSettings.VolumeModulationDestination.Modulators);

		FModulationDestination PitchMod;
		PitchMod.Init(MixerDevice->DeviceID, FName("Pitch"), false /* bInIsBuffered */);
		PitchMod.UpdateModulators(InitParams.ModulationSettings.PitchModulationDestination.Modulators);

		FModulationDestination HighpassMod;
		HighpassMod.Init(MixerDevice->DeviceID, FName("HPFCutoffFrequency"), false /* bInIsBuffered */);
		HighpassMod.UpdateModulators(InitParams.ModulationSettings.HighpassModulationDestination.Modulators);

		FModulationDestination LowpassMod;
		LowpassMod.Init(MixerDevice->DeviceID, FName("LPFCutoffFrequency"), false /* bInIsBuffered */);
		LowpassMod.UpdateModulators(InitParams.ModulationSettings.LowpassModulationDestination.Modulators);

		AudioMixerThreadCommand([
			this,
			SourceId,
			InitParams,
			VolumeModulation = MoveTemp(VolumeMod),
			HighpassModulation = MoveTemp(HighpassMod),
			LowpassModulation = MoveTemp(LowpassMod),
			PitchModulation = MoveTemp(PitchMod),
			SourceEffectChain
		]() mutable
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
			AUDIO_MIXER_CHECK(InitParams.SourceVoice != nullptr);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// Initialize the mixer source buffer decoder with the given mixer buffer
			SourceInfo.MixerSourceBuffer = InitParams.MixerSourceBuffer;
			AUDIO_MIXER_CHECK(SourceInfo.MixerSourceBuffer.IsValid());
			SourceInfo.MixerSourceBuffer->Init();
			SourceInfo.MixerSourceBuffer->OnBeginGenerate();

			SourceInfo.bIs3D = InitParams.bIs3D;
			SourceInfo.bIsPlaying = false;
			SourceInfo.bIsPaused = false;
			SourceInfo.bIsPausedForQuantization = false;
			SourceInfo.bDelayLineSet = false;
			SourceInfo.bIsStopping = false;
			SourceInfo.bIsActive = true;
			SourceInfo.bIsBusy = true;
			SourceInfo.bIsDone = false;
			SourceInfo.bIsLastBuffer = false;
			SourceInfo.bUseHRTFSpatializer = InitParams.bUseHRTFSpatialization;
			SourceInfo.bIsExternalSend = InitParams.bIsExternalSend;
			SourceInfo.bIsVorbis = InitParams.bIsVorbis;
			SourceInfo.PlayOrder = InitParams.PlayOrder;
			SourceInfo.AudioComponentID = InitParams.AudioComponentID;
			SourceInfo.bIsSoundfield = InitParams.bIsSoundfield;

			// Call initialization from the render thread so anything wanting to do any initialization here can do so (e.g. procedural sound waves)
			SourceInfo.SourceListener = InitParams.SourceListener;
			SourceInfo.SourceListener->OnBeginGenerate();

			SourceInfo.NumInputChannels = InitParams.NumInputChannels;
			SourceInfo.NumInputFrames = InitParams.NumInputFrames;

			// init and zero-out buffers
			const int32 BufferSize = NumOutputFrames * InitParams.NumInputChannels;
			SourceInfo.PreEffectBuffer.Reset();
			SourceInfo.PreEffectBuffer.AddZeroed(BufferSize);

			SourceInfo.PreDistanceAttenuationBuffer.Reset();
			SourceInfo.PreDistanceAttenuationBuffer.AddZeroed(BufferSize);

			// Initialize the number of per-source LPF filters based on input channels
			SourceInfo.LowPassFilter.Init(MixerDevice->SampleRate, InitParams.NumInputChannels);
			SourceInfo.HighPassFilter.Init(MixerDevice->SampleRate, InitParams.NumInputChannels);

			Audio::FInlineEnvelopeFollowerInitParams EnvelopeFollowerInitParams;
			EnvelopeFollowerInitParams.SampleRate = MixerDevice->SampleRate / NumOutputFrames;
			EnvelopeFollowerInitParams.AttackTimeMsec = (float)InitParams.EnvelopeFollowerAttackTime;
			EnvelopeFollowerInitParams.ReleaseTimeMsec = (float)InitParams.EnvelopeFollowerReleaseTime;
			EnvelopeFollowerInitParams.Mode = EPeakMode::Peak;
			SourceInfo.SourceEnvelopeFollower = Audio::FInlineEnvelopeFollower(EnvelopeFollowerInitParams);

			SourceInfo.VolumeModulation = MoveTemp(VolumeModulation);
			SourceInfo.PitchModulation = MoveTemp(PitchModulation);
			SourceInfo.LowpassModulation = MoveTemp(LowpassModulation);
			SourceInfo.HighpassModulation = MoveTemp(HighpassModulation);

			// Pass required info to clock manager
			const FQuartzQuantizedRequestData& QuantData = InitParams.QuantizedRequestData;
			if (QuantData.QuantizedCommandPtr)
			{
				if (false == MixerDevice->QuantizedEventClockManager.DoesClockExist(QuantData.ClockName))
				{
					UE_LOG(LogAudioMixer, Warning, TEXT("Quantization Clock: '%s' Does not exist."), *QuantData.ClockName.ToString());
					QuantData.QuantizedCommandPtr->Cancel();
				}
				else
				{
					FQuartzQuantizedCommandInitInfo QuantCommandInitInfo(QuantData, MixerDevice->GetSampleRate(), SourceId);
					SourceInfo.QuantizedCommandHandle = MixerDevice->QuantizedEventClockManager.AddCommandToClock(QuantCommandInitInfo);
				}
			}


			// Create the spatialization plugin source effect
			if (InitParams.bUseHRTFSpatialization)
			{
				AUDIO_MIXER_CHECK(bUsingSpatializationPlugin);
				LLM_SCOPE(ELLMTag::AudioMixerPlugins);

				// re-cache the spatialization plugin in case it changed
				bUsingSpatializationPlugin = false;
				SpatialInterfaceInfo = MixerDevice->GetCurrentSpatializationPluginInterfaceInfo();
				const auto& SpatializationPlugin = SpatialInterfaceInfo.SpatializationPlugin;
				if (SpatialInterfaceInfo.SpatializationPlugin.IsValid())
				{
					bUsingSpatializationPlugin = true;
				}

				SpatialInterfaceInfo.SpatializationPlugin->OnInitSource(SourceId, InitParams.AudioComponentUserID, InitParams.NumInputChannels, InitParams.SpatializationPluginSettings);
			}

			// Create the occlusion plugin source effect
			if (InitParams.OcclusionPluginSettings != nullptr)
			{
				MixerDevice->OcclusionInterface->OnInitSource(SourceId, InitParams.AudioComponentUserID, InitParams.NumInputChannels, InitParams.OcclusionPluginSettings);
				SourceInfo.bUseOcclusionPlugin = true;
			}

			// Create the reverb plugin source effect
			if (InitParams.ReverbPluginSettings != nullptr)
			{
				MixerDevice->ReverbPluginInterface->OnInitSource(SourceId, InitParams.AudioComponentUserID, InitParams.NumInputChannels, InitParams.ReverbPluginSettings);
				SourceInfo.bUseReverbPlugin = true;
			}

			if (InitParams.AudioLink.IsValid())
			{
				SourceInfo.AudioLink = InitParams.AudioLink;
			}

			// Optional Source Buffer listener.
			SourceInfo.SourceBufferListener = InitParams.SourceBufferListener;
			SourceInfo.bShouldSourceBufferListenerZeroBuffer = InitParams.bShouldSourceBufferListenerZeroBuffer;

			// Default all sounds to not consider effect chain tails when playing
			SourceInfo.bEffectTailsDone = true;

			// Which forms of routing to enable
			SourceInfo.bEnableBusSends = InitParams.bEnableBusSends;
			SourceInfo.bEnableBaseSubmix = InitParams.bEnableBaseSubmix;
			SourceInfo.bEnableSubmixSends = InitParams.bEnableSubmixSends;

			// Copy the source effect chain if the channel count is less than or equal to the number of channels supported by the effect chain
			if (InitParams.NumInputChannels <= InitParams.SourceEffectChainMaxSupportedChannels)
			{
				// If we're told to care about effect chain tails, then we're not allowed
				// to stop playing until the effect chain tails are finished
				SourceInfo.bEffectTailsDone = !InitParams.bPlayEffectChainTails;
				SourceInfo.SourceEffectChainId = InitParams.SourceEffectChainId;
				
				// Add the effect chain instances 
				SourceInfo.SourceEffects = MoveTemp(SourceEffectChain);
				
				// Add a slot entry for the preset so it can change while running. This will get sent to the running effect instance if the preset changes.
				SourceInfo.SourceEffectPresets.Add(nullptr);
				// If this is going to be a source bus, add this source id to the list of active bus ids
				if (InitParams.AudioBusId != INDEX_NONE)
				{
					// Setting this BusId will flag this source as a bus. It doesn't try to generate 
					// audio in the normal way but instead will render in a second stage, after normal source rendering.
					SourceInfo.AudioBusId = InitParams.AudioBusId;

					// Source bus duration allows us to stop a bus after a given time
					if (InitParams.SourceBusDuration != 0.0f)
					{
						SourceInfo.SourceBusDurationFrames = InitParams.SourceBusDuration * MixerDevice->GetSampleRate();
					}

					// Register this bus as an instance
					TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(SourceInfo.AudioBusId);
					if (AudioBusPtr.IsValid())
					{
						// If this bus is already registered, add this as a source id
						AudioBusPtr->AddInstanceId(SourceId, InitParams.NumInputChannels);
					}
					else
					{
						// If the bus is not registered, make a new entry. This will default to an automatic audio bus until explicitly made manual later.
						TSharedPtr<FMixerAudioBus> NewAudioBus = TSharedPtr<FMixerAudioBus>(new FMixerAudioBus(this, true, InitParams.AudioBusChannels));
						NewAudioBus->AddInstanceId(SourceId, InitParams.NumInputChannels);

						AudioBuses.Add(InitParams.AudioBusId, NewAudioBus);
					}
				}

			}

			// Iterate through source's bus sends and add this source to the bus send list
			// Note: buses can also send their audio to other buses.
			for (int32 BusSendType = 0; BusSendType < (int32)EBusSendType::Count; ++BusSendType)
			{
				for (const FInitAudioBusSend& AudioBusSend : InitParams.AudioBusSends[BusSendType])
				{
					// New struct to map which source (SourceId) is sending to the bus
					FAudioBusSend NewAudioBusSend;
					NewAudioBusSend.SourceId = SourceId;
					NewAudioBusSend.SendLevel = AudioBusSend.SendLevel;

					// Get existing BusId and add the send, or create new bus registration
					TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(AudioBusSend.AudioBusId);
					if (AudioBusPtr.IsValid())
					{
						AudioBusPtr->AddSend((EBusSendType)BusSendType, NewAudioBusSend);
					}
					else
					{
						// If the bus is not registered, make a new entry. This will default to an automatic audio bus until explicitly made manual later.
						TSharedPtr<FMixerAudioBus> NewAudioBus(new FMixerAudioBus(this, true, AudioBusSend.BusChannels));

						// Add a send to it. This will not have a bus instance id (i.e. won't output audio), but 
						// we register the send anyway in the event that this bus does play, we'll know to send this
						// source's audio to it.
						NewAudioBus->AddSend((EBusSendType)BusSendType, NewAudioBusSend);

						AudioBuses.Add(AudioBusSend.AudioBusId, NewAudioBus);
					}

					// Store on this source, which buses its sending its audio to
					SourceInfo.AudioBusSends[BusSendType].Add(AudioBusSend.AudioBusId);
				}
			}

			SourceInfo.CurrentFrameValues.Init(0.0f, InitParams.NumInputChannels);
			SourceInfo.NextFrameValues.Init(0.0f, InitParams.NumInputChannels);

			AUDIO_MIXER_CHECK(MixerSources[SourceId] == nullptr);
			MixerSources[SourceId] = InitParams.SourceVoice;

			// Loop through the source's sends and add this source to those submixes with the send info

			AUDIO_MIXER_CHECK(SourceInfo.SubmixSends.Num() == 0);

			// Initialize a new downmix data:
			check(SourceId < SourceInfos.Num());
			const int32 SourceInputChannels = (SourceInfo.bUseHRTFSpatializer && !SourceInfo.bIsExternalSend) ? 2 : SourceInfo.NumInputChannels;

			// Collect the soundfield encoding keys we need to initialize with our output buffers
			TArray<FMixerSubmixPtr> SoundfieldSubmixSends;

			for (int32 i = 0; i < InitParams.SubmixSends.Num(); ++i)
			{
				const FMixerSourceSubmixSend& MixerSubmixSend = InitParams.SubmixSends[i];

				FMixerSubmixPtr SubmixPtr = MixerSubmixSend.Submix.Pin();
				if (SubmixPtr.IsValid())
				{
					SourceInfo.SubmixSends.Add(MixerSubmixSend);

					if (MixerSubmixSend.SubmixSendStage == EMixerSourceSubmixSendStage::PreDistanceAttenuation)
					{
						SourceInfo.bHasPreDistanceAttenuationSend = true;
					}

					SubmixPtr->AddOrSetSourceVoice(InitParams.SourceVoice, MixerSubmixSend.SendLevel, MixerSubmixSend.SubmixSendStage);
					
					if (SubmixPtr->IsSoundfieldSubmix())
					{
						SoundfieldSubmixSends.Add(SubmixPtr);
					}
				}
			}

			// Initialize the submix output source for this source id
			FMixerSourceSubmixOutputBuffer& SourceSubmixOutputBuffer = SourceSubmixOutputBuffers[SourceId];

			FMixerSourceSubmixOutputBufferSettings SourceSubmixOutputResetSettings;
			SourceSubmixOutputResetSettings.NumOutputChannels = MixerDevice->GetDeviceOutputChannels();
			SourceSubmixOutputResetSettings.NumSourceChannels = SourceInputChannels;
			SourceSubmixOutputResetSettings.SoundfieldSubmixSends = SoundfieldSubmixSends;
			SourceSubmixOutputResetSettings.bIs3D = SourceInfo.bIs3D;
			SourceSubmixOutputResetSettings.bIsSoundfield = SourceInfo.bIsSoundfield;

			SourceSubmixOutputBuffer.Reset(SourceSubmixOutputResetSettings);

#if AUDIO_MIXER_ENABLE_DEBUG_MODE
			AUDIO_MIXER_CHECK(!SourceInfo.bIsDebugMode);
			SourceInfo.bIsDebugMode = InitParams.bIsDebugMode;
			SourceInfo.DebugName = InitParams.DebugName;
#endif 

			AUDIO_MIXER_DEBUG_LOG(SourceId, TEXT("Is initializing"));
		});
	}

	void FMixerSourceManager::ReleaseSourceId(const int32 SourceId)
	{
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AUDIO_MIXER_CHECK(NumActiveSources > 0);
		--NumActiveSources;

		GameThreadInfo.bIsBusy[SourceId] = false;

#if AUDIO_MIXER_ENABLE_DEBUG_MODE
		GameThreadInfo.bIsDebugMode[SourceId] = false;
#endif

#if ENABLE_AUDIO_DEBUG
		GameThreadInfo.CPUCoreUtilization[SourceId] = 0.0f;
#endif 

		GameThreadInfo.RelativeRenderCost[SourceId] = 1.0f;
		GameThreadInfo.FreeSourceIndices.Push(SourceId);

		AUDIO_MIXER_CHECK(GameThreadInfo.FreeSourceIndices.Contains(SourceId));

		AudioMixerThreadCommand([this, SourceId]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			ReleaseSource(SourceId);
		});
	}

	void FMixerSourceManager::StartAudioBus(FAudioBusKey InAudioBusKey, int32 InNumChannels, bool bInIsAutomatic)
	{
		if (AudioBusKeys_AudioThread.Contains(InAudioBusKey))
		{
			return;
		}

		AudioBusKeys_AudioThread.Add(InAudioBusKey);

		AudioMixerThreadCommand([this, InAudioBusKey, InNumChannels, bInIsAutomatic]()
		{
			// If this audio bus id already exists, set it to not be automatic and return it
			TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(InAudioBusKey);
			if (AudioBusPtr.IsValid())
			{
				// If this audio bus already existed, make sure the num channels lines up
				ensure(AudioBusPtr->GetNumChannels() == InNumChannels);
				AudioBusPtr->SetAutomatic(bInIsAutomatic);
			}
			else
			{
				// If the bus is not registered, make a new entry.
				TSharedPtr<FMixerAudioBus> NewBusData(new FMixerAudioBus(this, bInIsAutomatic, InNumChannels));

				AudioBuses.Add(InAudioBusKey, NewBusData);
			}
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("StartAudioBus()"));
	}

	void FMixerSourceManager::StopAudioBus(FAudioBusKey InAudioBusKey)
	{
		if (!AudioBusKeys_AudioThread.Contains(InAudioBusKey))
		{
			return;
		}

		AudioBusKeys_AudioThread.Remove(InAudioBusKey);

		AudioMixerThreadCommand([this, InAudioBusKey]()
		{
			TSharedPtr<FMixerAudioBus>* AudioBusPtr = AudioBuses.Find(InAudioBusKey);
			if (AudioBusPtr)
			{
				if (!(*AudioBusPtr)->IsAutomatic())
				{
					// Immediately stop all sources which were source buses
					for (FSourceInfo& SourceInfo : SourceInfos)
					{
						if (SourceInfo.AudioBusId == InAudioBusKey.ObjectId)
						{
							SourceInfo.bIsPlaying = false;
							SourceInfo.bIsPaused = false;
							SourceInfo.bIsActive = false;
							SourceInfo.bIsStopping = false;
						}
					}
					AudioBuses.Remove(InAudioBusKey);
				}
			}
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("StopAudioBus()"));
	}

	bool FMixerSourceManager::IsAudioBusActive(FAudioBusKey InAudioBusKey) const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);
		return AudioBusKeys_AudioThread.Contains(InAudioBusKey);
	}

	int32 FMixerSourceManager::GetAudioBusNumChannels(FAudioBusKey InAudioBusKey) const
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
		TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(InAudioBusKey);
		if (AudioBusPtr.IsValid())
		{
			return AudioBusPtr->GetNumChannels();
		}

		return 0;
	}

	void FMixerSourceManager::AddPatchOutputForAudioBus(FAudioBusKey InAudioBusKey, const FPatchOutputStrongPtr& InPatchOutputStrongPtr)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
		if (MixerDevice->IsAudioRenderingThread())
		{
			TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(InAudioBusKey);
			if (AudioBusPtr.IsValid())
			{
				AudioBusPtr->AddNewPatchOutput(InPatchOutputStrongPtr);
			}
		}
		else
		{
			// Queue up the command via MPSC command queue
			AudioMixerThreadMPSCCommand([this, InAudioBusKey, InPatchOutputStrongPtr]()
			{
				AddPatchOutputForAudioBus(InAudioBusKey, InPatchOutputStrongPtr);
			}, AUDIO_MIXER_THREAD_COMMAND_STRING("AddPatchOutputForAudioBus()"));
		}
	}

	void FMixerSourceManager::AddPatchOutputForAudioBus_AudioThread(FAudioBusKey InAudioBusKey, const FPatchOutputStrongPtr& InPatchOutputStrongPtr)
	{
		AudioMixerThreadCommand([this, InAudioBusKey, NewPatchPtr = InPatchOutputStrongPtr]() mutable
		{
			AddPatchOutputForAudioBus(InAudioBusKey, NewPatchPtr);
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("AddPatchOutputForAudioBus_AudioThread()"));
	}

	void FMixerSourceManager::AddPatchInputForAudioBus(FAudioBusKey InAudioBusKey, const FPatchInput& InPatchInput)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
		if (MixerDevice->IsAudioRenderingThread())
		{
			TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(InAudioBusKey);
			if (AudioBusPtr.IsValid())
			{
				AudioBusPtr->AddNewPatchInput(InPatchInput);
			}
		}
		else
		{
			// Queue up the command via MPSC command queue
			AudioMixerThreadMPSCCommand([this, InAudioBusKey, InPatchInput]()
			{
				AddPatchInputForAudioBus(InAudioBusKey, InPatchInput);
			}, AUDIO_MIXER_THREAD_COMMAND_STRING("AddPatchInputForAudioBus()"));
		}
	}

	void FMixerSourceManager::AddPatchInputForAudioBus_AudioThread(FAudioBusKey InAudioBusKey, const FPatchInput& InPatchInput)
	{
		AudioMixerThreadCommand([this, InAudioBusKey, InPatchInput]()
		{
			AddPatchInputForAudioBus(InAudioBusKey, InPatchInput);
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("AddPatchInputForAudioBus_AudioThread()"));
	}

	void FMixerSourceManager::Play(const int32 SourceId)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		// Compute the frame within which to start the sound based on the current "thread faction" on the audio thread
		double StartTime = MixerDevice->GetAudioThreadTime();

		AudioMixerThreadCommand([this, SourceId, StartTime]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];
			
			SourceInfo.bIsPlaying = true;
			SourceInfo.bIsPaused = false;
			SourceInfo.bIsActive = true;

			SourceInfo.StartTime = StartTime;

			AUDIO_MIXER_DEBUG_LOG(SourceId, TEXT("Is playing"));
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("Play()"));
	}

	void FMixerSourceManager::CancelQuantizedSound(const int32 SourceId)
	{
		if (!MixerDevice)
		{
			return;
		}

		// If we are in the audio rendering thread, this is being called either before
		// or after source generation, so it is safe (and preffered) to call StopInternal()
		// synchronously. 
		if (MixerDevice->IsAudioRenderingThread())
		{
			StopInternal(SourceId);

			// Verify we have a reasonable Source
			AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			//Update game thread state
			SourceInfo.bIsDone = true;

			// Notify that we're now done with this source
			if (SourceInfo.SourceListener)
			{
				SourceInfo.SourceListener->OnDone();
			}
			if (SourceInfo.AudioLink)
			{
				SourceInfo.AudioLink->OnSourceDone(SourceId);
			}
		}
	}

	void FMixerSourceManager::Stop(const int32 SourceId)
	{
		if (!MixerDevice)
		{
			return;
		}

		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);

		//Assert that we are being called from the GameThread and the
		//source isn't busy.  Then call StopInternal() in a thread command
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId]()
		{
			StopInternal(SourceId);
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("Stop()"));
	}

	void FMixerSourceManager::StopInternal(const int32 SourceId)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		FSourceInfo& SourceInfo = SourceInfos[SourceId];

		SourceInfo.bIsPlaying = false;
		SourceInfo.bIsPaused = false;
		SourceInfo.bIsActive = false;
		SourceInfo.bIsStopping = false;

		if (SourceInfo.bIsPausedForQuantization)
		{
			UE_LOG(LogAudioMixer, Display, TEXT("StopInternal() cancelling command [%s]"), *SourceInfo.QuantizedCommandHandle.CommandPtr->GetCommandName().ToString());
			SourceInfo.QuantizedCommandHandle.Cancel();
			SourceInfo.bIsPausedForQuantization = false;
		}

		AUDIO_MIXER_DEBUG_LOG(SourceId, TEXT("Is immediately stopping"));
	}

	void FMixerSourceManager::StopFade(const int32 SourceId, const int32 NumFrames)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK(NumFrames > 0);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, NumFrames]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			SourceInfo.bIsPaused = false;
			SourceInfo.bIsStopping = true;

			if (SourceInfo.bIsPausedForQuantization)
			{
				// no need to fade, we haven't actually started playing
				StopInternal(SourceId);
				return;
			}
			
			// Only allow multiple of 4 fade frames and positive
			int32 NumFadeFrames = AlignArbitrary(NumFrames, 4);
			if (NumFadeFrames <= 0)
			{
				// Stop immediately if we've been given no fade frames
				SourceInfo.bIsPlaying = false;
				SourceInfo.bIsPaused = false;
				SourceInfo.bIsActive = false;
				SourceInfo.bIsStopping = false;
			}
			else
			{
				// compute the fade slope
				SourceInfo.VolumeFadeStart = SourceInfo.VolumeSourceStart;
				SourceInfo.VolumeFadeNumFrames = NumFadeFrames;
				SourceInfo.VolumeFadeSlope = -SourceInfo.VolumeSourceStart / SourceInfo.VolumeFadeNumFrames;
				SourceInfo.VolumeFadeFramePosition = 0;
			}

			AUDIO_MIXER_DEBUG_LOG(SourceId, TEXT("Is stopping with fade"));
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("StopFade()"));
	}
	
	void FMixerSourceManager::Pause(const int32 SourceId)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			SourceInfo.bIsPaused = true;
			SourceInfo.bIsActive = false;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("Pause()"));
	}

	void FMixerSourceManager::SetPitch(const int32 SourceId, const float Pitch)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);

		AudioMixerThreadCommand([this, SourceId, Pitch]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
			check(NumOutputFrames > 0);

			SourceInfos[SourceId].PitchSourceParam.SetValue(Pitch, NumOutputFrames);
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetPitch()"));
	}

	void FMixerSourceManager::SetVolume(const int32 SourceId, const float Volume)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, Volume]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
			check(NumOutputFrames > 0);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// Only set the volume if we're not stopping. Stopping sources are setting their volume to 0.0.
			if (!SourceInfo.bIsStopping)
			{
				// If we've not yet set a volume, we need to immediately set the start and destination to be the same value (to avoid an initial fade in)
				if (SourceInfos[SourceId].VolumeSourceDestination < 0.0f)
				{
					SourceInfos[SourceId].VolumeSourceStart = Volume;
				}

				SourceInfos[SourceId].VolumeSourceDestination = Volume;
			}
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetVolume()"));
	}

	void FMixerSourceManager::SetDistanceAttenuation(const int32 SourceId, const float DistanceAttenuation)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, DistanceAttenuation]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
			check(NumOutputFrames > 0);

			// If we've not yet set a distance attenuation, we need to immediately set the start and destination to be the same value (to avoid an initial fade in)
			if (SourceInfos[SourceId].DistanceAttenuationSourceDestination < 0.0f)
			{
				SourceInfos[SourceId].DistanceAttenuationSourceStart = DistanceAttenuation;
			}

			SourceInfos[SourceId].DistanceAttenuationSourceDestination = DistanceAttenuation;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetDistanceAttenuation()"));
	}

	void FMixerSourceManager::SetSpatializationParams(const int32 SourceId, const FSpatializationParams& InParams)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InParams]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			SourceInfos[SourceId].SpatParams = InParams;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetSpatializationParams()"));
	}

	void FMixerSourceManager::SetChannelMap(const int32 SourceId, const uint32 NumInputChannels, const Audio::FAlignedFloatBuffer& ChannelMap, const bool bInIs3D, const bool bInIsCenterChannelOnly)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, NumInputChannels, ChannelMap, bInIs3D, bInIsCenterChannelOnly]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			check(NumOutputFrames > 0);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];
			FMixerSourceSubmixOutputBuffer& SourceSubmixOutput = SourceSubmixOutputBuffers[SourceId];

			if (SourceSubmixOutput.GetNumSourceChannels() != NumInputChannels && !SourceInfo.bUseHRTFSpatializer)
			{
				// This means that this source has been reinitialized as a different source while this command was in flight,
				// In which case it is of no use to us. Exit.
				return;
			}

			// Set whether or not this is a 3d channel map and if its center channel only. Used for reseting channel maps on device change.
			SourceInfo.bIs3D = bInIs3D;
			SourceInfo.bIsCenterChannelOnly = bInIsCenterChannelOnly;

			bool bNeedsSpeakerMap = SourceSubmixOutput.SetChannelMap(ChannelMap, bInIsCenterChannelOnly);
			GameThreadInfo.bNeedsSpeakerMap[SourceId] = bNeedsSpeakerMap;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetChannelMap()"));
	}

	void FMixerSourceManager::SetLPFFrequency(const int32 SourceId, const float InLPFFrequency)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InLPFFrequency]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// LowPassFreq is cached off as the version set by this setter as well as that internal to the LPF.
			// There is a second cutoff frequency cached in SourceInfo.LowpassModulation updated per buffer callback.
			// On callback, the client version may be overridden with the modulation LPF value depending on which is more aggressive.  
			SourceInfo.LowPassFreq = InLPFFrequency;
			SourceInfo.LowPassFilter.StartFrequencyInterpolation(InLPFFrequency, NumOutputFrames);
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetLPFFrequency()"));
	}

	void FMixerSourceManager::SetHPFFrequency(const int32 SourceId, const float InHPFFrequency)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InHPFFrequency]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// HighPassFreq is cached off as the version set by this setter as well as that internal to the HPF.
			// There is a second cutoff frequency cached in SourceInfo.HighpassModulation updated per buffer callback.
			// On callback, the client version may be overridden with the modulation HPF value depending on which is more aggressive.  
			SourceInfo.HighPassFreq = InHPFFrequency;
			SourceInfo.HighPassFilter.StartFrequencyInterpolation(InHPFFrequency, NumOutputFrames);
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetHPFFrequency()"));
	}

	void FMixerSourceManager::SetModLPFFrequency(const int32 SourceId, const float InLPFFrequency)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InLPFFrequency]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];
			SourceInfo.LowpassModulationBase = InLPFFrequency;
			SourceInfo.bModFiltersUpdated = true;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetModLPFFrequency()"));
	}

	void FMixerSourceManager::SetModHPFFrequency(const int32 SourceId, const float InHPFFrequency)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InHPFFrequency]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];
			SourceInfo.HighpassModulationBase = InHPFFrequency;
			SourceInfo.bModFiltersUpdated = true;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetModHPFFrequency()"));
	}

	void FMixerSourceManager::SetModulationRouting(const int32 SourceId, FSoundModulationDefaultSettings& ModulationSettings)
	{
		FSourceInfo& SourceInfo = SourceInfos[SourceId];

		FModulationDestination VolumeMod;
		VolumeMod.Init(MixerDevice->DeviceID, FName("Volume"), false /* bInIsBuffered */, true /* bInValueLinear */);
		VolumeMod.UpdateModulators(ModulationSettings.VolumeModulationDestination.Modulators);

		FModulationDestination PitchMod;
		PitchMod.Init(MixerDevice->DeviceID, FName("Pitch"), false /* bInIsBuffered */);
		PitchMod.UpdateModulators(ModulationSettings.PitchModulationDestination.Modulators);

		FModulationDestination HighpassMod;
		HighpassMod.Init(MixerDevice->DeviceID, FName("HPFCutoffFrequency"), false /* bInIsBuffered */);
		HighpassMod.UpdateModulators(ModulationSettings.HighpassModulationDestination.Modulators);

		FModulationDestination LowpassMod;
		LowpassMod.Init(MixerDevice->DeviceID, FName("LPFCutoffFrequency"), false /* bInIsBuffered */);
		LowpassMod.UpdateModulators(ModulationSettings.LowpassModulationDestination.Modulators);


		AudioMixerThreadCommand([
			this,
				SourceId,
				VolumeModulation = MoveTemp(VolumeMod),
				HighpassModulation = MoveTemp(HighpassMod),
				LowpassModulation = MoveTemp(LowpassMod),
				PitchModulation = MoveTemp(PitchMod)
		]() mutable
			{
				FSourceInfo& SourceInfo = SourceInfos[SourceId];

				SourceInfo.VolumeModulation = MoveTemp(VolumeModulation);
				SourceInfo.PitchModulation = MoveTemp(PitchModulation);
				SourceInfo.LowpassModulation = MoveTemp(LowpassModulation);
				SourceInfo.HighpassModulation = MoveTemp(HighpassModulation);
			}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetModulationRouting()")
		);
	}

	void FMixerSourceManager::SetSourceBufferListener(const int32 SourceId, FSharedISourceBufferListenerPtr& InSourceBufferListener, bool InShouldSourceBufferListenerZeroBuffer)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InSourceBufferListener, InShouldSourceBufferListenerZeroBuffer]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];
			SourceInfo.SourceBufferListener = InSourceBufferListener;
			SourceInfo.bShouldSourceBufferListenerZeroBuffer = InShouldSourceBufferListenerZeroBuffer;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetSourceBufferListener()"));
	}

	void FMixerSourceManager::SetModVolume(const int32 SourceId, const float InModVolume)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InModVolume]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];
			SourceInfo.VolumeModulationBase = InModVolume;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetModVolume()"));
	}

	void FMixerSourceManager::SetModPitch(const int32 SourceId, const float InModPitch)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InModPitch]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			FSourceInfo& SourceInfo = SourceInfos[SourceId];
			SourceInfo.PitchModulationBase = InModPitch;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetModPitch()"));
	}

	void FMixerSourceManager::SetSubmixSendInfo(const int32 SourceId, const FMixerSourceSubmixSend& InSubmixSend)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InSubmixSend]()
		{
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			FMixerSubmixPtr InSubmixPtr = InSubmixSend.Submix.Pin();
			if (InSubmixPtr.IsValid())
			{
				// Determine whether submix send is new and whether any sends have 
				// a pre-distance-attenuation send.
				bool bIsNew = true;
				SourceInfo.bHasPreDistanceAttenuationSend = InSubmixSend.SubmixSendStage == EMixerSourceSubmixSendStage::PreDistanceAttenuation;

				for (FMixerSourceSubmixSend& SubmixSend : SourceInfo.SubmixSends)
				{
					FMixerSubmixPtr SubmixPtr = SubmixSend.Submix.Pin();

					if (SubmixPtr.IsValid())
					{
						if (SubmixPtr->GetId() == InSubmixPtr->GetId())
						{
							// Update existing submix send if it already exists
							SubmixSend.SendLevel = InSubmixSend.SendLevel;
							SubmixSend.SubmixSendStage = InSubmixSend.SubmixSendStage;
							bIsNew = false;
							if (SourceInfo.bHasPreDistanceAttenuationSend)
							{
								break;
							}
						}

						if (SubmixSend.SubmixSendStage == EMixerSourceSubmixSendStage::PreDistanceAttenuation)
						{
							SourceInfo.bHasPreDistanceAttenuationSend = true;
						}
					}
				}

				if (bIsNew)
				{
					SourceInfo.SubmixSends.Add(InSubmixSend);
				}
				
				// If we don't have a pre-distance attenuation send, lets zero out the buffer so the output buffer stops doing math with it.
				if (!SourceInfo.bHasPreDistanceAttenuationSend)
				{
					SourceSubmixOutputBuffers[SourceId].SetPreAttenuationSourceBuffer(nullptr);
				}

				FMixerSourceVoice* SourceVoice = MixerSources[SourceId];
				if (ensureAlways(nullptr != SourceVoice))
				{
					InSubmixPtr->AddOrSetSourceVoice(SourceVoice, InSubmixSend.SendLevel, InSubmixSend.SubmixSendStage);
				}
			}
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetSubmixSendInfo()"));
	}

	void FMixerSourceManager::ClearSubmixSendInfo(const int32 SourceId, const FMixerSourceSubmixSend& InSubmixSend)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InSubmixSend]()
		{
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			FMixerSubmixPtr InSubmixPtr = InSubmixSend.Submix.Pin();
			if (InSubmixPtr.IsValid())
			{
				for (int32 i = SourceInfo.SubmixSends.Num() - 1; i >= 0; --i)
				{
					if (SourceInfo.SubmixSends[i].Submix == InSubmixSend.Submix)
					{
						SourceInfo.SubmixSends.RemoveAtSwap(i, EAllowShrinking::No);
					}
				}

				// Update the has predist attenuation send state
				SourceInfo.bHasPreDistanceAttenuationSend = false;
				for (FMixerSourceSubmixSend& SubmixSend : SourceInfo.SubmixSends)
				{
					FMixerSubmixPtr SubmixPtr = SubmixSend.Submix.Pin();
					if (SubmixPtr.IsValid())
					{
						if (SubmixSend.SubmixSendStage == EMixerSourceSubmixSendStage::PreDistanceAttenuation)
						{
							SourceInfo.bHasPreDistanceAttenuationSend = true;
							break;
						}
					}
				}

				// If we don't have a pre-distance attenuation send, lets zero out the buffer so the output buffer stops doing math with it.
				if (!SourceInfo.bHasPreDistanceAttenuationSend)
				{
					SourceSubmixOutputBuffers[SourceId].SetPreAttenuationSourceBuffer(nullptr);
				}

				// Now remove the source voice from the submix send list
				InSubmixPtr->RemoveSourceVoice(MixerSources[SourceId]);
			}
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("ClearSubmixSendInfo()"));
	}

	void FMixerSourceManager::SetBusSendInfo(const int32 SourceId, EBusSendType InAudioBusSendType, uint32 AudioBusId, float BusSendLevel)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK(GameThreadInfo.bIsBusy[SourceId]);
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		AudioMixerThreadCommand([this, SourceId, InAudioBusSendType, AudioBusId, BusSendLevel]()
		{
			// Create mapping of source id to bus send level
			FAudioBusSend BusSend;
			BusSend.SourceId = SourceId;
			BusSend.SendLevel = BusSendLevel;

			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// Retrieve the bus we want to send audio to
			TSharedPtr<FMixerAudioBus>* AudioBusPtr = AudioBuses.Find(AudioBusId);

			// If we already have a bus, we update the amount of audio we want to send to it
			if (AudioBusPtr)
			{
				(*AudioBusPtr)->AddSend(InAudioBusSendType, BusSend);
			}
			else
			{
				// If the bus is not registered, make a new entry on the send
				TSharedPtr<FMixerAudioBus> NewBusData(new FMixerAudioBus(this, true, SourceInfo.NumInputChannels));

				// Add a send to it. This will not have a bus instance id (i.e. won't output audio), but 
				// we register the send anyway in the event that this bus does play, we'll know to send this
				// source's audio to it.
				NewBusData->AddSend(InAudioBusSendType, BusSend);

				AudioBuses.Add(AudioBusId, NewBusData);
			}

			// Check to see if we need to create new bus data. If we are not playing a bus with this id, then we
			// need to create a slot for it such that when a bus does play, it'll start rendering audio from this source
			bool bExisted = false;
			for (uint32 BusId : SourceInfo.AudioBusSends[(int32)InAudioBusSendType])
			{
				if (BusId == AudioBusId)
				{
					bExisted = true;
					break;
				}
			}

			if (!bExisted)
			{
				SourceInfo.AudioBusSends[(int32)InAudioBusSendType].Add(AudioBusId);
			}
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetBusSendInfo()"));
	}

	void FMixerSourceManager::SetListenerTransforms(const TArray<FTransform>& InListenerTransforms)
	{
		AudioMixerThreadCommand([this, InListenerTransforms]()
		{
			ListenerTransforms = InListenerTransforms;
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("SetListenerTransforms()"));
	}

	const TArray<FTransform>* FMixerSourceManager::GetListenerTransforms() const
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
		return &ListenerTransforms;
	}

	int64 FMixerSourceManager::GetNumFramesPlayed(const int32 SourceId) const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);
		return SourceInfos[SourceId].NumFramesPlayed;
	}

	float FMixerSourceManager::GetEnvelopeValue(const int32 SourceId) const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);
		return SourceInfos[SourceId].SourceEnvelopeValue;
	}

#if ENABLE_AUDIO_DEBUG
	double FMixerSourceManager::GetCPUCoreUtilization(const int32 SourceId) const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		return GameThreadInfo.CPUCoreUtilization[SourceId];
	}
#endif // if ENABLE_AUDIO_DEBUG

	float FMixerSourceManager::GetRelativeRenderCost(const int32 SourceId) const
	{
		return GameThreadInfo.RelativeRenderCost[SourceId];
	}

	bool FMixerSourceManager::IsUsingHRTFSpatializer(const int32 SourceId) const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);
		return GameThreadInfo.bIsUsingHRTFSpatializer[SourceId];
	}

	bool FMixerSourceManager::NeedsSpeakerMap(const int32 SourceId) const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);
		return GameThreadInfo.bNeedsSpeakerMap[SourceId];
	}

	void FMixerSourceManager::ReadSourceFrame(const int32 SourceId)
	{
		FSourceInfo& SourceInfo = SourceInfos[SourceId];

		const int32 NumChannels = SourceInfo.NumInputChannels;

		// Check if the next frame index is out of range of the total number of frames we have in our current audio buffer
		bool bNextFrameOutOfRange = (SourceInfo.CurrentFrameIndex + 1) >= SourceInfo.CurrentAudioChunkNumFrames;
		bool bCurrentFrameOutOfRange = SourceInfo.CurrentFrameIndex >= SourceInfo.CurrentAudioChunkNumFrames;

		bool bReadCurrentFrame = true;

		// Check the boolean conditions that determine if we need to pop buffers from our queue (in PCMRT case) *OR* loop back (looping PCM data)
		while (bNextFrameOutOfRange || bCurrentFrameOutOfRange)
		{
			// If our current frame is in range, but next frame isn't, read the current frame now to avoid pops when transitioning between buffers
			if (bNextFrameOutOfRange && !bCurrentFrameOutOfRange)
			{
				// Don't need to read the current frame audio after reading new audio chunk
				bReadCurrentFrame = false;

				AUDIO_MIXER_CHECK(SourceInfo.CurrentPCMBuffer.IsValid());
				const float* AudioData = SourceInfo.CurrentPCMBuffer->AudioData.GetData();
				const int32 CurrentSampleIndex = SourceInfo.CurrentFrameIndex * NumChannels;

				for (int32 Channel = 0; Channel < NumChannels; ++Channel)
				{
					SourceInfo.CurrentFrameValues[Channel] = AudioData[CurrentSampleIndex + Channel];
				}
			}

			// If this is our first PCM buffer, we don't need to do a callback to get more audio
			if (SourceInfo.CurrentPCMBuffer.IsValid())
			{
				if (SourceInfo.CurrentPCMBuffer->LoopCount == Audio::LOOP_FOREVER && !SourceInfo.CurrentPCMBuffer->bRealTimeBuffer)
				{
					AUDIO_MIXER_DEBUG_LOG(SourceId, TEXT("Hit Loop boundary, looping."));

					SourceInfo.CurrentFrameIndex = FMath::Max(SourceInfo.CurrentFrameIndex - SourceInfo.CurrentAudioChunkNumFrames, 0);
					break;
				}

				if (ensure(SourceInfo.MixerSourceBuffer.IsValid()))
				{
#if ENABLE_AUDIO_DEBUG
					// Writing to this value is a read/write race condition on the CPUCoreUtilization value. Calling this
					// out as an acceptable race condition given that it is utilized for debug purposes only. 
					GameThreadInfo.CPUCoreUtilization[SourceId] = SourceInfo.MixerSourceBuffer->GetCPUCoreUtilization();
#endif // if ENABLE_AUDIO_DEBUG

					GameThreadInfo.RelativeRenderCost[SourceId] = SourceInfo.MixerSourceBuffer->GetRelativeRenderCost();

					SourceInfo.MixerSourceBuffer->OnBufferEnd();
				}
			}

			// If we have audio in our queue, we're still playing
			if (ensure(SourceInfo.MixerSourceBuffer.IsValid()) && SourceInfo.MixerSourceBuffer->GetNumBuffersQueued() > 0 && NumChannels > 0)
			{
				SourceInfo.CurrentPCMBuffer = SourceInfo.MixerSourceBuffer->GetNextBuffer();
				SourceInfo.CurrentAudioChunkNumFrames = SourceInfo.CurrentPCMBuffer->AudioData.Num() / NumChannels;

				// Subtract the number of frames in the current buffer from our frame index.
				// Note: if this is the first time we're playing, CurrentFrameIndex will be 0
				if (bReadCurrentFrame)
				{
					SourceInfo.CurrentFrameIndex = FMath::Max(SourceInfo.CurrentFrameIndex - SourceInfo.CurrentAudioChunkNumFrames, 0);
				}
				else
				{
					// Since we're not reading the current frame, we allow the current frame index to be negative (NextFrameIndex will then be 0)
					// This prevents dropping a frame of audio on the buffer boundary
					SourceInfo.CurrentFrameIndex = -1;
				}
			}
			else
			{
				SourceInfo.bIsLastBuffer = !SourceInfo.SubCallbackDelayLengthInFrames;
				SourceInfo.SubCallbackDelayLengthInFrames = 0;
				return;
			}

			bNextFrameOutOfRange = (SourceInfo.CurrentFrameIndex + 1) >= SourceInfo.CurrentAudioChunkNumFrames;
			bCurrentFrameOutOfRange = SourceInfo.CurrentFrameIndex >= SourceInfo.CurrentAudioChunkNumFrames;
		}

		if (SourceInfo.CurrentPCMBuffer.IsValid())
		{
			// Grab the float PCM audio data (which could be a new audio chunk from previous ReadSourceFrame call)
			const float* AudioData = SourceInfo.CurrentPCMBuffer->AudioData.GetData();
			const int32 CurrentSampleIndex = SourceInfo.CurrentFrameIndex * NumChannels;
			const int32 NextSampleIndex = (SourceInfo.CurrentFrameIndex + 1)  * NumChannels;
			const int32 AudioDataNum = SourceInfo.CurrentPCMBuffer->AudioData.Num();

			if(ensureAlwaysMsgf(AudioDataNum >= NextSampleIndex + NumChannels
				, TEXT("Bailing due to bad CurrentPCMBuffer:  AudioData.Num() = %i, NextSampleIndex = %i, NumChannels = %i"), AudioDataNum, NextSampleIndex, NumChannels))
			{
				if (bReadCurrentFrame)
				{
					for (int32 Channel = 0; Channel < NumChannels; ++Channel)
					{
						SourceInfo.CurrentFrameValues[Channel] = AudioData[CurrentSampleIndex + Channel];
						SourceInfo.NextFrameValues[Channel] = AudioData[NextSampleIndex + Channel];
					}
				}
				else if (NextSampleIndex != SourceInfo.CurrentPCMBuffer->AudioData.Num())
				{
					for (int32 Channel = 0; Channel < NumChannels; ++Channel)
					{
						SourceInfo.NextFrameValues[Channel] = AudioData[NextSampleIndex + Channel];
					}
				}
			}
			else
			{
				// fill w/ silence instead of the bad access
				for (int32 Channel = 0; Channel < NumChannels; ++Channel)
				{
					SourceInfo.CurrentFrameValues[Channel] = 0.f;
					SourceInfo.NextFrameValues[Channel] = 0.f;
				}
			}
		}
	}

	void FMixerSourceManager::ComputeSourceBuffersForIdRange(const bool bGenerateBuses, const int32 SourceIdStart, const int32 SourceIdEnd)
	{
		CSV_SCOPED_TIMING_STAT(Audio, SourceBuffers);
		CONDITIONAL_SCOPE_CYCLE_COUNTER(STAT_AudioMixerSourceBuffers, (SourceIdStart < SourceIdEnd));

		const double AudioRenderThreadTime = MixerDevice->GetAudioRenderThreadTime();
		const double AudioClockDelta = MixerDevice->GetAudioClockDelta();

		for (int32 SourceId = SourceIdStart; SourceId < SourceIdEnd; ++SourceId)
		{
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			if (!SourceInfo.bIsBusy || !SourceInfo.bIsPlaying || SourceInfo.bIsPaused || SourceInfo.bIsPausedForQuantization)
			{
				continue;
			}

			// If this source is still playing at this point but technically done, zero the buffers. We haven't yet been removed by the FMixerSource owner.
			// This should be rare but could happen due to thread timing since done-ness is queried on audio thread.
			if (SourceInfo.bIsDone)
			{
				const int32 NumSamples = NumOutputFrames * SourceInfo.NumInputChannels;

				SourceInfo.PreDistanceAttenuationBuffer.Reset();
				SourceInfo.PreDistanceAttenuationBuffer.AddZeroed(NumSamples);

				SourceInfo.SourceBuffer.Reset();
				SourceInfo.SourceBuffer.AddZeroed(NumSamples);

				continue;
			}

			const bool bIsSourceBus = SourceInfo.AudioBusId != INDEX_NONE;
			if ((bGenerateBuses && !bIsSourceBus) || (!bGenerateBuses && bIsSourceBus))
			{
				continue;
			}

			// Fill array with elements all at once to avoid sequential Add() operation overhead.
			const int32 NumSamples = NumOutputFrames * SourceInfo.NumInputChannels;
			
			// Initialize both the pre-distance attenuation buffer and the source buffer
			SourceInfo.PreDistanceAttenuationBuffer.Reset();
			SourceInfo.PreDistanceAttenuationBuffer.AddZeroed(NumSamples);


			SourceInfo.SourceEffectScratchBuffer.Reset();
			SourceInfo.SourceEffectScratchBuffer.AddZeroed(NumSamples);

			SourceInfo.SourceBuffer.Reset();
			SourceInfo.SourceBuffer.AddZeroed(NumSamples);

			if (SourceInfo.SubCallbackDelayLengthInFrames && !SourceInfo.bDelayLineSet)
			{
				SourceInfo.SourceBufferDelayLine.SetCapacity(SourceInfo.SubCallbackDelayLengthInFrames * SourceInfo.NumInputChannels + SourceInfo.NumInputChannels);
				SourceInfo.SourceBufferDelayLine.PushZeros(SourceInfo.SubCallbackDelayLengthInFrames * SourceInfo.NumInputChannels);
				SourceInfo.bDelayLineSet = true;
			}

			float* PreDistanceAttenBufferPtr = SourceInfo.PreDistanceAttenuationBuffer.GetData();

			// if this is a bus, we just want to copy the bus audio to this source's output audio
			// Note we need to copy this since bus instances may have different audio via dynamic source effects, etc.
			if (bIsSourceBus)
			{
				// Get the source's rendered and mixed audio bus data
				const TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(SourceInfo.AudioBusId);
				if (AudioBusPtr.IsValid())
				{
					int32 NumFramesPlayed = NumOutputFrames;
					if (SourceInfo.SourceBusDurationFrames != INDEX_NONE)
					{
						// If we're now finishing, only copy over the real data
						if ((SourceInfo.NumFramesPlayed + NumOutputFrames) >= SourceInfo.SourceBusDurationFrames)
						{
							NumFramesPlayed = SourceInfo.SourceBusDurationFrames - SourceInfo.NumFramesPlayed;
							SourceInfo.bIsLastBuffer = true;
						}
					}

					SourceInfo.NumFramesPlayed += NumFramesPlayed;

					// Retrieve the channel map of going from the audio bus channel count to the source channel count since they may not match
					int32 NumAudioBusChannels = AudioBusPtr->GetNumChannels();
					if (NumAudioBusChannels != SourceInfo.NumInputChannels)
					{
						Audio::FAlignedFloatBuffer ChannelMap;
						MixerDevice->Get2DChannelMap(SourceInfo.bIsVorbis, AudioBusPtr->GetNumChannels(), SourceInfo.NumInputChannels, SourceInfo.bIsCenterChannelOnly, ChannelMap);
						AudioBusPtr->CopyCurrentBuffer(ChannelMap, SourceInfo.NumInputChannels, SourceInfo.PreDistanceAttenuationBuffer, NumFramesPlayed);
					}
					else
					{
						AudioBusPtr->CopyCurrentBuffer(SourceInfo.NumInputChannels, SourceInfo.PreDistanceAttenuationBuffer, NumFramesPlayed);
					}
				}
			}
			else
			{

#if AUDIO_SUBFRAME_ENABLED
				// If we're not going to start yet, just continue
				double StartFraction = (SourceInfo.StartTime - AudioRenderThreadTime) / AudioClockDelta;
				if (StartFraction >= 1.0)
				{
					// note this is already zero'd so no need to write zeroes
					SourceInfo.PitchSourceParam.Reset();
					continue;
				}

				// Init the frame index iterator to 0 (i.e. render whole buffer)
				int32 StartFrame = 0;

				// If the start fraction is greater than 0.0 (and is less than 1.0), we are starting on a sub-frame
				// Otherwise, just start playing it right away
				if (StartFraction > 0.0)
				{
					StartFrame = NumOutputFrames * StartFraction;
				}

				// Update sample index to the frame we're starting on, accounting for source channels
				int32 SampleIndex = StartFrame * SourceInfo.NumInputChannels;
				bool bWriteOutZeros = true;
#else
				int32 SampleIndex = 0;
				int32 StartFrame = 0;
#endif

				// Modulate parameter target should modulation be active
				// Due to managing two separate pitch values that are updated at different rates
				// (game thread rate and copy set by SetPitch and buffer callback rate set by Modulation System),
				// the PitchSourceParam's target is marshaled before processing by mult'ing in the modulation pitch,
				// processing the buffer, and then resetting it back if modulation is active. 

				const bool bModActive = MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid();
				if (bModActive)
				{
					SourceInfo.PitchModulation.ProcessControl(SourceInfo.PitchModulationBase);
				}

				const float TargetPitch = SourceInfo.PitchSourceParam.GetTarget();
				// Convert from semitones to frequency multiplier
				const float ModPitch = bModActive
					? Audio::GetFrequencyMultiplier(SourceInfo.PitchModulation.GetValue())
					: 1.0f;
				const float FinalPitch = FMath::Clamp(TargetPitch * ModPitch, MinModulationPitchRangeFreqCVar, MaxModulationPitchRangeFreqCVar);
				SourceInfo.PitchSourceParam.SetValue(FinalPitch, NumOutputFrames);

#if UE_AUDIO_PROFILERTRACE_ENABLED
				const bool bChannelEnabled = UE_TRACE_CHANNELEXPR_IS_ENABLED(AudioMixerChannel);
				if (bChannelEnabled)
				{
					UE_TRACE_LOG(Audio, MixerSourcePitch, AudioMixerChannel)
						<< MixerSourcePitch.DeviceId(MixerDevice->DeviceID)
						<< MixerSourcePitch.Timestamp(FPlatformTime::Cycles64())
						<< MixerSourcePitch.PlayOrder(SourceInfo.PlayOrder)
						<< MixerSourcePitch.Pitch(TargetPitch);
				}
#endif // UE_AUDIO_PROFILERTRACE_ENABLED

				float CurrentAlpha = SourceInfo.CurrentFrameAlpha;

				for (int32 Frame = StartFrame; Frame < NumOutputFrames; ++Frame)
				{
					// If we've read our last buffer, we're done
					if (SourceInfo.bIsLastBuffer)
					{
						break;
					}

					// Whether or not we need to read another sample from the source buffers
					// If we haven't yet played any frames, then we will need to read the first source samples no matter what
					bool bReadNextSample = !SourceInfo.bHasStarted;

					// Reset that we've started generating audio
					SourceInfo.bHasStarted = true;

					// Update the PrevFrameIndex value for the source based on alpha value
					if (CurrentAlpha >= 1.0f)
					{
						// Our inter-frame alpha lerping value is causing us to read new source frames
						bReadNextSample = true;
						
						const float Delta = FMath::FloorToFloat(CurrentAlpha);
						const int DeltaInt = (int)Delta;

						// Bump up the current frame index
						SourceInfo.CurrentFrameIndex += DeltaInt;

						// Bump up the frames played -- this is tracking the total frames in source file played
						// CurrentFrameIndex can wrap for looping sounds so won't be accurate in that case
						SourceInfo.NumFramesPlayed += DeltaInt;

						CurrentAlpha -= Delta;
					}

					// If our alpha parameter caused us to jump to a new source frame, we need
					// read new samples into our prev and next frame sample data
					if (bReadNextSample)
					{
						ReadSourceFrame(SourceId);
					}

					// perform linear SRC to get the next sample value from the decoded buffer
					if (SourceInfo.SubCallbackDelayLengthInFrames == 0)
					{
						for (int32 Channel = 0; Channel < SourceInfo.NumInputChannels; ++Channel)
						{
							const float CurrFrameValue = SourceInfo.CurrentFrameValues[Channel];
							const float NextFrameValue = SourceInfo.NextFrameValues[Channel];
							PreDistanceAttenBufferPtr[SampleIndex++] = FMath::Lerp(CurrFrameValue, NextFrameValue, CurrentAlpha);
						}
					}
					else
					{
						for (int32 Channel = 0; Channel < SourceInfo.NumInputChannels; ++Channel)
						{
							const float CurrFrameValue = SourceInfo.CurrentFrameValues[Channel];
							const float NextFrameValue = SourceInfo.NextFrameValues[Channel];

							const float CurrentSample = FMath::Lerp(CurrFrameValue, NextFrameValue, CurrentAlpha);

							SourceInfo.SourceBufferDelayLine.Push(&CurrentSample, 1);
							SourceInfo.SourceBufferDelayLine.Pop(&PreDistanceAttenBufferPtr[SampleIndex++], 1);
						}
					}

					const float CurrentPitchScale = SourceInfo.PitchSourceParam.Update();
					CurrentAlpha += CurrentPitchScale;
				}

				SourceInfo.CurrentFrameAlpha = CurrentAlpha;

				// After processing the frames, reset the pitch param
				SourceInfo.PitchSourceParam.Reset();

				// Reset target value as modulation may have modified prior to processing
				// And source param should not store modulation value internally as its
				// processed by the modulation plugin independently.
				SourceInfo.PitchSourceParam.SetValue(TargetPitch, NumOutputFrames);
			}
		}
	}

	void FMixerSourceManager::ConnectBusPatches()
	{
		while (TOptional<FPendingAudioBusConnection> PendingAudioBusConnection = PendingAudioBusConnections.Dequeue())
		{
			FAudioBusKey& AudioBusKey = PendingAudioBusConnection->AudioBusKey;
			int32 NumChannels = PendingAudioBusConnection->NumChannels;
			bool bIsAutomatic = PendingAudioBusConnection->bIsAutomatic;

			// If this audio bus id already exists, set it to not be automatic and return it
			TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(AudioBusKey);
			if (AudioBusPtr.IsValid())
			{
				// If this audio bus already existed, make sure the num channels lines up
				ensure(AudioBusPtr->GetNumChannels() == NumChannels);
				AudioBusPtr->SetAutomatic(bIsAutomatic);
			}
			else
			{
				// If the bus is not registered, make a new entry.
				AudioBusPtr = TSharedPtr<FMixerAudioBus>(new FMixerAudioBus(this, bIsAutomatic, NumChannels));
				AudioBuses.Add(AudioBusKey, AudioBusPtr);
			}

			switch (PendingAudioBusConnection->PatchVariant.GetIndex())
			{
			case FPendingAudioBusConnection::FPatchVariant::IndexOfType<FPatchInput>():
				AudioBusPtr->AddNewPatchInput(PendingAudioBusConnection->PatchVariant.Get<FPatchInput>());
				break;
			case FPendingAudioBusConnection::FPatchVariant::IndexOfType<FPatchOutputStrongPtr>():
				AudioBusPtr->AddNewPatchOutput(PendingAudioBusConnection->PatchVariant.Get<FPatchOutputStrongPtr>());
				break;
			}
		}
	}

	void FMixerSourceManager::ComputeBuses()
	{
		RenderThreadPhase = ESourceManagerRenderThreadPhase::ComputeBusses;

		ConnectBusPatches();

		// Loop through the bus registry and mix source audio
		for (auto& Entry : AudioBuses)
		{
			TSharedPtr<FMixerAudioBus>& AudioBus = Entry.Value;
			AudioBus->MixBuffer();
		}
	}

	void FMixerSourceManager::UpdateBuses()
	{
		RenderThreadPhase = ESourceManagerRenderThreadPhase::UpdateBusses;

		// Update the bus states post mixing. This flips the current/previous buffer indices.
		for (auto& Entry : AudioBuses)
		{
			TSharedPtr<FMixerAudioBus>& AudioBus = Entry.Value;
			AudioBus->Update();
		}
	}

	// ctor
	FMixerSourceManager::FAudioMixerThreadCommand::FAudioMixerThreadCommand(TFunction<void()>&& InFunction, const char* InDebugString, bool bInDeferExecution)
	: Function(MoveTemp(InFunction))
	, bDeferExecution(bInDeferExecution)		
#if WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
	, DebugString(InDebugString)
#endif //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
	{
	}

	void FMixerSourceManager::FAudioMixerThreadCommand::operator()() const
	{
#if WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
		StartExecuteTimeInCycles = FPlatformTime::Cycles64();
#endif //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG

		Function();

#if WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
		StartExecuteTimeInCycles = 0;
#endif //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
	}

	FString FMixerSourceManager::FAudioMixerThreadCommand::GetSafeDebugString() const
	{
#if WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
		return FString(DebugString ? ANSI_TO_TCHAR(DebugString): TEXT(""));
#else  //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
		return {};
#endif //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
	}

	float FMixerSourceManager::FAudioMixerThreadCommand::GetExecuteTimeInSeconds() const
	{
#if WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
		return FPlatformTime::ToSeconds64(FPlatformTime::Cycles64() - StartExecuteTimeInCycles);
#else  //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
		return 0.f;
#endif //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
	}

	void FMixerSourceManager::ApplyDistanceAttenuation(FSourceInfo& SourceInfo, int32 NumSamples)
	{
		if (DisableDistanceAttenuationCvar)
		{
			return;
		}

		TArrayView<float> PostDistanceAttenBufferView(SourceInfo.SourceBuffer.GetData(), SourceInfo.SourceBuffer.Num());
		Audio::ArrayFade(PostDistanceAttenBufferView, SourceInfo.DistanceAttenuationSourceStart, SourceInfo.DistanceAttenuationSourceDestination);
		SourceInfo.DistanceAttenuationSourceStart = SourceInfo.DistanceAttenuationSourceDestination;
	}

	void FMixerSourceManager::ComputePluginAudio(FSourceInfo& SourceInfo, FMixerSourceSubmixOutputBuffer& InSourceSubmixOutputBuffer, int32 SourceId, int32 NumSamples)
	{
		if (BypassAudioPluginsCvar)
		{
			// If we're bypassing audio plugins, our pre- and post-effect channels are the same as the input channels
			SourceInfo.NumPostEffectChannels = SourceInfo.NumInputChannels;

			// Set the ptr to use for post-effect buffers:
			InSourceSubmixOutputBuffer.SetPostAttenuationSourceBuffer(&SourceInfo.SourceBuffer);

			if (SourceInfo.bHasPreDistanceAttenuationSend)
			{
				InSourceSubmixOutputBuffer.SetPreAttenuationSourceBuffer(&SourceInfo.PreDistanceAttenuationBuffer);
			}
			return;
		}

		if (SourceInfo.AudioLink.IsValid())
		{
			IAudioLinkSourcePushed::FOnNewBufferParams Params;
			Params.SourceId = SourceId;
			Params.Buffer = SourceInfo.PreDistanceAttenuationBuffer;
			SourceInfo.AudioLink->OnNewBuffer(Params);
		}

		// If we have Source Buffer Listener
		if (SourceInfo.SourceBufferListener.IsValid())
		{
			// Pack all our state into a single struct.
			ISourceBufferListener::FOnNewBufferParams Params;
			Params.SourceId			= SourceId;
			Params.AudioData		= SourceInfo.PreDistanceAttenuationBuffer.GetData();
			Params.NumSamples		= SourceInfo.PreDistanceAttenuationBuffer.Num();
			Params.NumChannels		= SourceInfo.NumInputChannels;
			Params.SampleRate		= MixerDevice->GetSampleRate();

			// Fire callback.
			SourceInfo.SourceBufferListener->OnNewBuffer(Params);

			// Optionally, clear the buffer after we've broadcast it. 
			if (SourceInfo.bShouldSourceBufferListenerZeroBuffer)
			{
				FMemory::Memzero(SourceInfo.PreDistanceAttenuationBuffer.GetData(), SourceInfo.PreDistanceAttenuationBuffer.Num() * sizeof(float));
				FMemory::Memzero(SourceInfo.SourceBuffer.GetData(), SourceInfo.SourceBuffer.Num() * sizeof(float));
			}
		}

		float* PostDistanceAttenBufferPtr = SourceInfo.SourceBuffer.GetData();

		bool bShouldMixInReverb = false;
		if (SourceInfo.bUseReverbPlugin)
		{
			const FSpatializationParams* SourceSpatParams = &SourceInfo.SpatParams;

			// Move the audio buffer to the reverb plugin buffer
			FAudioPluginSourceInputData AudioPluginInputData;
			AudioPluginInputData.SourceId = SourceId;
			AudioPluginInputData.AudioBuffer = &SourceInfo.SourceBuffer;
			AudioPluginInputData.SpatializationParams = SourceSpatParams;
			AudioPluginInputData.NumChannels = SourceInfo.NumInputChannels;
			AudioPluginInputData.AudioComponentId = SourceInfo.AudioComponentID;
			SourceInfo.AudioPluginOutputData.AudioBuffer.Reset();
			SourceInfo.AudioPluginOutputData.AudioBuffer.AddZeroed(AudioPluginInputData.AudioBuffer->Num());

			MixerDevice->ReverbPluginInterface->ProcessSourceAudio(AudioPluginInputData, SourceInfo.AudioPluginOutputData);

			// Make sure the buffer counts didn't change and are still the same size
			AUDIO_MIXER_CHECK(SourceInfo.AudioPluginOutputData.AudioBuffer.Num() == NumSamples);

			//If the reverb effect doesn't send it's audio to an external device, mix the output data back in.
			if (!MixerDevice->bReverbIsExternalSend)
			{
				// Copy the reverb-processed data back to the source buffer
				InSourceSubmixOutputBuffer.CopyReverbPluginOutputData(SourceInfo.AudioPluginOutputData.AudioBuffer);
				bShouldMixInReverb = true;
			}
		}

		TArrayView<const float> ReverbPluginOutputBufferView(InSourceSubmixOutputBuffer.GetReverbPluginOutputData(), NumSamples);
		TArrayView<const float> AudioPluginOutputDataView(SourceInfo.AudioPluginOutputData.AudioBuffer.GetData(), NumSamples);
		TArrayView<float> PostDistanceAttenBufferView(PostDistanceAttenBufferPtr, NumSamples);

		if (SourceInfo.bUseOcclusionPlugin)
		{
			const FSpatializationParams* SourceSpatParams = &SourceInfo.SpatParams;

			// Move the audio buffer to the occlusion plugin buffer
			FAudioPluginSourceInputData AudioPluginInputData;
			AudioPluginInputData.SourceId = SourceId;
			AudioPluginInputData.AudioBuffer = &SourceInfo.SourceBuffer;
			AudioPluginInputData.SpatializationParams = SourceSpatParams;
			AudioPluginInputData.NumChannels = SourceInfo.NumInputChannels;
			AudioPluginInputData.AudioComponentId = SourceInfo.AudioComponentID;

			SourceInfo.AudioPluginOutputData.AudioBuffer.Reset();
			SourceInfo.AudioPluginOutputData.AudioBuffer.AddZeroed(AudioPluginInputData.AudioBuffer->Num());

			MixerDevice->OcclusionInterface->ProcessAudio(AudioPluginInputData, SourceInfo.AudioPluginOutputData);

			// Make sure the buffer counts didn't change and are still the same size
			AUDIO_MIXER_CHECK(SourceInfo.AudioPluginOutputData.AudioBuffer.Num() == NumSamples);

			// Copy the occlusion-processed data back to the source buffer and mix with the reverb plugin output buffer
			if (bShouldMixInReverb)
			{
				Audio::ArraySum(ReverbPluginOutputBufferView, AudioPluginOutputDataView, PostDistanceAttenBufferView);
			}
			else
			{
				FMemory::Memcpy(PostDistanceAttenBufferPtr, SourceInfo.AudioPluginOutputData.AudioBuffer.GetData(), sizeof(float) * NumSamples);
			}
		}
		else if (bShouldMixInReverb)
		{
			Audio::ArrayMixIn(ReverbPluginOutputBufferView, PostDistanceAttenBufferView);
		}

		// If the source has HRTF processing enabled, run it through the spatializer
		if (SourceInfo.bUseHRTFSpatializer)
		{
			CSV_SCOPED_TIMING_STAT(Audio, HRTF);
			SCOPE_CYCLE_COUNTER(STAT_AudioMixerHRTF);

			AUDIO_MIXER_CHECK(SpatialInterfaceInfo.SpatializationPlugin.IsValid());
			AUDIO_MIXER_CHECK(SourceInfo.NumInputChannels <= SpatialInterfaceInfo.MaxChannelsSupportedBySpatializationPlugin);

			FAudioPluginSourceInputData AudioPluginInputData;
			AudioPluginInputData.AudioBuffer = &SourceInfo.SourceBuffer;
			AudioPluginInputData.NumChannels = SourceInfo.NumInputChannels;
			AudioPluginInputData.SourceId = SourceId;
			AudioPluginInputData.SpatializationParams = &SourceInfo.SpatParams;
			AudioPluginInputData.AudioComponentId = SourceInfo.AudioComponentID;

			if (!SpatialInterfaceInfo.bSpatializationIsExternalSend)
			{
				SourceInfo.AudioPluginOutputData.AudioBuffer.Reset();
				SourceInfo.AudioPluginOutputData.AudioBuffer.AddZeroed(2 * NumOutputFrames);
			}

			{
				LLM_SCOPE(ELLMTag::AudioMixerPlugins);
				SpatialInterfaceInfo.SpatializationPlugin->ProcessAudio(AudioPluginInputData, SourceInfo.AudioPluginOutputData);
			}

			// If this is an external send, we treat this source audio as if it was still a mono source
			// This will allow it to traditionally pan in the ComputeOutputBuffers function and be
			// sent to submixes (e.g. reverb) panned and mixed down. Certain submixes will want this spatial 
			// information in addition to the external send. We've already bypassed adding this source
			// to a base submix (e.g. master/eq, etc)
			if (SpatialInterfaceInfo.bSpatializationIsExternalSend)
			{
				// Otherwise our pre- and post-effect channels are the same as the input channels
				SourceInfo.NumPostEffectChannels = SourceInfo.NumInputChannels;

				// Set the ptr to use for post-effect buffers rather than the plugin output data (since the plugin won't have output audio data)
				InSourceSubmixOutputBuffer.SetPostAttenuationSourceBuffer(&SourceInfo.SourceBuffer);

				if (SourceInfo.bHasPreDistanceAttenuationSend)
				{
					InSourceSubmixOutputBuffer.SetPreAttenuationSourceBuffer(&SourceInfo.PreDistanceAttenuationBuffer);
				}
			}
			else
			{
				// Otherwise, we are now a 2-channel file and should not be spatialized using normal 3d spatialization
				SourceInfo.NumPostEffectChannels = 2;

				// Set the ptr to use for post-effect buffers rather than the plugin output data (since the plugin won't have output audio data)
				InSourceSubmixOutputBuffer.SetPostAttenuationSourceBuffer(&SourceInfo.AudioPluginOutputData.AudioBuffer);

				if (SourceInfo.bHasPreDistanceAttenuationSend)
				{
					InSourceSubmixOutputBuffer.SetPreAttenuationSourceBuffer(&SourceInfo.PreDistanceAttenuationBuffer);
				}
			}
		}
		else
		{
			// Otherwise our pre- and post-effect channels are the same as the input channels
			SourceInfo.NumPostEffectChannels = SourceInfo.NumInputChannels;

			InSourceSubmixOutputBuffer.SetPostAttenuationSourceBuffer(&SourceInfo.SourceBuffer);

			if (SourceInfo.bHasPreDistanceAttenuationSend)
			{
				InSourceSubmixOutputBuffer.SetPreAttenuationSourceBuffer(&SourceInfo.PreDistanceAttenuationBuffer);
			}
		}
	}

	void FMixerSourceManager::ComputePostSourceEffectBufferForIdRange(bool bGenerateBuses, const int32 SourceIdStart, const int32 SourceIdEnd)
	{
		CSV_SCOPED_TIMING_STAT(Audio, SourceEffectsBuffers);
		CONDITIONAL_SCOPE_CYCLE_COUNTER(STAT_AudioMixerSourceEffectBuffers, (SourceIdStart < SourceIdEnd));

		const bool bIsDebugModeEnabled = DebugSoloSources.Num() > 0;

		for (int32 SourceId = SourceIdStart; SourceId < SourceIdEnd; ++SourceId)
		{
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			if (!SourceInfo.bIsBusy || !SourceInfo.bIsPlaying || SourceInfo.bIsPaused || SourceInfo.bIsPausedForQuantization || (SourceInfo.bIsDone && SourceInfo.bEffectTailsDone))
			{
				continue;
			}

			const bool bIsSourceBus = SourceInfo.AudioBusId != INDEX_NONE;
			if ((bGenerateBuses && !bIsSourceBus) || (!bGenerateBuses && bIsSourceBus))
			{
				continue;
			}

			// Copy and store the current state of the pre-distance attenuation buffer before we feed it through our source effects
			// This is used by pre-effect sends
			if (SourceInfo.AudioBusSends[(int32)EBusSendType::PreEffect].Num() > 0)
			{
				SourceInfo.PreEffectBuffer.Reset();
				SourceInfo.PreEffectBuffer.Reserve(SourceInfo.PreDistanceAttenuationBuffer.Num());

				FMemory::Memcpy(SourceInfo.PreEffectBuffer.GetData(), SourceInfo.PreDistanceAttenuationBuffer.GetData(), sizeof(float)*SourceInfo.PreDistanceAttenuationBuffer.Num());
			}

			float* PreDistanceAttenBufferPtr = SourceInfo.PreDistanceAttenuationBuffer.GetData();
			const int32 NumSamples = SourceInfo.PreDistanceAttenuationBuffer.Num();

			TArrayView<float> PreDistanceAttenBufferView(PreDistanceAttenBufferPtr, NumSamples);

			// Update volume fade information if we're stopping
			{
				float VolumeStart = 1.0f;
				float VolumeDestination = 1.0f;
				if (SourceInfo.bIsStopping)
				{
					int32 NumFadeFrames = FMath::Min(SourceInfo.VolumeFadeNumFrames - SourceInfo.VolumeFadeFramePosition, NumOutputFrames);

					SourceInfo.VolumeFadeFramePosition += NumFadeFrames;
					SourceInfo.VolumeSourceDestination = SourceInfo.VolumeFadeSlope * (float)SourceInfo.VolumeFadeFramePosition + SourceInfo.VolumeFadeStart;

					if (FMath::IsNearlyZero(SourceInfo.VolumeSourceDestination, KINDA_SMALL_NUMBER))
					{
						SourceInfo.VolumeSourceDestination = 0.0f;
					}

					const int32 NumFadeSamples = NumFadeFrames * SourceInfo.NumInputChannels;

					VolumeStart = SourceInfo.VolumeSourceStart;
					VolumeDestination = SourceInfo.VolumeSourceDestination;
					if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
					{
						const bool bHasProcessed = SourceInfo.VolumeModulation.GetHasProcessed();
						const float ModVolumeStart = SourceInfo.VolumeModulation.GetValue();
						SourceInfo.VolumeModulation.ProcessControl(SourceInfo.VolumeModulationBase);
						const float ModVolumeEnd = SourceInfo.VolumeModulation.GetValue();
						if (bHasProcessed)
						{
							VolumeStart *= ModVolumeStart;
						}
						else
						{
							VolumeStart *= ModVolumeEnd;
						}
						VolumeDestination *= ModVolumeEnd;
					}

					TArrayView<float> PreDistanceAttenBufferFadeSamplesView(PreDistanceAttenBufferPtr, NumFadeSamples);
					Audio::ArrayFade(PreDistanceAttenBufferFadeSamplesView, VolumeStart, VolumeDestination);

					// Zero the rest of the buffer
					if (NumFadeFrames < NumOutputFrames)
					{
						int32 SamplesLeft = NumSamples - NumFadeSamples;

						// Protect memzero call with some sanity checking on the inputs.
						if (SamplesLeft > 0 && NumFadeSamples >= 0 && NumFadeSamples < NumSamples)
						{
							FMemory::Memzero(&PreDistanceAttenBufferPtr[NumFadeSamples], sizeof(float) * SamplesLeft);
						}
					}
				}
				else
				{
					VolumeStart = SourceInfo.VolumeSourceStart;
					VolumeDestination = SourceInfo.VolumeSourceDestination;
					if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
					{
						const bool bHasProcessed = SourceInfo.VolumeModulation.GetHasProcessed();
						const float ModVolumeStart = SourceInfo.VolumeModulation.GetValue();
						SourceInfo.VolumeModulation.ProcessControl(SourceInfo.VolumeModulationBase);
						const float ModVolumeEnd = SourceInfo.VolumeModulation.GetValue();
						if (bHasProcessed)
						{
							VolumeStart *= ModVolumeStart;
						}
						else
						{
							VolumeStart *= ModVolumeEnd;
						}
						VolumeDestination *= ModVolumeEnd;
					}

					Audio::ArrayFade(PreDistanceAttenBufferView, VolumeStart, VolumeDestination);
				}

#if UE_AUDIO_PROFILERTRACE_ENABLED
				const bool bChannelEnabled = UE_TRACE_CHANNELEXPR_IS_ENABLED(AudioMixerChannel);
				if (bChannelEnabled)
				{
					UE_TRACE_LOG(Audio, MixerSourceVolume, AudioMixerChannel)
						<< MixerSourceVolume.DeviceId(MixerDevice->DeviceID)
						<< MixerSourceVolume.Timestamp(FPlatformTime::Cycles64())
						<< MixerSourceVolume.PlayOrder(SourceInfo.PlayOrder)
						<< MixerSourceVolume.Volume(VolumeDestination);

					UE_TRACE_LOG(Audio, MixerSourceDistanceAttenuation, AudioMixerChannel)
						<< MixerSourceDistanceAttenuation.DeviceId(MixerDevice->DeviceID)
						<< MixerSourceDistanceAttenuation.Timestamp(FPlatformTime::Cycles64())
						<< MixerSourceDistanceAttenuation.PlayOrder(SourceInfo.PlayOrder)
						<< MixerSourceDistanceAttenuation.DistanceAttenuation(SourceInfo.DistanceAttenuationSourceDestination);
				}
#endif // UE_AUDIO_PROFILERTRACE_ENABLED
			}

			SourceInfo.VolumeSourceStart = SourceInfo.VolumeSourceDestination;

			// Now process the effect chain if it exists
			if (!DisableSourceEffectsCvar && SourceInfo.SourceEffects.Num() > 0)
			{
				// Prepare this source's effect chain input data
				SourceInfo.SourceEffectInputData.CurrentVolume = SourceInfo.VolumeSourceDestination;

				const float Pitch = Audio::GetFrequencyMultiplier(SourceInfo.PitchModulation.GetValue());
				SourceInfo.SourceEffectInputData.CurrentPitch = SourceInfo.PitchSourceParam.GetValue() * Pitch;
				SourceInfo.SourceEffectInputData.AudioClock = MixerDevice->GetAudioClock();
				if (SourceInfo.NumInputFrames > 0)
				{
					SourceInfo.SourceEffectInputData.CurrentPlayFraction = (float)SourceInfo.NumFramesPlayed / SourceInfo.NumInputFrames;
				}
				SourceInfo.SourceEffectInputData.SpatParams = SourceInfo.SpatParams;

				// Get a ptr to pre-distance attenuation buffer ptr
				float* OutputSourceEffectBufferPtr = SourceInfo.SourceEffectScratchBuffer.GetData();

				SourceInfo.SourceEffectInputData.InputSourceEffectBufferPtr = SourceInfo.PreDistanceAttenuationBuffer.GetData();
				SourceInfo.SourceEffectInputData.NumSamples = NumSamples;

				// Loop through the effect chain passing in buffers
				FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
				{
					for (TSoundEffectSourcePtr& SoundEffectSource : SourceInfo.SourceEffects)
					{
						bool bPresetUpdated = false;
						if (SoundEffectSource->IsActive())
						{
							bPresetUpdated = SoundEffectSource->Update();
						}

						if (SoundEffectSource->IsActive())
						{
							SoundEffectSource->ProcessAudio(SourceInfo.SourceEffectInputData, OutputSourceEffectBufferPtr);

							// Copy output to input
							FMemory::Memcpy(SourceInfo.SourceEffectInputData.InputSourceEffectBufferPtr, OutputSourceEffectBufferPtr, sizeof(float) * NumSamples);
						}
					}
				}
			}

			const bool bWasEffectTailsDone = SourceInfo.bEffectTailsDone;

			if (!DisableEnvelopeFollowingCvar)
			{
				// Compute the source envelope using pre-distance attenuation buffer
				float AverageSampleValue = Audio::ArrayGetAverageAbsValue(PreDistanceAttenBufferView);
				SourceInfo.SourceEnvelopeValue = SourceInfo.SourceEnvelopeFollower.ProcessSample(AverageSampleValue);
				SourceInfo.SourceEnvelopeValue = FMath::Clamp(SourceInfo.SourceEnvelopeValue, 0.f, 1.f);

				SourceInfo.bEffectTailsDone = SourceInfo.bEffectTailsDone || SourceInfo.SourceEnvelopeValue < ENVELOPE_TAIL_THRESHOLD;
			}
			else
			{
				SourceInfo.bEffectTailsDone = true;
			}

			if (!bWasEffectTailsDone && SourceInfo.bEffectTailsDone)
			{
				SourceInfo.SourceListener->OnEffectTailsDone();
			}

			const bool bModActive = MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid();
			bool bUpdateModFilters = bModActive && (SourceInfo.bModFiltersUpdated || SourceInfo.LowpassModulation.IsActive() || SourceInfo.HighpassModulation.IsActive());

			if (SourceInfo.IsRenderingToSubmixes() || bUpdateModFilters)
			{
				// Only scale with distance attenuation and send to source audio to plugins if we're not in output-to-bus only mode
				const int32 NumOutputSamplesThisSource = NumOutputFrames * SourceInfo.NumInputChannels;

				if (!SourceInfo.IsRenderingToSubmixes())
				{
					SourceInfo.LowpassModulation.ProcessControl(SourceInfo.LowpassModulationBase);
					SourceInfo.LowPassFilter.StartFrequencyInterpolation(SourceInfo.LowpassModulation.GetValue(), NumOutputFrames);

					SourceInfo.HighpassModulation.ProcessControl(SourceInfo.HighpassModulationBase);
					SourceInfo.HighPassFilter.StartFrequencyInterpolation(SourceInfo.HighpassModulation.GetValue(), NumOutputFrames);
				}
				else if (bUpdateModFilters)
				{
					const float LowpassFreq = FMath::Min(SourceInfo.LowpassModulationBase, SourceInfo.LowPassFreq);
					SourceInfo.LowpassModulation.ProcessControl(LowpassFreq);
					SourceInfo.LowPassFilter.StartFrequencyInterpolation(SourceInfo.LowpassModulation.GetValue(), NumOutputFrames);

					const float HighpassFreq = FMath::Max(SourceInfo.HighpassModulationBase, SourceInfo.HighPassFreq);
					SourceInfo.HighpassModulation.ProcessControl(HighpassFreq);
					SourceInfo.HighPassFilter.StartFrequencyInterpolation(SourceInfo.HighpassModulation.GetValue(), NumOutputFrames);
				}

				const bool bBypassLPF = DisableFilteringCvar || (SourceInfo.LowPassFilter.GetCutoffFrequency() >= (MAX_FILTER_FREQUENCY - KINDA_SMALL_NUMBER));
				const bool bBypassHPF = DisableFilteringCvar || DisableHPFilteringCvar || (SourceInfo.HighPassFilter.GetCutoffFrequency() <= (MIN_FILTER_FREQUENCY + KINDA_SMALL_NUMBER));

				float* SourceBuffer = SourceInfo.SourceBuffer.GetData();
				float* HpfInputBuffer = PreDistanceAttenBufferPtr; // assume bypassing LPF (HPF uses input buffer as input)

				if (!bBypassLPF)
				{
					// Not bypassing LPF, so tell HPF to use LPF output buffer as input
					HpfInputBuffer = SourceBuffer;

					// process LPF audio block
					SourceInfo.LowPassFilter.ProcessAudioBuffer(PreDistanceAttenBufferPtr, SourceBuffer, NumOutputSamplesThisSource);
				}

				if (!bBypassHPF)
				{
					// process HPF audio block
					SourceInfo.HighPassFilter.ProcessAudioBuffer(HpfInputBuffer, SourceBuffer, NumOutputSamplesThisSource);
				}

#if UE_AUDIO_PROFILERTRACE_ENABLED
				const bool bChannelEnabled = UE_TRACE_CHANNELEXPR_IS_ENABLED(AudioMixerChannel);
				if (bChannelEnabled)
				{
					float LPFFrequency = MAX_FILTER_FREQUENCY;
					if (!bBypassLPF)
					{
						LPFFrequency = SourceInfo.LowpassModulation.GetValue();
					}

					float HPFFrequency = MIN_FILTER_FREQUENCY;
					if (!bBypassHPF)
					{
						HPFFrequency = SourceInfo.HighpassModulation.GetValue();
					}

					UE_TRACE_LOG(Audio, MixerSourceFilters, AudioMixerChannel)
						<< MixerSourceFilters.DeviceId(MixerDevice->DeviceID)
						<< MixerSourceFilters.Timestamp(FPlatformTime::Cycles64())
						<< MixerSourceFilters.PlayOrder(SourceInfo.PlayOrder)
						<< MixerSourceFilters.HPFFrequency(HPFFrequency)
						<< MixerSourceFilters.LPFFrequency(LPFFrequency);
					UE_TRACE_LOG(Audio, MixerSourceEnvelope, AudioMixerChannel)
						<< MixerSourceEnvelope.DeviceId(MixerDevice->DeviceID)
						<< MixerSourceEnvelope.Timestamp(FPlatformTime::Cycles64())
						<< MixerSourceEnvelope.PlayOrder(SourceInfo.PlayOrder)
						<< MixerSourceEnvelope.Envelope(SourceInfo.SourceEnvelopeValue);
				}
#endif // UE_AUDIO_PROFILERTRACE_ENABLED

				// We manually reset interpolation to avoid branches in filter code
				SourceInfo.LowPassFilter.StopFrequencyInterpolation();
				SourceInfo.HighPassFilter.StopFrequencyInterpolation();

				if (bBypassLPF && bBypassHPF)
				{
					FMemory::Memcpy(SourceBuffer, PreDistanceAttenBufferPtr, NumSamples * sizeof(float));
				}
			}

			if (SourceInfo.IsRenderingToSubmixes() || SpatialInterfaceInfo.bSpatializationIsExternalSend)
			{
				// Apply distance attenuation
				ApplyDistanceAttenuation(SourceInfo, NumSamples);

				FMixerSourceSubmixOutputBuffer& SourceSubmixOutputBuffer = SourceSubmixOutputBuffers[SourceId];

				// Send source audio to plugins
				ComputePluginAudio(SourceInfo, SourceSubmixOutputBuffer, SourceId, NumSamples);
			}

			// Check the source effect tails condition
			if (SourceInfo.bIsLastBuffer && SourceInfo.bEffectTailsDone)
			{
				// If we're done and our tails our done, clear everything out
				SourceInfo.CurrentFrameValues.Reset();
				SourceInfo.NextFrameValues.Reset();
				SourceInfo.CurrentPCMBuffer = nullptr;
			}
		}
	}

	void FMixerSourceManager::ComputeOutputBuffersForIdRange(const bool bGenerateBuses, const int32 SourceIdStart, const int32 SourceIdEnd)
	{
		CSV_SCOPED_TIMING_STAT(Audio, SourceOutputBuffers);
		CONDITIONAL_SCOPE_CYCLE_COUNTER(STAT_AudioMixerSourceOutputBuffers, (SourceIdStart < SourceIdEnd));

		for (int32 SourceId = SourceIdStart; SourceId < SourceIdEnd; ++SourceId)
		{
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// Don't need to compute anything if the source is not playing or paused (it will remain at 0.0 volume)
			// Note that effect chains will still be able to continue to compute audio output. The source output 
			// will simply stop being read from.
			if (!SourceInfo.bIsBusy || !SourceInfo.bIsPlaying || (SourceInfo.bIsDone && SourceInfo.bEffectTailsDone))
			{
				continue;
			}

			// If we're in generate buses mode and not a bus, or vice versa, or if we're set to only output audio to buses.
			// If set to output buses, no need to do any panning for the source. The buses will do the panning.
			const bool bIsSourceBus = SourceInfo.AudioBusId != INDEX_NONE;
			if ((bGenerateBuses && !bIsSourceBus) || (!bGenerateBuses && bIsSourceBus) || !SourceInfo.IsRenderingToSubmixes())
			{
				continue;
			}

			FMixerSourceSubmixOutputBuffer& SourceSubmixOutputBuffer = SourceSubmixOutputBuffers[SourceId];
			SourceSubmixOutputBuffer.ComputeOutput(SourceInfo.SpatParams);
		}
	}

	void FMixerSourceManager::GenerateSourceAudio(const bool bGenerateBuses, const int32 SourceIdStart, const int32 SourceIdEnd)
	{
		// Buses generate their input buffers independently
		// Get the next block of frames from the source buffers
		ComputeSourceBuffersForIdRange(bGenerateBuses, SourceIdStart, SourceIdEnd);

		// Compute the audio source buffers after their individual effect chain processing
		ComputePostSourceEffectBufferForIdRange(bGenerateBuses, SourceIdStart, SourceIdEnd);

		// Get the audio for the output buffers
		ComputeOutputBuffersForIdRange(bGenerateBuses, SourceIdStart, SourceIdEnd);
	}

	void FMixerSourceManager::GenerateSourceAudio(const bool bGenerateBuses)
	{
		RenderThreadPhase = bGenerateBuses ?
			ESourceManagerRenderThreadPhase::GenerateSrcAudio_WithBusses :
			ESourceManagerRenderThreadPhase::GenerateSrcAudio_WithoutBusses;
					
		// If there are no buses, don't need to do anything here
		if (bGenerateBuses && !AudioBuses.Num())
		{
			return;
		}

		if (NumSourceWorkers > 0 && !DisableParallelSourceProcessingCvar)
		{
			AUDIO_MIXER_CHECK(SourceWorkers.Num() == NumSourceWorkers);
			for (int32 i = 0; i < SourceWorkers.Num(); ++i)
			{
				FAudioMixerSourceWorker& Worker = SourceWorkers[i]->GetTask();
				Worker.SetGenerateBuses(bGenerateBuses);

				SourceWorkers[i]->StartBackgroundTask();
			}

			for (int32 i = 0; i < SourceWorkers.Num(); ++i)
			{
				SourceWorkers[i]->EnsureCompletion();
			}
		}
		else
		{
			GenerateSourceAudio(bGenerateBuses, 0, NumTotalSources);
		}
	}

	void FMixerSourceManager::MixOutputBuffers(const int32 SourceId, int32 InNumOutputChannels, const float InSendLevel, EMixerSourceSubmixSendStage InSubmixSendStage, FAlignedFloatBuffer& OutWetBuffer) const
	{
		if (InSendLevel > 0.0f)
		{
			const FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// Don't need to mix into submixes if the source is paused
			if (!SourceInfo.bIsPaused && !SourceInfo.bIsPausedForQuantization && !SourceInfo.bIsDone && SourceInfo.bIsPlaying)
			{
				const FMixerSourceSubmixOutputBuffer& SourceSubmixOutputBuffer = SourceSubmixOutputBuffers[SourceId];
				SourceSubmixOutputBuffer.MixOutput(InSendLevel, InSubmixSendStage, OutWetBuffer);
			}
		}
	}

	void FMixerSourceManager::Get2DChannelMap(const int32 SourceId, int32 InNumOutputChannels, Audio::FAlignedFloatBuffer& OutChannelMap)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		const FSourceInfo& SourceInfo = SourceInfos[SourceId];
		MixerDevice->Get2DChannelMap(SourceInfo.bIsVorbis, SourceInfo.NumInputChannels, InNumOutputChannels, SourceInfo.bIsCenterChannelOnly, OutChannelMap);
	}

	const ISoundfieldAudioPacket* FMixerSourceManager::GetEncodedOutput(const int32 SourceId, const FSoundfieldEncodingKey& InKey) const
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		const FSourceInfo& SourceInfo = SourceInfos[SourceId];

		// Don't need to mix into submixes if the source is paused
		if (!SourceInfo.bIsPaused && !SourceInfo.bIsPausedForQuantization && !SourceInfo.bIsDone && SourceInfo.bIsPlaying)
		{
			const FMixerSourceSubmixOutputBuffer& SourceSubmixOutputBuffer = SourceSubmixOutputBuffers[SourceId];
			return SourceSubmixOutputBuffer.GetSoundfieldPacket(InKey);
		}

		return nullptr;
	}

	const FQuat FMixerSourceManager::GetListenerRotation(const int32 SourceId) const
	{
		const FMixerSourceSubmixOutputBuffer& SubmixOutputBuffer = SourceSubmixOutputBuffers[SourceId];
		return SubmixOutputBuffer.GetListenerRotation();
	}

	void FMixerSourceManager::UpdateDeviceChannelCount(const int32 InNumOutputChannels)
	{
		AudioMixerThreadCommand([this, InNumOutputChannels]()
		{
			NumOutputSamples = NumOutputFrames * MixerDevice->GetNumDeviceChannels();

			// Update all source's to appropriate channel maps
			for (int32 SourceId = 0; SourceId < NumTotalSources; ++SourceId)
			{
				FSourceInfo& SourceInfo = SourceInfos[SourceId];

				// Don't need to do anything if it's not active or not paused. 
				if (!SourceInfo.bIsActive && !SourceInfo.bIsPaused)
				{
					continue;
				}

				FMixerSourceSubmixOutputBuffer& SourceSubmixOutputBuffer = SourceSubmixOutputBuffers[SourceId];
				SourceSubmixOutputBuffer.SetNumOutputChannels(InNumOutputChannels);

				SourceInfo.ScratchChannelMap.Reset();
				const int32 NumSourceChannels = SourceInfo.bUseHRTFSpatializer ? 2 : SourceInfo.NumInputChannels;

				// If this is a 3d source, then just zero out the channel map, it'll cause a temporary blip
				// but it should reset in the next tick
				if (SourceInfo.bIs3D)
				{
					GameThreadInfo.bNeedsSpeakerMap[SourceId] = true;
					SourceInfo.ScratchChannelMap.AddZeroed(NumSourceChannels * InNumOutputChannels);
				}
				// If it's a 2D sound, then just get a new channel map appropriate for the new device channel count
				else
				{
					SourceInfo.ScratchChannelMap.Reset();
					MixerDevice->Get2DChannelMap(SourceInfo.bIsVorbis, NumSourceChannels, InNumOutputChannels, SourceInfo.bIsCenterChannelOnly, SourceInfo.ScratchChannelMap);
				}

				SourceSubmixOutputBuffer.SetChannelMap(SourceInfo.ScratchChannelMap, SourceInfo.bIsCenterChannelOnly);
			}
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("UpdateDeviceChannelCount()"));
	}

	void FMixerSourceManager::UpdateSourceEffectChain(const uint32 InSourceEffectChainId, const TArray<FSourceEffectChainEntry>& InSourceEffectChain, const bool bPlayEffectChainTails)
	{
		AudioMixerThreadCommand([this, InSourceEffectChainId, InSourceEffectChain, bPlayEffectChainTails]()
		{
			FSoundEffectSourceInitData InitData;
			InitData.AudioClock = MixerDevice->GetAudioClock();
			InitData.SampleRate = MixerDevice->SampleRate;
			InitData.AudioDeviceId = MixerDevice->DeviceID;

			for (int32 SourceId = 0; SourceId < NumTotalSources; ++SourceId)
			{
				FSourceInfo& SourceInfo = SourceInfos[SourceId];

				if (SourceInfo.SourceEffectChainId == InSourceEffectChainId)
				{
					SourceInfo.bEffectTailsDone = !bPlayEffectChainTails;

					// Check to see if the chain didn't actually change
					FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
					{
						TArray<TSoundEffectSourcePtr>& ThisSourceEffectChain = SourceInfo.SourceEffects;
						bool bReset = false;
						if (InSourceEffectChain.Num() == ThisSourceEffectChain.Num())
						{
							for (int32 SourceEffectId = 0; SourceEffectId < ThisSourceEffectChain.Num(); ++SourceEffectId)
							{
								const FSourceEffectChainEntry& ChainEntry = InSourceEffectChain[SourceEffectId];

								TSoundEffectSourcePtr SourceEffectInstance = ThisSourceEffectChain[SourceEffectId];
								if (!SourceEffectInstance->IsPreset(ChainEntry.Preset))
								{
									// As soon as one of the effects change or is not the same, then we need to rebuild the effect graph
									bReset = true;
									break;
								}

								// Otherwise just update if it's just to bypass
								SourceEffectInstance->SetEnabled(!ChainEntry.bBypass);
							}
						}
						else
						{
							bReset = true;
						}

						if (bReset)
						{
							InitData.NumSourceChannels = SourceInfo.NumInputChannels;

							// First reset the source effect chain
							ResetSourceEffectChain(SourceId);

							// Rebuild it
							TArray<TSoundEffectSourcePtr> SourceEffects;
							BuildSourceEffectChain(SourceId, InitData, InSourceEffectChain, SourceEffects);

							SourceInfo.SourceEffects = SourceEffects;
							SourceInfo.SourceEffectPresets.Add(nullptr);
						}
					}
				}
			}
		}, AUDIO_MIXER_THREAD_COMMAND_STRING("UpdateSourceEffectChain()"), /*bDeferExecution*/true);
	}

	void FMixerSourceManager::PauseSoundForQuantizationCommand(const int32 SourceId)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		FSourceInfo& SourceInfo = SourceInfos[SourceId];

		SourceInfo.bIsPausedForQuantization = true;
		SourceInfo.bIsActive = false;
	}

	void FMixerSourceManager::SetSubBufferDelayForSound(const int32 SourceId, const int32 FramesToDelay)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		FSourceInfo& SourceInfo = SourceInfos[SourceId];

		SourceInfo.SubCallbackDelayLengthInFrames = FramesToDelay;
	}

	void FMixerSourceManager::UnPauseSoundForQuantizationCommand(const int32 SourceId)
	{
		AUDIO_MIXER_CHECK(SourceId < NumTotalSources);
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		FSourceInfo& SourceInfo = SourceInfos[SourceId];

		SourceInfo.bIsPausedForQuantization = false;
		SourceInfo.bIsActive = !SourceInfo.bIsPaused;

		SourceInfo.QuantizedCommandHandle.Reset();
	}

	const float* FMixerSourceManager::GetPreDistanceAttenuationBuffer(const int32 SourceId) const
	{
		const FSourceInfo& SourceInfo = SourceInfos[SourceId];

		if (SourceInfo.bIsPaused || SourceInfo.bIsPausedForQuantization)
		{
			return nullptr;
		}

		return SourceInfo.PreDistanceAttenuationBuffer.GetData();
	}

	const float* FMixerSourceManager::GetPreEffectBuffer(const int32 SourceId) const
	{
		const FSourceInfo& SourceInfo = SourceInfos[SourceId];

		if (SourceInfo.bIsPaused || SourceInfo.bIsPausedForQuantization)
		{
			return nullptr;
		}
		
		return SourceInfo.PreEffectBuffer.GetData();
	}

	const float* FMixerSourceManager::GetPreviousSourceBusBuffer(const int32 SourceId) const
	{
		if (SourceId < SourceInfos.Num())
		{
			return GetPreviousAudioBusBuffer(SourceInfos[SourceId].AudioBusId);
		}
		return nullptr;
	}

	const float* FMixerSourceManager::GetPreviousAudioBusBuffer(const int32 AudioBusId) const
	{
		// This is only called from within a scope-lock
		const TSharedPtr<FMixerAudioBus> AudioBusPtr = AudioBuses.FindRef(AudioBusId);
		if (AudioBusPtr.IsValid())
		{
			return AudioBusPtr->GetPreviousBusBuffer();
		}
		return nullptr;
	}

	int32 FMixerSourceManager::GetNumChannels(const int32 SourceId) const
	{
		return SourceInfos[SourceId].NumInputChannels;
	}

	bool FMixerSourceManager::IsSourceBus(const int32 SourceId) const
	{
		return SourceInfos[SourceId].AudioBusId != INDEX_NONE;
	}

	void FMixerSourceManager::ComputeNextBlockOfSamples()
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		CSV_SCOPED_TIMING_STAT(Audio, SourceManagerUpdate);
		SCOPE_CYCLE_COUNTER(STAT_AudioMixerSourceManagerUpdate);
		CSV_CUSTOM_STAT(Audio, NumActiveSources, NumActiveSources, ECsvCustomStatOp::Set);

		RenderThreadPhase = ESourceManagerRenderThreadPhase::Begin;

		if (FPlatformProcess::SupportsMultithreading())
		{
			// Get the this blocks commands before rendering audio
			PumpCommandQueue();
		}
		else if (bPumpQueue)
		{
			bPumpQueue = false;
			PumpCommandQueue();
		}

		// Notify modulation interface that we are beginning to update
		RenderThreadPhase = ESourceManagerRenderThreadPhase::ProcessModulators;
		if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
		{
			MixerDevice->ModulationInterface->ProcessModulators(MixerDevice->GetAudioClockDelta());
		}

		// Update pending tasks and release them if they're finished
		UpdatePendingReleaseData();

		// First generate non-bus audio (bGenerateBuses = false)
		GenerateSourceAudio(false);

		// Now mix in the non-bus audio into the buses
		ComputeBuses();

		// Now generate bus audio (bGenerateBuses = true)
		GenerateSourceAudio(true);

		// Update the buses now
		UpdateBuses();

		// Let the plugin know we finished processing all sources
		if (bUsingSpatializationPlugin)
		{
			RenderThreadPhase = ESourceManagerRenderThreadPhase::SpatialInterface_OnAllSourcesProcessed;
			AUDIO_MIXER_CHECK(SpatialInterfaceInfo.SpatializationPlugin.IsValid());
			LLM_SCOPE(ELLMTag::AudioMixerPlugins);
			SpatialInterfaceInfo.SpatializationPlugin->OnAllSourcesProcessed();
		}

		// Let the plugin know we finished processing all sources
		if (bUsingSourceDataOverridePlugin)
		{
			RenderThreadPhase = ESourceManagerRenderThreadPhase::SourceDataOverride_OnAllSourcesProcessed;
			AUDIO_MIXER_CHECK(SourceDataOverridePlugin.IsValid());
			LLM_SCOPE(ELLMTag::AudioMixerPlugins);
			SourceDataOverridePlugin->OnAllSourcesProcessed();
		}

		// Update the game thread copy of source doneness
		RenderThreadPhase = ESourceManagerRenderThreadPhase::UpdateGameThreadCopies;
		for (int32 SourceId = 0; SourceId < NumTotalSources; ++SourceId)
		{		
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			// Check for the stopping condition to "turn the sound off"
			if (SourceInfo.bIsLastBuffer)
			{
				if (!SourceInfo.bIsDone)
				{
					SourceInfo.bIsDone = true;

					// Notify that we're now done with this source
					SourceInfo.SourceListener->OnDone();

					if (SourceInfo.AudioLink)
					{
						SourceInfo.AudioLink->OnSourceDone(SourceId);
					}
				}
			}
		}
		RenderThreadPhase = ESourceManagerRenderThreadPhase::Finished;
	}

	void FMixerSourceManager::ClearStoppingSounds()
	{
		for (int32 SourceId = 0; SourceId < NumTotalSources; ++SourceId)
		{
			FSourceInfo& SourceInfo = SourceInfos[SourceId];

			if (!SourceInfo.bIsDone && SourceInfo.bIsStopping && SourceInfo.VolumeSourceDestination == 0.0f)
			{
				SourceInfo.bIsStopping = false;
				SourceInfo.bIsDone = true;
				SourceInfo.SourceListener->OnDone();
				if (SourceInfo.AudioLink)
				{
					SourceInfo.AudioLink->OnSourceDone(SourceId);
				}
			}

		}
	}

	void FMixerSourceManager::AudioMixerThreadMPSCCommand(TFunction<void()>&& InCommand, const char* InDebugString)
	{
		MpscCommandQueue.Enqueue( FAudioMixerMpscCommand{ MoveTemp(InCommand), InDebugString, false });
	}

	void FMixerSourceManager::AudioMixerThreadCommand(TFunction<void()>&& InFunction, const char* InDebugString, bool bInDeferExecution /*= false*/)
	{
		FAudioMixerThreadCommand AudioCommand(MoveTemp(InFunction), InDebugString, bInDeferExecution);

		// collect values for debugging
		// outside of the ScopeLock so we can avoid doing a bunch of work that doesn't require the lock
		SIZE_T OldMax = 0;
		SIZE_T NewMax = 0;
		SIZE_T NewNum = 0;
		SIZE_T CurrentBufferSizeInBytes = 0;
		int32 AudioThreadCommandIndex = -1;
		{
			// Here, we make sure that we don't flip our command double buffer while modifying the command buffer
			FScopeLock ScopeLock(&CommandBufferIndexCriticalSection);
			AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

			// Add the function to the command queue:
			AudioThreadCommandIndex = !RenderThreadCommandBufferIndex.GetValue();
			FCommands& Commands = CommandBuffers[AudioThreadCommandIndex];

			OldMax = Commands.SourceCommandQueue.Max();
			
			// always add commands to the buffer. If we're not going to assert, might as well chug along and hope we can recover!
			Commands.SourceCommandQueue.Add(AudioCommand);
			NumCommands.Increment();

			NewNum = Commands.SourceCommandQueue.Num();
			NewMax = Commands.SourceCommandQueue.Max();
			CurrentBufferSizeInBytes = Commands.SourceCommandQueue.GetAllocatedSize();
		}
		
		// log warnings for command buffer growing too large
		if (OldMax != NewMax)
		{
			// Only throw a warning every time we have to reallocate, which will be less often then every single time we add
			static SIZE_T WarnSize = 1024 * 1024;
			if (CurrentBufferSizeInBytes > WarnSize )
			{
				float TimeSinceLastComplete = FPlatformTime::ToSeconds64(FPlatformTime::Cycles64() - LastPumpCompleteTimeInCycles);

				UE_LOG(LogAudioMixer, Error, TEXT("Command Queue %d has grown to %ukb, containing %d cmds, last complete pump was %2.5f seconds ago."),
					AudioThreadCommandIndex, CurrentBufferSizeInBytes >> 10, NewNum, TimeSinceLastComplete);
				WarnSize *= 2;

				DoStallDiagnostics();
			}
			
			// check that we haven't gone over the max size
			const SIZE_T MaxBufferSizeInBytes = ((SIZE_T)CommandBufferMaxSizeInMbCvar) << 20;
			if (CurrentBufferSizeInBytes >= MaxBufferSizeInBytes)
			{
				int32 NumTimesOvergrown = CommandBuffers[AudioThreadCommandIndex].NumTimesOvergrown.Increment();
				UE_LOG(LogAudioMixer, Error, TEXT("%d: Command buffer %d allocated size has grown to %umb! Likely cause the AudioRenderer has hung"),
					NumTimesOvergrown, AudioThreadCommandIndex, CurrentBufferSizeInBytes >> 20);
			}
		}

		// update trace values
		CSV_CUSTOM_STAT(Audio, AudioMixerThreadCommands, static_cast<int32>(NewNum), ECsvCustomStatOp::Set);
		TRACE_INT_VALUE(TEXT("AudioMixerThreadCommands::NumCommands"), NewNum);
		TRACE_INT_VALUE(TEXT("AudioMixerThreadCommands::CurrentBufferSizeInKb"), CurrentBufferSizeInBytes >> 10);
	}


	void FMixerSourceManager::PumpCommandQueue()
	{
		TRACE_CPUPROFILER_EVENT_SCOPE(AudioMixerThreadCommands::PumpCommandQueue)
		AudioRenderThreadId = FPlatformTLS::GetCurrentThreadId();
		
		// If we're already triggered, we need to wait for the audio thread to reset it before pumping
		if (FPlatformProcess::SupportsMultithreading())
		{
			if (CommandsProcessedEvent->Wait(0))
			{
				return;
			}
		}

		// Pump the MPSC command queue
		RenderThreadPhase = ESourceManagerRenderThreadPhase::PumpMpscCmds;
		TOptional Opt{ MpscCommandQueue.Dequeue() };
		while (Opt.IsSet())
		{
			// First copy/move out the command and keep a copy of it.
			{
				FWriteScopeLock Lock(CurrentlyExecutingCmdLock);
				CurrentlyExecuteingCmd = MoveTemp(Opt.GetValue());
			}
			
			// Execute the current under a read-lock.
			{
				FReadScopeLock Lock(CurrentlyExecutingCmdLock);
				CurrentlyExecuteingCmd();
			}
				
			Opt = MpscCommandQueue.Dequeue();
		}

		int32 CurrentRenderThreadIndex = RenderThreadCommandBufferIndex.GetValue();
		FCommands& Commands = CommandBuffers[CurrentRenderThreadIndex];

		const int32 NumCommandsToExecute = Commands.SourceCommandQueue.Num();
		TRACE_INT_VALUE(TEXT("AudioMixerThreadCommands::NumCommandsToExecute"), NumCommandsToExecute);

		// Pop and execute all the commands that came since last update tick
		TArray<FAudioMixerThreadCommand> DelayedCommands;
		RenderThreadPhase = ESourceManagerRenderThreadPhase::PumpCmds;
		for (int32 Id = 0; Id < NumCommandsToExecute; ++Id)
		{
			// First copy/move out the command and keep a copy of it.
			{ 
				FWriteScopeLock Lock(CurrentlyExecutingCmdLock);
				CurrentlyExecuteingCmd = MoveTemp(Commands.SourceCommandQueue[Id]);
			}
			
			// Execute the current command or differ under a read-lock.
			{
				FReadScopeLock Lock(CurrentlyExecutingCmdLock);
				if (CurrentlyExecuteingCmd.bDeferExecution)
				{
					CurrentlyExecuteingCmd.bDeferExecution = false;
					DelayedCommands.Add(CurrentlyExecuteingCmd);
				}
				else
				{
					CurrentlyExecuteingCmd(); // execute
				}
			}
			
			NumCommands.Decrement();
		}

		LastPumpCompleteTimeInCycles = FPlatformTime::Cycles64();
		// This is intentionally re-assigning the Command Queue and clearing the buffer in the process
		Commands.SourceCommandQueue = MoveTemp(DelayedCommands);
		Commands.SourceCommandQueue.Reserve(GetCommandBufferInitialCapacity());

		if (FPlatformProcess::SupportsMultithreading())
		{
			check(CommandsProcessedEvent != nullptr);
			CommandsProcessedEvent->Trigger();
		}
		else
		{
			RenderThreadCommandBufferIndex.Set(!CurrentRenderThreadIndex);
		}
	}

	void FMixerSourceManager::FlushCommandQueue(bool bPumpInCommand)
	{
		check(CommandsProcessedEvent != nullptr);

		// If we have no commands enqueued, exit
		if (NumCommands.GetValue() == 0)
		{
			UE_LOG(LogAudioMixer, Verbose, TEXT("No commands were queued while flushing the source manager."));
			return;
		}

		// Make sure current current executing 
		bool bTimedOut = false;
		if (!CommandsProcessedEvent->Wait(CommandBufferFlushWaitTimeMsCvar))
		{
			CommandsProcessedEvent->Trigger();
			bTimedOut = true;
			UE_LOG(LogAudioMixer, Warning, TEXT("Timed out waiting to flush the source manager command queue (1)."));
		}
		else
		{
			UE_LOG(LogAudioMixer, Verbose, TEXT("Flush succeeded in the source manager command queue (1)."));
		}

		// Call update to trigger a final pump of commands
		Update(bTimedOut);

		if (bPumpInCommand)
		{
			PumpCommandQueue();
		}

		// Wait one more time for the double pump
		if (!CommandsProcessedEvent->Wait(1000))
		{
			CommandsProcessedEvent->Trigger();
			UE_LOG(LogAudioMixer, Warning, TEXT("Timed out waiting to flush the source manager command queue (2)."));
		}
		else
		{
			UE_LOG(LogAudioMixer, Verbose, TEXT("Flush succeeded the source manager command queue (2)."));
		}
	}

	void FMixerSourceManager::UpdatePendingReleaseData(bool bForceWait)
	{
		RenderThreadPhase = ESourceManagerRenderThreadPhase::UpdatePendingReleaseData;
		
		// Don't block, but let tasks finish naturally
		for (int32 i = PendingSourceBuffers.Num() - 1; i >= 0; --i)
		{
			FMixerSourceBuffer* MixerSourceBuffer = PendingSourceBuffers[i].Get();

			bool bDeleteSourceBuffer = true;
			if (bForceWait)
			{
				MixerSourceBuffer->EnsureAsyncTaskFinishes();
			}
			else if (!MixerSourceBuffer->IsAsyncTaskDone())
			{			
				bDeleteSourceBuffer = false;
			}

			if (bDeleteSourceBuffer)
			{
				PendingSourceBuffers.RemoveAtSwap(i, EAllowShrinking::No);
			}
		}
	}

	bool FMixerSourceManager::FSourceInfo::IsRenderingToSubmixes() const
	{
		return bEnableBaseSubmix || bEnableSubmixSends;
	}

	void FMixerSourceManager::DoStallDiagnostics()
	{
		LogRenderThreadStall();
		LogInflightAsyncTasks();
		LogCallstacks();
	}

	void FMixerSourceManager::LogRenderThreadStall()
	{
		// If we are in either of the Cmd pump phases dump the current command.
		if (RenderThreadPhase == ESourceManagerRenderThreadPhase::PumpMpscCmds ||
			RenderThreadPhase == ESourceManagerRenderThreadPhase::PumpCmds)
		{
			FReadScopeLock Lock(CurrentlyExecutingCmdLock);
			UE_LOG(LogAudioMixer, Warning, TEXT("Stall in Cmd Queue: Cmd='%s', Executing For: %2.5f secs, AudioRenderThread='%s'"),
				*CurrentlyExecuteingCmd.GetSafeDebugString(), CurrentlyExecuteingCmd.GetExecuteTimeInSeconds(), ToCStr(LexToString(RenderThreadPhase)));
		}
		else
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Stall in AudioRenderThread Phase: '%s'"), ToCStr(LexToString(RenderThreadPhase)));
		}
	}

	void FMixerSourceManager::LogInflightAsyncTasks()
	{
		// NOTE: we iterate these lists without a lock, so this is somewhat dangerous!

		// Dump all in flight decodes/procedural sources.
		using FSrcBuffer = TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe>;
		TArray<FMixerSourceBuffer::FDiagnosticState> InflightTasks;
		for (FSourceInfo& i : SourceInfos)
		{
			if (i.MixerSourceBuffer.IsValid())
			{
				FMixerSourceBuffer::FDiagnosticState State;
				i.MixerSourceBuffer->GetDiagnosticState(State);
				if (State.bInFlight)
				{
					InflightTasks.Add(State);
				}
			}
		}
		for (FSrcBuffer& i : PendingSourceBuffers)
		{
			FMixerSourceBuffer::FDiagnosticState State;
			if (i.IsValid())
			{
				i->GetDiagnosticState(State);
				if (State.bInFlight)
				{
					InflightTasks.Add(State);
				}
			}
		}
		for (FMixerSourceBuffer::FDiagnosticState& i : InflightTasks)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Inflight Task: %s, %2.2f secs, Procedural=%d"),
				*i.WaveName.ToString(), i.RunTimeInSecs, (int32)i.bProcedural);
		}
	}

	void FMixerSourceManager::LogCallstacks()
	{
		LogCallstack(AudioRenderThreadId);
	}

	void FMixerSourceManager::LogCallstack(uint32 InThreadId)
	{
		if (InThreadId != INVALID_AUDIO_RENDER_THREAD_ID)
		{
			const SIZE_T StackTraceSize = 65536;
			ANSICHAR StackTrace[StackTraceSize] = { 0 };
			FPlatformStackWalk::ThreadStackWalkAndDump(StackTrace, StackTraceSize, 0, InThreadId);
			UE_LOG(LogAudioMixer, Warning, TEXT("***** ThreadStackWalkAndDump for ThreadId(%lu) ******\n%s"), InThreadId, ANSI_TO_TCHAR(StackTrace));
		}
	}
}

===================================


=== AudioMixerSourceManager.h ===
=================================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "AudioBusSubsystem.h"
#include "AudioMixerBuffer.h"
#include "AudioMixerBus.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSourceOutputBuffer.h"
#include "AudioMixerSubmix.h"
#include "AudioMixerTrace.h"
#include "Containers/MpscQueue.h"
#include "DSP/BufferVectorOperations.h"
#include "DSP/EnvelopeFollower.h"
#include "DSP/InterpolatedOnePole.h"
#include "DSP/ParamInterpolator.h"
#include "IAudioExtensionPlugin.h"
#include "ISoundfieldFormat.h"
#include "Sound/SoundModulationDestination.h"
#include "Sound/QuartzQuantizationUtilities.h"
#include "Stats/Stats.h"

#include "AudioMixerSourceManager.generated.h"

// Default this to on (it's quite a small memory footprint).
#ifndef WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG
	#define WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG (1)
#endif //WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG

// Tracks the time it takes to up the source manager (computes source buffers, source effects, sample rate conversion)
DECLARE_CYCLE_STAT_EXTERN(TEXT("Source Manager Update"), STAT_AudioMixerSourceManagerUpdate, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to compute the source buffers (handle decoding tasks, resampling)
DECLARE_CYCLE_STAT_EXTERN(TEXT("Source Buffers"), STAT_AudioMixerSourceBuffers, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the source buffers through their source effects
DECLARE_CYCLE_STAT_EXTERN(TEXT("Source Effect Buffers"), STAT_AudioMixerSourceEffectBuffers, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to apply channel maps and get final pre-submix source buffers
DECLARE_CYCLE_STAT_EXTERN(TEXT("Source Output Buffers"), STAT_AudioMixerSourceOutputBuffers, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the HRTF effect.
DECLARE_CYCLE_STAT_EXTERN(TEXT("HRTF"), STAT_AudioMixerHRTF, STATGROUP_AudioMixer, AUDIOMIXER_API);

// For diagnostics, keep track of what phase of updating the Source manager is in currently.
UENUM()
enum ESourceManagerRenderThreadPhase: uint8
{
	Begin,
	
	PumpMpscCmds,	
	PumpCmds,
	ProcessModulators,
	UpdatePendingReleaseData,
	GenerateSrcAudio_WithBusses,
	ComputeBusses,
	GenerateSrcAudio_WithoutBusses,
	UpdateBusses,
	SpatialInterface_OnAllSourcesProcessed,
	SourceDataOverride_OnAllSourcesProcessed,
	UpdateGameThreadCopies,
	
	Finished,
};

namespace Audio
{
	class FMixerSubmix;
	class FMixerDevice;
	class FMixerSourceVoice;
	class FMixerSourceBuffer;
	class ISourceListener;
	class FMixerSourceSubmixOutputBuffer;

	/** Struct defining a source voice buffer. */
	struct FMixerSourceVoiceBuffer
	{
		/** PCM float data. */
		FAlignedFloatBuffer AudioData;

		/** How many times this buffer will loop. */
		int32 LoopCount = 0;

		/** If this buffer is from real-time decoding and needs to make callbacks for more data. */
		bool bRealTimeBuffer = false;
	};


	class ISourceListener
	{
	public:
		virtual ~ISourceListener() = default;

		// Called before a source begins to generate audio. 
		virtual void OnBeginGenerate() = 0;

		// Called when a loop point is hit
		virtual void OnLoopEnd() = 0;

		// Called when the source finishes on the audio render thread
		virtual void OnDone() = 0;

		// Called when the source's effect tails finish on the audio render thread.
		virtual void OnEffectTailsDone() = 0;

	};

	struct FMixerSourceSubmixSend
	{
		// The submix ptr
		FMixerSubmixWeakPtr Submix;

		// The amount of audio that is to be mixed into this submix
		float SendLevel = 0.0f;

		// Whather or not this is the primary send (i.e. first in the send chain)
		bool bIsMainSend = false;

		// Whether or not this is a pre-distance attenuation send
		EMixerSourceSubmixSendStage SubmixSendStage = EMixerSourceSubmixSendStage::PostDistanceAttenuation;

		// If this is a soundfield submix, this is a pointer to the submix's Soundfield Factory.
		// If this is nullptr, the submix is not a soundfield submix.
		ISoundfieldFactory* SoundfieldFactory = nullptr;
	};

	// Struct holding mappings of bus ids (unique ids) to send level
	struct FInitAudioBusSend
	{
		uint32 AudioBusId = INDEX_NONE;
		float SendLevel = 0.0f;
		int32 BusChannels = 0;
	};

	struct FMixerSourceVoiceInitParams
	{
		TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe> MixerSourceBuffer = nullptr;
		ISourceListener* SourceListener = nullptr;
		TArray<FMixerSourceSubmixSend> SubmixSends;
		TArray<FInitAudioBusSend> AudioBusSends[(int32)EBusSendType::Count];
		uint32 AudioBusId = INDEX_NONE;
		int32 AudioBusChannels = 0;
		float SourceBusDuration = 0.0f;
		uint32 SourceEffectChainId = INDEX_NONE;
		TArray<FSourceEffectChainEntry> SourceEffectChain;
		int32 SourceEffectChainMaxSupportedChannels = 0;
		FMixerSourceVoice* SourceVoice = nullptr;
		int32 NumInputChannels = 0;
		int32 NumInputFrames = 0;
		float EnvelopeFollowerAttackTime = 10.0f;
		float EnvelopeFollowerReleaseTime = 100.0f;
		FString DebugName;
		USpatializationPluginSourceSettingsBase* SpatializationPluginSettings = nullptr;
		UOcclusionPluginSourceSettingsBase* OcclusionPluginSettings = nullptr;
		UReverbPluginSourceSettingsBase* ReverbPluginSettings = nullptr;
		USourceDataOverridePluginSourceSettingsBase* SourceDataOverridePluginSettings = nullptr;

		FSoundModulationDefaultSettings ModulationSettings;

		FQuartzQuantizedRequestData QuantizedRequestData;

		FSharedISourceBufferListenerPtr SourceBufferListener;

		IAudioLinkFactory::FAudioLinkSourcePushedSharedPtr AudioLink;

		FName AudioComponentUserID;
		uint64 AudioComponentID = 0;
		bool bIs3D = false;
		bool bPlayEffectChainTails = false;
		bool bUseHRTFSpatialization = false;
		bool bIsExternalSend = false;
		bool bIsDebugMode  = false;
		bool bEnableBusSends = false;
		bool bEnableBaseSubmix = false;
		bool bEnableSubmixSends = false;
		bool bIsVorbis = false;
		bool bIsSoundfield = false;
		bool bIsSeeking = false;
		bool bShouldSourceBufferListenerZeroBuffer = false;

		uint32 PlayOrder = INDEX_NONE;
	};

	struct FSourceManagerInitParams
	{
		// Total number of sources to use in the source manager
		int32 NumSources = 0;

		// Number of worker threads to use for the source manager.
		int32 NumSourceWorkers = 0;
	};

	class FMixerSourceManager
	{
	public:
		FMixerSourceManager(FMixerDevice* InMixerDevice);
		~FMixerSourceManager();

		void Init(const FSourceManagerInitParams& InitParams);
		void Update(bool bTimedOut = false);

		bool GetFreeSourceId(int32& OutSourceId);
		int32 GetNumActiveSources() const;
		int32 GetNumActiveAudioBuses() const;

		void ReleaseSourceId(const int32 SourceId);
		void InitSource(const int32 SourceId, const FMixerSourceVoiceInitParams& InitParams);

		// Creates and starts an audio bus manually.
		void StartAudioBus(FAudioBusKey InAudioBusKey, int32 InNumChannels, bool bInIsAutomatic);

		// Stops an audio bus manually
		void StopAudioBus(FAudioBusKey InAudioBusKey);

		// Queries if an audio bus is active. Must be called from the audio thread.
		bool IsAudioBusActive(FAudioBusKey InAudioBusKey) const;

		// Returns the number of channels currently set for the audio bus associated with
		// the provided BusId.  Returns 0 if the audio bus is inactive.
		int32 GetAudioBusNumChannels(FAudioBusKey InAudioBusKey) const;

		// Adds a patch output for an audio bus from the Audio Render Thread
		void AddPatchOutputForAudioBus(FAudioBusKey InAudioBusKey, const FPatchOutputStrongPtr& InPatchOutputStrongPtr);

		// Adds a patch output for an audio bus from the Audio Thread
		void AddPatchOutputForAudioBus_AudioThread(FAudioBusKey InAudioBusKey, const FPatchOutputStrongPtr& InPatchOutputStrongPtr);

		// Adds a patch input for an audio bus
		void AddPatchInputForAudioBus(FAudioBusKey InAudioBusKey, const FPatchInput& InPatchInput);

		// Adds a patch input for an audio bus from the Audio Thread
		void AddPatchInputForAudioBus_AudioThread(FAudioBusKey InAudioBusKey, const FPatchInput& InPatchInput);

		void Play(const int32 SourceId);
		void Stop(const int32 SourceId);
		void CancelQuantizedSound(const int32 SourceId);
		void StopInternal(const int32 SourceId);
		void StopFade(const int32 SourceId, const int32 NumFrames);
		void Pause(const int32 SourceId);
		void SetPitch(const int32 SourceId, const float Pitch);
		void SetVolume(const int32 SourceId, const float Volume);
		void SetDistanceAttenuation(const int32 SourceId, const float DistanceAttenuation);
		void SetSpatializationParams(const int32 SourceId, const FSpatializationParams& InParams);
		void SetChannelMap(const int32 SourceId, const uint32 NumInputChannels, const Audio::FAlignedFloatBuffer& InChannelMap, const bool bInIs3D, const bool bInIsCenterChannelOnly);
		void SetLPFFrequency(const int32 SourceId, const float Frequency);
		void SetHPFFrequency(const int32 SourceId, const float Frequency);

		// Sets base (i.e. carrier) frequency of modulatable parameters
		void SetModPitch(const int32 SourceId, const float InModPitch);
		void SetModVolume(const int32 SourceId, const float InModVolume);
		void SetModLPFFrequency(const int32 SourceId, const float InModFrequency);
		void SetModHPFFrequency(const int32 SourceId, const float InModFrequency);
		
		void SetModulationRouting(const int32 SourceId, FSoundModulationDefaultSettings& ModulationSettings);

		void SetSourceBufferListener(const int32 SourceId, FSharedISourceBufferListenerPtr& InSourceBufferListener, bool InShouldSourceBufferListenerZeroBuffer);

		void SetListenerTransforms(const TArray<FTransform>& ListenerTransforms);
		const TArray<FTransform>* GetListenerTransforms() const;

		int64 GetNumFramesPlayed(const int32 SourceId) const;
		float GetEnvelopeValue(const int32 SourceId) const;
#if ENABLE_AUDIO_DEBUG
		double GetCPUCoreUtilization(const int32 SourceId) const;
#endif // ENABLE_AUDIO_DEBUG
		float GetRelativeRenderCost(const int32 SourceId) const;
		bool IsUsingHRTFSpatializer(const int32 SourceId) const;
		bool NeedsSpeakerMap(const int32 SourceId) const;
		void ComputeNextBlockOfSamples();
		void ClearStoppingSounds();
		void MixOutputBuffers(const int32 SourceId, int32 InNumOutputChannels, const float InSendLevel, EMixerSourceSubmixSendStage InSubmixSendStage, FAlignedFloatBuffer& OutWetBuffer) const;

		// Retrieves a channel map for the given source ID for the given output channels
		// can be used even when a source is 3D if the source is doing any kind of bus sending or otherwise needs a channel map
		void Get2DChannelMap(const int32 SourceId, int32 InNumOutputChannels, Audio::FAlignedFloatBuffer& OutChannelMap);

		// Called by a soundfield submix to get encoded audio.
		// If this source wasn't encoded (possibly because it is paused or finished playing),
		// this returns nullptr.
		// Returned nonnull pointers are only guaranteed to be valid on the audio mixer render thread.
		const ISoundfieldAudioPacket* GetEncodedOutput(const int32 SourceId, const FSoundfieldEncodingKey& InKey) const;

		const FQuat GetListenerRotation(const int32 SourceId) const;

		void SetSubmixSendInfo(const int32 SourceId, const FMixerSourceSubmixSend& SubmixSend);
		void ClearSubmixSendInfo(const int32 SourceId, const FMixerSourceSubmixSend& SubmixSend);

		void SetBusSendInfo(const int32 SourceId, EBusSendType InAudioBusSendType, uint32 AudiobusId, float BusSendLevel);

		void UpdateDeviceChannelCount(const int32 InNumOutputChannels);

		void UpdateSourceEffectChain(const uint32 SourceEffectChainId, const TArray<FSourceEffectChainEntry>& SourceEffectChain, const bool bPlayEffectChainTails);


		// Quantized event methods
		void PauseSoundForQuantizationCommand(const int32 SourceId);
		void SetSubBufferDelayForSound(const int32 SourceId, const int32 FramesToDelay);
		void UnPauseSoundForQuantizationCommand(const int32 SourceId);

		// Buffer getters
		const float* GetPreDistanceAttenuationBuffer(const int32 SourceId) const;
		const float* GetPreEffectBuffer(const int32 SourceId) const;
		const float* GetPreviousSourceBusBuffer(const int32 SourceId) const;
		const float* GetPreviousAudioBusBuffer(const int32 AudioBusId) const;
		int32 GetNumChannels(const int32 SourceId) const;
		int32 GetNumOutputFrames() const { return NumOutputFrames; }
		bool IsSourceBus(const int32 SourceId) const;
		void PumpCommandQueue();
		void UpdatePendingReleaseData(bool bForceWait = false);
		void FlushCommandQueue(bool bPumpCommandQueue = false);

		// Pushes a TFUnction command into an MPSC queue from an arbitrary thread to the audio render thread
		void AudioMixerThreadMPSCCommand(TFunction<void()>&& InCommand, const char* InDebugString=nullptr);
		
		void AddPendingAudioBusConnection(FAudioBusKey AudioBusKey, int32 NumChannels, bool bIsAutomatic, FPatchInput PatchInput)
		{
			PendingAudioBusConnections.Enqueue(FPendingAudioBusConnection{ FPendingAudioBusConnection::FPatchVariant(TInPlaceType<FPatchInput>(), MoveTemp(PatchInput)), MoveTemp(AudioBusKey), NumChannels, bIsAutomatic });
		}

		void AddPendingAudioBusConnection(FAudioBusKey AudioBusKey, int32 NumChannels, bool bIsAutomatic, FPatchOutputStrongPtr PatchOutputStrongPtr)
		{
			PendingAudioBusConnections.Enqueue(FPendingAudioBusConnection{ FPendingAudioBusConnection::FPatchVariant(TInPlaceType<FPatchOutputStrongPtr>(), MoveTemp(PatchOutputStrongPtr)), MoveTemp(AudioBusKey), NumChannels, bIsAutomatic });
		}

	private:
#define INVALID_AUDIO_RENDER_THREAD_ID static_cast<uint32>(-1)
		uint32 AudioRenderThreadId = INVALID_AUDIO_RENDER_THREAD_ID;
		void ReleaseSource(const int32 SourceId);
		void BuildSourceEffectChain(const int32 SourceId, FSoundEffectSourceInitData& InitData, const TArray<FSourceEffectChainEntry>& SourceEffectChain, TArray<TSoundEffectSourcePtr>& OutSourceEffects);
		void ResetSourceEffectChain(const int32 SourceId);
		void ReadSourceFrame(const int32 SourceId);

		void GenerateSourceAudio(const bool bGenerateBuses);
		void GenerateSourceAudio(const bool bGenerateBuses, const int32 SourceIdStart, const int32 SourceIdEnd);

		void ComputeSourceBuffersForIdRange(const bool bGenerateBuses, const int32 SourceIdStart, const int32 SourceIdEnd);
		void ComputePostSourceEffectBufferForIdRange(const bool bGenerateBuses, const int32 SourceIdStart, const int32 SourceIdEnd);
		void ComputeOutputBuffersForIdRange(const bool bGenerateBuses, const int32 SourceIdStart, const int32 SourceIdEnd);

		void ConnectBusPatches();
		void ComputeBuses();
		void UpdateBuses();

		struct FAudioMixerThreadCommand
		{
			// ctor
			FAudioMixerThreadCommand() = default;
			FAudioMixerThreadCommand(TFunction<void()>&& InFunction, const char* InDebugString, bool bInDeferExecution = false);
			
			// function-call operator
			void operator()() const;

			// data
			TFunction<void()> Function;

			// Defers the execution by a single call to PumpCommandQueue()
			// (used for commands that affect a playing source,
			// and that source gets initialized after the command executes
			bool bDeferExecution = false;

#if WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG			
			const char* DebugString=nullptr;					// Statically defined string from macro AUDIO_MIXER_THREAD_COMMAND_STRING
			mutable uint64_t StartExecuteTimeInCycles=0;		// Set just before Function is called, for diagnostics.
#endif // #if WITH_AUDIO_MIXER_THREAD_COMMAND_DEBUG

			FString GetSafeDebugString() const;
			float GetExecuteTimeInSeconds() const;
		};

		void AudioMixerThreadCommand(TFunction<void()>&& InFunction, const char* InDebugString = nullptr, bool bInDeferExecution = false);

		static const int32 NUM_BYTES_PER_SAMPLE = 2;

		// Private class which perform source buffer processing in a worker task
		class FAudioMixerSourceWorker : public FNonAbandonableTask
		{
			FMixerSourceManager* SourceManager;
			int32 StartSourceId;
			int32 EndSourceId;
			bool bGenerateBuses;

		public:
			FAudioMixerSourceWorker(FMixerSourceManager* InSourceManager, const int32 InStartSourceId, const int32 InEndSourceId)
				: SourceManager(InSourceManager)
				, StartSourceId(InStartSourceId)
				, EndSourceId(InEndSourceId)
				, bGenerateBuses(false)
			{
			}

			void SetGenerateBuses(bool bInGenerateBuses)
			{
				bGenerateBuses = bInGenerateBuses;
			}

			void DoWork()
			{
				SourceManager->GenerateSourceAudio(bGenerateBuses, StartSourceId, EndSourceId);
			}

			FORCEINLINE TStatId GetStatId() const
			{
				RETURN_QUICK_DECLARE_CYCLE_STAT(FAudioMixerSourceWorker, STATGROUP_ThreadPoolAsyncTasks);
			}
		};

		// Critical section to ensure mutating effect chains is thread-safe
		FCriticalSection EffectChainMutationCriticalSection;

		FMixerDevice* MixerDevice;

		// Info about spatialization plugin
		FAudioDevice::FAudioSpatializationInterfaceInfo SpatialInterfaceInfo;
		
		// Cached ptr to an optional source data override plugin
		TAudioSourceDataOverridePtr SourceDataOverridePlugin;

		IAudioLinkFactory* AudioLinkFactory = nullptr;

		// Array of pointers to game thread audio source objects
		TArray<FMixerSourceVoice*> MixerSources;

		// A command queue to execute commands from audio thread (or game thread) to audio mixer device thread.
		struct FCommands
		{
			FThreadSafeCounter NumTimesOvergrown = 0;
			TArray<FAudioMixerThreadCommand> SourceCommandQueue;
		};
		
		FCommands CommandBuffers[2];
		FThreadSafeCounter RenderThreadCommandBufferIndex;

		FEvent* CommandsProcessedEvent;
		FCriticalSection CommandBufferIndexCriticalSection;

		TArray<int32> DebugSoloSources;

		using FAudioMixerMpscCommand = FAudioMixerThreadCommand;
		TMpscQueue<FAudioMixerMpscCommand> MpscCommandQueue;
		
		struct FSourceInfo
		{
			FSourceInfo() {}
			~FSourceInfo() {}

			// Object which handles source buffer decoding
			TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe> MixerSourceBuffer;
			ISourceListener* SourceListener;

			// Data used for rendering sources
			TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe> CurrentPCMBuffer;
			int32 CurrentAudioChunkNumFrames;

			// The post-attenuation source buffer, used to send audio to submixes
			Audio::FAlignedFloatBuffer SourceBuffer;
			Audio::FAlignedFloatBuffer PreEffectBuffer;
			Audio::FAlignedFloatBuffer PreDistanceAttenuationBuffer;
			Audio::FAlignedFloatBuffer SourceEffectScratchBuffer;

			// Data used for delaying the rendering of source audio for sample-accurate quantization
			int32 SubCallbackDelayLengthInFrames{ 0 };
			Audio::TCircularAudioBuffer<float> SourceBufferDelayLine;

			TArray<float> CurrentFrameValues;
			TArray<float> NextFrameValues;
			float CurrentFrameAlpha;
			int32 CurrentFrameIndex;
			int64 NumFramesPlayed;

			// The number of frames to wait before starting the source
			double StartTime;

			TArray<FMixerSourceSubmixSend> SubmixSends;

			// What audio bus Id this source is sonfiying, if it is a source bus. This is INDEX_NONE for sources which are not source buses.
			uint32 AudioBusId;

			// Number of samples to count for source bus
			int64 SourceBusDurationFrames;

			// What buses this source is sending its audio to. Used to remove this source from the bus send list.
			TArray<uint32> AudioBusSends[(int32)EBusSendType::Count];

			// Interpolated source params
			FParam PitchSourceParam;
			float VolumeSourceStart;
			float VolumeSourceDestination;
			float VolumeFadeSlope;
			float VolumeFadeStart;
			int32 VolumeFadeFramePosition;
			int32 VolumeFadeNumFrames;

			float DistanceAttenuationSourceStart;
			float DistanceAttenuationSourceDestination;

			// Legacy filter LFP & HPF frequency set directly (not by modulation) on source
			float LowPassFreq;
			float HighPassFreq;

			// One-Pole LPFs and HPFs per source
			Audio::FInterpolatedLPF LowPassFilter;
			Audio::FInterpolatedHPF HighPassFilter;

			// Source effect instances
			uint32 SourceEffectChainId;
			TArray<TSoundEffectSourcePtr> SourceEffects;
			TArray<USoundEffectSourcePreset*> SourceEffectPresets;
			bool bEffectTailsDone;
			FSoundEffectSourceInputData SourceEffectInputData;

			FAudioPluginSourceOutputData AudioPluginOutputData;

			// A DSP object which tracks the amplitude envelope of a source.
			Audio::FInlineEnvelopeFollower SourceEnvelopeFollower;
			float SourceEnvelopeValue;

			// Modulation destinations
			Audio::FModulationDestination VolumeModulation;
			Audio::FModulationDestination PitchModulation;
			Audio::FModulationDestination LowpassModulation;
			Audio::FModulationDestination HighpassModulation;

			// Modulation Base (i.e. Carrier) Values
			float VolumeModulationBase;
			float PitchModulationBase;
			float LowpassModulationBase;
			float HighpassModulationBase;

			FSpatializationParams SpatParams;
			Audio::FAlignedFloatBuffer ScratchChannelMap;

			// Quantization data
			FQuartzQuantizedCommandHandle QuantizedCommandHandle;

			// Optional Source buffer listener.
			FSharedISourceBufferListenerPtr SourceBufferListener;

			// Optional AudioLink.
			IAudioLinkFactory::FAudioLinkSourcePushedSharedPtr AudioLink;

			// State management
			uint8 bIs3D:1;
			uint8 bIsCenterChannelOnly:1;
			uint8 bIsActive:1;
			uint8 bIsPlaying:1;
			uint8 bIsPaused:1;
			uint8 bIsPausedForQuantization:1;
			uint8 bDelayLineSet:1;
			uint8 bIsStopping:1;
			uint8 bHasStarted:1;
			uint8 bIsBusy:1;
			uint8 bUseHRTFSpatializer:1;
			uint8 bIsExternalSend:1;
			uint8 bUseOcclusionPlugin:1;
			uint8 bUseReverbPlugin:1;
			uint8 bIsDone:1;
			uint8 bIsLastBuffer:1;
			uint8 bEnableBusSends : 1;
			uint8 bEnableBaseSubmix : 1;
			uint8 bEnableSubmixSends : 1;
			uint8 bIsVorbis:1;
			uint8 bIsSoundfield:1;
			uint8 bHasPreDistanceAttenuationSend:1;
			uint8 bModFiltersUpdated : 1;
			uint8 bShouldSourceBufferListenerZeroBuffer : 1;

			// Source format info
			int32 NumInputChannels;
			int32 NumPostEffectChannels;
			int32 NumInputFrames;

			uint32 PlayOrder;

			// ID for associated Audio Component if there is one, 0 otherwise
			uint64 AudioComponentID;

			FORCEINLINE void ResetModulators(const Audio::FDeviceId InDeviceId)
			{
				VolumeModulation.Init(InDeviceId, FName("Volume"), false /* bInIsBuffered */, true /* bInValueLinear */);
				PitchModulation.Init(InDeviceId, FName("Pitch"));
				HighpassModulation.Init(InDeviceId, FName("HPFCutoffFrequency"));
				LowpassModulation.Init(InDeviceId, FName("LPFCutoffFrequency"));

				VolumeModulationBase = 0.0f;
				PitchModulationBase = 0.0f;
				HighpassModulationBase = MIN_FILTER_FREQUENCY;
				LowpassModulationBase = MAX_FILTER_FREQUENCY;
			}

			//Helper function for determining if OutputToBusOnly is enabled
			bool IsRenderingToSubmixes() const;

#if AUDIO_MIXER_ENABLE_DEBUG_MODE
			uint8 bIsDebugMode : 1;
			FString DebugName;
#endif // AUDIO_MIXER_ENABLE_DEBUG_MODE
		};

		static void ApplyDistanceAttenuation(FSourceInfo& InSourceInfo, int32 NumSamples);
		void ComputePluginAudio(FSourceInfo& InSourceInfo, FMixerSourceSubmixOutputBuffer& InSourceSubmixOutputBuffer, int32 SourceId, int32 NumSamples);

		// Hang/crash diagnostics.
		void DoStallDiagnostics();

		void LogRenderThreadStall();
		void LogInflightAsyncTasks();
		void LogCallstacks();
		void LogCallstack(uint32 InThreadId);

		// Array of listener transforms
		TArray<FTransform> ListenerTransforms;

		// Array of source infos.
		TArray<FSourceInfo> SourceInfos;

		// This array is independent of SourceInfos array to optimize for cache coherency
		TArray<FMixerSourceSubmixOutputBuffer> SourceSubmixOutputBuffers;

		// Map of bus object Id's to audio bus data. 
		TMap<FAudioBusKey, TSharedPtr<FMixerAudioBus>> AudioBuses; 
		TArray<FAudioBusKey> AudioBusKeys_AudioThread;

		// Async task workers for processing sources in parallel
		TArray<FAsyncTask<FAudioMixerSourceWorker>*> SourceWorkers;

		// Array of task data waiting to finished. Processed on audio render thread.
		TArray<TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe>> PendingSourceBuffers;

		// General information about sources in source manager accessible from game thread
		struct FGameThreadInfo
		{
			TArray<int32> FreeSourceIndices;
			TArray<bool> bIsBusy;
			TArray<bool> bNeedsSpeakerMap;
			TArray<bool> bIsDebugMode;
			TArray<bool> bIsUsingHRTFSpatializer;
#if ENABLE_AUDIO_DEBUG
			TArray<double> CPUCoreUtilization;
#endif // #if ENABLE_AUDIO_DEBUG
			TArray<float> RelativeRenderCost;
		} GameThreadInfo;

		int32 NumActiveSources;
		int32 NumTotalSources;
		int32 NumOutputFrames;
		int32 NumOutputSamples;
		int32 NumSourceWorkers;

		// Commands queued up to execute
		FThreadSafeCounter NumCommands;

		uint8 bInitialized : 1;
		uint8 bUsingSpatializationPlugin : 1;
		uint8 bUsingSourceDataOverridePlugin : 1;

		// Set to true when the audio source manager should pump the command queue
		FThreadSafeBool bPumpQueue;
		std::atomic<uint64> LastPumpCompleteTimeInCycles=0;
		std::atomic<ESourceManagerRenderThreadPhase> RenderThreadPhase=ESourceManagerRenderThreadPhase::Begin;
		FRWLock CurrentlyExecutingCmdLock;						// R/W slim lock for the currently executing cmd, so we can safely query it.
		FAudioMixerThreadCommand CurrentlyExecuteingCmd;		// Keep this as a member so we can't always peek the executing cmd.

		struct FPendingAudioBusConnection
		{
			using FPatchVariant = TVariant<FPatchInput, FPatchOutputStrongPtr>;
			FPatchVariant PatchVariant;
			FAudioBusKey AudioBusKey;
			int32 NumChannels = 0;
			bool bIsAutomatic = false;
		};

		TMpscQueue<FPendingAudioBusConnection> PendingAudioBusConnections;

		friend class FMixerSourceVoice;
	};
}

=================================


=== AudioMixerSourceOutputBuffer.cpp ===
========================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerSourceOutputBuffer.h"
#include "SoundFieldRendering.h"
#include "AudioMixerSubmix.h"
#include "DSP/FloatArrayMath.h"

namespace Audio
{
	// Utility function to convert cartesian coordinates to spherical coordinates
	static void ConvertCartesianToSpherical(const FVector& InVector, float& OutAzimuth, float& OutElevation, float& OutRadius)
	{
		// Convert coordinates from unreal cartesian system to left handed spherical coordinates (zenith is positive elevation, right is positive azimuth)
		const float InX = -InVector.Z; //InVector.Y;
		const float InY = InVector.X;// -InVector.Z;
		const float InZ = -InVector.Y;


		OutElevation = FMath::Atan2(InY, InX);

		// Note, rather than using arccos(z / radius) here, we use Atan2 to avoid wrapping issues with negative elevation values.
		OutAzimuth = FMath::Atan2(FMath::Sqrt(InX * InX + InY * InY), InZ);
		OutRadius = InVector.Size();
	}

	FMixerSourceSubmixOutputBuffer::FMixerSourceSubmixOutputBuffer(FMixerDevice* InMixerDevice, uint32 InNumSourceChannels, uint32 InNumOutputChannels, uint32 InNumFrames)
		: PreAttenuationSourceBuffer(nullptr)
		, PostAttenuationSourceBuffer(nullptr)
		, SourceChannelMap(InNumSourceChannels, InNumOutputChannels)
		, NumSourceChannels(InNumSourceChannels)
		, NumFrames(InNumFrames)
		, NumOutputChannels(InNumOutputChannels)
		, MixerDevice(InMixerDevice)
		, bIsInitialDownmix(true)
		, bIs3D(false)
		, bIsVorbis(false)
	{
		PreAttenuationOutputBuffer.Reset();
		PreAttenuationOutputBuffer.AddUninitialized(InNumFrames * InNumOutputChannels);

		PostAttenuationOutputBuffer.Reset();
		PostAttenuationOutputBuffer.AddUninitialized(InNumFrames * InNumOutputChannels);
	}

	FMixerSourceSubmixOutputBuffer::~FMixerSourceSubmixOutputBuffer()
	{

	}

	void FMixerSourceSubmixOutputBuffer::Reset(const FMixerSourceSubmixOutputBufferSettings& InInitSettings)
	{
		// Whether or not this is a 3D submix output
		bIs3D = InInitSettings.bIs3D;
		bIsVorbis = InInitSettings.bIsVorbis;

		// Reset our record-keeping data
		NumOutputChannels = InInitSettings.NumOutputChannels;
		NumSourceChannels = InInitSettings.NumSourceChannels;

		// Reset the source channel map
		SourceChannelMap.Reset(NumSourceChannels, NumOutputChannels);

		// Reset the output buffers
		PreAttenuationOutputBuffer.Reset();
		PreAttenuationOutputBuffer.AddUninitialized(NumFrames * NumOutputChannels);

		PostAttenuationOutputBuffer.Reset();
		PostAttenuationOutputBuffer.AddUninitialized(NumFrames * NumOutputChannels);

		// Reset the post and pre source buffers
		PostAttenuationSourceBuffer = nullptr;
		PreAttenuationSourceBuffer = nullptr;

		// Reset the soundfield data
		EncodedSoundfieldDownmixes.Reset();
		SoundfieldDecoder.Reset();
		bIsInitialDownmix = true;

		// Make a new soundfield decoder if this sound is a soundfield source
		if (InInitSettings.bIsSoundfield)
		{
			SoundfieldDecoder = CreateDefaultSourceAmbisonicsDecoder(MixerDevice);
		}

		// Create data for each of the soundfield submix sends
		for (const FMixerSubmixPtr& SoundfieldSubmixPtr : InInitSettings.SoundfieldSubmixSends)
		{
			// Get the encoding key for the given soundfield submix this source is sending to
			FSoundfieldEncodingKey EncodingKey = SoundfieldSubmixPtr->GetKeyForSubmixEncoding();

			// Create a data bucket based on this encoding key
			FSoundfieldData& SoundfieldData = EncodedSoundfieldDownmixes.FindOrAdd(EncodingKey);

			// Get the soundfield submix's factory object, which creates encoders, decoders, transcoders, etc.
			ISoundfieldFactory* Factory = SoundfieldSubmixPtr->GetSoundfieldFactory();
			check(Factory);

			FAudioPluginInitializationParams PluginInitParams = SoundfieldSubmixPtr->GetInitializationParamsForSoundfieldStream();
			PluginInitParams.NumOutputChannels = NumSourceChannels;

			SoundfieldData.EncoderSettings = SoundfieldSubmixPtr->GetSoundfieldSettings().Duplicate();

			// If this source is soundfield, we need to use a transcoder
			if (InInitSettings.bIsSoundfield)
			{
				if (Factory->GetSoundfieldFormatName() == GetUnrealAmbisonicsFormatName())
				{
					SoundfieldData.bIsUnrealAmbisonicsSubmix = true;
				}
				else if (Factory->CanTranscodeFromSoundfieldFormat(GetUnrealAmbisonicsFormatName(), GetAmbisonicsSourceDefaultSettings()))
				{
					SoundfieldData.SoundfieldTranscoder = Factory->CreateTranscoderStream(GetUnrealAmbisonicsFormatName(), GetAmbisonicsSourceDefaultSettings(), Factory->GetSoundfieldFormatName(), *SoundfieldData.EncoderSettings, PluginInitParams);
				}
			}
			else
			{
				check(SoundfieldData.EncoderSettings.IsValid());

				SoundfieldData.SoundfieldEncoder = Factory->CreateEncoderStream(PluginInitParams, *SoundfieldData.EncoderSettings);
			}

			// Create a blank packet for memory of the encoded packet
			SoundfieldData.EncodedPacket = Factory->CreateEmptyPacket();
		}
	}

	void FMixerSourceSubmixOutputBuffer::SetNumOutputChannels(uint32 InNumOutputChannels)
	{
		NumOutputChannels = InNumOutputChannels;

		SourceChannelMap.Reset(NumSourceChannels, NumOutputChannels);

		PreAttenuationOutputBuffer.Reset();
		PreAttenuationOutputBuffer.AddUninitialized(NumFrames * NumOutputChannels);

		PostAttenuationOutputBuffer.Reset();
		PostAttenuationOutputBuffer.AddUninitialized(NumFrames * NumOutputChannels);
	}

	bool FMixerSourceSubmixOutputBuffer::SetChannelMap(const FAlignedFloatBuffer& InChannelMap, bool bInIsCenterChannelOnly)
	{
		bool bNeedsNewChannelMap = false;

		// Fix up the channel map in case the device output count changed
		const uint32 ChannelMapSize = SourceChannelMap.CopySize / sizeof(float);

		if (InChannelMap.Num() != ChannelMapSize)
		{
			FAlignedFloatBuffer NewChannelMap;

			if (bIs3D)
			{
				NewChannelMap.AddZeroed(ChannelMapSize);
				bNeedsNewChannelMap = true;
			}
			else
			{
				const uint32 ChannelMapOutputChannels = ChannelMapSize / NumSourceChannels;
				FMixerDevice::Get2DChannelMap(bIsVorbis, NumSourceChannels, ChannelMapOutputChannels, bInIsCenterChannelOnly, NewChannelMap);
			}

			SourceChannelMap.SetChannelMap(NewChannelMap.GetData());
		}
		else
		{
			SourceChannelMap.SetChannelMap(InChannelMap.GetData());
		}

		return bNeedsNewChannelMap;
	}

	void FMixerSourceSubmixOutputBuffer::SetPreAttenuationSourceBuffer(FAlignedFloatBuffer* InPreAttenuationSourceBuffer)
	{
		PreAttenuationSourceBuffer = InPreAttenuationSourceBuffer;
	}

	void FMixerSourceSubmixOutputBuffer::SetPostAttenuationSourceBuffer(FAlignedFloatBuffer* InPostAttenuationSourceBuffer)
	{
		PostAttenuationSourceBuffer = InPostAttenuationSourceBuffer;
	}

	void FMixerSourceSubmixOutputBuffer::ComputeOutput(const FSpatializationParams& InSpatParams)
	{
		// No need to compute an output if there is no source buffer available
		if (!PostAttenuationSourceBuffer && !PreAttenuationSourceBuffer)
		{
			return;
		}

		// Update our rotational data based off the spat params
		SoundfieldPositionalData.Rotation = InSpatParams.ListenerOrientation;
		SoundSourceRotation = InSpatParams.EmitterWorldRotation;
		
		if (bIs3D && !bIsInitialDownmix)
		{
			ComputeOutput3D();
		}
		else
		{
			ComputeOutput2D();
			bIsInitialDownmix = false;
		}

		// Now check if we need to do any sound field encoding
		if (EncodedSoundfieldDownmixes.Num())
		{
			EncodeToSoundfieldFormats(InSpatParams);
		}
	}

	void FMixerSourceSubmixOutputBuffer::ComputeOutput3D(FAlignedFloatBuffer& InSourceBuffer, FAlignedFloatBuffer& OutSourceBuffer)
	{
		if (SoundfieldDecoder.IsValid())
		{
			FAmbisonicsSoundfieldBuffer SoundfieldBuffer;
			SoundfieldBuffer.AudioBuffer = MoveTemp(InSourceBuffer);
			SoundfieldBuffer.NumChannels = NumSourceChannels;
			SoundfieldBuffer.PreviousRotation = SoundfieldBuffer.Rotation;
			SoundfieldBuffer.Rotation = SoundSourceRotation;

			SoundfieldPositionalData.NumChannels = NumOutputChannels;
			SoundfieldPositionalData.ChannelPositions = MixerDevice->GetDefaultPositionMap(NumOutputChannels);

			FSoundfieldDecoderInputData SoundfieldDecoderInputData =
			{
				SoundfieldBuffer,
				SoundfieldPositionalData,
				static_cast<int32>(InSourceBuffer.Num() / NumSourceChannels),
				MixerDevice->GetSampleRate()
			};

			FSoundfieldDecoderOutputData SoundFieldDecoderOutputData = { OutSourceBuffer };

			SoundfieldDecoder->Decode(SoundfieldDecoderInputData, SoundFieldDecoderOutputData);

			InSourceBuffer = MoveTemp(SoundfieldBuffer.AudioBuffer);
		}
		else if (NumSourceChannels == 1)
		{
			switch (NumOutputChannels)
			{
			case 8:
				MixMonoTo8ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
				break;
			case 6:
				MixMonoTo6ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
				break;
			case 4:
				MixMonoTo4ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
				break;
			case 2:
				MixMonoTo2ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
				break;
			}

		}
		else if (NumSourceChannels == 2)
		{
			switch (NumOutputChannels)
			{
			case 8:
				Mix2ChannelsTo8ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
				break;
			case 6:
				Mix2ChannelsTo6ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
				break;
			case 4:
				Mix2ChannelsTo4ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
				break;
			case 2:
				Mix2ChannelsTo2ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
				break;
			}
		}
		else
		{
			DownmixBuffer(NumSourceChannels, NumOutputChannels, InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelStartGains, SourceChannelMap.ChannelDestinationGains);
		}
	}

	void FMixerSourceSubmixOutputBuffer::ComputeOutput3D()
	{
		// Compute the output buffers if there is a corresponding pre or post source buffer set

		if (PreAttenuationSourceBuffer)
		{
			ComputeOutput3D(*PreAttenuationSourceBuffer, PreAttenuationOutputBuffer);
		}

		if (PostAttenuationSourceBuffer)
		{
			ComputeOutput3D(*PostAttenuationSourceBuffer, PostAttenuationOutputBuffer);
		}

		// Do the channel map copy from dest to start (which prevents zippering of dynamic channel mapping for 3d audio) after the data has been computed for both pre- and post- attenuation channel downmixing
		SourceChannelMap.CopyDestinationToStart();
	}

	void FMixerSourceSubmixOutputBuffer::ComputeOutput2D(FAlignedFloatBuffer& InSourceBuffer, FAlignedFloatBuffer& OutSourceBuffer)
	{
		// For 2D sources, we just apply the gain matrix in ChannelDestionationGains with no interpolation.
		if (SoundfieldDecoder.IsValid())
		{
			FAmbisonicsSoundfieldBuffer SoundfieldBuffer;
			SoundfieldBuffer.AudioBuffer = MoveTemp(InSourceBuffer);
			SoundfieldBuffer.NumChannels = NumSourceChannels;
			SoundfieldBuffer.PreviousRotation = SoundfieldBuffer.Rotation;
			SoundfieldBuffer.Rotation = SoundSourceRotation;

			SoundfieldPositionalData.NumChannels = NumOutputChannels;
			SoundfieldPositionalData.ChannelPositions = MixerDevice->GetDefaultPositionMap(NumOutputChannels);

			FSoundfieldDecoderInputData SoundfieldDecoderInputData =
			{
				SoundfieldBuffer,
				SoundfieldPositionalData,
				static_cast<int32>(InSourceBuffer.Num() / NumSourceChannels),
				MixerDevice->GetSampleRate()
			};

			FSoundfieldDecoderOutputData SoundfieldDecoderOutputData = { OutSourceBuffer };

			SoundfieldDecoder->Decode(SoundfieldDecoderInputData, SoundfieldDecoderOutputData);

			// Move the encoded ambisonics source buffer back to PostEffectBuffers to prevent reallocation
			InSourceBuffer = MoveTemp(SoundfieldBuffer.AudioBuffer);
		}
		else if (NumSourceChannels == 1)
		{
			switch (NumOutputChannels)
			{
			case 8:
				Audio::MixMonoTo8ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
				break;
			case 6:
				Audio::MixMonoTo6ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
				break;
			case 4:
				Audio::MixMonoTo4ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
				break;
			case 2:
				Audio::MixMonoTo2ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
				break;
			}
		}
		else if (NumSourceChannels == 2)
		{
			switch (NumOutputChannels)
			{
			case 8:
				Audio::Mix2ChannelsTo8ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
				break;
			case 6:
				Audio::Mix2ChannelsTo6ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
				break;
			case 4:
				Audio::Mix2ChannelsTo4ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
				break;
			case 2:
				Audio::Mix2ChannelsTo2ChannelsFast(InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
				break;
			}
		}
		else
		{
			Audio::DownmixBuffer(NumSourceChannels, NumOutputChannels, InSourceBuffer, OutSourceBuffer, SourceChannelMap.ChannelDestinationGains);
		}
	}

	void FMixerSourceSubmixOutputBuffer::ComputeOutput2D()
	{
		if (PreAttenuationSourceBuffer)
		{
			ComputeOutput2D(*PreAttenuationSourceBuffer, PreAttenuationOutputBuffer);
		}

		if (PostAttenuationSourceBuffer)
		{
			ComputeOutput2D(*PostAttenuationSourceBuffer, PostAttenuationOutputBuffer);
		}
	}

	void FMixerSourceSubmixOutputBuffer::EncodeToSoundfieldFormats(const FSpatializationParams& InSpatParams)
	{
		check(MixerDevice);

		SoundfieldPositionalData.NumChannels = NumSourceChannels;

		// Spoof rotation of the source as if it's rotation of the listener when encoding non-sound-field to sound-field
		SoundfieldPositionalData.Rotation = InSpatParams.EmitterWorldRotation;

		InputChannelPositions.Reset();

		if (bIs3D)
		{
			if (NumSourceChannels == 1)
			{
				FChannelPositionInfo ChannelPosition;
				ChannelPosition.Channel = EAudioMixerChannel::FrontCenter;
				ConvertCartesianToSpherical(InSpatParams.EmitterPosition, ChannelPosition.Azimuth, ChannelPosition.Elevation, ChannelPosition.Radius);

				ChannelPosition.Radius = InSpatParams.Distance;
				InputChannelPositions.Add(ChannelPosition);

				SoundfieldPositionalData.ChannelPositions = &InputChannelPositions;
			}
			else if (NumSourceChannels == 2)
			{
				FChannelPositionInfo LeftChannelPosition;
				LeftChannelPosition.Channel = EAudioMixerChannel::FrontLeft;
				ConvertCartesianToSpherical(InSpatParams.LeftChannelPosition, LeftChannelPosition.Azimuth, LeftChannelPosition.Elevation, LeftChannelPosition.Radius);

				InputChannelPositions.Add(LeftChannelPosition);

				FChannelPositionInfo RightChannelPosition;
				LeftChannelPosition.Channel = EAudioMixerChannel::FrontRight;
				ConvertCartesianToSpherical(InSpatParams.RightChannelPosition, RightChannelPosition.Azimuth, RightChannelPosition.Elevation, RightChannelPosition.Radius);

				InputChannelPositions.Add(RightChannelPosition);

				SoundfieldPositionalData.ChannelPositions = &InputChannelPositions;
			}
		}

		// if 2D or not a supported channel configuration, use default position map
		if (!InputChannelPositions.Num())
		{
			SoundfieldPositionalData.ChannelPositions = MixerDevice->GetDefaultPositionMap(NumSourceChannels);
		}

		// Run the encoders.
		for (auto& Soundfield : EncodedSoundfieldDownmixes)
		{
			FSoundfieldData& SoundfieldData = Soundfield.Value;

			if (PreAttenuationSourceBuffer)
			{
				EncodeSoundfield(SoundfieldData , *PreAttenuationSourceBuffer);
			}

			if (PostAttenuationSourceBuffer)
			{
				EncodeSoundfield(SoundfieldData, *PostAttenuationSourceBuffer);
			}
		}
	}

	void FMixerSourceSubmixOutputBuffer::EncodeSoundfield(FSoundfieldData& InSoundfieldData, Audio::FAlignedFloatBuffer& InSourceBuffer)
	{
		check(InSoundfieldData.EncoderSettings.IsValid());
		check(InSoundfieldData.EncodedPacket.IsValid());

		InSoundfieldData.EncodedPacket->Reset();

		// We will have an soundfield transcoder if this sound source is a soundfield format
		if (InSoundfieldData.SoundfieldTranscoder)
		{
			FAmbisonicsSoundfieldBuffer SoundfieldBuffer;
			SoundfieldBuffer.AudioBuffer = MoveTemp(InSourceBuffer);
			SoundfieldBuffer.NumChannels = NumSourceChannels;
			SoundfieldBuffer.PreviousRotation = SoundfieldBuffer.Rotation;
			SoundfieldBuffer.Rotation = SoundSourceRotation;

			InSoundfieldData.SoundfieldTranscoder->Transcode(SoundfieldBuffer, GetAmbisonicsSourceDefaultSettings(), *InSoundfieldData.EncodedPacket, *InSoundfieldData.EncoderSettings);
			InSourceBuffer = MoveTemp(SoundfieldBuffer.AudioBuffer);
		}
		else if (InSoundfieldData.SoundfieldEncoder)
		{
			FSoundfieldEncoderInputData SoundfieldEncoderInputData =
			{
				InSourceBuffer,
				static_cast<int32>(NumSourceChannels),
				*InSoundfieldData.EncoderSettings,
				SoundfieldPositionalData
			};

			InSoundfieldData.SoundfieldEncoder->Encode(SoundfieldEncoderInputData, *InSoundfieldData.EncodedPacket);
		}
		else if (InSoundfieldData.bIsUnrealAmbisonicsSubmix)
		{
			FAmbisonicsSoundfieldBuffer& OutputPacket = DowncastSoundfieldRef<FAmbisonicsSoundfieldBuffer>(*InSoundfieldData.EncodedPacket);

			// Fixme: This is an array copy. Can we serve InPositionalData directly to this soundfield?
			OutputPacket.AudioBuffer = InSourceBuffer;
			OutputPacket.NumChannels = NumSourceChannels;
			OutputPacket.PreviousRotation = OutputPacket.Rotation;
			OutputPacket.Rotation = SoundSourceRotation;
		}
	}

	void FMixerSourceSubmixOutputBuffer::MixOutput(float InSendLevel, EMixerSourceSubmixSendStage InSubmixSendStage, FAlignedFloatBuffer& OutMixedBuffer) const
	{
		if (InSubmixSendStage == EMixerSourceSubmixSendStage::PostDistanceAttenuation)
		{
			Audio::ArrayMixIn(PostAttenuationOutputBuffer, OutMixedBuffer, InSendLevel);
		}
		else
		{
			Audio::ArrayMixIn(PreAttenuationOutputBuffer, OutMixedBuffer, InSendLevel);
		}
	}

	FQuat FMixerSourceSubmixOutputBuffer::GetListenerRotation() const
	{
		return SoundfieldPositionalData.Rotation;
	}

	void FMixerSourceSubmixOutputBuffer::CopyReverbPluginOutputData(FAlignedFloatBuffer& InAudioBuffer)
	{
		ReverbPluginOutputBuffer.Reset();
		ReverbPluginOutputBuffer.Append(InAudioBuffer);
	}

	const float* FMixerSourceSubmixOutputBuffer::GetReverbPluginOutputData() const
	{
		return ReverbPluginOutputBuffer.GetData();
	}

	const ISoundfieldAudioPacket* FMixerSourceSubmixOutputBuffer::GetSoundfieldPacket(const FSoundfieldEncodingKey& InKey) const
	{
		if(EncodedSoundfieldDownmixes.Contains(InKey))
		{
			const FSoundfieldData& SoundfieldData = EncodedSoundfieldDownmixes[InKey];
			return SoundfieldData.EncodedPacket.Get();
		}

		return nullptr;
	}

	ISoundfieldAudioPacket* FMixerSourceSubmixOutputBuffer::GetSoundFieldPacket(const FSoundfieldEncodingKey& InKey)
	{
		FSoundfieldData& SoundfieldData = EncodedSoundfieldDownmixes.FindOrAdd(InKey);
		return SoundfieldData.EncodedPacket.Get();
	}


}

========================================


=== AudioMixerSourceOutputBuffer.h ===
======================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once


#include "CoreMinimal.h"
#include "ISoundfieldFormat.h"
#include "IAudioExtensionPlugin.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSubmix.h"

namespace Audio
{
	class FMixerSubmix;

	struct FMixerSourceSubmixOutputBufferSettings
	{
		uint32 NumSourceChannels;
		uint32 NumOutputChannels;
		TArray<FMixerSubmixPtr> SoundfieldSubmixSends;
		bool bIs3D;
		bool bIsVorbis;
		bool bIsSoundfield;
	};

	/** 
	* Used in audio mixer source manager to convert source audio to channel output and mix into submixes
	*/
	class FMixerSourceSubmixOutputBuffer
	{
	public:
		FMixerSourceSubmixOutputBuffer(FMixerDevice* InMixerDevice, uint32 InNumSourceChannels, uint32 InNumOutputChannels, uint32 InNumFrames);

		~FMixerSourceSubmixOutputBuffer();

		// Resets the source submix output to prepare for new source data
		void Reset(const FMixerSourceSubmixOutputBufferSettings& InResetSettings);

		// Sets the number of output channels
		void SetNumOutputChannels(uint32 InNumOutputChannels);

		// Returns the number of source channels of this source
		uint32 GetNumSourceChannels() const { return NumSourceChannels; }

		// Sets the channel map
		bool SetChannelMap(const FAlignedFloatBuffer& InChannelMap, bool bInIsCenterChannelOnly);

		// Sets the pre and post attenuation source buffers. This is the source buffer data derived from source manager source processing.
		void SetPreAttenuationSourceBuffer(FAlignedFloatBuffer* InPreAttenuationBuffer);
		void SetPostAttenuationSourceBuffer(FAlignedFloatBuffer* InPostAttenuationBuffer);
		void CopyReverbPluginOutputData(FAlignedFloatBuffer& InAudioBuffer);
		const float* GetReverbPluginOutputData() const;

		// Retrieves the current sound field packet for the given key
		const ISoundfieldAudioPacket* GetSoundfieldPacket(const FSoundfieldEncodingKey& InKey) const;
		ISoundfieldAudioPacket* GetSoundFieldPacket(const FSoundfieldEncodingKey& InKey);

		// Computes the output buffer given the spat params. This buffer can then be mixed to submixes
		void ComputeOutput(const FSpatializationParams& InSpatParams);

		// Called by submixes to mix this output buffer to their buffer
		void MixOutput(float SendLevel, EMixerSourceSubmixSendStage InSubmixSendStage, FAlignedFloatBuffer& OutMixedBuffer) const;

		// Return the listener rotation
		// TODO: consolidate the code that is using this to be private to this class.
		FQuat GetListenerRotation() const;

	private: // private classes

		// Private struct used for channel mapping
		struct FSourceChannelMap
		{
			alignas(16) float ChannelStartGains[AUDIO_MIXER_MAX_OUTPUT_CHANNELS * AUDIO_MIXER_MAX_OUTPUT_CHANNELS];
			alignas(16) float ChannelDestinationGains[AUDIO_MIXER_MAX_OUTPUT_CHANNELS * AUDIO_MIXER_MAX_OUTPUT_CHANNELS];

			// This is the number of bytes the gain array is using:
			// (Number of input channels * number of output channels) * sizeof float.
			int32 CopySize = 0;
			bool bIsInit = false;

			FSourceChannelMap(int32 InNumInChannels, int32 InNumOutChannels)
				: CopySize(InNumInChannels* InNumOutChannels * sizeof(float))
			{
				checkSlow(InNumInChannels <= AUDIO_MIXER_MAX_OUTPUT_CHANNELS);
				checkSlow(InNumOutChannels <= AUDIO_MIXER_MAX_OUTPUT_CHANNELS);
				FMemory::Memzero(ChannelStartGains, CopySize);
			}

			FORCEINLINE void Reset(int32 InNumInChannels, int32 InNumOutChannels)
			{
				checkSlow(InNumInChannels <= AUDIO_MIXER_MAX_OUTPUT_CHANNELS);
				checkSlow(InNumOutChannels <= AUDIO_MIXER_MAX_OUTPUT_CHANNELS);

				CopySize = InNumInChannels * InNumOutChannels * sizeof(float);
				FMemory::Memzero(ChannelStartGains, CopySize);
				FMemory::Memzero(ChannelDestinationGains, CopySize);
				bIsInit = false;
			}

			FORCEINLINE void CopyDestinationToStart()
			{
				FMemory::Memcpy(ChannelStartGains, ChannelDestinationGains, CopySize);
			}

			FORCEINLINE void SetChannelMap(const float* RESTRICT InChannelGains)
			{
				FMemory::Memcpy(ChannelDestinationGains, InChannelGains, CopySize);
				if (!bIsInit)
				{
					FMemory::Memcpy(ChannelStartGains, InChannelGains, CopySize);
					bIsInit = true;
				}
			}

		private:
			FSourceChannelMap()
				: CopySize(0)
				, bIsInit(false)
			{
			}
		};

		struct FSoundfieldData
		{
			// If the sound source is not a soundfield source and we're sending to a soundfield submix, it gets encoded
			TUniquePtr<ISoundfieldEncoderStream> SoundfieldEncoder;

			// If the sound source is soundfield, and we're sending to a soundfield submix, it gets transcoded
			TUniquePtr<ISoundfieldTranscodeStream> SoundfieldTranscoder;

			// The optional soundfield encoder settings
			TUniquePtr<ISoundfieldEncodingSettingsProxy> EncoderSettings;

			// The encoded soundfield packet
			TUniquePtr<ISoundfieldAudioPacket> EncodedPacket;

			// If this is a unreal ambisonics soundfield buffer, we hand it the submixed buffer directly.
			bool bIsUnrealAmbisonicsSubmix;
		};

	private: // private methods

		void ComputeOutput3D(FAlignedFloatBuffer& InSource, FAlignedFloatBuffer& InOutput);
		void ComputeOutput3D();
		void ComputeOutput2D(FAlignedFloatBuffer& InSource, FAlignedFloatBuffer& InOutput);
		void ComputeOutput2D();

		void EncodeSoundfield(FSoundfieldData& InSoundfieldData, Audio::FAlignedFloatBuffer& InSourceBuffer);
		void EncodeToSoundfieldFormats(const FSpatializationParams& InSpatParams);

	private: // private data

		// Buffer for reverb plugins to write into
		FAlignedFloatBuffer ReverbPluginOutputBuffer;

		// The source buffer created before distance attenuation is applied
		FAlignedFloatBuffer* PreAttenuationSourceBuffer;

		// The source buffer created after distance attenuation is applied
		FAlignedFloatBuffer* PostAttenuationSourceBuffer;

		// Data used to map the source channel data to the output channel configuration
		FSourceChannelMap SourceChannelMap;

		// The result of the source output with source data derived pre distance attenuation
		FAlignedFloatBuffer PreAttenuationOutputBuffer;

		// The result of the source output with source data derived post distance attenuation
		FAlignedFloatBuffer PostAttenuationOutputBuffer;

		// The number of source channels (sound input)
		uint32 NumSourceChannels;

		// The number of interleaved frames in the source
		const uint32 NumFrames;

		// The number of device output channels
		uint32 NumOutputChannels;

		// The owning mixer device
		FMixerDevice* MixerDevice;

		// Whether this is the initial downmix
		bool bIsInitialDownmix;

		// If this is a 3D sound source
		bool bIs3D;

		// Whether this source is vorbis encoded (used for 2D speakermapping)
		bool bIsVorbis;

		// Cached parameters for encoding to a soundfield format
		FSoundfieldSpeakerPositionalData SoundfieldPositionalData;

		// The current sound source rotation
		FQuat SoundSourceRotation;

		// Map of sound field encoding to encoding data
		TMap<FSoundfieldEncodingKey, FSoundfieldData> EncodedSoundfieldDownmixes;

		// Channel positions of the sound field
		TArray<Audio::FChannelPositionInfo> InputChannelPositions;

		// If this source is an ambisonics source, we use this to down mix the source to output channel mix.
		TUniquePtr<ISoundfieldDecoderStream> SoundfieldDecoder;

	};


}

======================================


=== AudioMixerSourceVoice.cpp ===
=================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerSourceVoice.h"
#include "AudioMixerSource.h"
#include "AudioMixerSourceManager.h"
#include "AudioMixerDevice.h"

namespace Audio
{

	/**
	* FMixerSourceVoice Implementation
	*/

	FMixerSourceVoice::FMixerSourceVoice()
	{
		Reset(nullptr);
	}

	FMixerSourceVoice::~FMixerSourceVoice()
	{
	}

	void FMixerSourceVoice::Reset(FMixerDevice* InMixerDevice)
	{
		if (InMixerDevice)
		{
			MixerDevice = InMixerDevice;
			SourceManager = MixerDevice->GetSourceManager();
		}
		else
		{
			MixerDevice = nullptr;
			SourceManager = nullptr;
		}

		Pitch = -1.0f;
		Volume = -1.0f;
		DistanceAttenuation = -1.0f;
		Distance = -1.0f;
		LPFFrequency = -1.0f;
		HPFFrequency = -1.0f;
		SourceId = INDEX_NONE;
		bIsPlaying = false;
		bIsPaused = false;
		bIsActive = false;
		bIsBus = false;
		bEnableBusSends = false;
		bEnableBaseSubmix = false;
		bEnableSubmixSends = false;
		bStopFadedOut = false;

		PitchModBase = TNumericLimits<float>::Max();
		VolumeModBase = TNumericLimits<float>::Max();
		LPFFrequencyModBase = TNumericLimits<float>::Max();
		HPFFrequencyModBase = TNumericLimits<float>::Max();

		SubmixSends.Reset();
	}

	bool FMixerSourceVoice::Init(const FMixerSourceVoiceInitParams& InitParams)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (SourceManager->GetFreeSourceId(SourceId))
		{
			AUDIO_MIXER_CHECK(InitParams.SourceListener != nullptr);
			AUDIO_MIXER_CHECK(InitParams.NumInputChannels > 0);

			bEnableBusSends = InitParams.bEnableBusSends;
			bEnableBaseSubmix = InitParams.bEnableBaseSubmix;
			bEnableSubmixSends = InitParams.bEnableSubmixSends;

			bIsBus = InitParams.AudioBusId != INDEX_NONE;

			for (int32 i = 0; i < InitParams.SubmixSends.Num(); ++i)
			{
				FMixerSubmixPtr SubmixPtr = InitParams.SubmixSends[i].Submix.Pin();
				if (SubmixPtr.IsValid())
				{
					SubmixSends.Add(SubmixPtr->GetId(), InitParams.SubmixSends[i]);
				}
			}

			bStopFadedOut = false;
			SourceManager->InitSource(SourceId, InitParams);
			return true;
		}

		return false;
	}

	void FMixerSourceVoice::Release()
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		SourceManager->ReleaseSourceId(SourceId);
	}

	void FMixerSourceVoice::SetPitch(const float InPitch)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (Pitch != InPitch)
		{
			Pitch = InPitch;
			SourceManager->SetPitch(SourceId, InPitch);
		}
	}

	void FMixerSourceVoice::SetVolume(const float InVolume)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (Volume != InVolume)
		{
			Volume = InVolume;
			SourceManager->SetVolume(SourceId, InVolume);
		}
	}

	void FMixerSourceVoice::SetDistanceAttenuation(const float InDistanceAttenuation)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (DistanceAttenuation != InDistanceAttenuation)
		{
			DistanceAttenuation = InDistanceAttenuation;
			SourceManager->SetDistanceAttenuation(SourceId, InDistanceAttenuation);
		}
	}

	void FMixerSourceVoice::SetLPFFrequency(const float InLPFFrequency)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (LPFFrequency != InLPFFrequency)
		{
			LPFFrequency = InLPFFrequency;
			SourceManager->SetLPFFrequency(SourceId, LPFFrequency);
		}
	}

	void FMixerSourceVoice::SetHPFFrequency(const float InHPFFrequency)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (HPFFrequency != InHPFFrequency)
		{
			HPFFrequency = InHPFFrequency;
			SourceManager->SetHPFFrequency(SourceId, HPFFrequency);
		}
	}

	void FMixerSourceVoice::SetModVolume(const float InVolumeModBase)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (InVolumeModBase != VolumeModBase)
		{
			VolumeModBase = InVolumeModBase;
			SourceManager->SetModVolume(SourceId, VolumeModBase);
		}
	}

	void FMixerSourceVoice::SetModPitch(const float InPitchModBase)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (InPitchModBase != PitchModBase)
		{
			PitchModBase = InPitchModBase;
			SourceManager->SetModPitch(SourceId, InPitchModBase);
		}
	}

	void FMixerSourceVoice::SetModHPFFrequency(const float InHPFFrequencyModBase)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (InHPFFrequencyModBase != HPFFrequencyModBase)
		{
			HPFFrequencyModBase = InHPFFrequencyModBase;
			SourceManager->SetModHPFFrequency(SourceId, InHPFFrequencyModBase);
		}
	}

	void FMixerSourceVoice::SetModLPFFrequency(const float InLPFFrequencyModBase)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (InLPFFrequencyModBase != LPFFrequencyModBase)
		{
			LPFFrequencyModBase = InLPFFrequencyModBase;
			SourceManager->SetModLPFFrequency(SourceId, InLPFFrequencyModBase);
		}
	}

	void FMixerSourceVoice::SetModulationRouting(FSoundModulationDefaultRoutingSettings& RoutingSettings)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		SourceManager->SetModulationRouting(SourceId, RoutingSettings);
	}

	void FMixerSourceVoice::SetSourceBufferListener(FSharedISourceBufferListenerPtr& InSourceBufferListener, bool InShouldSourceBufferListenerZeroBuffer)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		SourceManager->SetSourceBufferListener(SourceId, InSourceBufferListener, InShouldSourceBufferListenerZeroBuffer);
	}

	void FMixerSourceVoice::SetChannelMap(const uint32 NumInputChannels, const Audio::FAlignedFloatBuffer& InChannelMap, const bool bInIs3D, const bool bInIsCenterChannelOnly)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		SourceManager->SetChannelMap(SourceId, NumInputChannels, InChannelMap, bInIs3D, bInIsCenterChannelOnly);
	}

	void FMixerSourceVoice::SetSpatializationParams(const FSpatializationParams& InParams)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		SourceManager->SetSpatializationParams(SourceId, InParams);
	}

	void FMixerSourceVoice::Play()
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		bIsPlaying = true;
		bIsPaused = false;
		bIsActive = true;

		SourceManager->Play(SourceId);
	}

	void FMixerSourceVoice::Stop()
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		bIsPlaying = false;
		bIsPaused = false;
		bIsActive = false;
		// We are instantly fading out with this stop command
		bStopFadedOut = true;
		SourceManager->Stop(SourceId);
	}

	void FMixerSourceVoice::StopFade(int32 NumFrames)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		bIsPaused = false;
		SourceManager->StopFade(SourceId, NumFrames);
	}

	int32 FMixerSourceVoice::GetSourceId() const
	{
		return SourceId;
	}

	float FMixerSourceVoice::GetDistanceAttenuation() const
	{
		return DistanceAttenuation;
	}

	float FMixerSourceVoice::GetDistance() const
	{
		return Distance;
	}

	void FMixerSourceVoice::Pause()
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		bIsPaused = true;
		bIsActive = false;
		SourceManager->Pause(SourceId);
	}

	bool FMixerSourceVoice::IsPlaying() const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		return bIsPlaying;
	}

	bool FMixerSourceVoice::IsPaused() const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		return bIsPaused;
	}

	bool FMixerSourceVoice::IsActive() const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		return bIsActive;
	}

	bool FMixerSourceVoice::NeedsSpeakerMap() const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		return SourceManager->NeedsSpeakerMap(SourceId);
	}

	bool FMixerSourceVoice::IsUsingHRTFSpatializer(bool bDefaultValue) const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (SourceId != INDEX_NONE)
		{
			return SourceManager->IsUsingHRTFSpatializer(SourceId);
		}

		return bDefaultValue;
	}

	int64 FMixerSourceVoice::GetNumFramesPlayed() const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		return SourceManager->GetNumFramesPlayed(SourceId);
	}

	float FMixerSourceVoice::GetEnvelopeValue() const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		return SourceManager->GetEnvelopeValue(SourceId);
	}

#if ENABLE_AUDIO_DEBUG
	double FMixerSourceVoice::GetCPUCoreUtilization() const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		return SourceManager->GetCPUCoreUtilization(SourceId);
	}
#endif // ENABLE_AUDIO_DEBUG

	float FMixerSourceVoice::GetRelativeRenderCost() const
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		return SourceManager->GetRelativeRenderCost(SourceId);
	}

	void FMixerSourceVoice::MixOutputBuffers(int32 InNumOutputChannels, const float SendLevel, EMixerSourceSubmixSendStage InSubmixSendStage, FAlignedFloatBuffer& OutWetBuffer) const
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		if (IsRenderingToSubmixes())
		{
			SourceManager->MixOutputBuffers(SourceId, InNumOutputChannels, SendLevel, InSubmixSendStage, OutWetBuffer);
		}
	}

	const ISoundfieldAudioPacket* FMixerSourceVoice::GetEncodedOutput(const FSoundfieldEncodingKey& InKey) const
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		if (IsRenderingToSubmixes())
		{
			return SourceManager->GetEncodedOutput(SourceId, InKey);
		}
		return nullptr;
	}

	const FQuat FMixerSourceVoice::GetListenerRotationForVoice() const
	{
		return SourceManager->GetListenerRotation(SourceId);
	}

	void FMixerSourceVoice::SetSubmixSendInfo(FMixerSubmixWeakPtr Submix, const float SendLevel, const EMixerSourceSubmixSendStage SendStage/* = EMixerSourceSubmixSendStage::PostDistanceAttenuation*/)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		FMixerSubmixPtr SubmixPtr = Submix.Pin();
		if (SubmixPtr.IsValid())
		{
			FMixerSourceSubmixSend* SubmixSend = SubmixSends.Find(SubmixPtr->GetId());

			if (!SubmixSend)
			{
				FMixerSourceSubmixSend NewSubmixSend;
				NewSubmixSend.Submix = Submix;
				NewSubmixSend.SendLevel = SendLevel;
				NewSubmixSend.bIsMainSend = false;
				NewSubmixSend.SubmixSendStage = SendStage;

				SubmixSends.Add(SubmixPtr->GetId(), NewSubmixSend);
				SourceManager->SetSubmixSendInfo(SourceId, NewSubmixSend);
			}
			else if (!FMath::IsNearlyEqual(SubmixSend->SendLevel, SendLevel) || SubmixSend->SubmixSendStage != SendStage)
			{
				SubmixSend->SendLevel = SendLevel;
				SubmixSend->SubmixSendStage = SendStage;
				SourceManager->SetSubmixSendInfo(SourceId, *SubmixSend);
			}
		}
	}

	void FMixerSourceVoice::ClearSubmixSendInfo(FMixerSubmixWeakPtr Submix)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		FMixerSubmixPtr SubmixPtr = Submix.Pin();
		if (SubmixPtr.IsValid())
		{
			FMixerSourceSubmixSend* SubmixSend = SubmixSends.Find(SubmixPtr->GetId());
			if (SubmixSend)
			{
				SourceManager->ClearSubmixSendInfo(SourceId, *SubmixSend);
				SubmixSends.Remove(SubmixPtr->GetId());
			}
		}
	}

	void FMixerSourceVoice::SetOutputToBusOnly(bool bInOutputToBusOnly)
	{
		if (bInOutputToBusOnly)
		{
			bEnableBusSends = true;
		}

		bEnableBaseSubmix = !bInOutputToBusOnly;
		bEnableSubmixSends = !bInOutputToBusOnly;
	}

	void FMixerSourceVoice::SetEnablement(bool bInEnableBusSendRouting, bool bInEnableMainSubmixOutput, bool bInEnableSubmixSendRouting)
	{
		bEnableBusSends = bInEnableBusSendRouting;
		bEnableBaseSubmix = bInEnableMainSubmixOutput;
		bEnableSubmixSends = bInEnableSubmixSendRouting;
	}


	void FMixerSourceVoice::SetAudioBusSendInfo(EBusSendType InBusSendType, uint32 AudioBusId, float BusSendLevel)
	{
		AUDIO_MIXER_CHECK_GAME_THREAD(MixerDevice);

		if (!bEnableBusSends)
		{
			BusSendLevel = 0.0f;
		}

		SourceManager->SetBusSendInfo(SourceId, InBusSendType, AudioBusId, BusSendLevel);
	}

	bool FMixerSourceVoice::IsRenderingToSubmixes() const
	{
		return bEnableBaseSubmix || bEnableSubmixSends;
	}

	void FMixerSourceVoice::OnMixBus(FMixerSourceVoiceBuffer* OutMixerSourceBuffer)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		check(OutMixerSourceBuffer->AudioData.Num() > 0);

		for (int32 i = 0; i < OutMixerSourceBuffer->AudioData.Num(); ++i)
		{
			OutMixerSourceBuffer->AudioData[i] = 0.0f;
		}
	}
}

=================================


=== AudioMixerSourceVoice.h ===
===============================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "AudioMixerBuffer.h"
#include "AudioMixerSourceManager.h"

namespace Audio
{
	struct FMixerSourceVoiceBuffer;
	struct FMixerSourceVoiceFilterParams;
	struct FMixerSourceVoiceInitParams;
	class FMixerDevice;
	class FMixerSubmix;
	class FMixerSource;
	class FMixerSourceManager;
	class ISourceBufferQueueListener;


	class FMixerSourceVoice
	{
	public:
		FMixerSourceVoice();
		~FMixerSourceVoice();

		// Resets the source voice state
		void Reset(FMixerDevice* InMixerDevice);

		// Initializes the mixer source voice
		bool Init(const FMixerSourceVoiceInitParams& InFormat);

		// Releases the source voice back to the source buffer pool
		void Release();

		// Sets the source voice pitch value.
		void SetPitch(const float InPitch);

		// Sets the source voice volume value.
		void SetVolume(const float InVolume);

		// Sets the source voice distance attenuation.
		void SetDistanceAttenuation(const float InDistanceAttenuation);
		
		// Sets the source voice's LPF filter frequency.
		void SetLPFFrequency(const float InFrequency);

		// Sets the source voice's HPF filter frequency.
		void SetHPFFrequency(const float InFrequency);

		// Sets the source voice modulation base pitch value.
		void SetModPitch(const float InPitch);

		// Sets the source voice's volume modulation base frequency.
		void SetModVolume(const float InVolume);

		// Sets the source voice's LPF filter modulation base frequency.
		void SetModLPFFrequency(const float InFrequency);

		// Sets the source voice's HPF filter modulation base frequency.
		void SetModHPFFrequency(const float InFrequency);

		void SetModulationRouting(FSoundModulationDefaultRoutingSettings& RoutingSettings);

		// Set the source voice's SourceBufferListener and associated boolean.
		void SetSourceBufferListener(FSharedISourceBufferListenerPtr& InSourceBufferListener, bool InShouldSourceBufferListenerZeroBuffer);

		// Sets the source voice's channel map (2d or 3d).
		void SetChannelMap(const uint32 NumInputChannels, const Audio::FAlignedFloatBuffer& InChannelMap, const bool bInIs3D, const bool bInIsCenterChannelOnly);

		// Sets params used by HRTF spatializer
		void SetSpatializationParams(const FSpatializationParams& InParams);

		// Starts the source voice generating audio output into it's submix.
		void Play();

		// Pauses the source voice (i.e. stops generating output but keeps its state as "active and playing". Can be restarted.)
		void Pause();

		// Immediately stops the source voice (no longer playing or active, can't be restarted.)
		void Stop();

		// Does a faded stop (to avoid discontinuity)
		void StopFade(int32 NumFrames);

		// Returns the source's Id
		int32 GetSourceId() const;

		// Returns the source's distance attenuation
		float GetDistanceAttenuation() const;

		// Returns the source's distance from the closest listener
		float GetDistance() const;

		// Queries if the voice is playing
		bool IsPlaying() const;

		// Queries if the voice is paused
		bool IsPaused() const;

		// Queries if the source voice is active.
		bool IsActive() const;

		// Queries if the source has finished its fade out.
		bool IsStopFadedOut() const { return bStopFadedOut; }

		// Whether or not the device changed and needs another speaker map sent
		bool NeedsSpeakerMap() const;

		// Whether or not the voice is currently using HRTF spatialization.
		//
		// @param bDefaultValue - This value will be returned if voice does not have a valid source id.
		bool IsUsingHRTFSpatializer(bool bDefaultValue) const;

		// Retrieves the total number of samples played.
		int64 GetNumFramesPlayed() const;

		// Retrieves the envelope value of the source.
		float GetEnvelopeValue() const;

#if ENABLE_AUDIO_DEBUG
		double GetCPUCoreUtilization() const;
#endif // ENABLE_AUDIO_DEBUG

		// Retrieves the current "render cost" of the mixer source voice. Used for debug display and for limiting voice count.
		// 1.0 is equivalent to a single decoding sound source. 
		// Useful as a metric more human-centric than CPU utilization.
		float GetRelativeRenderCost() const;

		// Mixes the dry and wet buffer audio into the given buffers.
		void MixOutputBuffers(int32 InNumChannels, const float SendLevel, EMixerSourceSubmixSendStage InSubmixSendStage, FAlignedFloatBuffer& OutWetBuffer) const;

		// For soundfield conversions, get the encoded audio.
		const ISoundfieldAudioPacket* GetEncodedOutput(const FSoundfieldEncodingKey& InKey) const;

		// This will return the listener rotation used for this source voice.
		const FQuat GetListenerRotationForVoice() const;

		// Sets the submix send levels
		void SetSubmixSendInfo(FMixerSubmixWeakPtr Submix, const float SendLevel, const EMixerSourceSubmixSendStage SendStage = EMixerSourceSubmixSendStage::PostDistanceAttenuation);

		// Clears the submix send to the given submix
		void ClearSubmixSendInfo(FMixerSubmixWeakPtr Submix);

		// Sets whether or not we are enabling sending audio to submixes (we could be sending audio to source buses though).
		void SetOutputToBusOnly(bool bInOutputToBusOnly);

		//Updates internal settings on which output types are enabled
		void SetEnablement(bool bInEnableBusSendRouting, bool bInEnableMainSubmixOutput, bool bInEnableSubmixSendRouting);

		// Set the source bus send levels
		void SetAudioBusSendInfo(EBusSendType InBusSendType, uint32 AudioBusId, float BusSendLevel);

		// Called when the source is a bus and needs to mix other sources together to generate output
		void OnMixBus(FMixerSourceVoiceBuffer* OutMixerSourceBuffer);

	private:

		friend class FMixerSourceManager;

		FMixerSourceManager* SourceManager;
		TMap<uint32, FMixerSourceSubmixSend> SubmixSends;
		FMixerDevice* MixerDevice;
		TArray<float> DeviceChannelMap;
		FThreadSafeBool bStopFadedOut;
		float Pitch;
		float Volume;
		float DistanceAttenuation;
		float Distance;
		float LPFFrequency;
		float HPFFrequency;
		float PitchModBase;
		float VolumeModBase;
		float LPFFrequencyModBase;
		float HPFFrequencyModBase;
		int32 SourceId;
		uint16 bIsPlaying : 1;
		uint16 bIsPaused : 1;
		uint16 bIsActive : 1;
		uint16 bIsBus : 1;
		uint16 bEnableBusSends : 1;
		uint16 bEnableBaseSubmix : 1;
		uint16 bEnableSubmixSends : 1;

		bool IsRenderingToSubmixes() const;
	};

}

===============================


=== AudioMixerSubmix.cpp ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "AudioMixerSubmix.h"

#include "Async/Async.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSourceVoice.h"
#include "AudioThread.h"
#include "DSP/FloatArrayMath.h"
#include "ISubmixBufferListener.h"
#include "Sound/SoundEffectPreset.h"
#include "Sound/SoundEffectSubmix.h"
#include "Sound/SoundModulationDestination.h"
#include "Sound/SoundSubmix.h"
#include "Sound/SoundSubmixSend.h"
#include "Misc/ScopeTryLock.h"
#include "ProfilingDebugging/CsvProfiler.h"
#include "AudioLinkLog.h"
#include "DSP/BufferDiagnostics.h"
#include "Algo/Accumulate.h"

// Link to "Audio" profiling category
CSV_DECLARE_CATEGORY_MODULE_EXTERN(AUDIOMIXERCORE_API, Audio);

static int32 RecoverRecordingOnShutdownCVar = 0;
FAutoConsoleVariableRef CVarRecoverRecordingOnShutdown(
	TEXT("au.RecoverRecordingOnShutdown"),
	RecoverRecordingOnShutdownCVar,
	TEXT("When set to 1, we will attempt to bounce the recording to a wav file if the game is shutdown while a recording is in flight.\n")
	TEXT("0: Disabled, 1: Enabled"),
	ECVF_Default);

static int32 BypassAllSubmixEffectsCVar = 0;
FAutoConsoleVariableRef CVarBypassAllSubmixEffects(
	TEXT("au.BypassAllSubmixEffects"),
	BypassAllSubmixEffectsCVar,
	TEXT("When set to 1, all submix effects will be bypassed.\n")
	TEXT("1: Submix Effects are disabled."),
	ECVF_Default);

static int32 LogSubmixEnablementCVar = 0;
FAutoConsoleVariableRef CVarLogSubmixEnablement(
	TEXT("au.LogSubmixAutoDisable"),
	LogSubmixEnablementCVar,
	TEXT("Enables logging of submix disable and enable state.\n")
	TEXT("1: Submix enablement logging is on. 0: Submix enablement/disablement logging is off."),
	ECVF_Default);

// Define profiling categories for submixes. 
DEFINE_STAT(STAT_AudioMixerEndpointSubmixes);
DEFINE_STAT(STAT_AudioMixerSubmixes);
DEFINE_STAT(STAT_AudioMixerSubmixChildren);
DEFINE_STAT(STAT_AudioMixerSubmixSource);
DEFINE_STAT(STAT_AudioMixerSubmixEffectProcessing);
DEFINE_STAT(STAT_AudioMixerSubmixBufferListeners);
DEFINE_STAT(STAT_AudioMixerSubmixSoundfieldChildren);
DEFINE_STAT(STAT_AudioMixerSubmixSoundfieldSources);
DEFINE_STAT(STAT_AudioMixerSubmixSoundfieldProcessors);

namespace Audio
{
	namespace MixerSubmixIntrinsics
	{

		FSpectrumAnalyzerSettings::EFFTSize GetSpectrumAnalyzerFFTSize(EFFTSize InFFTSize)
		{
			switch (InFFTSize)
			{
				case EFFTSize::DefaultSize:
					return FSpectrumAnalyzerSettings::EFFTSize::Default;
					break;

				case EFFTSize::Min:
					return FSpectrumAnalyzerSettings::EFFTSize::Min_64;
					break;

				case EFFTSize::Small:
					return FSpectrumAnalyzerSettings::EFFTSize::Small_256;
					break;

				case EFFTSize::Medium:
					return FSpectrumAnalyzerSettings::EFFTSize::Medium_512;
					break;

				case EFFTSize::Large:
					return FSpectrumAnalyzerSettings::EFFTSize::Large_1024;
					break;

				case EFFTSize::VeryLarge:
					return FSpectrumAnalyzerSettings::EFFTSize::VeryLarge_2048;
					break;

				case EFFTSize::Max:
					return FSpectrumAnalyzerSettings::EFFTSize::TestLarge_4096;
					break;

				default:
					return FSpectrumAnalyzerSettings::EFFTSize::Default;
					break;
			}
		}

		EWindowType GetWindowType(EFFTWindowType InWindowType)
		{
			switch (InWindowType)
			{
				case EFFTWindowType::None:
					return EWindowType::None;
					break;

				case EFFTWindowType::Hamming:
					return EWindowType::Hamming;
					break;

				case EFFTWindowType::Hann:
					return EWindowType::Hann;
					break;

				case EFFTWindowType::Blackman:
					return EWindowType::Blackman;
					break;

				default:
					return EWindowType::None;
					break;
			}
		}

		FSpectrumBandExtractorSettings::EMetric GetExtractorMetric(EAudioSpectrumType InSpectrumType)
		{
			using EMetric = FSpectrumBandExtractorSettings::EMetric;

			switch (InSpectrumType)
			{
				case EAudioSpectrumType::MagnitudeSpectrum:
					return EMetric::Magnitude;
					break;

				case EAudioSpectrumType::PowerSpectrum:
					return EMetric::Power;
					break;

				case EAudioSpectrumType::Decibel:
				default:
					return EMetric::Decibel;
					break;
			}
		}

		ISpectrumBandExtractor::EBandType GetExtractorBandType(EFFTPeakInterpolationMethod InMethod)
		{
			using EBandType = ISpectrumBandExtractor::EBandType;

			switch (InMethod)
			{
				case EFFTPeakInterpolationMethod::NearestNeighbor:
					return EBandType::NearestNeighbor;
					break;

				case EFFTPeakInterpolationMethod::Linear:
					return EBandType::Lerp;
					break;

				case EFFTPeakInterpolationMethod::Quadratic:
					return EBandType::Quadratic;
					break;

				case EFFTPeakInterpolationMethod::ConstantQ:
				default:
					return EBandType::ConstantQ;
					break;
			}
		}
	}

	// Unique IDs for mixer submixes
	static uint32 GSubmixMixerIDs = 0;

	FMixerSubmix::FMixerSubmix(FMixerDevice* InMixerDevice)
		: Id(GSubmixMixerIDs++)
		, ParentSubmix(nullptr)
		, MixerDevice(InMixerDevice)
		, NumChannels(0)
		, NumSamples(0)
		, CurrentOutputVolume(1.0f)
		, TargetOutputVolume(1.0f)
		, CurrentWetLevel(1.0f)
		, TargetWetLevel(1.0f)
		, CurrentDryLevel(0.0f)
		, TargetDryLevel(0.0f)
		, EnvelopeNumChannels(0)
		, NumSubmixEffects(0)
		, bIsRecording(false)
		, bIsBackgroundMuted(false)
		, bAutoDisable(true)
		, bIsSilent(false)
		, bIsCurrentlyDisabled(false)
		, AutoDisableTime(0.1)
		, SilenceTimeStartSeconds(-1.0)
		, bIsSpectrumAnalyzing(false)
	{
	}

	FMixerSubmix::~FMixerSubmix()
	{
		ClearSoundEffectSubmixes();

		if (RecoverRecordingOnShutdownCVar && OwningSubmixObject.IsValid() && bIsRecording)
		{
			FString InterruptedFileName = TEXT("InterruptedRecording.wav");
			UE_LOG(LogAudioMixer, Warning, TEXT("Recording of Submix %s was interrupted. Saving interrupted recording as %s."), *(OwningSubmixObject->GetName()), *InterruptedFileName);
			if (const USoundSubmix* SoundSubmix = Cast<const USoundSubmix>(OwningSubmixObject))
			{
				USoundSubmix* MutableSubmix = const_cast<USoundSubmix*>(SoundSubmix);
				MutableSubmix->StopRecordingOutput(MixerDevice, EAudioRecordingExportType::WavFile, InterruptedFileName, FString());
			}
		}
	}

	void FMixerSubmix::Init(const USoundSubmixBase* InSoundSubmix, bool bAllowReInit)
	{
		check(IsInAudioThread());
		if (InSoundSubmix != nullptr)
		{
			SubmixName = InSoundSubmix->GetName();

			// This is a first init and needs to be synchronous
			if (!OwningSubmixObject.IsValid())
			{
				OwningSubmixObject = InSoundSubmix;
				InitInternal();
			}
			// This is a re-init and needs to be thread safe
			else if (bAllowReInit)
			{
				check(OwningSubmixObject == InSoundSubmix);
				SubmixCommand([this]()
				{
					InitInternal();
				});
			}
			else if (const USoundfieldSubmix* SoundfieldSubmix = Cast<const USoundfieldSubmix>(OwningSubmixObject))
			{
				ISoundfieldFactory* SoundfieldFactory = SoundfieldSubmix->GetSoundfieldFactoryForSubmix();
				const USoundfieldEncodingSettingsBase* EncodingSettings = SoundfieldSubmix->GetSoundfieldEncodingSettings();

				TArray<USoundfieldEffectBase*> Effects = SoundfieldSubmix->GetSoundfieldProcessors();
				SetupSoundfieldStreams(EncodingSettings, Effects, SoundfieldFactory);
			}
		}
	}

	void FMixerSubmix::InitInternal()
	{
		// Loop through the submix's presets and make new instances of effects in the same order as the presets
		ClearSoundEffectSubmixes();

		// Copy any base data
		bAutoDisable = OwningSubmixObject->bAutoDisable;
		AutoDisableTime = (double)OwningSubmixObject->AutoDisableTime;
		bIsSilent = false;
		bIsCurrentlyDisabled = false;
		SilenceTimeStartSeconds = -1.0;

		if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
		{
			VolumeMod.Init(MixerDevice->DeviceID, FName("Volume"), false /* bInIsBuffered */, true /* bInValueLinear */);
			WetLevelMod.Init(MixerDevice->DeviceID, FName("Volume"), false /* bInIsBuffered */, true /* bInValueLinear */);
			DryLevelMod.Init(MixerDevice->DeviceID, FName("Volume"), false /* bInIsBuffered */, true /* bInValueLinear */);
		}

		if (const USoundSubmix* SoundSubmix = Cast<const USoundSubmix>(OwningSubmixObject))
		{
			VolumeModBaseDb = FMath::Clamp(SoundSubmix->OutputVolumeModulation.Value, MIN_VOLUME_DECIBELS, 0.0f);
			WetModBaseDb = FMath::Clamp(SoundSubmix->WetLevelModulation.Value, MIN_VOLUME_DECIBELS, 0.0f);
			DryModBaseDb = FMath::Clamp(SoundSubmix->DryLevelModulation.Value, MIN_VOLUME_DECIBELS, 0.0f);

			TargetOutputVolume = Audio::ConvertToLinear(VolumeModBaseDb);
			TargetWetLevel = Audio::ConvertToLinear(WetModBaseDb);
			TargetDryLevel = Audio::ConvertToLinear(DryModBaseDb);

			CurrentOutputVolume = TargetOutputVolume;
			CurrentDryLevel = TargetDryLevel;
			CurrentWetLevel = TargetWetLevel;

			if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
			{
				TSet<TObjectPtr<USoundModulatorBase>> VolumeModulator = SoundSubmix->OutputVolumeModulation.Modulators;
				TSet<TObjectPtr<USoundModulatorBase>> WetLevelModulator = SoundSubmix->WetLevelModulation.Modulators;
				TSet<TObjectPtr<USoundModulatorBase>> DryLevelModulator = SoundSubmix->DryLevelModulation.Modulators;

				// Queue this up to happen after submix init, when the mixer device has finished being added to the device manager
				SubmixCommand([this, VolMod = MoveTemp(VolumeModulator), WetMod = MoveTemp(WetLevelModulator), DryMod = MoveTemp(DryLevelModulator)]() mutable
				{
					UpdateModulationSettings(VolMod, WetMod, DryMod);
				});
			}
			
			// AudioLink send enabled? 
			if (SoundSubmix->bSendToAudioLink)
			{
				// If AudioLink is active, create a link.
				if (IAudioLinkFactory* LinkFactory = MixerDevice->GetAudioLinkFactory())
				{
					check(LinkFactory->GetSettingsClass());
					check(LinkFactory->GetSettingsClass()->GetDefaultObject());

					const UAudioLinkSettingsAbstract* Settings = !SoundSubmix->AudioLinkSettings ?
						GetDefault<UAudioLinkSettingsAbstract>(LinkFactory->GetSettingsClass()) : SoundSubmix->AudioLinkSettings.Get();

					AudioLinkInstance = LinkFactory->CreateSubmixAudioLink({ SoundSubmix, MixerDevice, Settings });
				}
			}
			
			FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
			{
    			NumSubmixEffects = 0;
				EffectChains.Reset();

				if (SoundSubmix->SubmixEffectChain.Num() > 0)
				{
					FSubmixEffectFadeInfo NewEffectFadeInfo;
					NewEffectFadeInfo.FadeVolume = FDynamicParameter(1.0f);
					NewEffectFadeInfo.bIsCurrentChain = true;
					NewEffectFadeInfo.bIsBaseEffect = true;

					for (USoundEffectSubmixPreset* EffectPreset : SoundSubmix->SubmixEffectChain)
					{
						if (EffectPreset)
						{
							++NumSubmixEffects;

							FSoundEffectSubmixInitData InitData;
							InitData.DeviceID = MixerDevice->DeviceID;
							InitData.SampleRate = MixerDevice->GetSampleRate();
							InitData.PresetSettings = nullptr;
							InitData.ParentPresetUniqueId = EffectPreset->GetUniqueID();

							// Create a new effect instance using the preset & enable
							TSoundEffectSubmixPtr SubmixEffect = USoundEffectPreset::CreateInstance<FSoundEffectSubmixInitData, FSoundEffectSubmix>(InitData, *EffectPreset);
							SubmixEffect->SetEnabled(true);

							// Add the effect to this submix's chain
							NewEffectFadeInfo.EffectChain.Add(SubmixEffect);
						}
					}

					EffectChains.Add(NewEffectFadeInfo);
				}
			}

			NumChannels = MixerDevice->GetNumDeviceChannels();
			const int32 NumOutputFrames = MixerDevice->GetNumOutputFrames();
			NumSamples = NumChannels * NumOutputFrames;
		}
		else if (const USoundfieldSubmix* SoundfieldSubmix = Cast<const USoundfieldSubmix>(OwningSubmixObject))
		{
			ISoundfieldFactory* SoundfieldFactory = SoundfieldSubmix->GetSoundfieldFactoryForSubmix();
			const USoundfieldEncodingSettingsBase* EncodingSettings = SoundfieldSubmix->GetSoundfieldEncodingSettings();

			TArray<USoundfieldEffectBase*> Effects = SoundfieldSubmix->GetSoundfieldProcessors();
			SetupSoundfieldStreams(EncodingSettings, Effects, SoundfieldFactory);
		}
		else if (const UEndpointSubmix* EndpointSubmix = Cast<const UEndpointSubmix>(OwningSubmixObject))
		{
			NumChannels = MixerDevice->GetNumDeviceChannels();
			const int32 NumOutputFrames = MixerDevice->GetNumOutputFrames();
			NumSamples = NumChannels * NumOutputFrames;

			IAudioEndpointFactory* EndpointFactory = EndpointSubmix->GetAudioEndpointForSubmix();
			const UAudioEndpointSettingsBase* EndpointSettings = EndpointSubmix->GetEndpointSettings();

			SetupEndpoint(EndpointFactory, EndpointSettings);
		}
		else if (const USoundfieldEndpointSubmix* SoundfieldEndpointSubmix = Cast<const USoundfieldEndpointSubmix>(OwningSubmixObject))
		{
 			ISoundfieldEndpointFactory* SoundfieldFactory = SoundfieldEndpointSubmix->GetSoundfieldEndpointForSubmix();
			const USoundfieldEncodingSettingsBase* EncodingSettings = SoundfieldEndpointSubmix->GetEncodingSettings();

			if (!SoundfieldFactory)
			{
				UE_LOG(LogAudio, Display, TEXT("Wasn't able to set up soundfield format for submix %s. Sending to default output."), *OwningSubmixObject->GetName());
				return;
			}

			if (!EncodingSettings)
			{
				EncodingSettings = SoundfieldFactory->GetDefaultEncodingSettings();

				if (!ensureMsgf(EncodingSettings, TEXT("Soundfield Endpoint %s did not return default encoding settings! Is ISoundfieldEndpointFactory::GetDefaultEncodingSettings() implemented?"), *SoundfieldFactory->GetEndpointTypeName().ToString()))
				{
					return;
				}
			}

			TArray<USoundfieldEffectBase*> Effects = SoundfieldEndpointSubmix->GetSoundfieldProcessors();

			SetupSoundfieldStreams(EncodingSettings, Effects, SoundfieldFactory);

			if (IsSoundfieldSubmix())
			{
				const USoundfieldEndpointSettingsBase* EndpointSettings = SoundfieldEndpointSubmix->GetEndpointSettings();

				if (!EndpointSettings)
				{
					EndpointSettings = SoundfieldFactory->GetDefaultEndpointSettings();

					if (!ensureMsgf(EncodingSettings, TEXT("Soundfield Endpoint %s did not return default encoding settings! Is ISoundfieldEndpointFactory::GetDefaultEndpointSettings() implemented?"), *SoundfieldFactory->GetEndpointTypeName().ToString()))
					{
						return;
					}
				}

				SetupEndpoint(SoundfieldFactory, EndpointSettings);
			}
			else
			{
				UE_LOG(LogAudio, Display, TEXT("Wasn't able to set up soundfield format for submix %s. Sending to default output."), *OwningSubmixObject->GetName());
				SoundfieldStreams.Reset();
			}
		}
		else
		{
			// If we've arrived here, we couldn't identify the type of the submix we're initializing.
			checkNoEntry();
		}
	}

	void FMixerSubmix::DownmixBuffer(const int32 InChannels, const FAlignedFloatBuffer& InBuffer, const int32 OutChannels, FAlignedFloatBuffer& OutNewBuffer)
	{
		Audio::FAlignedFloatBuffer MixdownGainsMap;
		Audio::FMixerDevice::Get2DChannelMap(false, InChannels, OutChannels, false, MixdownGainsMap);
		Audio::DownmixBuffer(InChannels, OutChannels, InBuffer, OutNewBuffer, MixdownGainsMap.GetData());
	}

	void FMixerSubmix::SetParentSubmix(TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> SubmixWeakPtr)
	{
		if (ParentSubmix == SubmixWeakPtr)
		{
			return;
		}

		TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe> ParentPtr = ParentSubmix.Pin();
		if (ParentPtr.IsValid())
		{
			const uint32 InChildId = GetId();
			ParentPtr->SubmixCommand([this, InChildId, SubmixWeakPtr]()
			{
				AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

				ChildSubmixes.Remove(InChildId);
			});
		}

		SubmixCommand([this, SubmixWeakPtr]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			ParentSubmix = SubmixWeakPtr;
			if (IsSoundfieldSubmix())
			{
				SetupSoundfieldStreamForParent();
			}
		});
	}

	void FMixerSubmix::AddChildSubmix(TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> SubmixWeakPtr)
	{
		SubmixCommand([this, SubmixWeakPtr]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe> SubmixSharedPtr = SubmixWeakPtr.Pin();
			if (SubmixSharedPtr.IsValid())
			{
				FChildSubmixInfo& ChildSubmixInfo = ChildSubmixes.Emplace(SubmixSharedPtr->GetId(), SubmixWeakPtr);

				if (IsSoundfieldSubmix())
				{
					SetupSoundfieldEncodingForChild(ChildSubmixInfo);
				}
			}
		});
	}

	void FMixerSubmix::RemoveChildSubmix(TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> SubmixWeakPtr)
	{
		TSharedPtr<FMixerSubmix, ESPMode::ThreadSafe> SubmixStrongPtr = SubmixWeakPtr.Pin();
		if (!SubmixStrongPtr.IsValid())
		{
			return;
		}

		const uint32 OldIdToRemove = SubmixStrongPtr->GetId();
		SubmixCommand([this, OldIdToRemove]()
		{
			AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

			ChildSubmixes.Remove(OldIdToRemove);
		});
	}

	void FMixerSubmix::RegisterAudioBus(const Audio::FAudioBusKey& InAudioBusKey, Audio::FPatchInput&& InPatchInput)
	{
		check(IsInAudioThread());

		SubmixCommand([this, InAudioBusKey, InPatchInput = MoveTemp(InPatchInput)]()
		{
			if (!AudioBuses.Contains(InAudioBusKey))
			{
				AudioBuses.Emplace(InAudioBusKey, InPatchInput);
			}
		});
	}

	void FMixerSubmix::UnregisterAudioBus(const Audio::FAudioBusKey& InAudioBusKey)
	{
		check(IsInAudioThread());

		SubmixCommand([this, InAudioBusKey]()
		{
			if (AudioBuses.Contains(InAudioBusKey))
			{
				AudioBuses.Remove(InAudioBusKey);
			}
		});
	}

	int32 FMixerSubmix::GetSubmixChannels() const
	{
		return NumChannels;
	}

	TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> FMixerSubmix::GetParentSubmix()
	{
		return ParentSubmix;
	}

	int32 FMixerSubmix::GetNumSourceVoices() const
	{
		return MixerSourceVoices.Num();
	}

	int32 FMixerSubmix::GetNumEffects() const
	{
		return NumSubmixEffects;
	}

	int32 FMixerSubmix::GetSizeOfSubmixChain() const
	{
		// Return the base size
		for (const FSubmixEffectFadeInfo& Info : EffectChains)
		{
			if (Info.bIsCurrentChain)
			{
				return Info.EffectChain.Num();
			}
		}
		return 0;
	}

	void FMixerSubmix::AddOrSetSourceVoice(FMixerSourceVoice* InSourceVoice, const float InSendLevel, EMixerSourceSubmixSendStage InSubmixSendStage)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		FSubmixVoiceData NewVoiceData;
		NewVoiceData.SendLevel = InSendLevel;
		NewVoiceData.SubmixSendStage = InSubmixSendStage;

		MixerSourceVoices.Add(InSourceVoice, NewVoiceData);
	}

	FPatchOutputStrongPtr FMixerSubmix::AddPatch(float InGain)
	{
		if (IsSoundfieldSubmix())
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Patch listening to SoundfieldSubmixes is not supported."));
			return nullptr;
		}

		return PatchSplitter.AddNewPatch(NumSamples, InGain);
	}

	void FMixerSubmix::RemoveSourceVoice(FMixerSourceVoice* InSourceVoice)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);
		
		// If the source has a corresponding ambisonics encoder, close it out.
		uint32 SourceEncoderID = INDEX_NONE;
		const FSubmixVoiceData* MixerSourceVoiceData = MixerSourceVoices.Find(InSourceVoice);

		// If we did find a valid corresponding FSubmixVoiceData, remove it from the map.
		if (MixerSourceVoiceData)
		{
			int32 NumRemoved = MixerSourceVoices.Remove(InSourceVoice);
			AUDIO_MIXER_CHECK(NumRemoved == 1);
		}
	}

	void FMixerSubmix::AddSoundEffectSubmix(FSoundEffectSubmixPtr InSoundEffectSubmix)
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		uint32 SubmixPresetId = InSoundEffectSubmix->GetParentPresetId();

		// Look to see if the submix preset ID is already present
		for (FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			for (FSoundEffectSubmixPtr& Effect : FadeInfo.EffectChain)
			{
				if (Effect.IsValid() && Effect->GetParentPresetId() == SubmixPresetId)
				{
					// Already added.
					return;
				}
			}
		}

		++NumSubmixEffects;
		if (EffectChains.Num() > 0)
		{
			for (FSubmixEffectFadeInfo& FadeInfo : EffectChains)
			{
				if (FadeInfo.bIsCurrentChain)
				{
					FadeInfo.EffectChain.Add(InSoundEffectSubmix);
					return;
				}
			}
		}
		else
		{
			FSubmixEffectFadeInfo& NewSubmixEffectChain = EffectChains.Add_GetRef(FSubmixEffectFadeInfo());
			NewSubmixEffectChain.bIsCurrentChain = true;
			NewSubmixEffectChain.FadeVolume = FDynamicParameter(1.0f);
			NewSubmixEffectChain.EffectChain.Add(InSoundEffectSubmix);
		}
	}

	void FMixerSubmix::RemoveSoundEffectSubmix(uint32 SubmixPresetId)
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		for (FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			for (FSoundEffectSubmixPtr& EffectInstance : FadeInfo.EffectChain)
			{
				if (EffectInstance.IsValid())
				{
					if (EffectInstance->GetParentPresetId() == SubmixPresetId)
					{
						EffectInstance.Reset();
						--NumSubmixEffects;
						return;
					}
				}
			}
		}
	}

	void FMixerSubmix::RemoveSoundEffectSubmixAtIndex(int32 InIndex)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		for (FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			if (FadeInfo.bIsCurrentChain)
			{
				if (InIndex >= 0 && InIndex < FadeInfo.EffectChain.Num())
				{
					FSoundEffectSubmixPtr& EffectInstance = FadeInfo.EffectChain[InIndex];
					if (EffectInstance.IsValid())
					{
						EffectInstance.Reset();
						--NumSubmixEffects;
					}
				}
				return;
			}
		}
	}

	void FMixerSubmix::ClearSoundEffectSubmixes()
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);

		TArray<TSoundEffectSubmixPtr> SubmixEffectsToReset;

		for (FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			for (FSoundEffectSubmixPtr& EffectInstance : FadeInfo.EffectChain)
			{
				if (EffectInstance.IsValid())
				{
					SubmixEffectsToReset.Add(EffectInstance);
				}
			}

			FadeInfo.EffectChain.Reset();
		}

		// Unregister these source effect instances from their owning USoundEffectInstance on the audio thread.
		// Have to pass to Game Thread prior to processing on AudioThread to avoid race condition with GC
		// (RunCommandOnAudioThread is not safe to call from any thread other than the GameThread).
		if (!SubmixEffectsToReset.IsEmpty())
		{
			AsyncTask(ENamedThreads::GameThread, [GTSubmixEffects = MoveTemp(SubmixEffectsToReset)]() mutable
			{
				FAudioThread::RunCommandOnAudioThread([ATSubmixEffects = MoveTemp(GTSubmixEffects)]() mutable
				{
					for (const TSoundEffectSubmixPtr& SubmixPtr : ATSubmixEffects)
					{
						USoundEffectPreset::UnregisterInstance(SubmixPtr);
					}
				});
			});
		}

		NumSubmixEffects = 0;
		EffectChains.Reset();
	}

	void FMixerSubmix::SetSubmixEffectChainOverride(const TArray<FSoundEffectSubmixPtr>& InSubmixEffectPresetChain, float InFadeTimeSec)
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);

		// Set every existing override to NOT be the current override
		for (FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			FadeInfo.bIsCurrentChain = false;
			FadeInfo.FadeVolume.Set(0.0f, InFadeTimeSec);
		}

		FSubmixEffectFadeInfo& NewSubmixEffectChain = EffectChains.Add_GetRef(FSubmixEffectFadeInfo());
		NewSubmixEffectChain.bIsCurrentChain = true;
		NewSubmixEffectChain.FadeVolume = FDynamicParameter(0.0f);
		NewSubmixEffectChain.FadeVolume.Set(1.0f, InFadeTimeSec);
		NewSubmixEffectChain.EffectChain = InSubmixEffectPresetChain; 
	}

	void FMixerSubmix::ClearSubmixEffectChainOverride(float InFadeTimeSec)
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);

		// Set all non-base submix chains to fading out, set the base submix chain to fading in
		for (FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			if (FadeInfo.bIsBaseEffect)
			{
				FadeInfo.bIsCurrentChain = true;
				FadeInfo.FadeVolume.Set(1.0f, InFadeTimeSec);
			}
			else
			{
				FadeInfo.bIsCurrentChain = false;
				FadeInfo.FadeVolume.Set(0.0f, InFadeTimeSec);
			}
		}
	}

	void FMixerSubmix::ReplaceSoundEffectSubmix(int32 InIndex, FSoundEffectSubmixPtr InEffectInstance)
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);

		for (FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			if (FadeInfo.bIsCurrentChain)
			{
				if (FadeInfo.EffectChain.IsValidIndex(InIndex))
				{
					FadeInfo.EffectChain[InIndex] = InEffectInstance;
				}
				break;
			}
		}
	}

	void FMixerSubmix::SetBackgroundMuted(bool bInMuted)
	{
		SubmixCommand([this, bInMuted]()
		{
			bIsBackgroundMuted = bInMuted;
		});
	}

	void FMixerSubmix::MixBufferDownToMono(const FAlignedFloatBuffer& InBuffer, int32 NumInputChannels, FAlignedFloatBuffer& OutBuffer)
	{
		check(NumInputChannels > 0);

		int32 NumFrames = InBuffer.Num() / NumInputChannels;
		OutBuffer.Reset();
		OutBuffer.AddZeroed(NumFrames);

		const float* InData = InBuffer.GetData();
		float* OutData = OutBuffer.GetData();

		const float GainFactor = 1.0f / FMath::Sqrt((float) NumInputChannels);

		for (int32 FrameIndex = 0; FrameIndex < NumFrames; FrameIndex++)
		{
			for (int32 ChannelIndex = 0; ChannelIndex < NumInputChannels; ChannelIndex++)
			{
				const int32 InputIndex = FrameIndex * NumInputChannels + ChannelIndex;
				OutData[FrameIndex] += InData[InputIndex] * GainFactor;
			}
		}
	}

	void FMixerSubmix::SetupSoundfieldEncodersForChildren()
	{
		check(SoundfieldStreams.Factory);
		check(SoundfieldStreams.Settings.IsValid());

		//Here we scan all child submixes to see which submixes need to be reencoded.
		for (auto& Iter : ChildSubmixes)
		{
			FChildSubmixInfo& ChildSubmix = Iter.Value;
			SetupSoundfieldEncodingForChild(ChildSubmix);
		}
	}

	void FMixerSubmix::SetupSoundfieldEncodingForChild(FChildSubmixInfo& InChild)
	{
		TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe> SubmixPtr = InChild.SubmixPtr.Pin();

		if (SubmixPtr.IsValid())
		{
			check(SoundfieldStreams.Factory && SoundfieldStreams.Settings.IsValid());

			// If this child submix is not a soundfield submix and we need to encode every child submix independently, set up an encoder.
			if (!SubmixPtr->IsSoundfieldSubmix() && SoundfieldStreams.Factory->ShouldEncodeAllStreamsIndependently(*SoundfieldStreams.Settings))
			{
				FAudioPluginInitializationParams InitParams = GetInitializationParamsForSoundfieldStream();
				InChild.Encoder = SoundfieldStreams.Factory->CreateEncoderStream(InitParams, *SoundfieldStreams.Settings);
			}
			else if(SubmixPtr->IsSoundfieldSubmix())
			{
				// If the child submix is of a soundfield format that needs to be transcoded, set up a transcoder.
				InChild.Transcoder = GetTranscoderForChildSubmix(SubmixPtr);
			}

			// see if we need to initialize our child submix encoder
			const bool bNeedsDownmixedChildEncoder = !SoundfieldStreams.DownmixedChildrenEncoder.IsValid();
			const bool bUsingUniqueEncoderForEachChildSubmix = !SoundfieldStreams.Factory->ShouldEncodeAllStreamsIndependently(*SoundfieldStreams.Settings);

			if (bNeedsDownmixedChildEncoder && bUsingUniqueEncoderForEachChildSubmix)
			{
				FAudioPluginInitializationParams InitParams = GetInitializationParamsForSoundfieldStream();
				SoundfieldStreams.DownmixedChildrenEncoder = SoundfieldStreams.Factory->CreateEncoderStream(InitParams, *SoundfieldStreams.Settings);
			}

			// If neither of these are true, either we are downmixing all child audio and encoding it once, or
			// this submix can handle the child's soundfield audio packet directly, so no encoder nor transcoder is needed.
		}
	}

	void FMixerSubmix::SetupSoundfieldStreamForParent()
	{
		TSharedPtr<FMixerSubmix, ESPMode::ThreadSafe> ParentSubmixSharedPtr = ParentSubmix.Pin();

		if (ParentSubmixSharedPtr.IsValid() && !ParentSubmixSharedPtr->IsSoundfieldSubmix())
		{
			// If the submix we're plugged into isn't a soundfield submix, we need to decode our soundfield for it.
			SetUpSoundfieldPositionalData(ParentSubmixSharedPtr);

			FAudioPluginInitializationParams InitParams = GetInitializationParamsForSoundfieldStream();
			SoundfieldStreams.ParentDecoder = SoundfieldStreams.Factory->CreateDecoderStream(InitParams, *SoundfieldStreams.Settings);
		}
	}

	void FMixerSubmix::SetUpSoundfieldPositionalData(const TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe>& InParentSubmix)
	{
		// If there is a parent and we are not passing it this submix's ambisonics audio, retrieve that submix's channel format.
		check(InParentSubmix.IsValid());

		const int32 NumParentChannels = InParentSubmix->GetSubmixChannels();
		SoundfieldStreams.CachedPositionalData.NumChannels = NumParentChannels;
		SoundfieldStreams.CachedPositionalData.ChannelPositions = MixerDevice->GetDefaultPositionMap(NumParentChannels);
		
		// For now we don't actually do any sort of rotation for decoded audio.
		SoundfieldStreams.CachedPositionalData.Rotation = FQuat::Identity;
	}

	void FMixerSubmix::MixInSource(const ISoundfieldAudioPacket& InAudio, const ISoundfieldEncodingSettingsProxy& InSettings, ISoundfieldAudioPacket& PacketToSumTo)
	{
		check(SoundfieldStreams.Mixer.IsValid());

		FSoundfieldMixerInputData InputData =
		{
			InAudio, // InputPacket
			InSettings, // EncodingSettings
			1.0f // SendLevel
		};

		SoundfieldStreams.Mixer->MixTogether(InputData, PacketToSumTo);
	}

	void FMixerSubmix::UpdateListenerRotation(const FQuat& InRotation)
	{
		SoundfieldStreams.CachedPositionalData.Rotation = InRotation;
	}

	void FMixerSubmix::MixInChildSubmix(FChildSubmixInfo& Child, ISoundfieldAudioPacket& PacketToSumTo)
	{
		check(IsSoundfieldSubmix());

		// We only either encode, transcode input, and never both. If we have both for this child, something went wrong in initialization.
		check(!(Child.Encoder.IsValid() && Child.Transcoder.IsValid()));

		TSharedPtr<FMixerSubmix, ESPMode::ThreadSafe> ChildSubmixSharedPtr = Child.SubmixPtr.Pin();
		if (ChildSubmixSharedPtr.IsValid())
		{
			if (!ChildSubmixSharedPtr->IsSoundfieldSubmix())
			{
				// Reset the output scratch buffer so that we can call ProcessAudio on the ChildSubmix with it:
				ScratchBuffer.Reset(ChildSubmixSharedPtr->NumSamples);
				ScratchBuffer.AddZeroed(ChildSubmixSharedPtr->NumSamples);
				

				// If this is true, the Soundfield Factory explicitly requested that a seperate encoder stream was set up for every
				// non-soundfield child submix.
				if (Child.Encoder.IsValid())
				{
					ChildSubmixSharedPtr->ProcessAudio(ScratchBuffer);

					// Encode the resulting audio and mix it in.
					FSoundfieldEncoderInputData InputData = {
						ScratchBuffer, /* AudioBuffer */
						ChildSubmixSharedPtr->NumChannels, /* NumChannels */
						*SoundfieldStreams.Settings, /** InputSettings */
						SoundfieldStreams.CachedPositionalData /** PosititonalData */
					};

					Child.Encoder->EncodeAndMixIn(InputData, PacketToSumTo);
				}
				else
				{
					// Otherwise, process and mix in the submix's audio to the scratch buffer, and we will encode ScratchBuffer later.
					ChildSubmixSharedPtr->ProcessAudio(ScratchBuffer);
				}
			}
			else if (Child.Transcoder.IsValid())
			{
				// Make sure our packet that we call process on is zeroed out:
				if (!Child.IncomingPacketToTranscode.IsValid())
				{
					Child.IncomingPacketToTranscode = ChildSubmixSharedPtr->SoundfieldStreams.Factory->CreateEmptyPacket();
				}
				else
				{
					Child.IncomingPacketToTranscode->Reset();
				}

				check(Child.IncomingPacketToTranscode.IsValid());

				ChildSubmixSharedPtr->ProcessAudio(*Child.IncomingPacketToTranscode);

				Child.Transcoder->TranscodeAndMixIn(*Child.IncomingPacketToTranscode, ChildSubmixSharedPtr->GetSoundfieldSettings(), PacketToSumTo, *SoundfieldStreams.Settings);
			}
			else
			{
				// No conversion necessary.
				ChildSubmixSharedPtr->ProcessAudio(PacketToSumTo);
			}

			//Propogate listener rotation down to this submix.
			// This is required if this submix doesn't have any sources sending to it, but does have at least one child submix.
			UpdateListenerRotation(ChildSubmixSharedPtr->SoundfieldStreams.CachedPositionalData.Rotation);
		}
	}

	bool FMixerSubmix::IsSoundfieldSubmix() const
	{
		return SoundfieldStreams.Factory != nullptr;
	}

	bool FMixerSubmix::IsDefaultEndpointSubmix() const
	{
		return !ParentSubmix.IsValid() && !(EndpointData.SoundfieldEndpoint.IsValid() || EndpointData.NonSoundfieldEndpoint.IsValid());
	}

	bool FMixerSubmix::IsExternalEndpointSubmix() const
	{
		return !ParentSubmix.IsValid() && (EndpointData.SoundfieldEndpoint.IsValid() || EndpointData.NonSoundfieldEndpoint.IsValid());
	}

	bool FMixerSubmix::IsSoundfieldEndpointSubmix() const
	{
		return !ParentSubmix.IsValid() && IsSoundfieldSubmix();
	}

	bool FMixerSubmix::IsDummyEndpointSubmix() const
	{
		if (EndpointData.NonSoundfieldEndpoint.IsValid())
		{
			return !EndpointData.NonSoundfieldEndpoint->IsImplemented();
		}
		else
		{
			return false;
		}
	}

	FName FMixerSubmix::GetSoundfieldFormat() const
	{
		if (IsSoundfieldSubmix())
		{
			return SoundfieldStreams.Factory->GetSoundfieldFormatName();
		}
		else
		{
			return ISoundfieldFactory::GetFormatNameForNoEncoding();
		}
	}

	ISoundfieldEncodingSettingsProxy& FMixerSubmix::GetSoundfieldSettings()
	{
		check(IsSoundfieldSubmix());
		check(SoundfieldStreams.Settings.IsValid());

		return *SoundfieldStreams.Settings;
	}

	FAudioPluginInitializationParams FMixerSubmix::GetInitializationParamsForSoundfieldStream()
	{
		FAudioPluginInitializationParams InitializationParams;
		InitializationParams.AudioDevicePtr = MixerDevice;
		InitializationParams.BufferLength = MixerDevice ? MixerDevice->GetNumOutputFrames() : 0;
		InitializationParams.NumOutputChannels = MixerDevice ? MixerDevice->GetNumDeviceChannels() : 0;
		InitializationParams.SampleRate = MixerDevice ? MixerDevice->SampleRate : 0.0f;

		// We only use one soundfield stream per source.
		InitializationParams.NumSources = 1;

		return InitializationParams;
	}

	FSoundfieldSpeakerPositionalData FMixerSubmix::GetDefaultPositionalDataForAudioDevice()
	{
		FSoundfieldSpeakerPositionalData PositionalData;
		PositionalData.NumChannels = MixerDevice->GetNumDeviceChannels();
		PositionalData.ChannelPositions = MixerDevice->GetDefaultPositionMap(PositionalData.NumChannels);

		// For now we don't actually do any sort of rotation for decoded audio.
		PositionalData.Rotation = FQuat::Identity;

		return PositionalData;
	}

	TUniquePtr<ISoundfieldTranscodeStream> FMixerSubmix::GetTranscoderForChildSubmix(const TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe>& InChildSubmix)
	{
		check(InChildSubmix.IsValid());
		check(IsSoundfieldSubmix() && InChildSubmix->IsSoundfieldSubmix());
		check(SoundfieldStreams.Settings.IsValid() && InChildSubmix->SoundfieldStreams.Settings.IsValid());

		if (GetSoundfieldFormat() != InChildSubmix->GetSoundfieldFormat())
		{
			ISoundfieldFactory* ChildFactory = InChildSubmix->GetSoundfieldFactory();

			if (SoundfieldStreams.Factory->CanTranscodeFromSoundfieldFormat(InChildSubmix->GetSoundfieldFormat(), *InChildSubmix->SoundfieldStreams.Settings))
			{
				FAudioPluginInitializationParams InitParams = GetInitializationParamsForSoundfieldStream();
				return SoundfieldStreams.Factory->CreateTranscoderStream(InChildSubmix->GetSoundfieldFormat(), InChildSubmix->GetSoundfieldSettings(), SoundfieldStreams.Factory->GetSoundfieldFormatName(), GetSoundfieldSettings(), InitParams);
			}
			else if (ChildFactory->CanTranscodeToSoundfieldFormat(GetSoundfieldFormat(), GetSoundfieldSettings()))
			{
				FAudioPluginInitializationParams InitParams = GetInitializationParamsForSoundfieldStream();
				return ChildFactory->CreateTranscoderStream(InChildSubmix->GetSoundfieldFormat(), InChildSubmix->GetSoundfieldSettings(), SoundfieldStreams.Factory->GetSoundfieldFormatName(), GetSoundfieldSettings(), InitParams);
			}
			else
			{
				return nullptr;
			}
		}
		else
		{
			if (SoundfieldStreams.Factory->IsTranscodeRequiredBetweenSettings(*InChildSubmix->SoundfieldStreams.Settings, *SoundfieldStreams.Settings))
			{
				FAudioPluginInitializationParams InitParams = GetInitializationParamsForSoundfieldStream();
				return SoundfieldStreams.Factory->CreateTranscoderStream(InChildSubmix->GetSoundfieldFormat(), InChildSubmix->GetSoundfieldSettings(), SoundfieldStreams.Factory->GetSoundfieldFormatName(), GetSoundfieldSettings(), InitParams);
			}
			else
			{
				return nullptr;
			}
		}
	}

	void FMixerSubmix::PumpCommandQueue()
	{
		TFunction<void()> Command;
		while (CommandQueue.Dequeue(Command))
		{
			Command();
		}
	}

	void FMixerSubmix::SubmixCommand(TFunction<void()> Command)
	{
		CommandQueue.Enqueue(MoveTemp(Command));
	}

	bool FMixerSubmix::IsValid() const
	{
		return OwningSubmixObject.IsValid();
	}

	bool FMixerSubmix::IsRenderingAudio() const
	{
		// If we're told to not auto-disable we act as if we're always rendering audio
		if (!bAutoDisable)
		{
			return true;
		}
		
		{
			// query the SubmixBufferListeners to see if they plan to render audio into this buffer
			FScopeLock Lock(&BufferListenerCriticalSection);
			for (const TWeakPtr<ISubmixBufferListener>& BufferListenerWeakPtr : BufferListenerPtrs)	
			{
				if (TSharedPtr<ISubmixBufferListener> BufferListener = BufferListenerWeakPtr.Pin())
				{
					if (BufferListener->IsRenderingAudio())
					{
						return true;
					}
				}
			}
		}

		// Query Modulation; if any of the submix's Modulation Destinations are being modulated they need to be processed,
		// because binaural sources still use these Destinations when the submix is set
		{
			if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
			{
				if (DryLevelMod.IsActive() || VolumeMod.IsActive())
				{
					return true;
				}
			}
		}

		// If this submix is not rendering any sources directly and silence has been detected, we need to check it's children submixes
		if (MixerSourceVoices.Num() == 0 && SilenceTimeStartSeconds >= 0.0)
		{
			// Use the audio clock to check against the disablement timeout
			double AudioClock = MixerDevice->GetAudioClock();
			double TimeSinceSilent = AudioClock - SilenceTimeStartSeconds;

			// If we're past the threshold for disablement, do one last check of any child submixes. Maybe they are now rendering audio.
			if (TimeSinceSilent > AutoDisableTime)
			{
				for (auto& ChildSubmixEntry : ChildSubmixes)
				{
					TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe> ChildSubmix = ChildSubmixEntry.Value.SubmixPtr.Pin();

					// If any of the submix's children are rendering audio then this submix is also rendering audio
					if (ChildSubmix && ChildSubmix->IsRenderingAudio())
					{
						return true;
					}
				}

				// We're past the auto-disablement threshold and no child submixes are rendering audio, we're now silent
				return false;
			}
		}
		return true;
	}

	void FMixerSubmix::SetAutoDisable(bool bInAutoDisable)
	{
		bAutoDisable = bInAutoDisable;
	}

	void FMixerSubmix::SetAutoDisableTime(float InAutoDisableTime)
	{
		AutoDisableTime = InAutoDisableTime;
	}

	void FMixerSubmix::ProcessAudio(FAlignedFloatBuffer& OutAudioBuffer)
	{
		AUDIO_MIXER_CHECK_AUDIO_PLAT_THREAD(MixerDevice);

		// Handle channel count change.
		if (NumChannels != MixerDevice->GetNumDeviceChannels())
		{
			// Device format may change channels if device is hot swapped
			NumChannels = MixerDevice->GetNumDeviceChannels();

			if (IsSoundfieldSubmix())
			{
				// Update decoder to match parent stream format.
				SetupSoundfieldStreamForParent();
			}
		}

		// If we hit this, it means that platform info gave us an invalid NumChannel count.
		if (!ensure(NumChannels != 0 && NumChannels <= AUDIO_MIXER_MAX_OUTPUT_CHANNELS))
		{
			return;
		}


		// If this is a Soundfield Submix, process our soundfield and decode it to a OutAudioBuffer.
		if (IsSoundfieldSubmix())
		{
			FScopeLock ScopeLock(&SoundfieldStreams.StreamsLock);

			// Initialize or clear the mixed down audio packet.
			if (!SoundfieldStreams.MixedDownAudio.IsValid())
			{
				SoundfieldStreams.MixedDownAudio = SoundfieldStreams.Factory->CreateEmptyPacket();
			}
			else
			{
				SoundfieldStreams.MixedDownAudio->Reset();
			}

			check(SoundfieldStreams.MixedDownAudio.IsValid());

			ProcessAudio(*SoundfieldStreams.MixedDownAudio);

			if (!SoundfieldStreams.ParentDecoder.IsValid())
			{
				return;
			}

			//Decode soundfield to interleaved float audio.
			FSoundfieldDecoderInputData DecoderInput =
			{
				*SoundfieldStreams.MixedDownAudio, /* SoundfieldBuffer */
				SoundfieldStreams.CachedPositionalData, /* PositionalData */
				MixerDevice ? MixerDevice->GetNumOutputFrames() : 0, /* NumFrames */
				MixerDevice ? MixerDevice->GetSampleRate() : 0.0f /* SampleRate */
			};

			FSoundfieldDecoderOutputData DecoderOutput = { OutAudioBuffer };

			SoundfieldStreams.ParentDecoder->DecodeAndMixIn(DecoderInput, DecoderOutput);
			return;
		}
		else
		{
			// Pump pending command queues. For Soundfield Submixes this occurs in ProcessAudio(ISoundfieldAudioPacket&).
			PumpCommandQueue();
		}
	
		const int32 NumOutputFrames = OutAudioBuffer.Num() / NumChannels;
		NumSamples = NumChannels * NumOutputFrames;

 		InputBuffer.Reset(NumSamples);
 		InputBuffer.AddZeroed(NumSamples);

		float* BufferPtr = InputBuffer.GetData();

		// As an optimization, early out if we're set to auto-disable and we're not rendering audio
		if (bAutoDisable && !IsRenderingAudio())
		{
			if (!bIsCurrentlyDisabled)
			{
				bIsCurrentlyDisabled = true;

				UE_CLOG(LogSubmixEnablementCVar == 1, LogAudioMixer, Display,
					TEXT("Submix Disabled. Num Sources: %d, Time Silent: %.2f, Disablement Threshold: %.2f, Submix Name: %s"), 
					MixerSourceVoices.Num(),
					(float)(MixerDevice->GetAudioClock() - SilenceTimeStartSeconds),
					AutoDisableTime,
					*SubmixName);
			}

			// Even though we're silent, broadcast the buffer to any listeners (will be a silent buffer)
			SendAudioToSubmixBufferListeners(InputBuffer);
			SendAudioToRegisteredAudioBuses(InputBuffer);
			return;
		}

		if (bIsCurrentlyDisabled)
		{
			bIsCurrentlyDisabled = false;
			UE_CLOG(LogSubmixEnablementCVar == 1, LogAudioMixer, Display, TEXT("Submix Re-Enabled: %s"), *SubmixName);
		}

		// Mix all submix audio into this submix's input scratch buffer
		{
			CSV_SCOPED_TIMING_STAT(Audio, SubmixChildren);
			CONDITIONAL_SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixChildren, (ChildSubmixes.Num() > 0));

			// First loop this submix's child submixes mixing in their output into this submix's dry/wet buffers.
			TArray<uint32> ToRemove;
			for (auto& ChildSubmixEntry : ChildSubmixes)
			{
				TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe> ChildSubmix = ChildSubmixEntry.Value.SubmixPtr.Pin();

				// Owning submix can become invalid prior to BeginDestroy being called if object is
				// forcibly deleted in editor, so submix validity (in addition to pointer validity) is checked before processing
				if (ChildSubmix.IsValid() && ChildSubmix->IsValid())
				{
					if (ChildSubmix->IsRenderingAudio())
					{
						ChildSubmix->ProcessAudio(InputBuffer);

						// Check the buffer after processing to catch any bad values.
						AUDIO_CHECK_BUFFER_NAMED_MSG(InputBuffer, TEXT("Submix Chidren"), TEXT("Submix: %s"), *ChildSubmix->GetName());
					}
				}
				else
				{
					ToRemove.Add(ChildSubmixEntry.Key);
				}
			}

			for (uint32 Key : ToRemove)
			{
				ChildSubmixes.Remove(Key);
			}
		}

		{
			CSV_SCOPED_TIMING_STAT(Audio, SubmixSource);
			CONDITIONAL_SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixSource, (MixerSourceVoices.Num() > 0));

			// Loop through this submix's sound sources
			for (const auto& MixerSourceVoiceIter : MixerSourceVoices)
			{
				const FMixerSourceVoice* MixerSourceVoice = MixerSourceVoiceIter.Key;
				const float SendLevel = MixerSourceVoiceIter.Value.SendLevel;
				const EMixerSourceSubmixSendStage SubmixSendStage = MixerSourceVoiceIter.Value.SubmixSendStage;

				MixerSourceVoice->MixOutputBuffers(NumChannels, SendLevel, SubmixSendStage, InputBuffer);
				
				// Check the buffer after each voice mix to catch any bad values.
				AUDIO_CHECK_BUFFER_NAMED_MSG(InputBuffer, TEXT("Submix SourceMix"), TEXT("Submix: %s"), *GetName());
			}
		}

		DryChannelBuffer.Reset();

		// Update Dry Level using modulator
		if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
		{
			DryLevelMod.ProcessControl(DryModBaseDb);
			TargetDryLevel = DryLevelMod.GetValue();
		}
		else
		{
			TargetDryLevel = Audio::ConvertToLinear(DryModBaseDb);
		}

		TargetDryLevel *= DryLevelModifier;

		// Check if we need to allocate a dry buffer. This is stored here before effects processing. We mix in with wet buffer after effects processing.
		if (!FMath::IsNearlyEqual(TargetDryLevel, CurrentDryLevel) || !FMath::IsNearlyZero(CurrentDryLevel))
		{
			DryChannelBuffer.Append(InputBuffer);
		}

		{
			FScopeLock ScopeLock(&EffectChainMutationCriticalSection);

			if (!BypassAllSubmixEffectsCVar && EffectChains.Num() > 0)
			{		
				CSV_SCOPED_TIMING_STAT(Audio, SubmixEffectProcessing);
				SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixEffectProcessing);

				float SampleRate = MixerDevice->GetSampleRate();
				check(SampleRate > 0.0f);
				float DeltaTimeSec = NumOutputFrames / SampleRate;

				// Setup the input data buffer
				FSoundEffectSubmixInputData InputData;
				InputData.AudioClock = MixerDevice->GetAudioTime();

				// Compute the number of frames of audio. This will be independent of if we downmix our wet buffer.
				InputData.NumFrames = NumSamples / NumChannels;
				InputData.NumChannels = NumChannels;
				InputData.NumDeviceChannels = MixerDevice->GetNumDeviceChannels();
				InputData.ListenerTransforms = MixerDevice->GetListenerTransforms();
				InputData.AudioClock = MixerDevice->GetAudioClock();

				bool bProcessedAnEffect = false;

				// Zero and resize buffer holding mix of current effect chains
				SubmixChainMixBuffer.Reset(NumSamples);
				SubmixChainMixBuffer.SetNumZeroed(NumSamples);

				for (int32 EffectChainIndex = EffectChains.Num() - 1; EffectChainIndex >= 0; --EffectChainIndex)
				{
					FSubmixEffectFadeInfo& FadeInfo = EffectChains[EffectChainIndex];

					if (!FadeInfo.EffectChain.Num())
					{
						continue;
					}

					// If we're not the current chain and we've finished fading out, lets remove it from the effect chains
					if (!FadeInfo.bIsCurrentChain && FadeInfo.FadeVolume.IsDone())
					{
						// only remove effect chain if it's not the base effect chain
						if (!FadeInfo.bIsBaseEffect)
						{
							EffectChains.RemoveAtSwap(EffectChainIndex, EAllowShrinking::Yes);
						}
						continue;
					}

					// Prepare the scratch buffer for effect chain processing
					EffectChainOutputBuffer.Reset();
					EffectChainOutputBuffer.AddZeroed(NumSamples);

					const bool bResult = GenerateEffectChainAudio(InputData, InputBuffer, FadeInfo.EffectChain, EffectChainOutputBuffer);
					bProcessedAnEffect |= bResult;
					const FAlignedFloatBuffer* OutBuffer = bResult ? &EffectChainOutputBuffer : &InputBuffer;

					// Mix effect chain output into SubmixChainMixBuffer
					float StartFadeVolume = FadeInfo.FadeVolume.GetValue();
					FadeInfo.FadeVolume.Update(DeltaTimeSec);
					float EndFadeVolume = FadeInfo.FadeVolume.GetValue();

					// Mix this effect chain with other effect chains.
					ArrayMixIn(*OutBuffer, SubmixChainMixBuffer, StartFadeVolume, EndFadeVolume);
				}

				// If we processed any effects, write over the old input buffer vs mixing into it. This is basically the "wet channel" audio in a submix.
				if (bProcessedAnEffect)
				{
					FMemory::Memcpy((void*)BufferPtr, (void*)SubmixChainMixBuffer.GetData(), sizeof(float)* NumSamples);
				}

				// Update Wet Level using modulator
				if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
				{
					WetLevelMod.ProcessControl(WetModBaseDb);
					TargetWetLevel = WetLevelMod.GetValue();
				}
				else
				{
					TargetWetLevel = Audio::ConvertToLinear(WetModBaseDb);
				}

				TargetWetLevel *= WetLevelModifier;

				// Apply the wet level here after processing effects. 
				if (!FMath::IsNearlyEqual(TargetWetLevel, CurrentWetLevel) || !FMath::IsNearlyEqual(CurrentWetLevel, 1.0f))
				{
					if (FMath::IsNearlyEqual(TargetWetLevel, CurrentWetLevel))
					{
						ArrayMultiplyByConstantInPlace(InputBuffer, TargetWetLevel);
					}
					else
					{
						ArrayFade(InputBuffer, CurrentWetLevel, TargetWetLevel);
						CurrentWetLevel = TargetWetLevel;
					}
				}
			}
		}

		// Mix in the dry channel buffer
		if (DryChannelBuffer.Num() > 0)
		{
			// If we've already set the volume, only need to multiply by constant
			if (FMath::IsNearlyEqual(TargetDryLevel, CurrentDryLevel))
			{
				ArrayMultiplyByConstantInPlace(DryChannelBuffer, TargetDryLevel);
			}
			else
			{
				// To avoid popping, we do a fade on the buffer to the target volume
				ArrayFade(DryChannelBuffer, CurrentDryLevel, TargetDryLevel);
				CurrentDryLevel = TargetDryLevel;
			}
			ArrayMixIn(DryChannelBuffer, InputBuffer);
		}

		// If we're muted, memzero the buffer. Note we are still doing all the work to maintain buffer state between mutings.
		if (bIsBackgroundMuted)
		{
			FMemory::Memzero((void*)BufferPtr, sizeof(float) * NumSamples);
		}
	
		// If we are recording, Add out buffer to the RecordingData buffer:
		{
			FScopeLock ScopedLock(&RecordingCriticalSection);
			if (bIsRecording)
			{
				// TODO: Consider a scope lock between here and OnStopRecordingOutput.
				RecordingData.Append((float*)BufferPtr, NumSamples);
			}
		}

		// If spectrum analysis is enabled for this submix, downmix the resulting audio
		// and push it to the spectrum analyzer.
		{
			FScopeTryLock TryLock(&SpectrumAnalyzerCriticalSection);

			if (TryLock.IsLocked() && SpectrumAnalyzer.IsValid())
			{
				MixBufferDownToMono(InputBuffer, NumChannels, MonoMixBuffer);
				SpectrumAnalyzer->PushAudio(MonoMixBuffer.GetData(), MonoMixBuffer.Num());
				SpectrumAnalyzer->PerformAsyncAnalysisIfPossible(true);
			}
		}

		// Perform any envelope following if we're told to do so
		if (bIsEnvelopeFollowing)
		{
			const int32 BufferSamples = InputBuffer.Num();
			const float* AudioBufferPtr = InputBuffer.GetData();

			// Perform envelope following per channel
			FScopeLock EnvelopeScopeLock(&EnvelopeCriticalSection);
			FMemory::Memset(EnvelopeValues, sizeof(float) * AUDIO_MIXER_MAX_OUTPUT_CHANNELS);

			if (NumChannels > 0)
			{
				const int32 NumFrames = BufferSamples / NumChannels;
				if (EnvelopeFollower.GetNumChannels() != NumChannels)
				{
					EnvelopeFollower.SetNumChannels(NumChannels);
				}

				EnvelopeFollower.ProcessAudio(AudioBufferPtr, NumFrames);
				const TArray<float>& EnvValues = EnvelopeFollower.GetEnvelopeValues();

				check(EnvValues.Num() == NumChannels);

				FMemory::Memcpy(EnvelopeValues, EnvValues.GetData(), sizeof(float) * NumChannels);
				Audio::ArrayClampInPlace(MakeArrayView(EnvelopeValues, NumChannels), 0.f, 1.f);
			}

			EnvelopeNumChannels = NumChannels;
		}

		// Update output volume using modulator
		if (MixerDevice->IsModulationPluginEnabled() && MixerDevice->ModulationInterface.IsValid())
		{
			VolumeMod.ProcessControl(VolumeModBaseDb);
			TargetOutputVolume = VolumeMod.GetValue();
		}
		else
		{
			TargetOutputVolume = Audio::ConvertToLinear(VolumeModBaseDb);
		}

		TargetOutputVolume *= VolumeModifier;

		// Now apply the output volume
		if (!FMath::IsNearlyEqual(TargetOutputVolume, CurrentOutputVolume) || !FMath::IsNearlyEqual(CurrentOutputVolume, 1.0f))
		{
			// If we've already set the output volume, only need to multiply by constant
			if (FMath::IsNearlyEqual(TargetOutputVolume, CurrentOutputVolume))
			{
				Audio::ArrayMultiplyByConstantInPlace(InputBuffer, TargetOutputVolume);
			}
			else
			{
				// To avoid popping, we do a fade on the buffer to the target volume
				Audio::ArrayFade(InputBuffer, CurrentOutputVolume, TargetOutputVolume);
				CurrentOutputVolume = TargetOutputVolume;
			}
		}

		SendAudioToSubmixBufferListeners(InputBuffer);
		SendAudioToRegisteredAudioBuses(InputBuffer);

		// Mix the audio buffer of this submix with the audio buffer of the output buffer (i.e. with other submixes)
		Audio::ArrayMixIn(InputBuffer, OutAudioBuffer);

		// Once we've finished rendering submix audio, check if the output buffer is silent if we are auto-disabling
		if (bAutoDisable)
		{
			// Extremely cheap silent buffer detection: as soon as we hit a sample which isn't silent, we flag we're not silent
			bool bIsNowSilent = true;
			int i = 0;
#if PLATFORM_ENABLE_VECTORINTRINSICS
			int SimdNum = OutAudioBuffer.Num() & 0xFFFFFFF0;
			for (; i < SimdNum; i += 16)
			{
				VectorRegister4x4Float Samples = VectorLoad16(&OutAudioBuffer[i]);
				if (   VectorAnyGreaterThan(VectorAbs(Samples.val[0]), GlobalVectorConstants::SmallNumber)
					|| VectorAnyGreaterThan(VectorAbs(Samples.val[1]), GlobalVectorConstants::SmallNumber)
					|| VectorAnyGreaterThan(VectorAbs(Samples.val[2]), GlobalVectorConstants::SmallNumber)
					|| VectorAnyGreaterThan(VectorAbs(Samples.val[3]), GlobalVectorConstants::SmallNumber))
				{
					bIsNowSilent = false;
					i = INT_MAX;
					break;
				}
			}
#endif

			// Finish to the end of the buffer or check each sample if vector intrinsics are disabled
			for (; i < OutAudioBuffer.Num(); ++i)
			{
				// As soon as we hit a non-silent sample, we're not silent
				if (FMath::Abs(OutAudioBuffer[i]) > SMALL_NUMBER)
				{
					bIsNowSilent = false;
					break;
				}
			}

			// If this is the first time we're silent track when it happens
			if (bIsNowSilent && !bIsSilent)
			{
				bIsSilent = true;
				SilenceTimeStartSeconds = MixerDevice->GetAudioClock();
			}
			else
			{
				bIsSilent = false;
				SilenceTimeStartSeconds = -1.0;
			}
		}

	}

	void FMixerSubmix::SendAudioToSubmixBufferListeners(FAlignedFloatBuffer& OutAudioBuffer)
	{
		// Now loop through any buffer listeners and feed the listeners the result of this audio callback
		if (const USoundSubmix* SoundSubmix = Cast<const USoundSubmix>(OwningSubmixObject))
		{
			CSV_SCOPED_TIMING_STAT(Audio, SubmixBufferListeners);
			SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixBufferListeners);

			double AudioClock = MixerDevice->GetAudioTime();
			float SampleRate = MixerDevice->GetSampleRate();
			
			FScopeLock Lock(&BufferListenerCriticalSection);
			for (TWeakPtr<ISubmixBufferListener, ESPMode::ThreadSafe>& BufferListenerWeakPtr : BufferListenerPtrs)
			{
				if (TSharedPtr<ISubmixBufferListener> BufferListener = BufferListenerWeakPtr.Pin())
				{
					BufferListener->OnNewSubmixBuffer(SoundSubmix, OutAudioBuffer.GetData(), OutAudioBuffer.Num(), NumChannels, SampleRate, AudioClock);
				}
			}

			PatchSplitter.PushAudio(OutAudioBuffer.GetData(), OutAudioBuffer.Num());
			PruneSubmixBufferListeners();
		}
	}

	void FMixerSubmix::SendAudioToRegisteredAudioBuses(FAlignedFloatBuffer& OutAudioBuffer)
	{
		TRACE_CPUPROFILER_EVENT_SCOPE(FMixerSubmix::SendAudioToRegisteredAudioBuses);

		for (auto& [AudioBusKey, PatchInput] : AudioBuses)
		{
			PatchInput.PushAudio(OutAudioBuffer.GetData(), OutAudioBuffer.Num());
		}
	}

	void FMixerSubmix::UnregisterBufferListenerInternal(UPTRINT ListenerBufferPtr) 
	{
		FScopeLock Lock(&BufferListenerCriticalSection);
		BufferListenerPtrs.RemoveAll(
			[=](const TWeakPtr<ISubmixBufferListener>& Listener)
			{
				Listener.GetWeakPtrTypeHash();
				return reinterpret_cast<UPTRINT>(Listener.Pin().Get()) == ListenerBufferPtr;
			});
	}

	void FMixerSubmix::PruneSubmixBufferListeners()
	{
		FScopeLock Lock(&BufferListenerCriticalSection);
		BufferListenerPtrs.RemoveAll(
			[](const TWeakPtr<ISubmixBufferListener>& Listener)
			{
				return !Listener.IsValid();
			});
	}

	bool FMixerSubmix::GenerateEffectChainAudio(FSoundEffectSubmixInputData& InputData, const FAlignedFloatBuffer& InAudioBuffer, TArray<FSoundEffectSubmixPtr>& InEffectChain, FAlignedFloatBuffer& OutBuffer)
	{
		checkf(InAudioBuffer.Num() == OutBuffer.Num(), TEXT("Processing effect chain audio must not alter the number of samples in a buffer. Buffer size mismatch InAudioBuffer[%d] != OutBuffer[%d]"), InAudioBuffer.Num(), OutBuffer.Num());

		// Use the scratch buffer to hold the wet audio. For the first effect in the effect chain, this is the InAudioBuffer. 
		ScratchBuffer = InAudioBuffer;

		FSoundEffectSubmixOutputData OutputData;
		OutputData.AudioBuffer = &OutBuffer;
		OutputData.NumChannels = NumChannels;

		const int32 NumOutputFrames = OutBuffer.Num() / NumChannels;
		bool bProcessedAnEffect = false;

		for (FSoundEffectSubmixPtr& SubmixEffect : InEffectChain)
		{
			// SubmixEffectInfo.EffectInstance will be null if FMixerSubmix::RemoveSoundEffectSubmix was called earlier.
			if (!SubmixEffect.IsValid())
			{
				continue;
			}

			// Check to see if we need to down-mix our audio before sending to the submix effect
			const uint32 ChannelCountOverride = SubmixEffect->GetDesiredInputChannelCountOverride();
			if (ChannelCountOverride != INDEX_NONE && ChannelCountOverride != NumChannels)
			{
				// Perform the down-mix operation with the down-mixed scratch buffer
				DownmixedBuffer.SetNumUninitialized(NumOutputFrames * ChannelCountOverride);
				DownmixBuffer(NumChannels, ScratchBuffer, ChannelCountOverride, DownmixedBuffer);

				InputData.NumChannels = ChannelCountOverride;
				InputData.AudioBuffer = &DownmixedBuffer;
			}
			else
			{
				// If we're not down-mixing, then just pass in the current wet buffer and our channel count is the same as the output channel count
				InputData.NumChannels = NumChannels;
				InputData.AudioBuffer = &ScratchBuffer;
			}

			if (SubmixEffect->ProcessAudio(InputData, OutputData))
			{
				AUDIO_CHECK_BUFFER_NAMED_MSG(*OutputData.AudioBuffer,TEXT("Submix Effects"), TEXT("FxPreset=%s, Submix=%s"), 
					*GetNameSafe(SubmixEffect->GetPreset()), *GetName());
				
				// Mix in the dry signal directly
				const float DryLevel = SubmixEffect->GetDryLevel();
				if (DryLevel > 0.0f)
				{
					ArrayMixIn(ScratchBuffer, *OutputData.AudioBuffer, DryLevel);
				}
				// Copy the output to the input
				FMemory::Memcpy((void*)ScratchBuffer.GetData(), (void*)OutputData.AudioBuffer->GetData(), sizeof(float) * NumSamples);

				bProcessedAnEffect = true;
			}
		}

		return bProcessedAnEffect;
	}

	void FMixerSubmix::ProcessAudio(ISoundfieldAudioPacket& OutputAudio)
	{
		check(IsSoundfieldSubmix());
		PumpCommandQueue();

		// Mix all submix audio into OutputAudio.
		{
			CSV_SCOPED_TIMING_STAT(Audio, SubmixSoundfieldChildren);
			SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixSoundfieldChildren);

			// If we are mixing down all non-soundfield child submixes,
			// Set up the scratch buffer so that we can sum all non-soundfield child submixes to it.
			if (SoundfieldStreams.DownmixedChildrenEncoder.IsValid())
			{
				ScratchBuffer.Reset();
				ScratchBuffer.AddZeroed(MixerDevice->GetNumOutputFrames() * MixerDevice->GetNumDeviceChannels());
			}

			// First loop this submix's child submixes that are soundfields mixing in their output into this submix's dry/wet buffers.
			for (auto& ChildSubmixEntry : ChildSubmixes)
			{
				MixInChildSubmix(ChildSubmixEntry.Value, OutputAudio);
			}

			// If we mixed down all non-soundfield child submixes,
			// We encode and mix in here.
			if (ChildSubmixes.Num() && SoundfieldStreams.DownmixedChildrenEncoder.IsValid())
			{
				FSoundfieldSpeakerPositionalData PositionalData = GetDefaultPositionalDataForAudioDevice();

				FSoundfieldEncoderInputData InputData = {
						ScratchBuffer, /* AudioBuffer */
						MixerDevice->GetNumDeviceChannels(), /* NumChannels */
						*SoundfieldStreams.Settings, /** InputSettings */
						PositionalData /** PosititonalData */
				};

				SoundfieldStreams.DownmixedChildrenEncoder->EncodeAndMixIn(InputData, OutputAudio);
			}
		}

		// Mix all source sends into OutputAudio.
		{
			CSV_SCOPED_TIMING_STAT(Audio, SubmixSoundfieldSources);
			CONDITIONAL_SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixSoundfieldSources, (MixerSourceVoices.Num() > 0));

			check(SoundfieldStreams.Mixer.IsValid());

			// Loop through this submix's sound sources
			for (const auto& MixerSourceVoiceIter : MixerSourceVoices)
			{
				const FMixerSourceVoice* MixerSourceVoice = MixerSourceVoiceIter.Key;
				const float SendLevel = MixerSourceVoiceIter.Value.SendLevel;

				// if this voice has a valid encoded packet, mix it in.
				const ISoundfieldAudioPacket* Packet = MixerSourceVoice->GetEncodedOutput(GetKeyForSubmixEncoding());
				UpdateListenerRotation(MixerSourceVoice->GetListenerRotationForVoice());

				if (Packet)
				{
					FSoundfieldMixerInputData InputData =
					{
						*Packet,
						*SoundfieldStreams.Settings,
						SendLevel
					};

					SoundfieldStreams.Mixer->MixTogether(InputData, OutputAudio);
				}
			}
		}

		// Run soundfield processors.
		{
			CSV_SCOPED_TIMING_STAT(Audio, SubmixSoundfieldProcessors);
			CONDITIONAL_SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixSoundfieldProcessors, (SoundfieldStreams.EffectProcessors.Num() > 0));

			for (auto& EffectData : SoundfieldStreams.EffectProcessors)
			{
				check(EffectData.Processor.IsValid());
				check(EffectData.Settings.IsValid());

				EffectData.Processor->ProcessAudio(OutputAudio, *SoundfieldStreams.Settings, *EffectData.Settings);
			}
		}
	}

	void FMixerSubmix::ProcessAudioAndSendToEndpoint()
	{
		check(MixerDevice);

		//If this endpoint should no-op, just set the buffer to zero and return
		if (IsDummyEndpointSubmix())
		{
			EndpointData.AudioBuffer.Reset();
			EndpointData.AudioBuffer.AddZeroed(MixerDevice->GetNumOutputFrames() * MixerDevice->GetNumDeviceChannels());
			return;
		}

		if (IsSoundfieldSubmix())
		{
			if (!EndpointData.AudioPacket.IsValid())
			{
				EndpointData.AudioPacket = SoundfieldStreams.Factory->CreateEmptyPacket();
			}
			else
			{
				EndpointData.AudioPacket->Reset();
			}

			// First, process the audio chain for this submix.
			check(EndpointData.AudioPacket);
			ProcessAudio(*EndpointData.AudioPacket);

			if (EndpointData.SoundfieldEndpoint->GetRemainderInPacketBuffer() > 0)
			{
				EndpointData.SoundfieldEndpoint->PushAudio(MoveTemp(EndpointData.AudioPacket));
			}
			else
			{
				ensureMsgf(false, TEXT("Buffer overrun in Soundfield endpoint! %s may need to override ISoundfieldEndpoint::EndpointRequiresCallback() to return true."), *SoundfieldStreams.Factory->GetSoundfieldFormatName().ToString());
			}

			EndpointData.SoundfieldEndpoint->ProcessAudioIfNecessary();
		}
		else
		{
			// First, process the chain for this submix.
			EndpointData.AudioBuffer.Reset();
			EndpointData.AudioBuffer.AddZeroed(MixerDevice->GetNumOutputFrames() * MixerDevice->GetNumDeviceChannels());
			ProcessAudio(EndpointData.AudioBuffer);

			if (!EndpointData.Input.IsOutputStillActive())
			{
				// Either this is our first time pushing audio or we were disconnected.
				const float DurationPerCallback = MixerDevice->GetNumOutputFrames() / MixerDevice->GetSampleRate();

				EndpointData.Input = EndpointData.NonSoundfieldEndpoint->PatchNewInput(DurationPerCallback, EndpointData.SampleRate, EndpointData.NumChannels);

				if (!FMath::IsNearlyEqual(EndpointData.SampleRate, MixerDevice->GetSampleRate()))
				{
					// Initialize the resampler.
					float SampleRateRatio = EndpointData.SampleRate / MixerDevice->GetSampleRate();

					EndpointData.Resampler.Init(EResamplingMethod::Linear, SampleRateRatio, NumChannels);
					EndpointData.bShouldResample = true;

					// Add a little slack at the end of the resampled audio buffer in case we have roundoff jitter.
					EndpointData.ResampledAudioBuffer.Reset();
					EndpointData.ResampledAudioBuffer.AddUninitialized(EndpointData.AudioBuffer.Num() * SampleRateRatio + 16);
				}
			}

			// Resample if necessary.
			int32 NumResampledFrames = EndpointData.AudioBuffer.Num() / NumChannels;
			if (EndpointData.bShouldResample)
			{
				EndpointData.Resampler.ProcessAudio(EndpointData.AudioBuffer.GetData(), EndpointData.AudioBuffer.Num(), false, EndpointData.ResampledAudioBuffer.GetData(), EndpointData.ResampledAudioBuffer.Num(), NumResampledFrames);
			}
			else
			{
				EndpointData.ResampledAudioBuffer = MoveTemp(EndpointData.AudioBuffer);
			}

			// Downmix if necessary.
			const bool bShouldDownmix = EndpointData.NumChannels != NumChannels;
			if (bShouldDownmix)
			{
				EndpointData.DownmixedResampledAudioBuffer.Reset();
				EndpointData.DownmixedResampledAudioBuffer.AddUninitialized(NumResampledFrames * EndpointData.NumChannels);

				EndpointData.DownmixChannelMap.Reset();
				FMixerDevice::Get2DChannelMap(false, NumChannels, EndpointData.NumChannels, false, EndpointData.DownmixChannelMap);
				DownmixBuffer(NumChannels, EndpointData.ResampledAudioBuffer, EndpointData.NumChannels, EndpointData.DownmixedResampledAudioBuffer);
			}
			else
			{
				EndpointData.DownmixedResampledAudioBuffer = MoveTemp(EndpointData.ResampledAudioBuffer);
			}

			EndpointData.Input.PushAudio(EndpointData.DownmixedResampledAudioBuffer.GetData(), EndpointData.DownmixedResampledAudioBuffer.Num());
			EndpointData.NonSoundfieldEndpoint->ProcessAudioIfNeccessary();

			// If we did any pointer passing to bypass downmixing or resampling, pass the pointer back to avoid reallocating ResampledAudioBuffer or AudioBuffer.

			if (!bShouldDownmix)
			{
				EndpointData.ResampledAudioBuffer = MoveTemp(EndpointData.DownmixedResampledAudioBuffer);
			}

			if (!EndpointData.bShouldResample)
			{
				EndpointData.AudioBuffer = MoveTemp(EndpointData.ResampledAudioBuffer);
			}
		}
	}

	int32 FMixerSubmix::GetSampleRate() const
	{
		return MixerDevice->GetDeviceSampleRate();
	}

	int32 FMixerSubmix::GetNumOutputChannels() const
	{
		return MixerDevice->GetNumDeviceChannels();
	}

	int32 FMixerSubmix::GetNumChainEffects()
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
		for (const FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			if (FadeInfo.bIsCurrentChain)
			{
				return FadeInfo.EffectChain.Num();
			}
		}
		return 0;
	}

	FSoundEffectSubmixPtr FMixerSubmix::GetSubmixEffect(const int32 InIndex)
	{
		FScopeLock ScopeLock(&EffectChainMutationCriticalSection);
		for (const FSubmixEffectFadeInfo& FadeInfo : EffectChains)
		{
			if (FadeInfo.bIsCurrentChain)
			{
				if (InIndex < FadeInfo.EffectChain.Num())
				{
					return FadeInfo.EffectChain[InIndex];
				}
			}
		}
		return nullptr;
	}

	void FMixerSubmix::SetSoundfieldFactory(ISoundfieldFactory* InSoundfieldFactory)
	{
		SoundfieldStreams.Factory = InSoundfieldFactory;
	}

	void FMixerSubmix::SetupSoundfieldStreams(const USoundfieldEncodingSettingsBase* InAmbisonicsSettings, TArray<USoundfieldEffectBase*>& Processors, ISoundfieldFactory* InSoundfieldFactory)
	{
		FScopeLock ScopeLock(&SoundfieldStreams.StreamsLock);

		// SoundfieldStreams.Factory should have already been set by our first pass around the submix graph, since 
		// we use the soundfield factory
		check(SoundfieldStreams.Factory == InSoundfieldFactory);

		if (!InSoundfieldFactory)
		{
			return;
		}

		check(InAmbisonicsSettings != nullptr);
		// As a santity check, we ensure the passed in soundfield stream is what was used for the initial SetSoundfieldFactory call.
		check(InSoundfieldFactory == SoundfieldStreams.Factory);


		SoundfieldStreams.Reset();
		SoundfieldStreams.Factory = InSoundfieldFactory;

		// If this submix is encoded to a soundfield, 
		// Explicitly set NumChannels and NumSamples to 0 since they are technically irrelevant.
		NumChannels = 0;
		NumSamples = 0;

		SoundfieldStreams.Settings = InAmbisonicsSettings->GetProxy();

		// Check to see if this implementation of GetProxy failed.
		if (!ensureAlwaysMsgf(SoundfieldStreams.Settings.IsValid(), TEXT("Soundfield Format %s failed to create a settings proxy for settings asset %s."), *InSoundfieldFactory->GetSoundfieldFormatName().ToString(), *InAmbisonicsSettings->GetName()))
		{
			
			TeardownSoundfieldStreams();
			return;
		}
		
		SoundfieldStreams.Mixer = InSoundfieldFactory->CreateMixerStream(*SoundfieldStreams.Settings);

		if (!ensureAlwaysMsgf(SoundfieldStreams.Mixer.IsValid(), TEXT("Soundfield Format %s failed to create a settings proxy for settings asset %s."), *InSoundfieldFactory->GetSoundfieldFormatName().ToString(), *InAmbisonicsSettings->GetName()))
		{
			TeardownSoundfieldStreams();
			return;
		}

		// Create new processor proxies.
		for (USoundfieldEffectBase* Processor : Processors)
		{
			if (Processor != nullptr)
			{
				SoundfieldStreams.EffectProcessors.Emplace(SoundfieldStreams.Factory, *SoundfieldStreams.Settings, Processor);
			}
		}

		SetupSoundfieldEncodersForChildren();
		SetupSoundfieldStreamForParent();
	}

	void FMixerSubmix::TeardownSoundfieldStreams()
	{
		SoundfieldStreams.Reset();

		for (auto& ChildSubmix : ChildSubmixes)
		{
			ChildSubmix.Value.Encoder.Reset();
			ChildSubmix.Value.Transcoder.Reset();
		}
	}

	void FMixerSubmix::SetupEndpoint(IAudioEndpointFactory* InFactory, const UAudioEndpointSettingsBase* InSettings)
	{
		checkf(!IsSoundfieldSubmix(), TEXT("Soundfield Endpoint Submixes called with non-soundfield arguments."));
		check(!ParentSubmix.IsValid());
		EndpointData.Reset();

		if (!InFactory)
		{
			return;
		}

		TUniquePtr<IAudioEndpointSettingsProxy> SettingsProxy;
		if (InSettings)
		{
			SettingsProxy = InSettings->GetProxy();
		}
		else
		{
			InSettings = InFactory->GetDefaultSettings();
			ensureMsgf(InSettings, TEXT("The audio endpoint factory %s failed to generate default settings!"), *InFactory->GetEndpointTypeName().ToString());

			if (InSettings)
			{
				SettingsProxy = InSettings->GetProxy();
			}
		}

		if (SettingsProxy)
		{
			FAudioPluginInitializationParams InitParams = GetInitializationParamsForSoundfieldStream();
			EndpointData.NonSoundfieldEndpoint = InFactory->CreateNewEndpointInstance(InitParams, *SettingsProxy);
		}
		else
		{
			ensureMsgf(false, TEXT("Settings object %s failed to create a proxy object. Likely an error in the implementation of %s::GetProxy()."), *InSettings->GetName(), *InSettings->GetClass()->GetName());
		}
	}

	void FMixerSubmix::SetupEndpoint(ISoundfieldEndpointFactory* InFactory, const USoundfieldEndpointSettingsBase* InSettings)
	{
		checkf(IsSoundfieldSubmix(), TEXT("Non-Soundfield Endpoint Submixes called with soundfield arguments."));
		check(SoundfieldStreams.Factory == InFactory);
		check(!ParentSubmix.IsValid());

		EndpointData.Reset();

		if (!InFactory)
		{
			return;
		}

		TUniquePtr<ISoundfieldEndpointSettingsProxy> SettingsProxy;
		if (InSettings)
		{
			SettingsProxy = InSettings->GetProxy();
		}
		else
		{
			InSettings = InFactory->GetDefaultEndpointSettings();
			ensureMsgf(InSettings, TEXT("The audio endpoint factory %s failed to generate default settings!"), *InFactory->GetEndpointTypeName().ToString());

			if (InSettings)
			{
				SettingsProxy = InSettings->GetProxy();
			}
		}

		if (SettingsProxy)
		{
			FAudioPluginInitializationParams InitParams = GetInitializationParamsForSoundfieldStream();
			EndpointData.SoundfieldEndpoint = InFactory->CreateNewEndpointInstance(InitParams, *SettingsProxy);
		}
		else
		{
			ensureMsgf(false, TEXT("Settings object %s failed to create a proxy object. Likely an error in the implementation of %s::GetProxy()."), *InSettings->GetName(), *InSettings->GetClass()->GetName());
		}
	}

	void FMixerSubmix::UpdateEndpointSettings(TUniquePtr<IAudioEndpointSettingsProxy>&& InSettings)
	{
		checkf(!IsSoundfieldSubmix(), TEXT("UpdateEndpointSettings for a soundfield submix was called with an IAudioEndpointSettingsProxy rather than an ISoundfieldEndpointSettingsProxy."));
		if (ensureMsgf(EndpointData.NonSoundfieldEndpoint.IsValid(), TEXT("UpdateEndpointSettings called on an object that is not an endpoint submix.")))
		{
			EndpointData.NonSoundfieldEndpoint->SetNewSettings(MoveTemp(InSettings));
		}
	}

	void FMixerSubmix::UpdateEndpointSettings(TUniquePtr<ISoundfieldEndpointSettingsProxy>&& InSettings)
	{
		checkf(IsSoundfieldSubmix(), TEXT("UpdateEndpointSettings for a non-soundfield submix was called with an ISoundfieldEndpointSettingsProxy rather than an IAudioEndpointSettingsProxy."));
		if (ensureMsgf(EndpointData.SoundfieldEndpoint.IsValid(), TEXT("UpdateEndpointSettings called on an object that is not an endpoint submix.")))
		{
			EndpointData.SoundfieldEndpoint->SetNewSettings(MoveTemp(InSettings));
		}
	}

	void FMixerSubmix::OnStartRecordingOutput(float ExpectedDuration)
	{
		RecordingData.Reset();
		RecordingData.Reserve(ExpectedDuration * GetSampleRate());
		bIsRecording = true;
	}

	FAlignedFloatBuffer& FMixerSubmix::OnStopRecordingOutput(float& OutNumChannels, float& OutSampleRate)
	{
		FScopeLock ScopedLock(&RecordingCriticalSection);
		bIsRecording = false;
		OutNumChannels = NumChannels;
		OutSampleRate = GetSampleRate();
		return RecordingData;
	}

	void FMixerSubmix::PauseRecordingOutput()
	{
		if (!RecordingData.Num())
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Cannot pause recording output as no recording is in progress."));
			return;
		}
		
		bIsRecording = false;
	}

	void FMixerSubmix::ResumeRecordingOutput()
	{
		if (!RecordingData.Num())
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Cannot resume recording output as no recording is in progress."));
			return;
		}
		bIsRecording = true;
	}

	void FMixerSubmix::RegisterBufferListener(ISubmixBufferListener* BufferListener)
	{
		FScopeLock Lock(&BufferListenerCriticalSection);
		check(BufferListener);
		BufferListenerPtrs.AddUnique(BufferListener->AsShared());
	}

	void FMixerSubmix::RegisterBufferListener(TSharedRef<ISubmixBufferListener, ESPMode::ThreadSafe> BufferListener)
	{
		FScopeLock Lock(&BufferListenerCriticalSection);
		BufferListenerPtrs.AddUnique(BufferListener);
	}

	void FMixerSubmix::UnregisterBufferListener(ISubmixBufferListener* BufferListener)
	{
		FScopeLock Lock(&BufferListenerCriticalSection);
		check(BufferListener);
		BufferListenerPtrs.Remove(BufferListener->AsShared());
	}

	void FMixerSubmix::UnregisterBufferListener(TSharedRef<ISubmixBufferListener, ESPMode::ThreadSafe> BufferListener)
	{
		FScopeLock Lock(&BufferListenerCriticalSection);
		BufferListenerPtrs.Remove(BufferListener);
	}

	void FMixerSubmix::StartEnvelopeFollowing(int32 AttackTime, int32 ReleaseTime)
	{
		if (!bIsEnvelopeFollowing)
		{
			FEnvelopeFollowerInitParams EnvelopeFollowerInitParams;
			EnvelopeFollowerInitParams.SampleRate = GetSampleRate(); 
			EnvelopeFollowerInitParams.NumChannels = NumChannels; 
			EnvelopeFollowerInitParams.AttackTimeMsec = static_cast<float>(AttackTime);
			EnvelopeFollowerInitParams.ReleaseTimeMsec = static_cast<float>(ReleaseTime);
			EnvelopeFollower.Init(EnvelopeFollowerInitParams);

			// Zero out any previous envelope values which may have been in the array before starting up
			for (int32 ChannelIndex = 0; ChannelIndex < AUDIO_MIXER_MAX_OUTPUT_CHANNELS; ++ChannelIndex)
			{
				EnvelopeValues[ChannelIndex] = 0.0f;
			}

			bIsEnvelopeFollowing = true;
		}
	}

	void FMixerSubmix::StopEnvelopeFollowing()
	{
		bIsEnvelopeFollowing = false;
	}

	void FMixerSubmix::AddEnvelopeFollowerDelegate(const FOnSubmixEnvelopeBP& OnSubmixEnvelopeBP)
	{
		OnSubmixEnvelope.AddUnique(OnSubmixEnvelopeBP);
	}

	void FMixerSubmix::RemoveEnvelopeFollowerDelegate(const FOnSubmixEnvelopeBP& OnSubmixEnvelopeBP)
	{
		OnSubmixEnvelope.Remove(OnSubmixEnvelopeBP);
	}

	void FMixerSubmix::AddSpectralAnalysisDelegate(const FSoundSpectrumAnalyzerDelegateSettings& InDelegateSettings, const FOnSubmixSpectralAnalysisBP& OnSubmixSpectralAnalysisBP)
	{
		FSpectrumAnalysisDelegateInfo NewDelegateInfo;
	
		NewDelegateInfo.LastUpdateTime = -1.0f;
		NewDelegateInfo.DelegateSettings = InDelegateSettings;
		NewDelegateInfo.DelegateSettings.UpdateRate = FMath::Clamp(NewDelegateInfo.DelegateSettings.UpdateRate, 1.0f, 30.0f);
		NewDelegateInfo.UpdateDelta = 1.0f / NewDelegateInfo.DelegateSettings.UpdateRate;

		NewDelegateInfo.OnSubmixSpectralAnalysis.AddUnique(OnSubmixSpectralAnalysisBP);

		{
			FScopeLock SpectrumAnalyzerLock(&SpectrumAnalyzerCriticalSection);

			SpectralAnalysisDelegates.Add(MoveTemp(NewDelegateInfo));
		}
	}

	void FMixerSubmix::RemoveSpectralAnalysisDelegate(const FOnSubmixSpectralAnalysisBP& OnSubmixSpectralAnalysisBP)
	{
		FScopeLock SpectrumAnalyzerLock(&SpectrumAnalyzerCriticalSection);

		for (FSpectrumAnalysisDelegateInfo& Info : SpectralAnalysisDelegates)
		{
			if (Info.OnSubmixSpectralAnalysis.Contains(OnSubmixSpectralAnalysisBP))
			{
				Info.OnSubmixSpectralAnalysis.Remove(OnSubmixSpectralAnalysisBP);
			}
		}

		SpectralAnalysisDelegates.RemoveAllSwap([](FSpectrumAnalysisDelegateInfo& Info) {
			return !Info.OnSubmixSpectralAnalysis.IsBound();
		});
	}

	void FMixerSubmix::StartSpectrumAnalysis(const FSoundSpectrumAnalyzerSettings& InSettings)
	{
		ensure(IsInAudioThread());

		using namespace MixerSubmixIntrinsics;
		using EMetric = FSpectrumBandExtractorSettings::EMetric;
		using EBandType = ISpectrumBandExtractor::EBandType;

		bIsSpectrumAnalyzing = true;

		SpectrumAnalyzerSettings = InSettings;

		FSpectrumAnalyzerSettings AudioSpectrumAnalyzerSettings;

		AudioSpectrumAnalyzerSettings.FFTSize = GetSpectrumAnalyzerFFTSize(SpectrumAnalyzerSettings.FFTSize);
		AudioSpectrumAnalyzerSettings.WindowType = GetWindowType(SpectrumAnalyzerSettings.WindowType);
		AudioSpectrumAnalyzerSettings.HopSize = SpectrumAnalyzerSettings.HopSize;

		EMetric Metric = GetExtractorMetric(SpectrumAnalyzerSettings.SpectrumType);
		EBandType BandType = GetExtractorBandType(SpectrumAnalyzerSettings.InterpolationMethod);

		{
			FScopeLock SpectrumAnalyzerLock(&SpectrumAnalyzerCriticalSection);
			SpectrumAnalyzer = MakeShared<FAsyncSpectrumAnalyzer, ESPMode::ThreadSafe>(AudioSpectrumAnalyzerSettings, MixerDevice->GetSampleRate());


			for (FSpectrumAnalysisDelegateInfo& DelegateInfo : SpectralAnalysisDelegates)
			{
				FSpectrumBandExtractorSettings ExtractorSettings;

				ExtractorSettings.Metric = Metric;
				ExtractorSettings.DecibelNoiseFloor = DelegateInfo.DelegateSettings.DecibelNoiseFloor;
				ExtractorSettings.bDoNormalize = DelegateInfo.DelegateSettings.bDoNormalize;
				ExtractorSettings.bDoAutoRange = DelegateInfo.DelegateSettings.bDoAutoRange;
				ExtractorSettings.AutoRangeReleaseTimeInSeconds = DelegateInfo.DelegateSettings.AutoRangeReleaseTime;
				ExtractorSettings.AutoRangeAttackTimeInSeconds = DelegateInfo.DelegateSettings.AutoRangeAttackTime;

				DelegateInfo.SpectrumBandExtractor = ISpectrumBandExtractor::CreateSpectrumBandExtractor(ExtractorSettings);

				if (DelegateInfo.SpectrumBandExtractor.IsValid())
				{
					for (const FSoundSubmixSpectralAnalysisBandSettings& BandSettings : DelegateInfo.DelegateSettings.BandSettings)
					{
						ISpectrumBandExtractor::FBandSettings NewExtractorBandSettings;
						NewExtractorBandSettings.Type = BandType;
						NewExtractorBandSettings.CenterFrequency = BandSettings.BandFrequency;
						NewExtractorBandSettings.QFactor = BandSettings.QFactor;

						DelegateInfo.SpectrumBandExtractor->AddBand(NewExtractorBandSettings);

						FSpectralAnalysisBandInfo NewBand;

						FInlineEnvelopeFollowerInitParams EnvelopeFollowerInitParams;
						EnvelopeFollowerInitParams.SampleRate = DelegateInfo.DelegateSettings.UpdateRate;
						EnvelopeFollowerInitParams.AttackTimeMsec = static_cast<float>(BandSettings.AttackTimeMsec);
						EnvelopeFollowerInitParams.ReleaseTimeMsec = static_cast<float>(BandSettings.ReleaseTimeMsec);
						NewBand.EnvelopeFollower.Init(EnvelopeFollowerInitParams);
					
						DelegateInfo.SpectralBands.Add(NewBand);
					}
				} 
			}
		}
	}

	void FMixerSubmix::StopSpectrumAnalysis()
	{
		ensure(IsInAudioThread());

		FScopeLock SpectrumAnalyzerLock(&SpectrumAnalyzerCriticalSection);
		bIsSpectrumAnalyzing = false;
		SpectrumAnalyzer.Reset();
	}

	void FMixerSubmix::GetMagnitudeForFrequencies(const TArray<float>& InFrequencies, TArray<float>& OutMagnitudes)
	{
		FScopeLock SpectrumAnalyzerLock(&SpectrumAnalyzerCriticalSection);

		if (SpectrumAnalyzer.IsValid())
		{
			using EMethod = FSpectrumAnalyzer::EPeakInterpolationMethod;

			EMethod Method;	

			switch (SpectrumAnalyzerSettings.InterpolationMethod)
			{
				case EFFTPeakInterpolationMethod::NearestNeighbor:
					Method = EMethod::NearestNeighbor;
					break;

				case EFFTPeakInterpolationMethod::Linear:
					Method = EMethod::Linear;
					break;

				case EFFTPeakInterpolationMethod::Quadratic:
					Method = EMethod::Quadratic;
					break;

				default:
					Method = EMethod::Linear;
					break;
			}

			OutMagnitudes.Reset();
			OutMagnitudes.AddUninitialized(InFrequencies.Num());

			SpectrumAnalyzer->LockOutputBuffer();
			for (int32 Index = 0; Index < InFrequencies.Num(); Index++)
			{
				OutMagnitudes[Index] = SpectrumAnalyzer->GetMagnitudeForFrequency(InFrequencies[Index], Method);
			}
			SpectrumAnalyzer->UnlockOutputBuffer();
		}
		else
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Call StartSpectrumAnalysis before calling GetMagnitudeForFrequencies."));
		}
	}

	void FMixerSubmix::GetPhaseForFrequencies(const TArray<float>& InFrequencies, TArray<float>& OutPhases)
	{
		FScopeLock SpectrumAnalyzerLock(&SpectrumAnalyzerCriticalSection);

		if (SpectrumAnalyzer.IsValid())
		{
			using EMethod = FSpectrumAnalyzer::EPeakInterpolationMethod;

			EMethod Method;	

			switch (SpectrumAnalyzerSettings.InterpolationMethod)
			{
				case EFFTPeakInterpolationMethod::NearestNeighbor:
					Method = EMethod::NearestNeighbor;
					break;

				case EFFTPeakInterpolationMethod::Linear:
					Method = EMethod::Linear;
					break;

				case EFFTPeakInterpolationMethod::Quadratic:
					Method = EMethod::Quadratic;
					break;

				default:
					Method = EMethod::Linear;
					break;
			}

			OutPhases.Reset();
			OutPhases.AddUninitialized(InFrequencies.Num());

			SpectrumAnalyzer->LockOutputBuffer();
			for (int32 Index = 0; Index < InFrequencies.Num(); Index++)
			{
				OutPhases[Index] = SpectrumAnalyzer->GetPhaseForFrequency(InFrequencies[Index], Method);
			}
			SpectrumAnalyzer->UnlockOutputBuffer();
		}
		else
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Call StartSpectrumAnalysis before calling GetMagnitudeForFrequencies."));
		}
	}

	void FMixerSubmix::SetOutputVolume(float InOutputVolume)
	{
		VolumeModifier = FMath::Clamp(InOutputVolume, 0.0f, 1.0f);
	}

	void FMixerSubmix::SetDryLevel(float InDryLevel)
	{
		DryLevelModifier = FMath::Clamp(InDryLevel, 0.0f, 1.0f);
	}

	void FMixerSubmix::SetWetLevel(float InWetLevel)
	{
		WetLevelModifier = FMath::Clamp(InWetLevel, 0.0f, 1.0f);
	}

	void FMixerSubmix::UpdateModulationSettings(const TSet<TObjectPtr<USoundModulatorBase>>& InOutputModulators, const TSet<TObjectPtr<USoundModulatorBase>>& InWetLevelModulators, const TSet<TObjectPtr<USoundModulatorBase>>& InDryLevelModulators)
	{
		VolumeMod.UpdateModulators(InOutputModulators);
		WetLevelMod.UpdateModulators(InWetLevelModulators);
		DryLevelMod.UpdateModulators(InDryLevelModulators);
	}

	void FMixerSubmix::SetModulationBaseLevels(float InVolumeModBaseDb, float InWetModBaseDb, float InDryModBaseDb)
	{
		VolumeModBaseDb = InVolumeModBaseDb;
		WetModBaseDb = InWetModBaseDb;
		DryModBaseDb = InDryModBaseDb;
	}

	FModulationDestination* FMixerSubmix::GetOutputVolumeDestination()
	{
		return &VolumeMod;
	}

	FModulationDestination* FMixerSubmix::GetWetVolumeDestination()
	{
		return &WetLevelMod;
	}

	void FMixerSubmix::BroadcastDelegates()
	{
		if (bIsEnvelopeFollowing)
		{
			// Get the envelope data
			TArray<float> EnvelopeData;

			{
				// Make the copy of the envelope values using a critical section
				FScopeLock EnvelopeScopeLock(&EnvelopeCriticalSection);

				if (EnvelopeNumChannels > 0)
				{
					EnvelopeData.AddUninitialized(EnvelopeNumChannels);
					FMemory::Memcpy(EnvelopeData.GetData(), EnvelopeValues, sizeof(float)*EnvelopeNumChannels);
				}
			}

			// Broadcast to any bound delegates
			if (OnSubmixEnvelope.IsBound())
			{
				OnSubmixEnvelope.Broadcast(EnvelopeData);
			}

		}
		
		// If we're analyzing spectra and if we've got delegates setup
		if (bIsSpectrumAnalyzing) 
		{
			FScopeLock SpectrumLock(&SpectrumAnalyzerCriticalSection);

			if (SpectralAnalysisDelegates.Num() > 0)
			{
				if (ensureMsgf(SpectrumAnalyzer.IsValid(), TEXT("Analyzing spectrum with invalid spectrum analyzer")))
				{
					TArray<TPair<FSpectrumAnalysisDelegateInfo*, TArray<float>>> ResultsPerDelegate;
					
					{
						// This lock ensures that the spectrum analyzer's analysis buffer doesn't
						// change in this scope. 
						Audio::FAsyncSpectrumAnalyzerScopeLock AnalyzerLock(SpectrumAnalyzer.Get());

						for (FSpectrumAnalysisDelegateInfo& DelegateInfo : SpectralAnalysisDelegates)
						{
							TArray<float> SpectralResults;
							SpectralResults.Reset();
							const float CurrentTime = FPlatformTime::ToSeconds64(FPlatformTime::Cycles64());

							// Don't update the spectral band until it's time since the last tick.
							if (DelegateInfo.LastUpdateTime > 0.0f && ((CurrentTime - DelegateInfo.LastUpdateTime) < DelegateInfo.UpdateDelta))
							{
								continue;
							}

							DelegateInfo.LastUpdateTime = CurrentTime;

							if (ensure(DelegateInfo.SpectrumBandExtractor.IsValid()))
							{
								ISpectrumBandExtractor* Extractor = DelegateInfo.SpectrumBandExtractor.Get();

								SpectrumAnalyzer->GetBands(*Extractor, SpectralResults);
							}
							ResultsPerDelegate.Emplace(&DelegateInfo, MoveTemp(SpectralResults));
						}
					}

					for (TPair<FSpectrumAnalysisDelegateInfo*, TArray<float>> Results : ResultsPerDelegate)
					{
						FSpectrumAnalysisDelegateInfo* DelegateInfo = Results.Key;
						// Feed the results through the band envelope followers
						for (int32 ResultIndex = 0; ResultIndex < Results.Value.Num(); ++ResultIndex)
						{
							if (ensure(ResultIndex < DelegateInfo->SpectralBands.Num()))
							{
								FSpectralAnalysisBandInfo& BandInfo = DelegateInfo->SpectralBands[ResultIndex];

								Results.Value[ResultIndex] = BandInfo.EnvelopeFollower.ProcessSample(Results.Value[ResultIndex]);
							}
						}

						if (DelegateInfo->OnSubmixSpectralAnalysis.IsBound())
						{
							DelegateInfo->OnSubmixSpectralAnalysis.Broadcast(MoveTemp(Results.Value));
						}
					}
				}
			}
		}
	}

	FSoundfieldEncodingKey FMixerSubmix::GetKeyForSubmixEncoding()
	{
		check(IsSoundfieldSubmix() && SoundfieldStreams.Settings.IsValid());
		return FSoundfieldEncodingKey(SoundfieldStreams.Factory, *SoundfieldStreams.Settings);
	}

	ISoundfieldFactory* FMixerSubmix::GetSoundfieldFactory()
	{
		return SoundfieldStreams.Factory;
	}

}

============================


=== AudioMixerSubmix.h ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "AudioBusSubsystem.h"
#include "AudioMixer.h"
#include "AudioDefines.h"
#include "CoreMinimal.h"
#include "SampleBuffer.h"
#include "IAudioEndpoint.h"
#include "ISoundfieldEndpoint.h"
#include "Sound/SoundSubmix.h"
#include "Sound/SoundModulationDestination.h"
#include "DSP/EnvelopeFollower.h"
#include "DSP/MultithreadedPatching.h"
#include "DSP/SpectrumAnalyzer.h"
#include "Templates/SharedPointer.h"
#include "AudioDynamicParameter.h"
#include "Stats/Stats.h"
#include "UObject/WeakObjectPtrTemplates.h"
#include "IAudioLinkFactory.h"

// The time it takes to process the submix graph. Process submix effects, mix into the submix buffer, etc.
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Graph"), STAT_AudioMixerSubmixes, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the endpoint submixes.
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Graph Endpoint"), STAT_AudioMixerEndpointSubmixes, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the submix graph. Process submix effects, mix into the submix buffer, etc.
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Graph Child Processing"), STAT_AudioMixerSubmixChildren, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the submix graph. Process submix effects, mix into the submix buffer, etc.
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Graph Source Mixing"), STAT_AudioMixerSubmixSource, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the submix graph. Process submix effects, mix into the submix buffer, etc.
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Graph Effect Processing"), STAT_AudioMixerSubmixEffectProcessing, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the submix buffer listeners. 
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Buffer Listeners"), STAT_AudioMixerSubmixBufferListeners, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the submix soundfield child submixes. 
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Soundfield Children"), STAT_AudioMixerSubmixSoundfieldChildren, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the submix soundfield sources. 
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Soundfield Sources"), STAT_AudioMixerSubmixSoundfieldSources, STATGROUP_AudioMixer, AUDIOMIXER_API);

// The time it takes to process the submix soundfield processors.. 
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Soundfield Processors"), STAT_AudioMixerSubmixSoundfieldProcessors, STATGROUP_AudioMixer, AUDIOMIXER_API);

// Forward Declarations
class FOnSubmixEnvelopeBP;
class USoundEffectSubmix;
class USoundSubmix;
class USoundSubmixBase;
class USoundModulatorBase;

namespace Audio
{
	class IAudioMixerEffect;
	class FMixerSourceVoice;
	class FMixerDevice;

	enum EMixerSourceSubmixSendStage
	{
		// Whether to do the send pre distance attenuation
		PostDistanceAttenuation,

		// Whether to do the send post distance attenuation
		PreDistanceAttenuation,
	};

	struct FSubmixVoiceData
	{
		float SendLevel;
		EMixerSourceSubmixSendStage SubmixSendStage;

		FSubmixVoiceData()
			: SendLevel(1.0f)
			, SubmixSendStage(EMixerSourceSubmixSendStage::PostDistanceAttenuation)
		{
		}
	};

	class FMixerSubmix;

	struct FChildSubmixInfo : FNoncopyable
	{
		TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> SubmixPtr;

		// If the child submix is not a soundfield submix, we may need to encode its audio output in ProcessAudio.
		TUniquePtr<ISoundfieldEncoderStream> Encoder;

		// If this child submix is a soundfield submix that we can read the output of, we may need to transcode it's audio output.
		TUniquePtr<ISoundfieldTranscodeStream> Transcoder;

		// This is filled by either the Encoder or the Transcoder, and passed to this submix' mixer.
		TUniquePtr<ISoundfieldAudioPacket> IncomingPacketToTranscode;

		FChildSubmixInfo()
		{}

		FChildSubmixInfo(TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> SubmixWeakPtr)
			: SubmixPtr(SubmixWeakPtr)
		{
		}
	};

	class FMixerSubmix
	{
	public:
		AUDIOMIXER_API FMixerSubmix(FMixerDevice* InMixerDevice);
		AUDIOMIXER_API virtual ~FMixerSubmix();

		// Initialize the submix object with the USoundSubmix ptr. Sets up child and parent connects.
		AUDIOMIXER_API void Init(const USoundSubmixBase* InSoundSubmix, bool bAllowReInit = true);

		// Returns the mixer submix Id
		uint32 GetId() const { return Id; }

		// Return the owners name 
		AUDIOMIXER_API const FString& GetName() const { return SubmixName; }

		// Sets the parent submix to the given submix
		AUDIOMIXER_API void SetParentSubmix(TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> Submix);

		// Adds the given submix to this submix's children
		AUDIOMIXER_API void AddChildSubmix(TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> Submix);

		// Removes the given submix from this submix's children
		AUDIOMIXER_API void RemoveChildSubmix(TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> SubmixWeakPtr);

		// Registers the given audiobus to this submix
		AUDIOMIXER_API void RegisterAudioBus(const Audio::FAudioBusKey& InAudioBusKey, Audio::FPatchInput&& InPatchInput);

		// Unregisters a registered audiobus from this submix (if any)
		AUDIOMIXER_API void UnregisterAudioBus(const Audio::FAudioBusKey& InAudioBusKey);

		// Sets the output level of the submix in linear gain
		AUDIOMIXER_API void SetOutputVolume(float InOutputLevel);

		// Sets the static output volume of the submix in linear gain
		AUDIOMIXER_API void SetDryLevel(float InDryLevel);

		// Sets the wet level of the submix in linear gain
		AUDIOMIXER_API void SetWetLevel(float InWetLevel);

		// Update modulation settings of the submix
		AUDIOMIXER_API void UpdateModulationSettings(const TSet<TObjectPtr<USoundModulatorBase>>& InOutputModulators, const TSet<TObjectPtr<USoundModulatorBase>>& InWetLevelModulators, const TSet<TObjectPtr<USoundModulatorBase>>& InDryLevelModulators);

		// Update modulation settings of the submix with Decibel values
		AUDIOMIXER_API void SetModulationBaseLevels(float InVolumeModBaseDb, float InWetModeBaseDb, float InDryModBaseDb);

		FModulationDestination* GetOutputVolumeDestination();

		FModulationDestination* GetWetVolumeDestination();

		// Gets the submix channels channels
		AUDIOMIXER_API int32 GetSubmixChannels() const;

		// Gets this submix's parent submix
		AUDIOMIXER_API TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> GetParentSubmix();

		// Returns the number of source voices currently a part of this submix.
		AUDIOMIXER_API int32 GetNumSourceVoices() const;

		// Returns the number of wet effects in this submix.
		AUDIOMIXER_API int32 GetNumEffects() const;

		// Returns the size of the submix chain. 
		AUDIOMIXER_API int32 GetSizeOfSubmixChain() const;

		// Add (if not already added) or sets the amount of the source voice's send amount
		AUDIOMIXER_API void AddOrSetSourceVoice(FMixerSourceVoice* InSourceVoice, const float SendLevel, EMixerSourceSubmixSendStage InSubmixSendStage);

		AUDIOMIXER_API FPatchOutputStrongPtr AddPatch(float InGain);

		/** Removes the given source voice from the submix. */
		AUDIOMIXER_API void RemoveSourceVoice(FMixerSourceVoice* InSourceVoice);

		/** Appends the effect submix to the effect submix chain. */
		AUDIOMIXER_API void AddSoundEffectSubmix(FSoundEffectSubmixPtr InSoundEffectSubmix);

		/** Removes the submix effect from the effect submix chain. */
		AUDIOMIXER_API void RemoveSoundEffectSubmix(uint32 SubmixPresetId);

		/** Removes the submix effect from the effect submix chain at the given submix index. */
		AUDIOMIXER_API void RemoveSoundEffectSubmixAtIndex(int32 InIndex);

		/** Clears all submix effects from the effect submix chain. */
		AUDIOMIXER_API void ClearSoundEffectSubmixes();

		/** Sets a submix effect chain override with the given fade time in seconds. */
		AUDIOMIXER_API void SetSubmixEffectChainOverride(const TArray<FSoundEffectSubmixPtr>& InSubmixEffectPresetChain, float InFadeTimeSec);

		/** Clears any submix effect chain overrides in the given fade time in seconds. */
		AUDIOMIXER_API void ClearSubmixEffectChainOverride(float InFadeTimeSec);

		/** Swaps effect for provided submix at the given index.  Fails if effect at index doesn't exist */
		AUDIOMIXER_API void ReplaceSoundEffectSubmix(int32 InIndex, FSoundEffectSubmixPtr InEffectInstance);

		/** Whether or not this submix instance is muted. */
		AUDIOMIXER_API void SetBackgroundMuted(bool bInMuted);

		/** Checks to see if submix is valid.  Submix can be considered invalid if the OwningSubmix
		  * pointer is stale.
		  */
		AUDIOMIXER_API bool IsValid() const;

		// Function which processes audio.
		AUDIOMIXER_API void ProcessAudio(FAlignedFloatBuffer& OutAudio);
		AUDIOMIXER_API void ProcessAudio(ISoundfieldAudioPacket& OutputAudio);

		AUDIOMIXER_API void SendAudioToSubmixBufferListeners(FAlignedFloatBuffer& OutAudioBuffer);

		// This should be called if this submix doesn't send it's audio to a parent submix,
		// but rather an external endpoint.
		AUDIOMIXER_API void ProcessAudioAndSendToEndpoint();

		// Returns the device sample rate this submix is rendering to
		AUDIOMIXER_API int32 GetSampleRate() const;

		// Returns the output channels this submix is rendering to
		AUDIOMIXER_API int32 GetNumOutputChannels() const;

		// Returns the number of effects in this submix's effect chain
		AUDIOMIXER_API int32 GetNumChainEffects();

		// Returns the submix effect at the given effect chain index
		AUDIOMIXER_API FSoundEffectSubmixPtr GetSubmixEffect(const int32 InIndex);

		// This must be called on the entire submix graph before calling SetupSoundfieldStreams.
		AUDIOMIXER_API void SetSoundfieldFactory(ISoundfieldFactory* InSoundfieldFactory);

		// updates settings, potentially creating or removing ambisonics streams based on what types of submixes this submix is connected to.
		AUDIOMIXER_API void SetupSoundfieldStreams(const USoundfieldEncodingSettingsBase* SoundfieldSettings, TArray<USoundfieldEffectBase*>& Processors, ISoundfieldFactory* InSoundfieldFactory);
		AUDIOMIXER_API void TeardownSoundfieldStreams();

		AUDIOMIXER_API void SetupEndpoint(IAudioEndpointFactory* InFactory, const UAudioEndpointSettingsBase* InSettings);
		AUDIOMIXER_API void SetupEndpoint(ISoundfieldEndpointFactory* InFactory, const USoundfieldEndpointSettingsBase* InSettings);

		AUDIOMIXER_API void UpdateEndpointSettings(TUniquePtr<IAudioEndpointSettingsProxy>&& InSettings);
		AUDIOMIXER_API void UpdateEndpointSettings(TUniquePtr<ISoundfieldEndpointSettingsProxy>&& InSettings);

		// This is called by the corresponding USoundSubmix when StartRecordingOutput is called.
		AUDIOMIXER_API void OnStartRecordingOutput(float ExpectedDuration);

		// This is called by the corresponding USoundSubmix when StopRecordingOutput is called.
		AUDIOMIXER_API FAlignedFloatBuffer& OnStopRecordingOutput(float& OutNumChannels, float& OutSampleRate);

		// This is called by the corresponding USoundSubmix when PauseRecording is called.
		AUDIOMIXER_API void PauseRecordingOutput();

		// This is called by the corresponding USoundSubmix when ResumeRecording is called.
		AUDIOMIXER_API void ResumeRecordingOutput();

		// Register buffer listener with this submix
		// Unregister buffer listener with this submix

		UE_DEPRECATED(5.4, "This function is deprecated. Use RegisterBufferListener version that is provided a shared reference to a listener.")
		AUDIOMIXER_API void RegisterBufferListener(ISubmixBufferListener* BufferListener);
		
		UE_DEPRECATED(5.4, "This function is deprecated. Use UnregisterBufferListener version that is provided a shared reference to a listener.")
		AUDIOMIXER_API void UnregisterBufferListener(ISubmixBufferListener* BufferListener);

		AUDIOMIXER_API void RegisterBufferListener(TSharedRef<ISubmixBufferListener, ESPMode::ThreadSafe> BufferListener);
		AUDIOMIXER_API void UnregisterBufferListener(TSharedRef<ISubmixBufferListener, ESPMode::ThreadSafe> BufferListener);

		// Starts envelope following with the given attack time and release time
		AUDIOMIXER_API void StartEnvelopeFollowing(int32 AttackTime, int32 ReleaseTime);

		// Stops envelope following the submix
		AUDIOMIXER_API void StopEnvelopeFollowing();

		// Adds an envelope follower delegate
		AUDIOMIXER_API void AddEnvelopeFollowerDelegate(const FOnSubmixEnvelopeBP& OnSubmixEnvelopeBP);

		// Removes an existing envelope follower delegate
		AUDIOMIXER_API void RemoveEnvelopeFollowerDelegate(const FOnSubmixEnvelopeBP& OnSubmixEnvelopeBP);

		// Initializes a new FFT analyzer for this submix and immediately begins feeding audio to it.
		AUDIOMIXER_API void StartSpectrumAnalysis(const FSoundSpectrumAnalyzerSettings& InSettings);

		// Terminates whatever FFT Analyzer is being used for this submix.
		AUDIOMIXER_API void StopSpectrumAnalysis();

		// Adds an spectral analysis delegate
		AUDIOMIXER_API void AddSpectralAnalysisDelegate(const FSoundSpectrumAnalyzerDelegateSettings& InDelegateSettings, const FOnSubmixSpectralAnalysisBP& OnSubmixSpectralAnalysisBP);

		// Removes an existing spectral analysis delegate
		AUDIOMIXER_API void RemoveSpectralAnalysisDelegate(const FOnSubmixSpectralAnalysisBP& OnSubmixSpectralAnalysisBP);

		// Gets the most recent magnitude values for each corresponding value in InFrequencies (in Hz).
		// This requires StartSpectrumAnalysis to be called first.
		AUDIOMIXER_API void GetMagnitudeForFrequencies(const TArray<float>& InFrequencies, TArray<float>& OutMagnitudes);

		// Gets the most recent phase values for each corresponding value in InFrequencies (in Hz).
		// This requires StartSpectrumAnalysis to be called first.
		AUDIOMIXER_API void GetPhaseForFrequencies(const TArray<float>& InFrequencies, TArray<float>& OutPhases);

		// Broadcast the envelope and submix delegates on the game thread
		AUDIOMIXER_API void BroadcastDelegates();

		// returns true if this submix is encoded to a soundfield.
		AUDIOMIXER_API bool IsSoundfieldSubmix() const;

		// returns true if this submix sends it's audio to the default endpoint.
		AUDIOMIXER_API bool IsDefaultEndpointSubmix() const;

		// Returns true if this submix sends its audio to an IAudioEndpoint.
		AUDIOMIXER_API bool IsExternalEndpointSubmix() const;

		// returns true if this submix sends its audio to an ISoundfieldEndpoint.
		AUDIOMIXER_API bool IsSoundfieldEndpointSubmix() const;

		//Returns true if this is an endpoint type that should no-op for this platform
		AUDIOMIXER_API bool IsDummyEndpointSubmix() const;

		// Returns true if the submix is currently rendering audio. The current rendering time is passed in.
		AUDIOMIXER_API bool IsRenderingAudio() const;

		// Set whether or not this submix is told to auto disable. 
		AUDIOMIXER_API void SetAutoDisable(bool bInAutoDisable);

		// Sets the auto-disable time
		AUDIOMIXER_API void SetAutoDisableTime(float InAutoDisableTime);

		// Get a unique key for this submix's format and settings.
		// If another submix has an identical format and settings it will have an equivalent key.
		AUDIOMIXER_API FSoundfieldEncodingKey GetKeyForSubmixEncoding();

		AUDIOMIXER_API ISoundfieldFactory* GetSoundfieldFactory();

		AUDIOMIXER_API ISoundfieldEncodingSettingsProxy& GetSoundfieldSettings();

		AUDIOMIXER_API FAudioPluginInitializationParams GetInitializationParamsForSoundfieldStream();

		AUDIOMIXER_API FSoundfieldSpeakerPositionalData GetDefaultPositionalDataForAudioDevice();

		AUDIOMIXER_API TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe>  GetParent() const { return ParentSubmix; }
		AUDIOMIXER_API const TMap<uint32, FChildSubmixInfo>& GetChildren() const { return ChildSubmixes; }

	protected:
		// Initialize the submix internal
		AUDIOMIXER_API void InitInternal();

		// Down mix the given buffer to the desired down mix channel count
		static AUDIOMIXER_API void DownmixBuffer(const int32 InChannels, const FAlignedFloatBuffer& InBuffer, const int32 OutChannels, FAlignedFloatBuffer& OutNewBuffer);

		AUDIOMIXER_API void MixBufferDownToMono(const FAlignedFloatBuffer& InBuffer, int32 NumInputChannels, FAlignedFloatBuffer& OutBuffer);

		AUDIOMIXER_API void SetupSoundfieldEncodersForChildren();
		AUDIOMIXER_API void SetupSoundfieldEncodingForChild(FChildSubmixInfo& InChild);

		// Check to see if we need to decode from ambisonics for parent
		AUDIOMIXER_API void SetupSoundfieldStreamForParent();

		// This sets up the ambisonics positional data for speakers, based on what new format we need to convert to.
		AUDIOMIXER_API void SetUpSoundfieldPositionalData(const TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe>& InParentSubmix);

		// Encode a source and sum it into the mixed soundfield.
		AUDIOMIXER_API void MixInSource(const ISoundfieldAudioPacket& InAudio, const ISoundfieldEncodingSettingsProxy& InSettings, ISoundfieldAudioPacket& PacketToSumTo);

		AUDIOMIXER_API void UpdateListenerRotation(const FQuat& InRotation);

		// Calls ProcessAudio on the child submix, performs all necessary conversions and mixes in it's resulting audio.
		AUDIOMIXER_API void MixInChildSubmix(FChildSubmixInfo& Child, ISoundfieldAudioPacket& PacketToSumTo);

		AUDIOMIXER_API FName GetSoundfieldFormat() const;

		AUDIOMIXER_API TUniquePtr<ISoundfieldTranscodeStream> GetTranscoderForChildSubmix(const TSharedPtr<Audio::FMixerSubmix, ESPMode::ThreadSafe>& InChildSubmix);

	protected:
		struct AUDIOMIXER_API FSubmixBufferListenerInfo
		{
			ISubmixBufferListener* Listener = nullptr;
			FString Descriptor;
		};

		// Pump command queue
		AUDIOMIXER_API void PumpCommandQueue();

		// Add command to the command queue
		AUDIOMIXER_API void SubmixCommand(TFunction<void()> Command);

		// Generates audio from the given effect chain into the given buffer
		AUDIOMIXER_API bool GenerateEffectChainAudio(FSoundEffectSubmixInputData& InputData, const FAlignedFloatBuffer& InAudioBuffer, TArray<FSoundEffectSubmixPtr>& InEffectChain, FAlignedFloatBuffer& OutBuffer);

		// The name of this submix (the owning USoundSubmix) (at top so we can see in debugger it's name)
		FString SubmixName;
		
		// This mixer submix's Id
		uint32 Id;

		// Parent submix. 
		TWeakPtr<FMixerSubmix, ESPMode::ThreadSafe> ParentSubmix;

		// Child submixes
		TMap<uint32, FChildSubmixInfo> ChildSubmixes;

		// Struct to hold record keeping data about effect chain overrides
		struct FSubmixEffectFadeInfo
		{
			TArray<FSoundEffectSubmixPtr> EffectChain;

			FDynamicParameter FadeVolume = FDynamicParameter(1.0f);

			// If true, this effect override will be fading in or all the way faded in
			bool bIsCurrentChain = false;

			// If this effect fade info is the base effect
			bool bIsBaseEffect = false;
		};

		// The array of submix effect overrides. There may be more than one if multiple are fading out. There should be only one fading in (the current override).
		TArray<FSubmixEffectFadeInfo> EffectChains;
		FAlignedFloatBuffer EffectChainOutputBuffer;

		// Owning mixer device. 
		FMixerDevice* MixerDevice;

		// Map of mixer source voices with a given send level for this submix
		TMap<FMixerSourceVoice*, FSubmixVoiceData> MixerSourceVoices;

		FAlignedFloatBuffer ScratchBuffer;
		FAlignedFloatBuffer SubmixChainMixBuffer;
		FAlignedFloatBuffer InputBuffer;
		FAlignedFloatBuffer DownmixedBuffer;
		FAlignedFloatBuffer SourceInputBuffer;

		int32 NumChannels;
		int32 NumSamples;

		/**
		 * Individual processor in our 
		 */
		struct FSoundfieldEffectProcessorData
		{
			TUniquePtr<ISoundfieldEffectSettingsProxy> Settings;
			TUniquePtr<ISoundfieldEffectInstance> Processor;

			FSoundfieldEffectProcessorData(ISoundfieldFactory* InFactory, ISoundfieldEncodingSettingsProxy& InSettings, USoundfieldEffectBase* InProcessorBase)
			{
				check(InFactory);

				// As a sanity check, make sure if we've gotten to this point, this DSP processor supports this submix's format.
				check(InProcessorBase->SupportsFormat(InFactory->GetSoundfieldFormatName()));

				Processor = InProcessorBase->PrivateGetNewProcessor(InSettings);
				
				// If the processor doesn't have any settings, get the default settings for a processor of this type.
				const USoundfieldEffectSettingsBase* ProcessorSettings = InProcessorBase->Settings;
				if (!ProcessorSettings)
				{
					ProcessorSettings = InProcessorBase->PrivateGetDefaultSettings();
				}

				Settings = ProcessorSettings->PrivateGetProxy();
			}
		};

		struct FSoundfieldStreams
		{
			ISoundfieldFactory* Factory;

			// This encoder is used for the mixed down audio from all non-soundfield submixes plugged into
			// this submix. Will not be set up if ISoundfieldFactory::ShouldEncodeAllStreamsIndependently 
			// returns true.
			TUniquePtr<ISoundfieldEncoderStream> DownmixedChildrenEncoder;
			
			// Encoder used if a normal submix outputs to this submix.
			TUniquePtr<ISoundfieldDecoderStream> ParentDecoder;

			// This is the positional data we are decoding 
			FSoundfieldSpeakerPositionalData CachedPositionalData;

			// Mixes all encoded child submix inputs.
			TUniquePtr<ISoundfieldMixerStream> Mixer;

			// This is the packet we mix all input sources and child submixes to.
			TUniquePtr<ISoundfieldAudioPacket> MixedDownAudio;

			// Current settings for this submix.
			TUniquePtr<ISoundfieldEncodingSettingsProxy> Settings;

			// All soundfield processors attached to this submix.  
			TArray<FSoundfieldEffectProcessorData> EffectProcessors;

			// This critical section is contended by the soundfield overload of ProcessAudio and SetupSoundfieldStreams.
			FCriticalSection StreamsLock;

			FSoundfieldStreams()
				: Factory(nullptr)
			{}

			void Reset()
			{
				Factory = nullptr;
				ParentDecoder.Reset();
				Mixer.Reset();
				Settings.Reset();
			}
		};

		FSoundfieldStreams SoundfieldStreams;

		struct FEndpointData
		{
			// For endpoint submixes,
			// this is the primary method of pushing audio to the endpoint.
			Audio::FPatchInput Input;

			TUniquePtr<IAudioEndpoint> NonSoundfieldEndpoint;
			TUniquePtr<ISoundfieldEndpoint> SoundfieldEndpoint;

			// for non-soundfield endpoints, we use these buffers for processing.
			FAlignedFloatBuffer AudioBuffer;
			FAlignedFloatBuffer ResampledAudioBuffer;
			FAlignedFloatBuffer DownmixedResampledAudioBuffer;
			FAlignedFloatBuffer DownmixChannelMap;

			// Number of channels and sample rate for the external endpoint.
			int32 NumChannels;
			float SampleRate;

			// This is used if the endpoint has a different sample rate than our audio engine.
			Audio::FResampler Resampler;
			bool bShouldResample;

			// for soundfield endpoints, this is the buffer we use to send audio to the endpoint.
			TUniquePtr<ISoundfieldAudioPacket> AudioPacket;

			FEndpointData()
				: NumChannels(0)
				, SampleRate(0.0f)
				, bShouldResample(false)
			{}

			void Reset()
			{
				AudioBuffer.Reset();
				ResampledAudioBuffer.Reset();
				DownmixedResampledAudioBuffer.Reset();
				DownmixChannelMap.Reset();
				NonSoundfieldEndpoint.Reset();
				SoundfieldEndpoint.Reset();
			}
		};

		FEndpointData EndpointData;
		
		float CurrentOutputVolume;
		float TargetOutputVolume;
		float CurrentWetLevel;
		float TargetWetLevel;
		float CurrentDryLevel;
		float TargetDryLevel;

		FModulationDestination VolumeMod;
		FModulationDestination DryLevelMod;
		FModulationDestination WetLevelMod;

		float VolumeModBaseDb = 0.f;
		float DryModBaseDb = MIN_VOLUME_DECIBELS;
		float WetModBaseDb = 0.f;

		// modifiers set from BP code
		float VolumeModifier = 1.f;
		float DryLevelModifier = 1.f;
		float WetLevelModifier = 1.f;

		// Envelope following data
		float EnvelopeValues[AUDIO_MIXER_MAX_OUTPUT_CHANNELS];
		Audio::FEnvelopeFollower EnvelopeFollower;
		int32 EnvelopeNumChannels;
		FCriticalSection EnvelopeCriticalSection;

		// Spectrum analyzer. Created and destroyed on the audio thread.
		FCriticalSection SpectrumAnalyzerCriticalSection;
		FSoundSpectrumAnalyzerSettings SpectrumAnalyzerSettings;
		TSharedPtr<FAsyncSpectrumAnalyzer, ESPMode::ThreadSafe> SpectrumAnalyzer;
		
		// This buffer is used to downmix the submix output to mono before submitting it to the SpectrumAnalyzer.
		FAlignedFloatBuffer MonoMixBuffer;

		// The dry channel buffer
		FAlignedFloatBuffer DryChannelBuffer;

		// Submix command queue to shuffle commands from audio thread to audio render thread.
		TQueue<TFunction<void()>> CommandQueue;

		// List of submix buffer listeners. (mutable for pruning stale weak references)

		mutable TArray<TWeakPtr<ISubmixBufferListener>> BufferListenerPtrs;
		// Critical section used for modifying and interacting with buffer listeners
		mutable FCriticalSection BufferListenerCriticalSection;

		// This buffer is used for recorded output of the submix.
		FAlignedFloatBuffer RecordingData;

		// Returns the number of submix effects
		int32 NumSubmixEffects;

		// Bool set to true when this submix is recording data.
		uint8 bIsRecording : 1;

		// Whether or not this submix is muted.
		uint8 bIsBackgroundMuted : 1;

		// Whether or not auto-disablement is enabled. If true, the submix will disable itself.
		uint8 bAutoDisable : 1;

		// Whether or not the submix is currently rendering audio. I.e. audio was sent to it and mixing it, or any of its child submixes are rendering audio.
		uint8 bIsSilent : 1;

		// Whether or not we're currently disabled (i.e. the submix has been silent)
		uint8 bIsCurrentlyDisabled : 1;

		// The time to wait to disable the submix if the auto-disablement is active.
		double AutoDisableTime;

		// The time that the first full silent buffer was detected in the submix. Submix will auto-disable if the timeout is reached and the submix has bAutoDisable set to true.
		double SilenceTimeStartSeconds;

		// Bool set to true when envelope following is enabled
		FThreadSafeBool bIsEnvelopeFollowing;

		// Multi-cast delegate to broadcast envelope data from this submix instance
		FOnSubmixEnvelope OnSubmixEnvelope;

		struct FSpectralAnalysisBandInfo
		{
			FInlineEnvelopeFollower EnvelopeFollower;
		};

		struct FSpectrumAnalysisDelegateInfo
		{
			FSoundSpectrumAnalyzerDelegateSettings DelegateSettings;

			FOnSubmixSpectralAnalysis OnSubmixSpectralAnalysis;

			TUniquePtr<ISpectrumBandExtractor> SpectrumBandExtractor;
			TArray<FSpectralAnalysisBandInfo> SpectralBands;

			float LastUpdateTime = -1.0f;
			float UpdateDelta = 0.0f;

			FSpectrumAnalysisDelegateInfo()
			{
			}

			FSpectrumAnalysisDelegateInfo(FSpectrumAnalysisDelegateInfo&& Other)
			{
				OnSubmixSpectralAnalysis = Other.OnSubmixSpectralAnalysis;
				SpectrumBandExtractor.Reset(Other.SpectrumBandExtractor.Release());
				DelegateSettings = Other.DelegateSettings;
				SpectralBands = Other.SpectralBands;
			}

			~FSpectrumAnalysisDelegateInfo()
			{
			}
		};

		TArray<FSpectrumAnalysisDelegateInfo> SpectralAnalysisDelegates;

		// Bool set to true when spectrum analysis is enabled
		FThreadSafeBool bIsSpectrumAnalyzing;

		// Critical section used for when we are appending recorded data.
		FCriticalSection RecordingCriticalSection;

		// Critical section for mutation of the effect chain.
		FCriticalSection EffectChainMutationCriticalSection;

		// Handle back to the owning USoundSubmix. Used when the device is shutdown to prematurely end a recording.
		TWeakObjectPtr<const USoundSubmixBase> OwningSubmixObject;

		Audio::FPatchSplitter PatchSplitter;

		TUniquePtr<IAudioLink> AudioLinkInstance;

		friend class FMixerDevice;

	private:
		AUDIOMIXER_API void SendAudioToRegisteredAudioBuses(FAlignedFloatBuffer& OutAudioBuffer);

		void UnregisterBufferListenerInternal(UPTRINT ListenerBufferPtr);

		void PruneSubmixBufferListeners();

		// Registered audio buses
		TMap<Audio::FAudioBusKey, Audio::FPatchInput> AudioBuses;
	};
}

==========================


=== AudioMixerSubmixEffectDynamicsProcessor.cpp ===
===================================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "SubmixEffects/AudioMixerSubmixEffectDynamicsProcessor.h"

#include "AudioBusSubsystem.h"
#include "AudioDeviceManager.h"
#include "AudioMixerDevice.h"
#include "AudioMixerSubmix.h"
#include "ProfilingDebugging/CsvProfiler.h"
#include "ProfilingDebugging/CpuProfilerTrace.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioMixerSubmixEffectDynamicsProcessor)

// Link to "Audio" profiling category
CSV_DECLARE_CATEGORY_MODULE_EXTERN(AUDIOMIXERCORE_API, Audio);

DEFINE_STAT(STAT_AudioMixerSubmixDynamics);

static int32 bBypassSubmixDynamicsProcessor = 0;
FAutoConsoleVariableRef CVarBypassDynamicsProcessor(
	TEXT("au.Submix.Effects.DynamicsProcessor.Bypass"),
	bBypassSubmixDynamicsProcessor,
	TEXT("If non-zero, bypasses all submix dynamics processors currently active.\n"),
	ECVF_Default);

FSubmixEffectDynamicsProcessor::FSubmixEffectDynamicsProcessor()
{
	DeviceCreatedHandle = FAudioDeviceManagerDelegates::OnAudioDeviceCreated.AddRaw(this, &FSubmixEffectDynamicsProcessor::OnDeviceCreated);
	DeviceDestroyedHandle = FAudioDeviceManagerDelegates::OnAudioDeviceDestroyed.AddRaw(this, &FSubmixEffectDynamicsProcessor::OnDeviceDestroyed);
}

FSubmixEffectDynamicsProcessor::~FSubmixEffectDynamicsProcessor()
{
	ResetKey();

	FAudioDeviceManagerDelegates::OnAudioDeviceCreated.Remove(DeviceCreatedHandle);
	FAudioDeviceManagerDelegates::OnAudioDeviceDestroyed.Remove(DeviceDestroyedHandle);
}

Audio::FDeviceId FSubmixEffectDynamicsProcessor::GetDeviceId() const
{
	return DeviceId;
}

void FSubmixEffectDynamicsProcessor::Init(const FSoundEffectSubmixInitData& InitData)
{
	static const int32 ProcessorScratchNumChannels = 8;

	DynamicsProcessor.Init(InitData.SampleRate, ProcessorScratchNumChannels);

	DeviceId = InitData.DeviceID;

	if (USubmixEffectDynamicsProcessorPreset* ProcPreset = Cast<USubmixEffectDynamicsProcessorPreset>(Preset.Get()))
	{
		switch (ProcPreset->Settings.KeySource)
		{
			case ESubmixEffectDynamicsKeySource::AudioBus:
			{
				if (UAudioBus* AudioBus = ProcPreset->Settings.ExternalAudioBus)
				{
					KeySource.Update(ESubmixEffectDynamicsKeySource::AudioBus, AudioBus->GetUniqueID(), static_cast<int32>(AudioBus->AudioBusChannels) + 1);
				}
			}
			break;

			case ESubmixEffectDynamicsKeySource::Submix:
			{
				if (USoundSubmix* Submix = ProcPreset->Settings.ExternalSubmix)
				{
					KeySource.Update(ESubmixEffectDynamicsKeySource::Submix, Submix->GetUniqueID());
				}
			}
			break;

			default:
			{
				// KeySource is this effect's submix/input, so do nothing
			}
			break;
		}
	}
}

void FSubmixEffectDynamicsProcessor::ResetKey()
{
	KeySource.Reset();
}

void FSubmixEffectDynamicsProcessor::OnPresetChanged()
{
	GET_EFFECT_SETTINGS(SubmixEffectDynamicsProcessor);

	bBypass = Settings.bBypass;

	switch (Settings.DynamicsProcessorType)
	{
	default:
	case ESubmixEffectDynamicsProcessorType::Compressor:
		DynamicsProcessor.SetProcessingMode(Audio::EDynamicsProcessingMode::Compressor);
		break;

	case ESubmixEffectDynamicsProcessorType::Limiter:
		DynamicsProcessor.SetProcessingMode(Audio::EDynamicsProcessingMode::Limiter);
		break;

	case ESubmixEffectDynamicsProcessorType::Expander:
		DynamicsProcessor.SetProcessingMode(Audio::EDynamicsProcessingMode::Expander);
		break;

	case ESubmixEffectDynamicsProcessorType::Gate:
		DynamicsProcessor.SetProcessingMode(Audio::EDynamicsProcessingMode::Gate);
		break;

	case ESubmixEffectDynamicsProcessorType::UpwardsCompressor:
		DynamicsProcessor.SetProcessingMode(Audio::EDynamicsProcessingMode::UpwardsCompressor);
		break;
	}

	switch (Settings.PeakMode)
	{
	default:
	case ESubmixEffectDynamicsPeakMode::MeanSquared:
		DynamicsProcessor.SetPeakMode(Audio::EPeakMode::MeanSquared);
		break;

	case ESubmixEffectDynamicsPeakMode::RootMeanSquared:
		DynamicsProcessor.SetPeakMode(Audio::EPeakMode::RootMeanSquared);
		break;

	case ESubmixEffectDynamicsPeakMode::Peak:
		DynamicsProcessor.SetPeakMode(Audio::EPeakMode::Peak);
		break;
	}

	DynamicsProcessor.SetLookaheadMsec(Settings.LookAheadMsec);
	DynamicsProcessor.SetAttackTime(Settings.AttackTimeMsec);
	DynamicsProcessor.SetReleaseTime(Settings.ReleaseTimeMsec);
	DynamicsProcessor.SetThreshold(Settings.ThresholdDb);
	DynamicsProcessor.SetRatio(Settings.Ratio);
	DynamicsProcessor.SetKneeBandwidth(Settings.KneeBandwidthDb);
	DynamicsProcessor.SetInputGain(Settings.InputGainDb);
	DynamicsProcessor.SetOutputGain(Settings.OutputGainDb);
	DynamicsProcessor.SetAnalogMode(Settings.bAnalogMode);

	DynamicsProcessor.SetKeyAudition(Settings.bKeyAudition);
	DynamicsProcessor.SetKeyGain(Settings.KeyGainDb);
	DynamicsProcessor.SetKeyHighshelfCutoffFrequency(Settings.KeyHighshelf.Cutoff);
	DynamicsProcessor.SetKeyHighshelfEnabled(Settings.KeyHighshelf.bEnabled);
	DynamicsProcessor.SetKeyHighshelfGain(Settings.KeyHighshelf.GainDb);
	DynamicsProcessor.SetKeyLowshelfCutoffFrequency(Settings.KeyLowshelf.Cutoff);
	DynamicsProcessor.SetKeyLowshelfEnabled(Settings.KeyLowshelf.bEnabled);
	DynamicsProcessor.SetKeyLowshelfGain(Settings.KeyLowshelf.GainDb);

	static_assert(static_cast<int32>(ESubmixEffectDynamicsChannelLinkMode::Count) == static_cast<int32>(Audio::EDynamicsProcessorChannelLinkMode::Count), "Enumerations must match");
	DynamicsProcessor.SetChannelLinkMode(static_cast<Audio::EDynamicsProcessorChannelLinkMode>(Settings.LinkMode));

	UpdateKeyFromSettings(Settings);
}

Audio::FMixerDevice* FSubmixEffectDynamicsProcessor::GetMixerDevice()
{
	if (FAudioDeviceManager* DeviceManager = FAudioDeviceManager::Get())
	{
		return static_cast<Audio::FMixerDevice*>(DeviceManager->GetAudioDeviceRaw(DeviceId));
	}

	return nullptr;
}

bool FSubmixEffectDynamicsProcessor::UpdateKeySourcePatch()
{
	// Default (input as key) does not use source patch, so don't
	// continue checking or updating state.
	if (KeySource.GetType() == ESubmixEffectDynamicsKeySource::Default)
	{
		return false;
	}

	if (KeySource.Patch.IsValid())
	{
		return true;
	}

	switch (KeySource.GetType())
	{
		case ESubmixEffectDynamicsKeySource::AudioBus:
		{
			// Retrieving/mutating the MixerDevice is only safe during OnProcessAudio calls if
			// it is not called during Teardown.  The DynamicsProcessor should be Reset via
			// the OnDeviceDestroyed callback (prior to FAudioDevice::Teardown), so this call
			// should never be hit during Teardown.
			if (Audio::FMixerDevice* MixerDevice = GetMixerDevice())
			{
				const uint32 ObjectId = KeySource.GetObjectId();
				if (ObjectId != INDEX_NONE)
				{
					UAudioBusSubsystem* AudioBusSubsystem = MixerDevice->GetSubsystem<UAudioBusSubsystem>();
					if (AudioBusSubsystem)
					{
						const int32 NumChannels = KeySource.GetNumChannels();
						AudioBusSubsystem->StartAudioBus(Audio::FAudioBusKey(ObjectId), NumChannels, /*bInIsAutomatic=*/false);
						KeySource.Patch = AudioBusSubsystem->AddPatchOutputForAudioBus(Audio::FAudioBusKey(ObjectId), MixerDevice->GetNumOutputFrames(), NumChannels);
						DynamicsProcessor.SetKeyNumChannels(NumChannels);
					}
				}
			}
		}
		break;

		case ESubmixEffectDynamicsKeySource::Submix:
		{
			// Retrieving/mutating the MixerDevice is only safe during OnProcessAudio calls if
			// it is not called during Teardown.  The DynamicsProcessor should be Reset via
			// the OnDeviceDestroyed callback (prior to FAudioDevice::Teardown), so this call
			// should never be hit during Teardown.
			if (Audio::FMixerDevice* MixerDevice = GetMixerDevice())
			{
				const uint32 ObjectId = KeySource.GetObjectId();
				if (ObjectId != INDEX_NONE)
				{
					KeySource.Patch = MixerDevice->AddPatchForSubmix(ObjectId, 1.0f /* PatchGain */);
					if (KeySource.Patch.IsValid())
					{
						Audio::FMixerSubmixPtr SubmixPtr = MixerDevice->FindSubmixInstanceByObjectId(KeySource.GetObjectId());
						if (SubmixPtr.IsValid())
						{
							const int32 SubmixNumChannels = SubmixPtr->GetNumOutputChannels();
							KeySource.SetNumChannels(SubmixNumChannels);
							DynamicsProcessor.SetKeyNumChannels(SubmixNumChannels);
							return true;
						}
					}
				}	
			}
		}
		break;

		case ESubmixEffectDynamicsKeySource::Default:
		default:
		{
		}
		break;
	}

	return false;
}

void FSubmixEffectDynamicsProcessor::OnProcessAudio(const FSoundEffectSubmixInputData& InData, FSoundEffectSubmixOutputData& OutData)
{
	CSV_SCOPED_TIMING_STAT(Audio, SubmixDynamics);
	SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixDynamics);
	TRACE_CPUPROFILER_EVENT_SCOPE(FSubmixEffectDynamicsProcessor::OnProcessAudio);

	ensure(InData.NumChannels == OutData.NumChannels);

	const Audio::FAlignedFloatBuffer& InBuffer = *InData.AudioBuffer;
	Audio::FAlignedFloatBuffer& OutBuffer = *OutData.AudioBuffer;

	if (bBypassSubmixDynamicsProcessor || bBypass)
	{
		FMemory::Memcpy(OutBuffer.GetData(), InBuffer.GetData(), sizeof(float) * InBuffer.Num());
		return;
	}

	int32 NumKeyChannels = DynamicsProcessor.GetKeyNumChannels();
	int32 NumKeySamples = InData.NumFrames * NumKeyChannels;

	AudioExternal.Reset();
	
	// If set to default, enforce num key channels to always be number of input channels.
	// If either unset or KeySource was changed between frames back to 'Default', NumKeyChannels
	// could be stale or left as initialized number of scratch channels.
	if (KeySource.GetType() == ESubmixEffectDynamicsKeySource::Default)
	{
		if (InData.NumChannels != NumKeyChannels)
		{
			NumKeyChannels = InData.NumChannels;
			NumKeySamples = InData.NumFrames * NumKeyChannels;
			DynamicsProcessor.SetKeyNumChannels(NumKeyChannels);
		}
	}
	else
	{
		AudioExternal.AddZeroed(NumKeySamples);
	}

	if (UpdateKeySourcePatch())
	{
		KeySource.Patch->PopAudio(AudioExternal.GetData(), NumKeySamples, true /* bUseLatestAudio */);
	}

	if (InData.NumChannels != DynamicsProcessor.GetNumChannels())
	{
		DynamicsProcessor.SetNumChannels(InData.NumChannels);
	}

	// No key assigned (Uses input buffer as key)
	if (KeySource.GetType() == ESubmixEffectDynamicsKeySource::Default)
	{
		DynamicsProcessor.ProcessAudio(InBuffer.GetData(), InData.NumChannels * InData.NumFrames, OutBuffer.GetData());
	}
	// Key assigned
	else
	{
		DynamicsProcessor.ProcessAudio(InBuffer.GetData(), InData.NumChannels * InData.NumFrames, OutBuffer.GetData(), AudioExternal.GetData());
	}
}

void FSubmixEffectDynamicsProcessor::UpdateKeyFromSettings(const FSubmixEffectDynamicsProcessorSettings& InSettings)
{
	uint32 ObjectId = INDEX_NONE;
	int32 SourceNumChannels = 0;
	switch (InSettings.KeySource)
	{
		case ESubmixEffectDynamicsKeySource::AudioBus:
		{
			if (InSettings.ExternalAudioBus)
			{
				ObjectId = InSettings.ExternalAudioBus->GetUniqueID();
				SourceNumChannels = static_cast<int32>(InSettings.ExternalAudioBus->AudioBusChannels) + 1;
			}
		}
		break;

		case ESubmixEffectDynamicsKeySource::Submix:
		{
			if (InSettings.ExternalSubmix)
			{
				ObjectId = InSettings.ExternalSubmix->GetUniqueID();
			}
		}
		break;

		default:
		{
		}
		break;
	}

	KeySource.Update(InSettings.KeySource, ObjectId, SourceNumChannels);
}

void FSubmixEffectDynamicsProcessor::OnDeviceCreated(Audio::FDeviceId InDeviceId)
{
	if (InDeviceId == DeviceId)
	{
		GET_EFFECT_SETTINGS(SubmixEffectDynamicsProcessor);
		UpdateKeyFromSettings(Settings);

		FAudioDeviceManagerDelegates::OnAudioDeviceCreated.Remove(DeviceCreatedHandle);
	}
}

void FSubmixEffectDynamicsProcessor::OnDeviceDestroyed(Audio::FDeviceId InDeviceId)
{
	if (InDeviceId == DeviceId)
	{
		// Reset the key on device destruction to avoid reinitializing
		// it during FAudioDevice::Teardown via ProcessAudio.
		ResetKey();
		FAudioDeviceManagerDelegates::OnAudioDeviceDestroyed.Remove(DeviceDestroyedHandle);
	}
}

void USubmixEffectDynamicsProcessorPreset::OnInit()
{
	switch (Settings.KeySource)
	{
		case ESubmixEffectDynamicsKeySource::AudioBus:
		{
			SetAudioBus(Settings.ExternalAudioBus);
		}
		break;

		case ESubmixEffectDynamicsKeySource::Submix:
		{
			SetExternalSubmix(Settings.ExternalSubmix);
		}
		break;

		default:
		{
		}
		break;
	}
}

#if WITH_EDITOR
void USubmixEffectDynamicsProcessorPreset::PostEditChangeChainProperty(struct FPropertyChangedChainEvent& InChainEvent)
{
	if (InChainEvent.GetPropertyName() == GET_MEMBER_NAME_CHECKED(FSubmixEffectDynamicsProcessorSettings, KeySource))
	{
		switch (Settings.KeySource)
		{
		case ESubmixEffectDynamicsKeySource::AudioBus:
		{
			Settings.ExternalSubmix = nullptr;
		}
		break;

		case ESubmixEffectDynamicsKeySource::Submix:
		{
			Settings.ExternalAudioBus = nullptr;
		}
		break;

		case ESubmixEffectDynamicsKeySource::Default:
		default:
		{
			Settings.ExternalSubmix = nullptr;
			Settings.ExternalAudioBus = nullptr;
			static_assert(static_cast<int32>(ESubmixEffectDynamicsKeySource::Count) == 3, "Possible missing KeySource switch case coverage");
		}
		break;
		}
	}

	Super::PostEditChangeChainProperty(InChainEvent);
}
#endif // WITH_EDITOR

void USubmixEffectDynamicsProcessorPreset::Serialize(FStructuredArchive::FRecord Record)
{
	FArchive& UnderlyingArchive = Record.GetUnderlyingArchive();
	if (UnderlyingArchive.IsLoading())
	{
		if (Settings.bChannelLinked_DEPRECATED)
		{
			Settings.LinkMode = ESubmixEffectDynamicsChannelLinkMode::Average;
			Settings.bChannelLinked_DEPRECATED = 0;
		}
	}

	Super::Serialize(Record);
}

void USubmixEffectDynamicsProcessorPreset::ResetKey()
{
	EffectCommand<FSubmixEffectDynamicsProcessor>([](FSubmixEffectDynamicsProcessor& Instance)
	{
		Instance.ResetKey();
	});
}

void USubmixEffectDynamicsProcessorPreset::SetAudioBus(UAudioBus* InAudioBus)
{
	int32 BusChannels = 0;
	if (InAudioBus)
	{
		BusChannels = static_cast<int32>(InAudioBus->AudioBusChannels) + 1;
		SetKey(ESubmixEffectDynamicsKeySource::AudioBus, InAudioBus, BusChannels);
	}
	else
	{
		ResetKey();
	}
}

void USubmixEffectDynamicsProcessorPreset::SetExternalSubmix(USoundSubmix* InSubmix)
{
	if (InSubmix)
	{
		SetKey(ESubmixEffectDynamicsKeySource::Submix, InSubmix);
	}
	else
	{
		ResetKey();
	}
}

void USubmixEffectDynamicsProcessorPreset::SetKey(ESubmixEffectDynamicsKeySource InKeySource, UObject* InObject, int32 InNumChannels)
{
	if (InObject)
	{
		EffectCommand<FSubmixEffectDynamicsProcessor>([this, ObjectId = InObject->GetUniqueID(), InKeySource, InNumChannels](FSubmixEffectDynamicsProcessor& Instance)
		{
			Instance.KeySource.Update(InKeySource, ObjectId, InNumChannels);
		});
	}
}

void USubmixEffectDynamicsProcessorPreset::SetSettings(const FSubmixEffectDynamicsProcessorSettings& InSettings)
{
	UpdateSettings(InSettings);

	IterateEffects<FSubmixEffectDynamicsProcessor>([&](FSubmixEffectDynamicsProcessor& Instance)
	{
		Instance.UpdateKeyFromSettings(InSettings);
	});
}


===================================================


=== AudioMixerSubmixEffectDynamicsProcessor.h ===
=================================================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "AudioDevice.h"
#include "Delegates/IDelegateInstance.h"
#include "DSP/DynamicsProcessor.h"
#include "DSP/MultithreadedPatching.h"
#include "Misc/ScopeLock.h"
#include "Sound/SoundEffectSubmix.h"
#include "Sound/SoundSubmix.h"
#include "Sound/SoundSubmixSend.h"
#include "Stats/Stats.h"

#include "AudioMixerSubmixEffectDynamicsProcessor.generated.h"

// The time it takes to process the master dynamics.
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Dynamics"), STAT_AudioMixerSubmixDynamics, STATGROUP_AudioMixer, AUDIOMIXER_API);

namespace Audio
{
	// Forward Declarations
	class FMixerDevice;
}

UENUM(BlueprintType)
enum class ESubmixEffectDynamicsProcessorType : uint8
{
	Compressor = 0,
	Limiter,
	Expander,
	Gate,
	UpwardsCompressor,
	Count UMETA(Hidden)
};

UENUM(BlueprintType)
enum class ESubmixEffectDynamicsPeakMode : uint8
{
	MeanSquared = 0,
	RootMeanSquared,
	Peak,
	Count UMETA(Hidden)
};

UENUM(BlueprintType)
enum class ESubmixEffectDynamicsChannelLinkMode : uint8
{
	Disabled = 0,
	Average,
	Peak,
	Count UMETA(Hidden)
};

UENUM(BlueprintType)
enum class ESubmixEffectDynamicsKeySource : uint8
{
	// Defaults to use local submix (input) as key
	Default = 0,

	// Uses audio bus as key
	AudioBus,

	// Uses external submix as key
	Submix,

	Count UMETA(Hidden)
};

class FKeySource
{
	ESubmixEffectDynamicsKeySource Type = ESubmixEffectDynamicsKeySource::Default;
	int32 NumChannels = 0;
	uint32 ObjectId = INDEX_NONE;

	mutable FCriticalSection MutateSourceCritSection;

public:
	Audio::FPatchOutputStrongPtr Patch;

	void Reset()
	{
		Patch.Reset();

		{
			const FScopeLock ScopeLock(&MutateSourceCritSection);
			NumChannels = 0;
			ObjectId = INDEX_NONE;
			Type = ESubmixEffectDynamicsKeySource::Default;
		}
	}

	uint32 GetObjectId() const
	{
		const FScopeLock ScopeLock(&MutateSourceCritSection);
		return ObjectId;
	}

	int32 GetNumChannels() const
	{
		const FScopeLock ScopeLock(&MutateSourceCritSection);
		return NumChannels;
	}

	ESubmixEffectDynamicsKeySource GetType() const
	{
		const FScopeLock ScopeLock(&MutateSourceCritSection);
		return Type;
	}

	void SetNumChannels(const int32 InNumChannels)
	{
		const FScopeLock ScopeLock(&MutateSourceCritSection);
		NumChannels = InNumChannels;
	}

	void Update(ESubmixEffectDynamicsKeySource InType, uint32 InObjectId, int32 InNumChannels = 0)
	{
		bool bResetPatch = false;

		{
			const FScopeLock ScopeLock(&MutateSourceCritSection);
			if (Type != InType || ObjectId != InObjectId || NumChannels != InNumChannels)
			{
				Type = InType;
				ObjectId = InObjectId;
				NumChannels = InNumChannels;

				bResetPatch = true;
			}
		}

		if (bResetPatch)
		{
			Patch.Reset();
		}
	}
};

USTRUCT(BlueprintType)
struct FSubmixEffectDynamicProcessorFilterSettings
{
	GENERATED_USTRUCT_BODY()

	// Whether or not filter is enabled
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Filter, meta = (DisplayName = "Enabled"))
	uint8 bEnabled : 1;

	// The cutoff frequency of the HPF applied to key signal
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Filter, meta = (DisplayName = "Cutoff (Hz)", EditCondition = "bEnabled", ClampMin = "20.0", ClampMax = "20000.0", UIMin = "20.0", UIMax = "20000.0"))
	float Cutoff;

	// The gain of the filter shelf applied to the key signal
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Filter, meta = (DisplayName = "Gain (dB)", EditCondition = "bEnabled", ClampMin = "-60.0", ClampMax = "6.0", UIMin = "-60.0", UIMax = "6.0"))
	float GainDb;

	FSubmixEffectDynamicProcessorFilterSettings()
		: bEnabled(false)
		, Cutoff(20.0f)
		, GainDb(0.0f)
	{
	}
};

// Submix dynamics processor settings
USTRUCT(BlueprintType)
struct FSubmixEffectDynamicsProcessorSettings
{
	GENERATED_USTRUCT_BODY()

	// Type of processor to apply
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = General, meta = (DisplayName = "Type"))
	ESubmixEffectDynamicsProcessorType DynamicsProcessorType = ESubmixEffectDynamicsProcessorType::Compressor;

	// Mode of peak detection used on input key signal
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Dynamics, meta = (EditCondition = "!bBypass"))
	ESubmixEffectDynamicsPeakMode PeakMode = ESubmixEffectDynamicsPeakMode::Peak;

	// Mode of peak detection if key signal is multi-channel
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Dynamics, meta = (EditCondition = "!bBypass"))
	ESubmixEffectDynamicsChannelLinkMode LinkMode = ESubmixEffectDynamicsChannelLinkMode::Average;

	// The input gain of the dynamics processor
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = General, meta = (DisplayName = "Input Gain (dB)", UIMin = "-12.0", UIMax = "20.0", EditCondition = "!bBypass"))
	float InputGainDb = 0.0f;

	// The threshold at which to perform a dynamics processing operation
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Dynamics, meta = (DisplayName = "Threshold (dB)", ClampMin = "-60.0", ClampMax = "0.0", UIMin = "-60.0", UIMax = "0.0", EditCondition = "!bBypass"))
	float ThresholdDb = -6.0f;

	// The dynamics processor ratio used for compression/expansion
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Dynamics, meta = (
		EditCondition = "!bBypass && DynamicsProcessorType == ESubmixEffectDynamicsProcessorType::Compressor || DynamicsProcessorType == ESubmixEffectDynamicsProcessorType::Expander ||  DynamicsProcessorType == ESubmixEffectDynamicsProcessorType::UpwardsCompressor",
		ClampMin = "1.0", ClampMax = "20.0", UIMin = "1.0", UIMax = "20.0"))
	float Ratio = 1.5f;

	// The knee bandwidth of the processor to use
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Dynamics, meta = (DisplayName = "Knee (dB)", ClampMin = "0.0", ClampMax = "20.0", UIMin = "0.0", UIMax = "20.0", EditCondition = "!bBypass"))
	float KneeBandwidthDb = 10.0f;

	// The amount of time to look ahead of the current audio (Allows for transients to be included in dynamics processing)
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Response,  meta = (DisplayName = "Look Ahead (ms)", ClampMin = "0.0", ClampMax = "50.0", UIMin = "0.0", UIMax = "50.0", EditCondition = "!bBypass"))
	float LookAheadMsec = 3.0f;

	// The amount of time to ramp into any dynamics processing effect
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Response, meta = (DisplayName = "AttackTime (ms)", ClampMin = "1.0", ClampMax = "300.0", UIMin = "1.0", UIMax = "200.0", EditCondition = "!bBypass"))
	float AttackTimeMsec = 10.0f;

	// The amount of time to release the dynamics processing effect
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Response, meta = (DisplayName = "Release Time (ms)", ClampMin = "20.0", ClampMax = "5000.0", UIMin = "20.0", UIMax = "5000.0", EditCondition = "!bBypass"))
	float ReleaseTimeMsec = 100.0f;

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sidechain, meta = (EditCondition = "!bBypass"))
	ESubmixEffectDynamicsKeySource KeySource = ESubmixEffectDynamicsKeySource::Default;

	// If set, uses output of provided audio bus as modulator of input signal for dynamics processor (Uses input signal as default modulator)
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sidechain, meta = (EditCondition = "!bBypass && KeySource == ESubmixEffectDynamicsKeySource::AudioBus", EditConditionHides))
	TObjectPtr<UAudioBus> ExternalAudioBus = nullptr;

	// If set, uses output of provided submix as modulator of input signal for dynamics processor (Uses input signal as default modulator)
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sidechain, meta = (EditCondition = "!bBypass && KeySource == ESubmixEffectDynamicsKeySource::Submix", EditConditionHides))
	TObjectPtr<USoundSubmix> ExternalSubmix = nullptr;

	UPROPERTY()
	uint8 bChannelLinked_DEPRECATED : 1;

	// Toggles treating the attack and release envelopes as analog-style vs digital-style (Analog will respond a bit more naturally/slower)
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Response, meta = (EditCondition = "!bBypass"))
	uint8 bAnalogMode : 1;

	// Whether or not to bypass effect
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = General, meta = (DisplayName = "Bypass", DisplayAfter = "DynamicsProcessorType"))
	uint8 bBypass : 1;

	// Audition the key modulation signal, bypassing enveloping and processing the input signal.
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sidechain, meta = (DisplayName = "Key Audition", EditCondition = "!bBypass"))
	uint8 bKeyAudition : 1;

	// Gain to apply to key signal if key source not set to default (input).
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sidechain, meta = (
		DisplayName = "External Input Gain (dB)",
		EditCondition = "!bBypass && KeySource != ESubmixEffectDynamicsKeySource::Default",
		UIMin = "-60.0", UIMax = "30.0")
	)
	float KeyGainDb = 0.0f;

	// The output gain of the dynamics processor
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Output, meta = (DisplayName = "Output Gain (dB)", UIMin = "-60.0", UIMax = "30.0", EditCondition = "!bBypass"))
	float OutputGainDb = 0.0f;

	// High Shelf filter settings for key signal (external signal if supplied or input signal if not)
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sidechain, meta = (DisplayName = "Key Highshelf", EditCondition = "!bBypass"))
	FSubmixEffectDynamicProcessorFilterSettings KeyHighshelf;

	// Low Shelf filter settings for key signal (external signal if supplied or input signal if not)
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sidechain, meta = (DisplayName = "Key Lowshelf", EditCondition = "!bBypass"))
	FSubmixEffectDynamicProcessorFilterSettings KeyLowshelf;

	FSubmixEffectDynamicsProcessorSettings()
		: bChannelLinked_DEPRECATED(true)
		, bAnalogMode(true)
		, bBypass(false)
		, bKeyAudition(false)
	{
		KeyLowshelf.Cutoff = 20000.0f;
	}
};


class FSubmixEffectDynamicsProcessor : public FSoundEffectSubmix
{
public:
	AUDIOMIXER_API FSubmixEffectDynamicsProcessor();

	AUDIOMIXER_API virtual ~FSubmixEffectDynamicsProcessor();

	// Gets the effect's deviceId that owns it
	AUDIOMIXER_API Audio::FDeviceId GetDeviceId() const;

	// Called on an audio effect at initialization on audio thread before audio processing begins.
	AUDIOMIXER_API virtual void Init(const FSoundEffectSubmixInitData& InInitData) override;

	// Process the input block of audio. Called on audio render thread.
	AUDIOMIXER_API virtual void OnProcessAudio(const FSoundEffectSubmixInputData& InData, FSoundEffectSubmixOutputData& OutData) override;

	// Called when an audio effect preset is changed
	AUDIOMIXER_API virtual void OnPresetChanged() override;


protected:
	AUDIOMIXER_API Audio::FMixerDevice* GetMixerDevice();

	AUDIOMIXER_API void ResetKey();
	AUDIOMIXER_API void UpdateKeyFromSettings(const FSubmixEffectDynamicsProcessorSettings& InSettings);
	AUDIOMIXER_API bool UpdateKeySourcePatch();

	AUDIOMIXER_API void OnDeviceCreated(Audio::FDeviceId InDeviceId);
	AUDIOMIXER_API void OnDeviceDestroyed(Audio::FDeviceId InDeviceId);
	
	Audio::FAlignedFloatBuffer AudioExternal;

	Audio::FDeviceId DeviceId = INDEX_NONE;

	bool bBypass = false;

private:
	FKeySource KeySource;
	Audio::FDynamicsProcessor DynamicsProcessor;

	FDelegateHandle DeviceCreatedHandle;
	FDelegateHandle DeviceDestroyedHandle;

	friend class USubmixEffectDynamicsProcessorPreset;
};

UCLASS(ClassGroup = AudioSourceEffect, meta = (BlueprintSpawnableComponent), MinimalAPI)
class USubmixEffectDynamicsProcessorPreset : public USoundEffectSubmixPreset
{
	GENERATED_BODY()

public:
	EFFECT_PRESET_METHODS(SubmixEffectDynamicsProcessor)

	AUDIOMIXER_API virtual void OnInit() override;

	AUDIOMIXER_API virtual void Serialize(FStructuredArchive::FRecord Record) override;

#if WITH_EDITOR
	AUDIOMIXER_API virtual void PostEditChangeChainProperty(struct FPropertyChangedChainEvent& InChainEvent) override;
#endif // WITH_EDITOR

	UFUNCTION(BlueprintCallable, Category = "Audio|Effects")
	AUDIOMIXER_API void ResetKey();

	// Sets the source key input as the provided AudioBus' output.  If no object is provided, key is set
	// to effect's input.
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects")
	AUDIOMIXER_API void SetAudioBus(UAudioBus* AudioBus);

	// Sets the source key input as the provided Submix's output.  If no object is provided, key is set
	// to effect's input.
	UFUNCTION(BlueprintCallable, Category = "Audio|Effects")
	AUDIOMIXER_API void SetExternalSubmix(USoundSubmix* Submix);

	UFUNCTION(BlueprintCallable, Category = "Audio|Effects")
	AUDIOMIXER_API void SetSettings(const FSubmixEffectDynamicsProcessorSettings& Settings);

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = SubmixEffectPreset, meta = (ShowOnlyInnerProperties))
	FSubmixEffectDynamicsProcessorSettings Settings;

private:
	void SetKey(ESubmixEffectDynamicsKeySource InKeySource, UObject* InObject, int32 InNumChannels = 0);
};

=================================================


=== AudioMixerSubmixEffectEQ.cpp ===
====================================

// Copyright Epic Games, Inc. All Rights Reserved.


#include "SubmixEffects/AudioMixerSubmixEffectEQ.h"
#include "Misc/ScopeLock.h"
#include "AudioMixer.h"
#include "ProfilingDebugging/CsvProfiler.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioMixerSubmixEffectEQ)

// Link to "Audio" profiling category
CSV_DECLARE_CATEGORY_MODULE_EXTERN(AUDIOMIXERCORE_API, Audio);

DEFINE_STAT(STAT_AudioMixerSubmixEQ);

static bool IsEqual(const FSubmixEffectSubmixEQSettings& Left, const FSubmixEffectSubmixEQSettings& Right)
{
	// return false if the number of bands changed
	if (Left.EQBands.Num() != Right.EQBands.Num())
	{
		return false;
	}


	for (int32 i = 0; i < Right.EQBands.Num(); ++i)
	{
		const FSubmixEffectEQBand& OtherBand = Right.EQBands[i];
		const FSubmixEffectEQBand& ThisBand = Left.EQBands[i];

		if (OtherBand.bEnabled != ThisBand.bEnabled)
		{
			return false;
		}

		if (!FMath::IsNearlyEqual(OtherBand.Bandwidth, ThisBand.Bandwidth))
		{
			return false;
		}

		if (!FMath::IsNearlyEqual(OtherBand.Frequency, ThisBand.Frequency))
		{
			return false;
		}

		if (!FMath::IsNearlyEqual(OtherBand.GainDb, ThisBand.GainDb))
		{
			return false;
		}
	}

	// If we made it this far these are equal
	return true;
}


FSubmixEffectSubmixEQ::FSubmixEffectSubmixEQ()
	: SampleRate(0)
	, NumOutputChannels(2)
{
	FMemory::Memzero((void*)ScratchInBuffer, sizeof(float) * 2);
	FMemory::Memzero((void*)ScratchOutBuffer, sizeof(float) * 2);
}

void FSubmixEffectSubmixEQ::Init(const FSoundEffectSubmixInitData& InitData)
{
	SampleRate = InitData.SampleRate;

	// Assume 8 channels (max supported channels)
	NumOutputChannels = 8;

	const int32 NumFilters = NumOutputChannels / 2;
	for (int32 i = 0; i < NumFilters; ++i)
	{
		int32 Index = FiltersPerChannel.Add(FEQ());
	}

	bEQSettingsSet = false;
}

// Called when an audio effect preset is changed
void FSubmixEffectSubmixEQ::OnPresetChanged()
{
	LLM_SCOPE(ELLMTag::AudioMixer);

	GET_EFFECT_SETTINGS(SubmixEffectSubmixEQ);

	// Don't make any changes if this is the exact same parameters
	if (!IsEqual(GameThreadEQSettings, Settings))
	{
		GameThreadEQSettings = Settings;
		PendingSettings.SetParams(GameThreadEQSettings);
	}
}

void FSubmixEffectSubmixEQ::OnProcessAudio(const FSoundEffectSubmixInputData& InData, FSoundEffectSubmixOutputData& OutData)
{
	LLM_SCOPE(ELLMTag::AudioMixer);

	CSV_SCOPED_TIMING_STAT(Audio, SubmixEQ);
	SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixEQ);

	// Update parameters that may have been set from game thread
	UpdateParameters(InData.NumChannels);

	Audio::FAlignedFloatBuffer& InAudioBuffer = *InData.AudioBuffer;
	Audio::FAlignedFloatBuffer& OutAudioBuffer = *OutData.AudioBuffer;

	if (bEQSettingsSet && RenderThreadEQSettings.EQBands.Num() > 0)
	{
		// Feed every other channel through the EQ filters
		int32 NumFilters = InData.NumChannels / 2;
		for (int32 FilterIndex = 0; FilterIndex < NumFilters; ++FilterIndex)
		{
			FEQ& EQFilter = FiltersPerChannel[FilterIndex];
			const int32 ChannelOffset = FilterIndex * 2;
			for (int32 FrameIndex = 0; FrameIndex < InData.NumFrames; ++FrameIndex)
			{
				// Get the sample index of this frame for this filter
				const int32 SampleIndex = FrameIndex * InData.NumChannels + ChannelOffset;

				// Copy the audio from the input buffer for this frame
				ScratchInBuffer[0] = InAudioBuffer[SampleIndex];
				ScratchInBuffer[1] = InAudioBuffer[SampleIndex + 1];

				const int32 NumBands = EQFilter.Bands.Num();
				for (int32 BandIndex = 0; BandIndex < NumBands; ++BandIndex)
				{
					EQFilter.Bands[BandIndex].ProcessAudioFrame(ScratchInBuffer, ScratchOutBuffer);

					// Copy the output of this band into the input for sequential processing
					for (int32 Channel = 0; Channel < 2; ++Channel)
					{
						ScratchInBuffer[Channel] = ScratchOutBuffer[Channel];
					}
				}

				// Copy the results of this frame to the output buffer
				OutAudioBuffer[SampleIndex] = ScratchOutBuffer[0];
				OutAudioBuffer[SampleIndex + 1] = ScratchOutBuffer[1];
			}
		}
	}
	else
	{
		// pass through 
		for (int32 i = 0; i < InAudioBuffer.Num(); ++i)
		{
			OutAudioBuffer[i] = InAudioBuffer[i];
		}
		
	}

}

static float GetClampedGain(const float InGain)
{
	// These are clamped to match XAudio2 FXEQ_MIN_GAIN and FXEQ_MAX_GAIN
	return FMath::Clamp(InGain, 0.001f, 7.94f);
}

static float GetClampedBandwidth(const float InBandwidth)
{
	// These are clamped to match XAudio2 FXEQ_MIN_BANDWIDTH and FXEQ_MAX_BANDWIDTH
	return FMath::Clamp(InBandwidth, 0.1f, 2.0f);
}

static float GetClampedFrequency(const float InFrequency)
{
	// These are clamped to match XAudio2 FXEQ_MIN_FREQUENCY_CENTER and FXEQ_MAX_FREQUENCY_CENTER
	return FMath::Clamp(InFrequency, 20.0f, 20000.0f);
}

bool FSubmixEffectSubmixEQ::SetParameters(const FAudioEffectParameters& InParameters)
{
	const FAudioEQEffect& EQEffectParameters = static_cast<const FAudioEQEffect&>(InParameters);

	// This function maps the old audio engine eq effect params to the new eq effect.
	// Note that this is always a 4-band EQ and not flexible w/ respect.
	FSubmixEffectSubmixEQSettings NewSettings;
	FSubmixEffectEQBand Band;

	Band.bEnabled = true;
	Band.Frequency = GetClampedFrequency(EQEffectParameters.FrequencyCenter0);
	Band.Bandwidth = GetClampedBandwidth(EQEffectParameters.Bandwidth0);
	Band.GainDb = Audio::ConvertToDecibels(GetClampedGain(EQEffectParameters.Gain0));
	NewSettings.EQBands.Add(Band);

	Band.bEnabled = true;
	Band.Frequency = GetClampedFrequency(EQEffectParameters.FrequencyCenter1);
	Band.Bandwidth = GetClampedBandwidth(EQEffectParameters.Bandwidth1);
	Band.GainDb = Audio::ConvertToDecibels(GetClampedGain(EQEffectParameters.Gain1));
	NewSettings.EQBands.Add(Band);

	Band.bEnabled = true;
	Band.Frequency = GetClampedFrequency(EQEffectParameters.FrequencyCenter2);
	Band.Bandwidth = GetClampedBandwidth(EQEffectParameters.Bandwidth2);
	Band.GainDb = Audio::ConvertToDecibels(GetClampedGain(EQEffectParameters.Gain2));
	NewSettings.EQBands.Add(Band);

	Band.bEnabled = true;
	Band.Frequency = GetClampedFrequency(EQEffectParameters.FrequencyCenter3);
	Band.Bandwidth = GetClampedBandwidth(EQEffectParameters.Bandwidth3);
	Band.GainDb = Audio::ConvertToDecibels(GetClampedGain(EQEffectParameters.Gain3));
	NewSettings.EQBands.Add(Band);

	// Don't make any changes if this is the exact same parameters
	if (!IsEqual(GameThreadEQSettings, NewSettings))
	{
		GameThreadEQSettings = NewSettings;
		PendingSettings.SetParams(GameThreadEQSettings);
	}

	return true;
}

void FSubmixEffectSubmixEQ::UpdateParameters(const int32 InNumOutputChannels)
{
	// We need to update parameters if the output channel count changed
	bool bParamsChanged = false;

	// Also need to update if new settings have been applied
	FSubmixEffectSubmixEQSettings NewSettings;
	if (PendingSettings.GetParams(&NewSettings))
	{
		bParamsChanged = true;

		// Make sure we clamp our freq and bandwidth to reasonable values here
		for (FSubmixEffectEQBand& Band : NewSettings.EQBands)
		{
			Band.Frequency = GetClampedFrequency(Band.Frequency);
			Band.Bandwidth = GetClampedBandwidth(Band.Bandwidth);
		}

		RenderThreadEQSettings = NewSettings;
	}

	if (bParamsChanged || !bEQSettingsSet)
	{
		bEQSettingsSet = true;

		const int32 NumBandsInSetting = RenderThreadEQSettings.EQBands.Num();
		const int32 CurrentFilterCount = FiltersPerChannel.Num();

		// Now loop through all the bands and set them up on all the filters.
		for (int32 FilterIndex = 0; FilterIndex < CurrentFilterCount; ++FilterIndex)
		{
			FEQ& EqFilter = FiltersPerChannel[FilterIndex];
			EqFilter.bEnabled = true;

			// Create more bands as needed
			const int32 NumCurrentBands = EqFilter.Bands.Num();
			if (NumCurrentBands < NumBandsInSetting)
			{
				// Create and initialize the biquad filters per band
				for (int32 BandIndex = NumCurrentBands; BandIndex < NumBandsInSetting; ++BandIndex)
				{
					// Create new filter instance
					int32 BiquadIndex = EqFilter.Bands.Add(Audio::FBiquadFilter());

					// Initialize it
					EqFilter.Bands[BiquadIndex].Init(SampleRate, 2, Audio::EBiquadFilter::ParametricEQ);
				}
			}
			// Disable bands as needed
			else if (NumCurrentBands > NumBandsInSetting)
			{
				// Disable all filters that are greater than the number of bands in the new setting
				for (int32 BandIndex = NumBandsInSetting; BandIndex < NumCurrentBands; ++BandIndex)
				{
					EqFilter.Bands[BandIndex].SetEnabled(false);
				}
			}

			// Now copy the settings over to the specific EQ filter
			check(NumBandsInSetting <= EqFilter.Bands.Num());
			for (int32 BandIndex = 0; BandIndex < NumBandsInSetting; ++BandIndex)
			{
				const FSubmixEffectEQBand& EQBandSetting = RenderThreadEQSettings.EQBands[BandIndex];
				EqFilter.Bands[BandIndex].SetEnabled(EQBandSetting.bEnabled);
				EqFilter.Bands[BandIndex].SetParams(Audio::EBiquadFilter::ParametricEQ, EQBandSetting.Frequency, EQBandSetting.Bandwidth, EQBandSetting.GainDb);
	   		}
		}
	}
}

void USubmixEffectSubmixEQPreset::SetSettings(const FSubmixEffectSubmixEQSettings& InSettings)
{
	UpdateSettings(InSettings);
}


====================================


=== AudioMixerSubmixEffectEQ.h ===
==================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "DSP/EQ.h"
#include "Sound/SoundEffectSubmix.h"
#include "Sound/SoundMix.h"
#include "Stats/Stats.h"

#include "AudioMixerSubmixEffectEQ.generated.h"

// The time it takes to process the master EQ effect.
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix EQ"), STAT_AudioMixerSubmixEQ, STATGROUP_AudioMixer, AUDIOMIXER_API);

// A multiband EQ submix effect.
USTRUCT(BlueprintType)
struct FSubmixEffectEQBand
{
	GENERATED_USTRUCT_BODY()

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "SubmixEffect|Preset", meta = (ClampMin = "20.0", ClampMax = "20000.0", UIMin = "20.0", UIMax = "15000.0"))
	float Frequency;

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "SubmixEffect|Preset", meta = (ClampMin = "0.1", ClampMax = "2.0", UIMin = "0.1", UIMax = "2.0"))
	float Bandwidth;

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "SubmixEffect|Preset", meta = (DisplayName = "Gain (dB)", ClampMin = "-90.0", ClampMax = "20.0", UIMin = "-90.0", UIMax = "20.0"))
	float GainDb;

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "SubmixEffect|Preset")
	uint32 bEnabled : 1;

	FSubmixEffectEQBand()
		: Frequency(500.0f)
		, Bandwidth(2.0f)
		, GainDb(0.0f)
		, bEnabled(false)
	{
	}
};

// EQ submix effect
USTRUCT(BlueprintType)
struct FSubmixEffectSubmixEQSettings
{
	GENERATED_USTRUCT_BODY()

	// The EQ bands to use. 
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = "SubmixEffect|Preset")
	TArray<FSubmixEffectEQBand> EQBands;
};

class FSubmixEffectSubmixEQ : public FSoundEffectSubmix
{
public:
	AUDIOMIXER_API FSubmixEffectSubmixEQ();

	// Called on an audio effect at initialization on main thread before audio processing begins.
	AUDIOMIXER_API virtual void Init(const FSoundEffectSubmixInitData& InSampleRate) override;

	// Process the input block of audio. Called on audio thread.
	AUDIOMIXER_API virtual void OnProcessAudio(const FSoundEffectSubmixInputData& InData, FSoundEffectSubmixOutputData& OutData) override;

	// Sets the effect parameters using the old audio engine preset setting object
	AUDIOMIXER_API virtual bool SetParameters(const FAudioEffectParameters& InParameters) override;

	virtual bool SupportsDefaultEQ() const override
	{
		return true;
	}

	// Called when an audio effect preset is changed
	AUDIOMIXER_API virtual void OnPresetChanged() override;

protected:
	AUDIOMIXER_API void UpdateParameters(const int32 NumOutputChannels);

	// An EQ effect is a bank of biquad filters
	struct FEQ
	{
		bool bEnabled;
		TArray<Audio::FBiquadFilter> Bands;

		FEQ()
			: bEnabled(true)
		{}
	};

	// Each of these filters is a 2 channel biquad filter. 1 for each stereo pair
	TArray<FEQ> FiltersPerChannel;

	float ScratchInBuffer[2];
	float ScratchOutBuffer[2];
	float SampleRate;
	float NumOutputChannels;
	bool bEQSettingsSet;

	// A pending eq setting change
	Audio::TParams<FSubmixEffectSubmixEQSettings> PendingSettings;

	// Game thread copy of the eq setting
	FSubmixEffectSubmixEQSettings GameThreadEQSettings;

	// Audio render thread copy of the eq setting
	FSubmixEffectSubmixEQSettings RenderThreadEQSettings;
};

UCLASS(ClassGroup = AudioSourceEffect, meta = (BlueprintSpawnableComponent), MinimalAPI)
class USubmixEffectSubmixEQPreset : public USoundEffectSubmixPreset
{
	GENERATED_BODY()

public:

	EFFECT_PRESET_METHODS(SubmixEffectSubmixEQ)

	UFUNCTION(BlueprintCallable, Category = "Audio|Effects")
	AUDIOMIXER_API void SetSettings(const FSubmixEffectSubmixEQSettings& InSettings);

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = SubmixEffectPreset)
	FSubmixEffectSubmixEQSettings Settings;
};

==================================


=== AudioMixerSubmixEffectReverb.cpp ===
========================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "SubmixEffects/AudioMixerSubmixEffectReverb.h"
#include "AudioMixerEffectsManager.h"
#include "HAL/IConsoleManager.h"
#include "Sound/ReverbEffect.h"
#include "Audio.h"
#include "AudioMixer.h"
#include "DSP/BufferVectorOperations.h"
#include "DSP/FloatArrayMath.h"
#include "DSP/ReverbFast.h"
#include "DSP/Amp.h"
#include "ProfilingDebugging/CsvProfiler.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(AudioMixerSubmixEffectReverb)

// Link to "Audio" profiling category
CSV_DECLARE_CATEGORY_MODULE_EXTERN(AUDIOMIXERCORE_API, Audio);

DEFINE_STAT(STAT_AudioMixerSubmixReverb);

static int32 DisableSubmixReverbCVarFast = 0;
static FAutoConsoleVariableRef CVarDisableSubmixReverb(
	TEXT("au.DisableReverbSubmix"),
	DisableSubmixReverbCVarFast,
	TEXT("Disables the reverb submix.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);


static int32 EnableReverbStereoFlipForQuadCVarFast = 0;
static FAutoConsoleVariableRef CVarReverbStereoFlipForQuadFast(
	TEXT("au.EnableReverbStereoFlipForQuad"),
	EnableReverbStereoFlipForQuadCVarFast,
	TEXT("Enables doing a stereo flip for quad reverb when in surround.\n")
	TEXT("0: Not Enabled, 1: Enabled"),
	ECVF_Default);

static int32 DisableQuadReverbCVarFast = 0;
static FAutoConsoleVariableRef CVarDisableQuadReverbCVarFast(
	TEXT("au.DisableQuadReverb"),
	DisableQuadReverbCVarFast,
	TEXT("Disables quad reverb in surround.\n")
	TEXT("0: Not Disabled, 1: Disabled"),
	ECVF_Default);


const float FSubmixEffectReverb::MinWetness = 0.0f;
const float FSubmixEffectReverb::MaxWetness = 10.f;

FSubmixEffectReverb::FSubmixEffectReverb()
	: CurrentWetDry(-1.0f, -1.0f)
{
}

void FSubmixEffectReverb::Init(const FSoundEffectSubmixInitData& InitData)
{
	LLM_SCOPE(ELLMTag::AudioMixer);

	/* `FPlateReverb` produces slightly different quality effect than `FPlateReverb`. Comparing the Init
	 * settings between FSubmixEffectReverb and FSubmixEffectReverb slight differences will arise.
	 *
	 * The delay line implementations significantly differ between the `FPlateReverb` and `FPlateReverb` classes.
	 * Specifically, the `FPlateReverb` class utilizes linearly interpolated fractional delay line and fractional
	 * delays while the `FPlateReverb` class uses integer delay lines and integer delays whenever possible.
	 * Linearly interpolated fractional delay lines introduce a low pass filter dependent upon the fractional portion
	 * of the delay value. As a result, the `FPlateReverb` class produces a darker reverb.
	 */
	Audio::FPlateReverbFastSettings NewSettings;

	SampleRate = InitData.SampleRate;

	NewSettings.EarlyReflections.Decay = 0.9f;
	NewSettings.EarlyReflections.Absorption = 0.7f;
	NewSettings.EarlyReflections.Gain = 1.0f;
	NewSettings.EarlyReflections.PreDelayMsec = 0.0f;
	NewSettings.EarlyReflections.Bandwidth = 0.8f;

	NewSettings.LateReflections.LateDelayMsec = 0.0f;
	NewSettings.LateReflections.LateGainDB = 0.0f;
	NewSettings.LateReflections.Bandwidth = 0.54f;
	NewSettings.LateReflections.Diffusion = 0.60f;
	NewSettings.LateReflections.Dampening = 0.35f;
	NewSettings.LateReflections.Decay = 0.15f;
	NewSettings.LateReflections.Density = 0.85f;

	ReverbParams.SetParams(NewSettings);

	DecayCurve.AddKey(0.0f, 0.99f);
	DecayCurve.AddKey(2.0f, 0.45f);
	DecayCurve.AddKey(5.0f, 0.15f);
	DecayCurve.AddKey(10.0f, 0.1f);
	DecayCurve.AddKey(18.0f, 0.01f);
	DecayCurve.AddKey(19.0f, 0.002f);
	DecayCurve.AddKey(20.0f, 0.0001f);

	if (DisableSubmixReverbCVarFast == 0)
	{
		PlateReverb = MakeUnique<Audio::FPlateReverbFast>(SampleRate, 512, NewSettings);
	}
}

void FSubmixEffectReverb::OnPresetChanged()
{
	LLM_SCOPE(ELLMTag::AudioMixer);

	GET_EFFECT_SETTINGS(SubmixEffectReverb);

	FAudioReverbEffect ReverbEffect;
	ReverbEffect.bBypassEarlyReflections = Settings.bBypassEarlyReflections;
	ReverbEffect.bBypassLateReflections = Settings.bBypassLateReflections;
	ReverbEffect.Density = Settings.Density;
	ReverbEffect.Diffusion = Settings.Diffusion;
	ReverbEffect.Gain = Settings.Gain;
	ReverbEffect.GainHF = Settings.GainHF;
	ReverbEffect.DecayTime = Settings.DecayTime;
	ReverbEffect.DecayHFRatio = Settings.DecayHFRatio;
	ReverbEffect.ReflectionsGain = Settings.ReflectionsGain;
	ReverbEffect.ReflectionsDelay = Settings.ReflectionsDelay;
	ReverbEffect.LateGain = Settings.LateGain;
	ReverbEffect.LateDelay = Settings.LateDelay;
	ReverbEffect.AirAbsorptionGainHF = Settings.AirAbsorptionGainHF;

	ReverbEffect.Volume = Settings.bBypass ? 0.0f : FMath::Clamp(Settings.WetLevel, MinWetness, MaxWetness);

	SetParameters(ReverbEffect);

	// These wet dry parameters need to be set after the call to SetParameters(ReverbEffect) parameter.
	// SetParameters sets the WetDryParams, but they need to be overriden here. 
	Audio::FWetDry NewWetDryParams;
	NewWetDryParams.DryLevel = Settings.bBypass ? 1.0f : Settings.DryLevel;
	NewWetDryParams.WetLevel = Settings.bBypass ? 0.0f : FMath::Clamp(Settings.WetLevel, MinWetness, MaxWetness);

	WetDryParams.SetParams(NewWetDryParams);
}

void FSubmixEffectReverb::OnProcessAudio(const FSoundEffectSubmixInputData& InData, FSoundEffectSubmixOutputData& OutData)
{
	LLM_SCOPE(ELLMTag::AudioMixer);

	check(InData.NumChannels == 2);
 	if (OutData.NumChannels < 2 || DisableSubmixReverbCVarFast == 1)
	{
		// Not supported
		return;
	}

	if (!PlateReverb.IsValid())
	{
		Audio::FPlateReverbFastSettings NewSettings;
		ReverbParams.CopyParams(NewSettings);
		PlateReverb = MakeUnique<Audio::FPlateReverbFast>(SampleRate, 512, NewSettings);
	}

	CSV_SCOPED_TIMING_STAT(Audio, SubmixReverb);
	SCOPE_CYCLE_COUNTER(STAT_AudioMixerSubmixReverb);

	UpdateParameters();

	float LastWet = CurrentWetDry.WetLevel;
	float LastDry = CurrentWetDry.DryLevel;
	WetDryParams.GetParams(&CurrentWetDry);

	// Set to most recent if uninitialized (less than 0.0f)
	if (LastWet < 0.0f)
	{
		LastWet = CurrentWetDry.WetLevel;
	}


	WetInputBuffer.Reset();
	if (InData.AudioBuffer->Num() > 0)
	{
		// Wet level is applied to input audio to preserve reverb tail when changing wet level
		WetInputBuffer.AddZeroed(InData.AudioBuffer->Num());
		Audio::ArrayMixIn(*InData.AudioBuffer, WetInputBuffer, LastWet, CurrentWetDry.WetLevel);
	}

	PlateReverb->ProcessAudio(WetInputBuffer, InData.NumChannels, *OutData.AudioBuffer, OutData.NumChannels);
}

bool FSubmixEffectReverb::SetParameters(const FAudioEffectParameters& InParams)
{
	LLM_SCOPE(ELLMTag::AudioMixer);

	const FAudioReverbEffect& ReverbEffectParams = static_cast<const FAudioReverbEffect&>(InParams);

	/* `FPlateReverb` produces slightly different quality effect than `FPlateReverb`. Comparing the 
	 * settings between FSubmixEffectReverb and FSubmixEffectReverb slight differences will arise.
	 *
	 * The delay line implementations significantly differ between the `FPlateReverb` and `FPlateReverb` classes.
	 * Specifically, the `FPlateReverb` class utilizes linearly interpolated fractional delay line and fractional
	 * delays while the `FPlateReverb` class uses integer delay lines and integer delays whenever possible.
	 * Linearly interpolated fractional delay lines introduce a low pass filter dependent upon the fractional portion
	 * of the delay value. As a result, the `FPlateReverb` class produces a darker reverb.
	 */
	Audio::FPlateReverbFastSettings NewSettings;

	NewSettings.bEnableEarlyReflections = !ReverbEffectParams.bBypassEarlyReflections;
	NewSettings.bEnableLateReflections = !ReverbEffectParams.bBypassLateReflections;

	// Early Reflections
	NewSettings.EarlyReflections.Gain = FMath::GetMappedRangeValueClamped(FVector2f{ 0.0f, 3.16f }, FVector2f{ 0.0f, 1.0f }, ReverbEffectParams.ReflectionsGain);
	NewSettings.EarlyReflections.PreDelayMsec = FMath::GetMappedRangeValueClamped(FVector2f{ 0.0f, 0.3f }, FVector2f{ 0.0f, 300.0f }, ReverbEffectParams.ReflectionsDelay);
	NewSettings.EarlyReflections.Bandwidth = FMath::GetMappedRangeValueClamped(FVector2f{ 0.0f, 1.0f }, FVector2f{ 0.0f, 1.0f }, 1.0f - ReverbEffectParams.GainHF);

	// LateReflections
	NewSettings.LateReflections.LateDelayMsec = FMath::GetMappedRangeValueClamped(FVector2f{ 0.0f, 0.1f }, FVector2f{ 0.0f, 100.0f }, ReverbEffectParams.LateDelay);
	NewSettings.LateReflections.LateGainDB = FMath::GetMappedRangeValueClamped(FVector2f{ 0.0f, 1.0f }, FVector2f{ 0.0f, 1.0f }, ReverbEffectParams.Gain);
	NewSettings.LateReflections.Bandwidth = FMath::GetMappedRangeValueClamped(FVector2f{ 0.0f, 1.0f }, FVector2f{ 0.1f, 0.6f }, ReverbEffectParams.AirAbsorptionGainHF);
	NewSettings.LateReflections.Diffusion = FMath::GetMappedRangeValueClamped(FVector2f{ 0.05f, 1.0f }, FVector2f{ 0.0f, 0.95f }, ReverbEffectParams.Diffusion);
	NewSettings.LateReflections.Dampening = FMath::GetMappedRangeValueClamped(FVector2f{ 0.05f, 1.95f }, FVector2f{ 0.0f, 0.999f }, ReverbEffectParams.DecayHFRatio);
	NewSettings.LateReflections.Density = FMath::GetMappedRangeValueClamped(FVector2f{ 0.0f, 0.95f }, FVector2f{ 0.06f, 1.0f }, ReverbEffectParams.Density);

	// Use mapping function to get decay time in seconds to internal linear decay scale value
	const float DecayValue = DecayCurve.Eval(ReverbEffectParams.DecayTime);
	NewSettings.LateReflections.Decay = DecayValue;

	// Convert to db
	NewSettings.LateReflections.LateGainDB = Audio::ConvertToDecibels(NewSettings.LateReflections.LateGainDB);

	// Apply the settings the thread safe settings object
	ReverbParams.SetParams(NewSettings);

	// Apply wet/dry level
	// When using a FAudioReverbEffect, the volume parameter controls wetness and the dry level remains 0.
	Audio::FWetDry NewWetDry(ReverbEffectParams.Volume, 0.f);
	WetDryParams.SetParams(NewWetDry);

	return true;
}

void FSubmixEffectReverb::UpdateParameters()
{
	Audio::FPlateReverbFastSettings NewSettings;
	if (PlateReverb.IsValid() && ReverbParams.GetParams(&NewSettings))
	{
		PlateReverb->SetSettings(NewSettings);
	}

	// Check cVars for quad mapping
	Audio::FPlateReverbFastSettings::EQuadBehavior TargetQuadBehavior;
	if (DisableQuadReverbCVarFast)
	{
		// Disable quad mapping.
 		TargetQuadBehavior = Audio::FPlateReverbFastSettings::EQuadBehavior::StereoOnly;
	}
	else if (!DisableQuadReverbCVarFast && EnableReverbStereoFlipForQuadCVarFast)
	{
		// Enable quad flipped mapping
		TargetQuadBehavior = Audio::FPlateReverbFastSettings::EQuadBehavior::QuadFlipped;
	}
	else
	{
		// Enable quad mapping
		TargetQuadBehavior = Audio::FPlateReverbFastSettings::EQuadBehavior::QuadMatched;
	}

	if (!PlateReverb.IsValid())
	{
		return;
	}

	// Check if settings need to be updated
	const Audio::FPlateReverbFastSettings& ReverbSettings = PlateReverb->GetSettings();
	if (ReverbSettings.QuadBehavior != TargetQuadBehavior)
	{
		// Update quad settings 
		NewSettings = ReverbSettings;
		NewSettings.QuadBehavior = TargetQuadBehavior;
		PlateReverb->SetSettings(NewSettings);
	}
}

void USubmixEffectReverbPreset::SetSettingsWithReverbEffect(const UReverbEffect* InReverbEffect, const float InWetLevel, const float InDryLevel)
{
	if (InReverbEffect)
	{
		Settings.bBypassEarlyReflections = InReverbEffect->bBypassEarlyReflections;
		Settings.bBypassLateReflections = InReverbEffect->bBypassLateReflections;
		Settings.Density = InReverbEffect->Density;
		Settings.Diffusion = InReverbEffect->Diffusion;
		Settings.Gain = InReverbEffect->Gain;
		Settings.GainHF = InReverbEffect->GainHF;
		Settings.DecayTime = InReverbEffect->DecayTime;
		Settings.DecayHFRatio = InReverbEffect->DecayHFRatio;
		Settings.ReflectionsGain = InReverbEffect->ReflectionsGain;
		Settings.ReflectionsDelay = InReverbEffect->ReflectionsDelay;
		Settings.LateGain = InReverbEffect->LateGain;
		Settings.LateDelay = InReverbEffect->LateDelay;
		Settings.AirAbsorptionGainHF = InReverbEffect->AirAbsorptionGainHF;
		Settings.WetLevel = InWetLevel;
		Settings.DryLevel = InDryLevel;

		Update();
	}
}

void USubmixEffectReverbPreset::SetSettings(const FSubmixEffectReverbSettings& InSettings)
{
	UpdateSettings(InSettings);
}


========================================


=== AudioMixerSubmixEffectReverb.h ===
======================================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "AudioEffect.h"
#include "Curves/RichCurve.h"
#include "AudioEffect.h"
#include "Curves/RichCurve.h"
#include "DSP/Amp.h"
#include "DSP/ReverbFast.h"
#include "DSP/BufferVectorOperations.h"
#include "Sound/SoundEffectSubmix.h"
#include "Stats/Stats.h"

#include "AudioMixerSubmixEffectReverb.generated.h"

struct FAudioEffectParameters;

// The time it takes to process the master reverb.
DECLARE_CYCLE_STAT_EXTERN(TEXT("Submix Reverb"), STAT_AudioMixerSubmixReverb, STATGROUP_AudioMixer, AUDIOMIXER_API);

USTRUCT(BlueprintType)
struct FSubmixEffectReverbSettings
{
	GENERATED_USTRUCT_BODY()


	/** Bypasses early reflections */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = EarlyReflections)
	bool bBypassEarlyReflections;

	/** Reflections Delay - 0.0 < 0.007 < 0.3 Seconds - the time between the listener receiving the direct path sound and the first reflection */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = EarlyReflections, meta = (ClampMin = "0.0", ClampMax = "0.3", EditCondition = "!bBypass && !bBypassEarlyReflections"))
	float ReflectionsDelay;

	/** Reverb Gain High Frequency - 0.0 < 0.89 < 1.0 - attenuates the high frequency reflected sound */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = EarlyReflections, meta = (ClampMin = "0.0", ClampMax = "1.0", EditCondition = "!bBypass && !bBypassEarlyReflections"))
	float GainHF;

	/** Reflections Gain - 0.0 < 0.05 < 3.16 - controls the amount of initial reflections */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = EarlyReflections, meta = (ClampMin = "0.0", ClampMax = "3.16", EditCondition = "!bBypass && !bBypassEarlyReflections"))
	float ReflectionsGain;

	/** Bypasses late reflections. */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections)
	bool bBypassLateReflections;

	/** Late Reverb Delay - 0.0 < 0.011 < 0.1 Seconds - time difference between late reverb and first reflections */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections, meta = (ClampMin = "0.0", ClampMax = "0.1", EditCondition = "!bBypass && !bBypassLateReflections"))
	float LateDelay;

	/** Decay Time - 0.1 < 1.49 < 20.0 Seconds - larger is more reverb */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections, meta = (ClampMin = "0.1", ClampMax = "20.0", EditCondition = "!bBypass && !bBypassLateReflections"))
	float DecayTime;

	/** Density - 0.0 < 0.85 < 1.0 - Coloration of the late reverb - lower value is more grainy */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections, meta = (ClampMin = "0.0", ClampMax = "1.0", EditCondition = "!bBypass && !bBypassLateReflections"))
	float Density;

	/** Diffusion - 0.0 < 0.85 < 1.0 - Echo density in the reverberation decay - lower is more grainy */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections, meta = (ClampMin = "0.0", ClampMax = "1.0", EditCondition = "!bBypass && !bBypassLateReflections"))
	float Diffusion;

	/** Air Absorption - 0.0 < 0.994 < 1.0 - lower value means more absorption */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections, meta = (ClampMin = "0.0", ClampMax = "1.0", EditCondition = "!bBypass && !bBypassLateReflections"))
	float AirAbsorptionGainHF;

	/** Decay High Frequency Ratio - 0.1 < 0.83 < 2.0 - how much quicker or slower the high frequencies decay relative to the lower frequencies. */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections, meta = (ClampMin = "0.1", ClampMax = "2.0", EditCondition = "!bBypass && !bBypassLateReflections"))
	float DecayHFRatio;

	/** Late Reverb Gain - 0.0 < 1.26 < 10.0 - gain of the late reverb */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections, meta = (ClampMin = "0.0", ClampMax = "10.0", EditCondition = "!bBypass && !bBypassLateReflections"))
	float LateGain;

	/** Reverb Gain - 0.0 < 0.32 < 1.0 - overall reverb gain - master volume control */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = LateReflections, meta = (ClampMin = "0.0", ClampMax = "1.0", EditCondition = "!bBypass && !bBypassLateReflections"))
	float Gain;

	// Overall wet level of the reverb effect
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Routing, meta = (EditCondition = "!bBypass", UIMin = "0.0", UIMax = "1.0", ClampMin = "0.0", ClampMax = "10.0"))
	float WetLevel;

	// Overall dry level of the reverb effect
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Routing, meta = (EditCondition = "!bBypass", ClampMin = "0.0", ClampMax = "1.0"))
	float DryLevel;

	/** Bypasses reverb */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = General)
	bool bBypass;


	FSubmixEffectReverbSettings()
		: bBypassEarlyReflections(false)
		, ReflectionsDelay(0.007f)
		, GainHF(0.89f)
		, ReflectionsGain(0.05f)
		, bBypassLateReflections(false)
		, LateDelay(0.1f)
		, DecayTime(1.49f)
		, Density(0.85f)
		, Diffusion(0.85f)
		, AirAbsorptionGainHF(0.994f)
		, DecayHFRatio(0.83f)
		, LateGain(1.26f)
		, Gain(0.0f)
		, WetLevel(0.3f)
		, DryLevel(0.0f)
		, bBypass(false)
	{
	}
};

class FSubmixEffectReverb : public FSoundEffectSubmix
{
public:
	AUDIOMIXER_API FSubmixEffectReverb();

	// Called on an audio effect at initialization on main thread before audio processing begins.
	AUDIOMIXER_API virtual void Init(const FSoundEffectSubmixInitData& InSampleRate) override;
	
	// Called when an audio effect preset is changed
	AUDIOMIXER_API virtual void OnPresetChanged() override;

	// Forces receiving downmixed submix audio to stereo input for the reverb effect
	virtual uint32 GetDesiredInputChannelCountOverride() const override { return 2; }

	// Process the input block of audio. Called on audio thread.
	AUDIOMIXER_API virtual void OnProcessAudio(const FSoundEffectSubmixInputData& InData, FSoundEffectSubmixOutputData& OutData) override;

	// Sets the reverb effect parameters based from audio thread code
	AUDIOMIXER_API virtual bool SetParameters(const FAudioEffectParameters& InParameters) override;

	// Whether this effect supports the default reverb system
	virtual bool SupportsDefaultReverb() const override
	{
		return true;
	}

	// Returns the drylevel of the effect
	virtual float GetDryLevel() const override { return CurrentWetDry.DryLevel; }

private:

	static AUDIOMIXER_API const float MinWetness;
	static AUDIOMIXER_API const float MaxWetness;

	AUDIOMIXER_API void UpdateParameters();

	// The reverb effect
	TUniquePtr<Audio::FPlateReverbFast> PlateReverb;

	// The reverb effect params
	Audio::TParams<Audio::FPlateReverbFastSettings> ReverbParams;

	// Settings for wet and dry signal to be consumed on next buffer
	Audio::TParams<Audio::FWetDry> WetDryParams;

	// Level of wet/dry signal on current buffer
	Audio::FWetDry CurrentWetDry;

	Audio::FAlignedFloatBuffer WetInputBuffer;

	// Curve which maps old reverb times to new decay value
	FRichCurve DecayCurve;

	float SampleRate = 1.f;
};

UCLASS(MinimalAPI)
class USubmixEffectReverbPreset : public USoundEffectSubmixPreset
{
	GENERATED_BODY()

public:
	EFFECT_PRESET_METHODS(SubmixEffectReverb)

	UFUNCTION(BlueprintCallable, Category = "Audio|Effects")
	AUDIOMIXER_API void SetSettings(const FSubmixEffectReverbSettings& InSettings);

	UFUNCTION(BlueprintCallable, Category = "Audio|Effects")
	AUDIOMIXER_API void SetSettingsWithReverbEffect(const UReverbEffect* InReverbEffect, const float WetLevel, const float DryLevel = 0.0f);

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = SubmixEffectPreset)
	FSubmixEffectReverbSettings Settings;
};

======================================


=== FileDecoder.cpp ===
=======================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "FileDecoder.h"
#include "HAL/PlatformFileManager.h"
#include "DSP/FloatArrayMath.h"

FAudioFileReader::FAudioFileReader(const FString& InPath)
{
	QualityInfo = { 0 };

	IPlatformFile& PlatformFile = FPlatformFileManager::Get().GetPlatformFile();
	FileHandle.Reset(PlatformFile.OpenRead(*InPath));
	if (FileHandle.IsValid())
	{
		int64 FileSize = FileHandle->Size();
		CompressedFile.Reset();
		CompressedFile.AddUninitialized(FileSize);
		FileHandle->Read(CompressedFile.GetData(), FileSize);
		
		Decompressor.Reset(GetNewDecompressorForFile(InPath));

		if (Decompressor.IsValid())
		{
			Decompressor->ReadCompressedInfo(CompressedFile.GetData(), FileSize, &QualityInfo);
		}
		else
		{
			QualityInfo.NumChannels = 0;
			UE_LOG(LogTemp, Error, TEXT("Invalid file extension!"));
		}
	}
	else
	{
		QualityInfo.NumChannels = 0;
		UE_LOG(LogTemp, Error, TEXT("Invalid file %s!"), *InPath);
	}
}

void FAudioFileReader::GetFileInfo(FSoundQualityInfo& OutInfo)
{
	OutInfo = QualityInfo;
}

bool FAudioFileReader::PopAudio(float* OutAudio, int32 NumSamples)
{
	check(FileHandle.IsValid());
	check(Decompressor.IsValid());

	DecompressionBuffer.Reset();
	DecompressionBuffer.AddUninitialized(NumSamples);

	bool bIsFinished = Decompressor->ReadCompressedData((uint8*) DecompressionBuffer.GetData(), false, NumSamples * sizeof(Audio::DefaultUSoundWaveSampleType));

	// Convert to float:
	Audio::ArrayPcm16ToFloat(MakeArrayView((int16*)DecompressionBuffer.GetData(), NumSamples), MakeArrayView(OutAudio, NumSamples));

	return bIsFinished;
}

ICompressedAudioInfo* FAudioFileReader::GetNewDecompressorForFile(const FString& InPath)
{	
	using namespace Audio;
	using FMapping = TTuple<FString, FName>; 
	const FMapping Extensions[] =
	{	
		{ TEXT(".opus"), NAME_OPUS },
		{ TEXT(".vorbis"), NAME_OGG },
		{ TEXT(".binka"), NAME_BINKA }
	};

	const FString LowerPath = InPath.ToLower();
	if (const FMapping* Found = Algo::FindByPredicate(Extensions, [LowerPath](const auto &i) -> bool { return LowerPath.EndsWith(i.Key); }) )
	{
		return IAudioInfoFactoryRegistry::Get().Create(Found->Value);		
	}
	UE_LOG(LogTemp, Error, TEXT("Unable to determin/create decompressor for '%s'"), *InPath);
	return nullptr;
}

=======================


=== FileDecoder.h ===
=====================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "DSP/Dsp.h"
#include "SampleBuffer.h"
#include "AudioDecompress.h"
#include "GenericPlatform/GenericPlatformFile.h"
#include "Interfaces/IAudioFormat.h"

class FAudioFileReader
{
public:
	// Constructor. Takes a file path and immediately loads info.
	// Optionally, CallbackSize can be used to indicate the size of chunks
	// that will be popped off of this instance.
	// When set to 0, the entire file is decompressed into memory.
	AUDIOMIXER_API FAudioFileReader(const FString& InPath);

	// Returns file information.
	AUDIOMIXER_API void GetFileInfo(FSoundQualityInfo& OutInfo);

	AUDIOMIXER_API bool PopAudio(float* OutAudio, int32 NumSamples);

private:
	FAudioFileReader();

	// Handle back to the file this was constructed with.
	TUniquePtr<IFileHandle> FileHandle;

	// Actual decompressor in question.
	TUniquePtr<ICompressedAudioInfo> Decompressor;
	
	TArray<uint8> CompressedFile;
	TArray<Audio::DefaultUSoundWaveSampleType> DecompressionBuffer;

	FSoundQualityInfo QualityInfo;

	ICompressedAudioInfo* GetNewDecompressorForFile(const FString& InPath);

};

=====================


=== QuartzMetronome.cpp ===
===========================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Quartz/QuartzMetronome.h"
#include "Sound/QuartzSubscription.h"

namespace Audio
{
	FQuartzMetronome::FQuartzMetronome(FName InClockName)
		: TimeSinceStart(0), ClockName(InClockName)
	{
		SetTickRate(CurrentTickRate);
	}

	FQuartzMetronome::FQuartzMetronome(const FQuartzTimeSignature& InTimeSignature, FName InClockName)
		: CurrentTimeSignature(InTimeSignature), TimeSinceStart(0), ClockName(InClockName)
	{
		SetTickRate(CurrentTickRate);
	}

	FQuartzMetronome::~FQuartzMetronome()
	{
	}

	void FQuartzMetronome::Tick(int32 InNumSamples, int32 FramesOfLatency)
	{
		LastTickCpuCycles64 = FPlatformTime::Cycles64();


		for (int i = 0; i < static_cast<int32>(EQuartzCommandQuantization::Count); ++i)
		{
			const EQuartzCommandQuantization DurationType = static_cast<EQuartzCommandQuantization>(i);
			int32 EventFrame = FramesLeftInMusicalDuration[DurationType]; 
			FramesLeftInMusicalDuration[DurationType] -= InNumSamples;
			
			if (FramesLeftInMusicalDuration[DurationType] < 0)
			{
				// the beat value is constant
				if (!(DurationType == EQuartzCommandQuantization::Beat && PulseDurations.Num()))
				{
					do
					{
						PendingMetronomeEvents.Add(DurationType, EventFrame);
						
						EventFrame += MusicalDurationsInFrames[DurationType];
						FramesLeftInMusicalDuration[DurationType] += MusicalDurationsInFrames[DurationType];
					}
					while (FramesLeftInMusicalDuration[DurationType] <= 0);
				}
				else
				{
					// the beat value can change
					do
					{
						PendingMetronomeEvents.Add(DurationType, EventFrame);
						if (++PulseDurationIndex == PulseDurations.Num())
						{
							PulseDurationIndex = 0;
						}

						EventFrame += MusicalDurationsInFrames[DurationType];
						FramesLeftInMusicalDuration[DurationType] += PulseDurations[PulseDurationIndex];
						MusicalDurationsInFrames[DurationType] = PulseDurations[PulseDurationIndex];
					}
					while (FramesLeftInMusicalDuration[DurationType] <= 0);
				}
			}
		}

		// update transport
		if (PendingMetronomeEvents.HasPendingEvent(EQuartzCommandQuantization::Bar))
		{
			++CurrentTimeStamp.Bars;
			CurrentTimeStamp.Beat = 1;
		}
		else if (PendingMetronomeEvents.HasPendingEvent(EQuartzCommandQuantization::Beat))
		{
			++CurrentTimeStamp.Beat;
		}

		if (PulseDurations.Num())
		{
			CurrentTimeStamp.BeatFraction = 1.f - (FramesLeftInMusicalDuration[EQuartzCommandQuantization::Beat] / static_cast<float>(PulseDurations[PulseDurationIndex]));
		}
		else
		{
			CurrentTimeStamp.BeatFraction = 1.f - (FramesLeftInMusicalDuration[EQuartzCommandQuantization::Beat] / static_cast<float>(MusicalDurationsInFrames[EQuartzCommandQuantization::Beat]));
		}

		TimeSinceStart += double(InNumSamples) / CurrentTickRate.GetSampleRate(); 
		CurrentTimeStamp.Seconds = TimeSinceStart;
		FireEvents();
		PendingMetronomeEvents.Reset();
	}

	void FQuartzMetronome::SetTickRate(FQuartzClockTickRate InNewTickRate, int32 NumFramesLeft)
	{
		// early exit?
		const bool bSameAsOldTickRate = FMath::IsNearlyEqual(InNewTickRate.GetFramesPerTick(), CurrentTickRate.GetFramesPerTick());
		const bool bIsInitialized = (MusicalDurationsInFrames[0] > 0);

		if (bSameAsOldTickRate && bIsInitialized)
		{
			return;
		}

		// ratio between new and old rates
		const double Ratio = InNewTickRate.GetFramesPerTick() / CurrentTickRate.GetFramesPerTick();

		for (double& Value : FramesLeftInMusicalDuration.FramesInTimeValueInternal)
		{
			Value = NumFramesLeft + Ratio * (Value - NumFramesLeft);
		}

		CurrentTickRate = InNewTickRate;
		RecalculateDurations();
	}

	void FQuartzMetronome::SetSampleRate(float InNewSampleRate)
	{
		CurrentTickRate.SetSampleRate(InNewSampleRate);
		RecalculateDurations();
	}

	void FQuartzMetronome::SetTimeSignature(const FQuartzTimeSignature& InNewTimeSignature)
	{
		CurrentTimeSignature = InNewTimeSignature;
		RecalculateDurations();
	}

	double FQuartzMetronome::GetFramesUntilBoundary(FQuartzQuantizationBoundary InQuantizationBoundary) const
	{
		if (!ensure(InQuantizationBoundary.Quantization != EQuartzCommandQuantization::None))
		{
			return 0; // Metronome's should not have to deal w/ Quartization == None
		}

		if (InQuantizationBoundary.Multiplier < 1.0f)
		{
			UE_LOG(LogAudioQuartz, Warning, TEXT("Quantization Boundary being clamped to 1.0 (from %f)"), InQuantizationBoundary.Multiplier);
			InQuantizationBoundary.Multiplier = 1.f;
		}

		// number of frames until the next occurrence of this boundary
		double FramesUntilBoundary = FramesLeftInMusicalDuration[InQuantizationBoundary.Quantization];

		// how many multiples actually exist until the boundary we care about?
		int32 NumDurationsLeft = static_cast<int32>(InQuantizationBoundary.Multiplier) - 1;

		// in the simple case that's all we need to know
		bool bIsSimpleCase = FMath::IsNearlyEqual(InQuantizationBoundary.Multiplier, 1.f);

		// it is NOT the simple case if we are in Bar-Relative. // i.e. 1.f Beat here means "Beat 1 of the bar"
		bIsSimpleCase &= (InQuantizationBoundary.CountingReferencePoint != EQuarztQuantizationReference::BarRelative);

		if (CurrentTimeStamp.IsZero() && !InQuantizationBoundary.bFireOnClockStart)
		{
			FramesUntilBoundary = MusicalDurationsInFrames[InQuantizationBoundary.Quantization];

			if (NumDurationsLeft == 0)
			{
				return FramesUntilBoundary;
			}
		}
		else if (bIsSimpleCase || CurrentTimeStamp.IsZero())
		{
			return FramesUntilBoundary;
		}

		// counting from the current point in time
		if (InQuantizationBoundary.CountingReferencePoint == EQuarztQuantizationReference::CurrentTimeRelative)
		{
			// continue
		}
		// counting from the beginning of the of the current transport
		else if (InQuantizationBoundary.CountingReferencePoint == EQuarztQuantizationReference::TransportRelative)
		{
			// how many of these subdivisions have happened since in the transport lifespan
			int32 CurrentCount = CountNumSubdivisionsSinceStart(InQuantizationBoundary.Quantization);
			 
			// find the remainder
			if (CurrentCount >= InQuantizationBoundary.Multiplier)
			{
				CurrentCount %= static_cast<int32>(InQuantizationBoundary.Multiplier);
			}

			NumDurationsLeft -= CurrentCount;
		}
		// counting from the current bar
		else if (InQuantizationBoundary.CountingReferencePoint == EQuarztQuantizationReference::BarRelative)
		{
			const float NumSubdivisionsPerBar = CountNumSubdivisionsPerBar(InQuantizationBoundary.Quantization);
			const float NumSubdivisionsAlreadyOccuredInCurrentBar = CountNumSubdivisionsSinceBarStart(InQuantizationBoundary.Quantization);

			// the requested duration is longer than our current bar
			// do the math in bars instead
			if (NumSubdivisionsPerBar < 1.f && ensure(!FMath::IsNearlyZero(NumSubdivisionsPerBar)))
			{
				const float NumBarsPerSubdivision = 1.f / NumSubdivisionsPerBar;
				const float NumBarsRemaining = NumBarsPerSubdivision - (NumSubdivisionsAlreadyOccuredInCurrentBar - 1.f);

				InQuantizationBoundary.Multiplier = NumBarsRemaining;
				InQuantizationBoundary.Quantization = EQuartzCommandQuantization::Bar;
				
				NumDurationsLeft = static_cast<int32>(InQuantizationBoundary.Multiplier) - 1;
			}
			else
			{
				NumDurationsLeft = NumDurationsLeft % static_cast<int32>(NumSubdivisionsPerBar) - static_cast<int32>(NumSubdivisionsAlreadyOccuredInCurrentBar);
			}

			// if NumDurationsLeft is negative, it means the target has already passed this bar.
			// instead we will schedule the sound for the same target in the next bar
			if (NumDurationsLeft < 0)
			{
				NumDurationsLeft += NumSubdivisionsPerBar;
			}
		}

		const double FractionalPortion = FMath::Fractional(InQuantizationBoundary.Multiplier);

		// for Beats, the lengths are not uniform for complex meters
		if ((InQuantizationBoundary.Quantization == EQuartzCommandQuantization::Beat) && PulseDurations.Num())
		{
			// if the metronome hasn't ticked yet, then PulseDurationIndex is -1 (treat as index zero)
			int32 TempPulseDurationIndex = (PulseDurationIndex < 0) ? 0 : PulseDurationIndex;

			for (int i = 0; i < NumDurationsLeft; ++i)
			{
				// need to increment now because FramesUntilBoundary already
				// represents the current (fractional) pulse duration
				if (++TempPulseDurationIndex == PulseDurations.Num())
				{
					TempPulseDurationIndex = 0;
				}

				FramesUntilBoundary += PulseDurations[TempPulseDurationIndex];
			}

			if (++TempPulseDurationIndex == PulseDurations.Num())
			{
				TempPulseDurationIndex = 0;
			}

			FramesUntilBoundary += FractionalPortion * PulseDurations[TempPulseDurationIndex];
		}
		else
		{
			const float Multiplier = NumDurationsLeft + FractionalPortion;
			const float Duration = static_cast<float>(MusicalDurationsInFrames[InQuantizationBoundary.Quantization]);
			FramesUntilBoundary += Multiplier * Duration;
		}

		return FramesUntilBoundary;
	}

	float FQuartzMetronome::CountNumSubdivisionsPerBar(EQuartzCommandQuantization InSubdivision) const
	{
		if (InSubdivision == EQuartzCommandQuantization::Beat && PulseDurations.Num())
		{
			return static_cast<float>(PulseDurations.Num());
		}

		return static_cast<float>(MusicalDurationsInFrames[EQuartzCommandQuantization::Bar] / MusicalDurationsInFrames[InSubdivision]);
	}

	float FQuartzMetronome::CountNumSubdivisionsSinceBarStart(EQuartzCommandQuantization InSubdivision) const
	{
		// for our own counting, we don't say that "one bar has occurred since the start of the bar"
		if (InSubdivision == EQuartzCommandQuantization::Bar)
		{
			return 0.0f;
		}

		// Count starts at 1.0f since all musical subdivisions occur once at beat 0 in a bar
		float Count = 1.f;
		if ((InSubdivision == EQuartzCommandQuantization::Beat) && PulseDurations.Num())
		{
			Count += static_cast<float>(PulseDurationIndex);
		}
		else
		{
			const float BarProgress = 1.0f - (FramesLeftInMusicalDuration[EQuartzCommandQuantization::Bar] / static_cast<float>(MusicalDurationsInFrames[EQuartzCommandQuantization::Bar]));
			Count += (BarProgress * CountNumSubdivisionsPerBar(InSubdivision));
		}

		return Count;
	}

	float FQuartzMetronome::CountNumSubdivisionsSinceStart(EQuartzCommandQuantization InSubdivision) const
	{
		const int32 NumPerBar = CountNumSubdivisionsPerBar(InSubdivision);
		const int32 NumInThisBar = CountNumSubdivisionsSinceBarStart(InSubdivision);

		return (CurrentTimeStamp.Bars - 1) * NumPerBar + NumInThisBar;
	}

	void FQuartzMetronome::FFramesInTimeValue::Reset()
	{
		for (double& FrameCount : FramesInTimeValueInternal)
		{
			FrameCount = 0.0;
		}
	}

	double& FQuartzMetronome::FFramesInTimeValue::operator[](EQuartzCommandQuantization InTimeValue)
	{
		return FramesInTimeValueInternal[static_cast<int32>(InTimeValue)];
	}

	const double& FQuartzMetronome::FFramesInTimeValue::operator[](EQuartzCommandQuantization InTimeValue) const
	{
		return FramesInTimeValueInternal[static_cast<int32>(InTimeValue)];
	}

	double& FQuartzMetronome::FFramesInTimeValue::operator[](int32 Index)
	{
		return FramesInTimeValueInternal[Index];
	}

	const double& FQuartzMetronome::FFramesInTimeValue::operator[](int32 Index) const
	{
		return FramesInTimeValueInternal[Index];
	}

	void FQuartzMetronome::FMetronomeEventEntry::Reset()
	{
		EventFrames.Reset();
	}

	void FQuartzMetronome::FPendingMetronomeEvents::Reset()
	{
		for (FMetronomeEventEntry& Entry : CurrentMetronomeEvents)
		{
			Entry.Reset();
		}
	}

	bool FQuartzMetronome::FPendingMetronomeEvents::HasPendingEvent(const EQuartzCommandQuantization InDuration) const
	{
		return CurrentMetronomeEvents[static_cast<int32>(InDuration)].EventFrames.Num() != 0;
	}

	void FQuartzMetronome::FPendingMetronomeEvents::Add(const EQuartzCommandQuantization InDuration,
	                                                    const int32 InFrame)
	{
		CurrentMetronomeEvents[static_cast<int32>(InDuration)].EventFrames.Add(InFrame);
	}

	void FQuartzMetronome::CalculateDurationPhases(float (&OutPhases)[static_cast<int32>(EQuartzCommandQuantization::Count)]) const
	{
		for (int i = 0; i < static_cast<int32>(EQuartzCommandQuantization::Count); ++i)
		{
			OutPhases[i] = 1.f - FramesLeftInMusicalDuration[i] / static_cast<float>(MusicalDurationsInFrames[i]);
		}
	}

	void FQuartzMetronome::SubscribeToTimeDivision(MetronomeCommandQueuePtr InListenerQueue, EQuartzCommandQuantization InQuantizationBoundary)
	{
		MetronomeSubscriptionMatrix[(int32)InQuantizationBoundary].AddUnique(InListenerQueue);
		ListenerFlags |= 1 << (int32)InQuantizationBoundary;
	}

	void FQuartzMetronome::SubscribeToAllTimeDivisions(MetronomeCommandQueuePtr InListenerQueue)
	{
		int32 i = 0;
		for (TArray<MetronomeCommandQueuePtr>& QuantizationBoundarySubscribers : MetronomeSubscriptionMatrix)
		{
			QuantizationBoundarySubscribers.AddUnique(InListenerQueue);
			ListenerFlags |= (1 << i++);
		}
	}

	void FQuartzMetronome::UnsubscribeFromTimeDivision(MetronomeCommandQueuePtr InListenerQueue, EQuartzCommandQuantization InQuantizationBoundary)
	{
		MetronomeSubscriptionMatrix[(int32)InQuantizationBoundary].RemoveSingleSwap(InListenerQueue);

		if (MetronomeSubscriptionMatrix[(int32)InQuantizationBoundary].Num() == 0)
		{
			ListenerFlags &= ~(1 << (int32)InQuantizationBoundary);
		}
	}

	void FQuartzMetronome::UnsubscribeFromAllTimeDivisions(MetronomeCommandQueuePtr InListenerQueue)
	{
		int32 i = 0;
		for (TArray<MetronomeCommandQueuePtr>& QuantizationBoundarySubscribers : MetronomeSubscriptionMatrix)
		{
			QuantizationBoundarySubscribers.RemoveSingleSwap(InListenerQueue);
			
			if (QuantizationBoundarySubscribers.Num() == 0)
			{
				ListenerFlags &= ~(1 << i);
			}

			++i;
		}
	}

	void FQuartzMetronome::ResetTransport()
	{
		CurrentTimeStamp.Reset();

		FramesLeftInMusicalDuration.Reset();

		TimeSinceStart = 0.0;
		PulseDurationIndex = -1;
	}

	void FQuartzMetronome::RecalculateDurations()
	{
		PulseDurations.Reset();

		// get default values for each boundary:
		for (int32 i = 0; i < static_cast<int32>(EQuartzCommandQuantization::Count); ++i)
		{
			MusicalDurationsInFrames[i] = CurrentTickRate.GetFramesPerDuration(static_cast<EQuartzCommandQuantization>(i));
		}

		// determine actual length of a bar
		const double BarLength = CurrentTimeSignature.NumBeats * CurrentTickRate.GetFramesPerDuration(CurrentTimeSignature.BeatType);
		MusicalDurationsInFrames[EQuartzCommandQuantization::Bar] = BarLength;

		// default beat value to the denominator of our time signature
		MusicalDurationsInFrames[EQuartzCommandQuantization::Beat] = CurrentTickRate.GetFramesPerDuration(CurrentTimeSignature.BeatType);

		// potentially update the durations of BEAT and BAR
		if (CurrentTimeSignature.OptionalPulseOverride.Num() != 0)
		{
			// determine the length of each beat
			double LengthCounter = 0.0;
			double StepLength = 0.0;

			for (const FQuartzPulseOverrideStep& PulseStep : CurrentTimeSignature.OptionalPulseOverride)
			{
				for (int i = 0; i < PulseStep.NumberOfPulses; ++i)
				{
					StepLength = CurrentTickRate.GetFramesPerDuration(PulseStep.PulseDuration);
					LengthCounter += StepLength;

					PulseDurations.Add(StepLength);
				}
			}

			if (LengthCounter > BarLength)
			{
				UE_LOG(LogAudioQuartz, Warning
					, TEXT("Pulse override array on Time Signature reperesents more than a bar. The provided list will be trunctaed to 1 Bar in length"));

				return;
			}

			// extend the last duration to the length of the bar if needed
			while ((LengthCounter + StepLength) <= BarLength)
			{
				PulseDurations.Add(StepLength);
				LengthCounter += StepLength;
			}

			// check to see if all our pulses are the same length
			const double FirstValue = PulseDurations[0];
			bool bBeatDurationsAreConstant = true;

			for (const double& Values : PulseDurations)
			{
				if (!FMath::IsNearlyEqual(Values, FirstValue))
				{
					bBeatDurationsAreConstant = false;
					break;
				}
			}

			// we can just overwrite the duration array with the single value
			if (bBeatDurationsAreConstant)
			{
				MusicalDurationsInFrames[EQuartzCommandQuantization::Beat] = FirstValue;
				PulseDurations.Reset();
			}
		}
	}

	void FQuartzMetronome::FireEvents()
	{
		FQuartzMetronomeDelegateData Data;
		Data.Bar = (CurrentTimeStamp.Bars);
		Data.Beat = (CurrentTimeStamp.Beat);
		Data.BeatFraction = (CurrentTimeStamp.BeatFraction);
		Data.ClockName = ClockName;
		
		// loop through subscribers of each quantization boundary
		int32 i = -1;
		for (TArray<MetronomeCommandQueuePtr>& QuantizationBoundarySubscribers : MetronomeSubscriptionMatrix)
		{
			Data.Quantization = static_cast<EQuartzCommandQuantization>(++i);

			// if this quantization boundary had any events...
			if (PendingMetronomeEvents.HasPendingEvent(Data.Quantization))
			{
				// ...for each subscriber...
				for (const MetronomeCommandQueuePtr& Subscriber : QuantizationBoundarySubscribers)
				{
					// fire an event for each instance of that metronome event in this buffer
					for (const int32& MetronomeEventFrame : PendingMetronomeEvents.CurrentMetronomeEvents[i].EventFrames)
					{
						Data.FrameOffset = MetronomeEventFrame;
						Subscriber->PushLambda<Quartz::IMetronomeEventListener>(
							[=](Quartz::IMetronomeEventListener& InListener)
							{
								InListener.OnMetronomeEvent(Data);
							});
					}
				}
			}
		}
	}
} // namespace Audio
===========================


=== QuartzMetronome.h ===
=========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "Containers/Array.h"
#include "HAL/Platform.h"
#include "Sound/QuartzQuantizationUtilities.h"
#include "Templates/SharedPointer.h"
#include "UObject/NameTypes.h"

class FQuartzTickableObject;

namespace Audio
{
	using MetronomeCommandQueuePtr = Quartz::FQuartzGameThreadCommandQueuePtr; // todo: rename, "GameThread is not accurate"

	// Class to track the passage of musical time, and allow subscribers to be notified when these musical events take place
	class FQuartzMetronome
	{
	public:
		// ctor
		FQuartzMetronome(FName InClockName = {});
		FQuartzMetronome(const FQuartzTimeSignature& InTimeSignature, FName InClockName = {});

		// dtor
		~FQuartzMetronome();

		// Transport Control:
		void Tick(int32 InNumSamples, int32 FramesOfLatency = 0);

		void SetTickRate(FQuartzClockTickRate InNewTickRate, int32 NumFramesLeft = 0);

		void SetSampleRate(float InNewSampleRate);

		void SetTimeSignature(const FQuartzTimeSignature& InNewTimeSignature);

		void ResetTransport();

		// Getters
		const FQuartzClockTickRate& GetTickRate() const { return CurrentTickRate; }

		double GetFramesUntilBoundary(FQuartzQuantizationBoundary InQuantizationBoundary) const;

		const FQuartzTimeSignature & GetTimeSignature() const { return CurrentTimeSignature; }

		FQuartzTransportTimeStamp GetTimeStamp() const { return CurrentTimeStamp; }

		double GetTimeSinceStart() const { return TimeSinceStart; }

		uint64 GetLastTickCpuCycles64() const { return LastTickCpuCycles64; }

		void CalculateDurationPhases(float (&OutPhases)[static_cast<int32>(EQuartzCommandQuantization::Count)]) const;

		// Event Subscription
		void SubscribeToTimeDivision(MetronomeCommandQueuePtr InListenerQueue, EQuartzCommandQuantization InQuantizationBoundary);

		void SubscribeToAllTimeDivisions(MetronomeCommandQueuePtr InListenerQueue);

		void UnsubscribeFromTimeDivision(MetronomeCommandQueuePtr InListenerQueue, EQuartzCommandQuantization InQuantizationBoundary);

		void UnsubscribeFromAllTimeDivisions(MetronomeCommandQueuePtr InListenerQueue);


	private:

		// Helpers:
		void RecalculateDurations();

		void FireEvents();

		float CountNumSubdivisionsPerBar(EQuartzCommandQuantization InSubdivision) const;

		float CountNumSubdivisionsSinceBarStart(EQuartzCommandQuantization InSubdivision) const;

		float CountNumSubdivisionsSinceStart(EQuartzCommandQuantization InSubdivision) const;

		uint64 LastTickCpuCycles64{ 0 };

		int32 ListenerFlags{ 0 };

		FQuartzTransportTimeStamp CurrentTimeStamp;

		FQuartzTimeSignature CurrentTimeSignature;

		FQuartzClockTickRate CurrentTickRate;

		TArray<MetronomeCommandQueuePtr> MetronomeSubscriptionMatrix[static_cast<int32>(EQuartzCommandQuantization::Count)];
		
		// wrapper around our array so it can be indexed into by different Enums that represent musical time
		struct FFramesInTimeValue
		{
			void Reset();
			
			double& operator[](EQuartzCommandQuantization InTimeValue);
			const double& operator[](EQuartzCommandQuantization InTimeValue) const;
			double& operator[](int32 Index);
			const double& operator[](int32 Index) const;

			double FramesInTimeValueInternal[static_cast<int32>(EQuartzCommandQuantization::Count)]{ 0.0 };
		};

		struct FMetronomeEventEntry
		{
			TArray<int32> EventFrames;
			void Reset();
		};

		struct FPendingMetronomeEvents
		{
			void Add(const EQuartzCommandQuantization InDuration, const int32 InFrame);
			void Reset();
			bool HasPendingEvent(const EQuartzCommandQuantization InDuration) const;
			
			FMetronomeEventEntry CurrentMetronomeEvents[static_cast<int32>(EQuartzCommandQuantization::Count)];
		} PendingMetronomeEvents;

		// array of lengths of musical durations (in audio frames)
		FFramesInTimeValue MusicalDurationsInFrames;

		// array of the number of audio frames left until the respective musical duration
		FFramesInTimeValue FramesLeftInMusicalDuration;

		// optional array of pulse duration overrides (for odd meters)
		TArray<double> PulseDurations;

		// the index of the active pulse duration override
		int32 PulseDurationIndex{ -1 };

		int32 LastFramesOfLatency{ 0 };

		//Keeps track of time in seconds since the Clock was last reset
		double TimeSinceStart;

		FName ClockName;

	}; // class QuartzMetronome
} // namespace Audio
=========================


=== QuartzSubsystem.cpp ===
===========================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Quartz/QuartzSubsystem.h"

#include "Engine/World.h"
#include "Quartz/AudioMixerClockHandle.h"
#include "Quartz/QuartzMetronome.h"
#include "Quartz/AudioMixerClockManager.h"
#include "Sound/QuartzQuantizationUtilities.h"
#include "ProfilingDebugging/CountersTrace.h"
#include "ProfilingDebugging/CsvProfiler.h"
#include "Stats/Stats.h"

#include "AudioDevice.h"
#include "AudioMixerDevice.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(QuartzSubsystem)

static int32 MaxQuartzSubscribersToUpdatePerTickCvar = -1;
FAutoConsoleVariableRef CVarMaxQuartzSubscribersToUpdatePerTick(
	TEXT("au.Quartz.MaxSubscribersToUpdatePerTick"),
	MaxQuartzSubscribersToUpdatePerTickCvar,
	TEXT("Limits the number of Quartz subscribers to update per Tick.\n")
	TEXT("<= 0: No Limit, >= 1: Limit"),
	ECVF_Default);

static int32 SimulateNoAudioDeviceCvar = 0;
FAutoConsoleVariableRef CVarSimulateNoAudioDevice(
	TEXT("au.Quartz.SimulateNoAudioDevice"),
	SimulateNoAudioDeviceCvar,
	TEXT("If enabled, the QuartzSubsystem will assume no audio device, and will run new clocks in headless mode.\n")
	TEXT("0: Not Enabled, 1: Enabled"),
	ECVF_Default);

static Audio::FMixerDevice* GetAudioMixerDevice(const UWorld* InWorld)
{
	if(!InWorld || SimulateNoAudioDeviceCvar)
	{
		return nullptr;
	}

	FAudioDevice* AudioDevicePtr = InWorld->GetAudioDeviceRaw();
	if(AudioDevicePtr)
	{
		return static_cast<Audio::FMixerDevice*>(AudioDevicePtr);
	}

	return nullptr;
}

static TUniquePtr<FScopeLock> GetPersistentStateScopeLock(const UWorld* InWorld)
{
	if(Audio::FMixerDevice* MixerDevicePtr = GetAudioMixerDevice(InWorld))
	{
		return MakeUnique<FScopeLock>(&MixerDevicePtr->QuartzPersistentStateCritSec);
	}

	return {};
}


void UQuartzSubsystem::Initialize(FSubsystemCollectionBase& Collection)
{
	Super::Initialize(Collection);
	TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));

	if(const UWorld* WorldPtr = GetWorld())
	{
		if(Audio::FMixerDevice const* MixerDevice = static_cast<Audio::FMixerDevice*>(WorldPtr->GetAudioDeviceRaw()))
		{
			ClockManagerDataPtr = MixerDevice->QuartzSubsystemData;
		}
	}

	if(!ClockManagerDataPtr)
	{
		ClockManagerDataPtr = MakeShared<Audio::FPersistentQuartzSubsystemData>();
	}
}

void UQuartzSubsystem::Deinitialize()
{
	Super::Deinitialize();
	TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));

	if(Audio::FMixerDevice* MixerDevice = GetAudioMixerDevice(GetWorld()))
	{
		MixerDevice->QuartzSubsystemData = ClockManagerDataPtr;
	}
}

void UQuartzSubsystem::BeginDestroy()
{
	Super::BeginDestroy();

	// force un-subscribe all Quartz tickable objects
	if (ClockManagerDataPtr)
	{
		ClockManagerDataPtr->SubsystemClockManager.Flush();
	}
}

void FQuartzTickableObjectsManager::Tick(float DeltaTime)
{
	const int32 NumSubscribers = QuartzTickSubscribers.Num();
	if (MaxQuartzSubscribersToUpdatePerTickCvar <= 0 || NumSubscribers <= MaxQuartzSubscribersToUpdatePerTickCvar)
	{
		TArray<FQuartzTickableObject*> SubscribersCopy = QuartzTickSubscribers;

		// we can afford to update ALL subscribers
		for (FQuartzTickableObject* Entry : SubscribersCopy)
		{
			if (Entry && Entry->QuartzIsTickable())
			{
				Entry->QuartzTick(DeltaTime);
			}
		}

		UpdateIndex = 0;
	}
	else
	{
		// only update up to our limit
		for (int i = 0; i < MaxQuartzSubscribersToUpdatePerTickCvar; ++i)
		{
			FQuartzTickableObject* CurrentSubscriber = QuartzTickSubscribers[UpdateIndex];
			if (!ensure(CurrentSubscriber))
			{
				continue;
			}

			if (CurrentSubscriber->QuartzIsTickable())
			{
				CurrentSubscriber->QuartzTick(DeltaTime);
			}

			if (++UpdateIndex == NumSubscribers)
			{
				UpdateIndex = 0;
			}
		}
	}
}

bool FQuartzTickableObjectsManager::IsTickable() const
{
	const int32 NumSubscribers = QuartzTickSubscribers.Num();
	const bool bHasTickSubscribers = NumSubscribers > 0;
	TRACE_INT_VALUE(TEXT("QuartzSubsystem::NumSubscribers"), NumSubscribers);

	// if our manager has no clocks, and we have no ClockHandle subscribers, we don't need to tick
	if (!bHasTickSubscribers)
	{
		return false;
	}

	// if our manager has no clocks, and none of our subscribers are tickable, we don't need to tick
	for (const FQuartzTickableObject * Entry : QuartzTickSubscribers)
	{
		if (Entry && Entry->QuartzIsTickable())
		{
			return true;
		}
	}

	return false;
}

void FQuartzTickableObjectsManager::SubscribeToQuartzTick(FQuartzTickableObject* InObjectToTick)
{
	if (!InObjectToTick)
	{
		return;
	}

	QuartzTickSubscribers.AddUnique(InObjectToTick);
}

void FQuartzTickableObjectsManager::UnsubscribeFromQuartzTick(FQuartzTickableObject* InObjectToTick)
{
	if (!InObjectToTick)
	{
		return;
	}

	QuartzTickSubscribers.RemoveSingleSwap(InObjectToTick);
}


bool UQuartzSubsystem::DoesSupportWorldType(EWorldType::Type WorldType) const
{
	return Super::DoesSupportWorldType(WorldType) || WorldType == EWorldType::EditorPreview;
}


void UQuartzSubsystem::Tick(float DeltaTime)
{
	CSV_SCOPED_TIMING_STAT_EXCLUSIVE(Audio);
	Super::Tick(DeltaTime);
	TRACE_CPUPROFILER_EVENT_SCOPE(QuartzSubsystem::Tick);

	check(TickableObjectManagerPtr);
	check(ClockManagerDataPtr);
	TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));

	PruneStaleProxies();
	ClockManagerDataPtr->SubsystemClockManager.LowResoultionUpdate(DeltaTime);
	TickableObjectManagerPtr->Tick(DeltaTime);
}

bool UQuartzSubsystem::IsTickableWhenPaused() const
{
	return bTickEvenWhenPaused;
}

bool UQuartzSubsystem::IsTickable() const
{
	check(TickableObjectManagerPtr);
	check(ClockManagerDataPtr);
	TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));

	const int32 NumClocks = ClockManagerDataPtr->SubsystemClockManager.GetNumClocks();
	TRACE_INT_VALUE(TEXT("QuartzSubsystem::NumClocks"), NumClocks);

	// IsTickable() updates unreal insights values
	const bool bSubscribersNeedUpdate = TickableObjectManagerPtr->IsTickable();
	const bool bIsManagingClocks = NumClocks > 0;

	return bIsManagingClocks || bSubscribersNeedUpdate;
}

TStatId UQuartzSubsystem::GetStatId() const
{
	RETURN_QUICK_DECLARE_CYCLE_STAT(UQuartzSubsystem, STATGROUP_Tickables);
}

 void UQuartzSubsystem::SubscribeToQuartzTick(FQuartzTickableObject * InObjectToTick)
 {
	check(TickableObjectManagerPtr.IsValid());
 	TickableObjectManagerPtr->SubscribeToQuartzTick(InObjectToTick);
 }


 void UQuartzSubsystem::UnsubscribeFromQuartzTick(FQuartzTickableObject * InObjectToTick)
 {
	check(TickableObjectManagerPtr.IsValid());
 	TickableObjectManagerPtr->UnsubscribeFromQuartzTick(InObjectToTick);
 }


UQuartzSubsystem* UQuartzSubsystem::Get(const UWorld* const World)
{
	if (World)
	{
		return World->GetSubsystem<UQuartzSubsystem>();
	}

	return nullptr;
}


Audio::FQuartzQuantizedRequestData UQuartzSubsystem::CreateRequestDataForSchedulePlaySound(UQuartzClockHandle* InClockHandle, const FOnQuartzCommandEventBP& InDelegate, const FQuartzQuantizationBoundary& InQuantizationBoundary)
{
	Audio::FQuartzQuantizedRequestData CommandInitInfo;

	if (!InClockHandle)
	{
		return {};
	}

	CommandInitInfo.ClockName = InClockHandle->GetClockName();
	CommandInitInfo.QuantizationBoundary = InQuantizationBoundary;
	CommandInitInfo.QuantizedCommandPtr = MakeShared<Audio::FQuantizedPlayCommand>();
	CommandInitInfo.GameThreadSubscribers.Append(InQuantizationBoundary.GameThreadSubscribers);
	CommandInitInfo.GameThreadSubscribers.Add(InClockHandle->GetQuartzSubscriber());

	if (InDelegate.IsBound())
	{
		CommandInitInfo.GameThreadDelegateID = InClockHandle->AddCommandDelegate(InDelegate);
	}

	return CommandInitInfo;
}

bool UQuartzSubsystem::IsQuartzEnabled()
{
	return true;
}


Audio::FQuartzQuantizedRequestData UQuartzSubsystem::CreateRequestDataForTickRateChange(UQuartzClockHandle* InClockHandle, const FOnQuartzCommandEventBP& InDelegate, const Audio::FQuartzClockTickRate& InNewTickRate, const FQuartzQuantizationBoundary& InQuantizationBoundary)
{
	if (!ensure(InClockHandle))
	{
		return { };
	}

	const TSharedPtr<Audio::FQuantizedTickRateChange> TickRateChangeCommandPtr = MakeShared<Audio::FQuantizedTickRateChange>();
	TickRateChangeCommandPtr->SetTickRate(InNewTickRate);

	Audio::FQuartzQuantizedRequestData CommandInitInfo;

	CommandInitInfo.ClockName = InClockHandle->GetClockName();
	CommandInitInfo.QuantizationBoundary = InQuantizationBoundary;
	CommandInitInfo.QuantizedCommandPtr = TickRateChangeCommandPtr;
	CommandInitInfo.GameThreadSubscribers.Append(InQuantizationBoundary.GameThreadSubscribers);
	CommandInitInfo.GameThreadSubscribers.Add(InClockHandle->GetQuartzSubscriber());

	if (InDelegate.IsBound())
	{
		CommandInitInfo.GameThreadDelegateID = InClockHandle->AddCommandDelegate(InDelegate);
	}

	return CommandInitInfo;
}

Audio::FQuartzQuantizedRequestData UQuartzSubsystem::CreateRequestDataForTransportReset(UQuartzClockHandle* InClockHandle, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate)
{
	if (!ensure(InClockHandle))
	{
		return { };
	}

	const TSharedPtr<Audio::FQuantizedTransportReset> TransportResetCommandPtr = MakeShared<Audio::FQuantizedTransportReset>();

	Audio::FQuartzQuantizedRequestData CommandInitInfo;

	CommandInitInfo.ClockName = InClockHandle->GetClockName();
	CommandInitInfo.QuantizationBoundary = InQuantizationBoundary;
	CommandInitInfo.QuantizedCommandPtr = TransportResetCommandPtr;
	CommandInitInfo.GameThreadSubscribers.Append(InQuantizationBoundary.GameThreadSubscribers);
	CommandInitInfo.GameThreadSubscribers.Add(InClockHandle->GetQuartzSubscriber());

	if (InDelegate.IsBound())
	{
		CommandInitInfo.GameThreadDelegateID = InClockHandle->AddCommandDelegate(InDelegate);
	}

	return CommandInitInfo;
}

Audio::FQuartzQuantizedRequestData UQuartzSubsystem::CreateRequestDataForStartOtherClock(UQuartzClockHandle* InClockHandle, FName InClockToStart, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate)
{
	if (!ensure(InClockHandle))
	{
		return { };
	}

	const TSharedPtr<Audio::FQuantizedOtherClockStart> TransportResetCommandPtr = MakeShared<Audio::FQuantizedOtherClockStart>();

	Audio::FQuartzQuantizedRequestData CommandInitInfo;

	CommandInitInfo.ClockName = InClockHandle->GetClockName();
	CommandInitInfo.OtherClockName = InClockToStart;
	CommandInitInfo.QuantizationBoundary = InQuantizationBoundary;
	CommandInitInfo.QuantizedCommandPtr = TransportResetCommandPtr;
	CommandInitInfo.GameThreadSubscribers.Append(InQuantizationBoundary.GameThreadSubscribers);
	CommandInitInfo.GameThreadSubscribers.Add(InClockHandle->GetQuartzSubscriber());

	if (InDelegate.IsBound())
	{
		CommandInitInfo.GameThreadDelegateID = InClockHandle->AddCommandDelegate(InDelegate);
	}

	return CommandInitInfo;
}

Audio::FQuartzQuantizedRequestData UQuartzSubsystem::CreateRequestDataForQuantizedNotify(UQuartzClockHandle* InClockHandle, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, float InMsOffset)
{
	if (!ensure(InClockHandle))
	{
		return { };
	}

	const TSharedPtr<Audio::FQuantizedNotify> NotifyCommandPtr = MakeShared<Audio::FQuantizedNotify>(InMsOffset);

	Audio::FQuartzQuantizedRequestData CommandInitInfo;

	CommandInitInfo.ClockName = InClockHandle->GetClockName();
	CommandInitInfo.QuantizationBoundary = InQuantizationBoundary;
	CommandInitInfo.QuantizedCommandPtr = NotifyCommandPtr;
	CommandInitInfo.GameThreadSubscribers.Append(InQuantizationBoundary.GameThreadSubscribers);
	CommandInitInfo.GameThreadSubscribers.Add(InClockHandle->GetQuartzSubscriber());

	if (InDelegate.IsBound())
	{
		CommandInitInfo.GameThreadDelegateID = InClockHandle->AddCommandDelegate(InDelegate);
	}

	return CommandInitInfo;
}

Audio::FQuartzClockManager* UQuartzSubsystem::GetClockManager(const UObject* WorldContextObject, bool bUseAudioEngineClockManager)
{
	// decide if the clock should be managed by the AudioDevice (audio engine) or the Subsystem (this object)
	Audio::FQuartzClockManager* ClockManager;
	Audio::FMixerDevice* MixerDevice = GetAudioMixerDevice(WorldContextObject->GetWorld());
	if(!bUseAudioEngineClockManager || !MixerDevice)
	{
		check(ClockManagerDataPtr);
		TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));
		ClockManager = &ClockManagerDataPtr->SubsystemClockManager;
	}
	else
	{
		ClockManager = &MixerDevice->QuantizedEventClockManager;
	}

	// we should have fallen back to this object
	return ClockManager;
}

UQuartzClockHandle* UQuartzSubsystem::CreateNewClock(const UObject* WorldContextObject, FName ClockName, FQuartzClockSettings InSettings, bool bOverrideSettingsIfClockExists, bool bUseAudioEngineClockManager)
{
	if (ClockName.IsNone() || !WorldContextObject)
	{
		return nullptr;
	}

	Audio::FQuartzClockManager* ClockManager = GetClockManager(WorldContextObject, bUseAudioEngineClockManager);
	check(ClockManager); // should have at least fallen back to "this" object as a manager

	// numerator of time signature must be >= 1
	if (InSettings.TimeSignature.NumBeats < 1)
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Clock: (%s) is attempting to set a time signature with a Numerator < 1.  Clamping to 1 beat per bar"), *ClockName.ToString());
		InSettings.TimeSignature.NumBeats = 1;
	}

	Audio::FQuartzClockProxy ClockProxy = ClockManager->GetOrCreateClock(ClockName, InSettings, bOverrideSettingsIfClockExists);
	UQuartzClockHandle* ClockHandle = static_cast<UQuartzClockHandle*>(NewObject<UQuartzClockHandle>()->Init(WorldContextObject->GetWorld()));
	ClockHandle->SubscribeToClock(WorldContextObject, ClockName, &ClockProxy);

	// if we are not the manager for the clock, it means the FAudioDevice is,
	// so we hold onto our own copy of the proxy
	check(ClockManagerDataPtr);
	TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));
	ClockManagerDataPtr->ActiveAudioMixerClockProxies.Add(ClockProxy);

	return ClockHandle;
}


void UQuartzSubsystem::DeleteClockByName(const UObject* WorldContextObject, FName ClockName)
{
	// first look for the clock on the audio device's clock manager
	bool bShouldDeleteSynchronous = false;
	Audio::FQuartzClockManager* ClockManager = GetClockManager(WorldContextObject, /*bUseAudioEngineClockManager*/ true);

	if (ClockManager && !ClockManager->DoesClockExist(ClockName))
	{
		// if we didn't find it, assume the clock is on the subsystem's clock manager
		ClockManager = GetClockManager(WorldContextObject, /*bUseAudioEngineClockManager*/ false);
		bShouldDeleteSynchronous = true;
	}

	// if the clock is managed by the audio mixer device,
	// bShouldDeleteSynchronous is false, and it will be deleted on the correct thread.
	// if its managed by the subsystem, bShouldDeleteSynchronous will be true
	if(ClockManager)
	{
		ClockManager->RemoveClock(ClockName, bShouldDeleteSynchronous);
		PruneStaleProxies();
	}
}

void UQuartzSubsystem::DeleteClockByHandle(const UObject* WorldContextObject, UQuartzClockHandle*& InClockHandle)
{
	if (InClockHandle)
	{
		DeleteClockByName(WorldContextObject, InClockHandle->GetClockName());
	}
}

UQuartzClockHandle* UQuartzSubsystem::GetHandleForClock(const UObject* WorldContextObject, FName ClockName)
{
	Audio::FQuartzClockManager* ClockManager = GetClockManager(WorldContextObject);
	if (!ClockManager || !ClockManager->DoesClockExist(ClockName))
	{
		return nullptr;
	}

	Audio::FQuartzClockProxy ClockHandle = ClockManager->GetClock(ClockName);

	UQuartzClockHandle* ClockHandlePtr = static_cast<UQuartzClockHandle*>(NewObject<UQuartzClockHandle>()->Init(WorldContextObject->GetWorld()));
	return ClockHandlePtr->SubscribeToClock(WorldContextObject, ClockName, &ClockHandle);
}


Audio::FQuartzClockProxy UQuartzSubsystem::GetProxyForClock(FName ClockName) const
{
	if(Audio::FQuartzClockProxy const* ProxyPtr = FindProxyByName(ClockName))
	{
		return *ProxyPtr; // caller gets their own copy
	}

	return {};
}

void UQuartzSubsystem::AddProxyForExternalClock(const Audio::FQuartzClockProxy& InProxy)
{
	// make sure we aren't adding a duplicate name
	if(FindProxyByName(InProxy.GetClockName()))
	{
		UE_LOG(LogAudioQuartz, Warning, TEXT("Received request to add external Clock: (%s) when a clock of that name already exists (Ignoring Request)"), *InProxy.GetClockName().ToString());
		return;
	}
}


bool UQuartzSubsystem::DoesClockExist(const UObject* WorldContextObject, FName ClockName)
{
	Audio::FQuartzClockProxy const* Proxy = FindProxyByName(ClockName);
	if(Proxy && Proxy->IsValid())
	{
		return Proxy->DoesClockExist();
	}

	return {};
}

bool UQuartzSubsystem::IsClockRunning(const UObject* WorldContextObject, FName ClockName)
{
	Audio::FQuartzClockProxy const* Proxy = FindProxyByName(ClockName);
	if(Proxy && Proxy->IsValid())
	{
		return Proxy->IsClockRunning();
	}

	return {};
}

float UQuartzSubsystem::GetDurationOfQuantizationTypeInSeconds(const UObject* WorldContextObject, FName ClockName, const EQuartzCommandQuantization& QuantizationType, float Multiplier)
{
	Audio::FQuartzClockProxy const* Proxy = FindProxyByName(ClockName);
	if(Proxy && Proxy->IsValid())
	{
		return Proxy->GetDurationOfQuantizationTypeInSeconds(QuantizationType, Multiplier);
	}

	return {};
}

FQuartzTransportTimeStamp UQuartzSubsystem::GetCurrentClockTimestamp(const UObject* WorldContextObject, const FName& InClockName)
{
	Audio::FQuartzClockProxy const* Proxy = FindProxyByName(InClockName);
	if(Proxy && Proxy->IsValid())
	{
		return Proxy->GetCurrentClockTimestamp();
	}

	return {};
}

float UQuartzSubsystem::GetEstimatedClockRunTime(const UObject* WorldContextObject, const FName& InClockName)
{
	Audio::FQuartzClockProxy const* Proxy = FindProxyByName(InClockName);
	if(Proxy && Proxy->IsValid())
	{
		return Proxy->GetEstimatedClockRunTimeSeconds();
	}

	return {};
}

// todo: move FQuartLatencyTracker off the AudioMixerClockManager? (GameThread->AudioRenderThread tracking)
float UQuartzSubsystem::GetGameThreadToAudioRenderThreadAverageLatency(const UObject* WorldContextObject)
{
	Audio::FQuartzClockManager* ClockManager = GetClockManager(WorldContextObject);
	if (!ClockManager)
	{
		return { };
	}
	return ClockManager->GetLifetimeAverageLatency();
}


float UQuartzSubsystem::GetGameThreadToAudioRenderThreadMinLatency(const UObject* WorldContextObject)
{
	Audio::FQuartzClockManager* ClockManager = GetClockManager(WorldContextObject);
	if (!ClockManager)
	{
		return { };
	}
	return ClockManager->GetMinLatency();
}


float UQuartzSubsystem::GetGameThreadToAudioRenderThreadMaxLatency(const UObject* WorldContextObject)
{
	Audio::FQuartzClockManager* ClockManager = GetClockManager(WorldContextObject);
	if (!ClockManager)
	{
		return { };
	}
	return ClockManager->GetMinLatency();
}


float UQuartzSubsystem::GetAudioRenderThreadToGameThreadAverageLatency()
{
	check(TickableObjectManagerPtr.IsValid());
	return TickableObjectManagerPtr->GetLifetimeAverageLatency();
}


float UQuartzSubsystem::GetAudioRenderThreadToGameThreadMinLatency()
{
	check(TickableObjectManagerPtr.IsValid());
	return TickableObjectManagerPtr->GetMinLatency();
}


float UQuartzSubsystem::GetAudioRenderThreadToGameThreadMaxLatency()
{
	check(TickableObjectManagerPtr.IsValid());
	return TickableObjectManagerPtr->GetMaxLatency();
}


float UQuartzSubsystem::GetRoundTripAverageLatency(const UObject* WorldContextObject)
{
	// very much an estimate
	return GetAudioRenderThreadToGameThreadAverageLatency() + GetGameThreadToAudioRenderThreadAverageLatency(WorldContextObject);
}


float UQuartzSubsystem::GetRoundTripMinLatency(const UObject* WorldContextObject)
{
	return GetAudioRenderThreadToGameThreadMaxLatency() + GetGameThreadToAudioRenderThreadMaxLatency(WorldContextObject);
}


float UQuartzSubsystem::GetRoundTripMaxLatency(const UObject* WorldContextObject)
{
	return GetAudioRenderThreadToGameThreadMinLatency() + GetGameThreadToAudioRenderThreadMinLatency(WorldContextObject);
}

void UQuartzSubsystem::SetQuartzSubsystemTickableWhenPaused(const bool bInTickableWhenPaused)
{
	bTickEvenWhenPaused = bInTickableWhenPaused;
}

TWeakPtr<FQuartzTickableObjectsManager> UQuartzSubsystem::GetTickableObjectManager() const
{
	return TickableObjectManagerPtr;
}

void UQuartzSubsystem::PruneStaleProxies()
{
	check(ClockManagerDataPtr);
	TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));
	PruneStaleProxiesInternal(ClockManagerDataPtr->ActiveExternalClockProxies);
	PruneStaleProxiesInternal(ClockManagerDataPtr->ActiveAudioMixerClockProxies);
}

void UQuartzSubsystem::PruneStaleProxiesInternal(TArray<Audio::FQuartzClockProxy>& ContainerToPrune)
{
	 for(int32 i = 0; i < ContainerToPrune.Num(); ++i)
	 {
		 if(ContainerToPrune[i].IsValid() == false)
		 {
		 	ContainerToPrune.RemoveAtSwap(i--, EAllowShrinking::No);
		 }
	 }
}

Audio::FQuartzClockProxy* UQuartzSubsystem::FindProxyByName(const FName& ClockName)
{
	check(ClockManagerDataPtr);
	TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));
	Audio::FQuartzClockProxy* Result = ClockManagerDataPtr->ActiveAudioMixerClockProxies.FindByKey(ClockName);

	// if the subsystem doesn't have a match, check the externally-registered clock proxies
	if(!Result)
	{
		Result = ClockManagerDataPtr->ActiveExternalClockProxies.FindByKey(ClockName);
	}

	return Result;
}

Audio::FQuartzClockProxy const* UQuartzSubsystem::FindProxyByName(const FName& ClockName) const
{
	check(ClockManagerDataPtr);
	TUniquePtr<FScopeLock> Lock(GetPersistentStateScopeLock(GetWorld()));

	Audio::FQuartzClockProxy const* Result = ClockManagerDataPtr->ActiveAudioMixerClockProxies.FindByKey(ClockName);

	// if the subsystem doesn't have a match, check the externally-registered clock proxies
	if(!Result)
	{
		Result = ClockManagerDataPtr->ActiveExternalClockProxies.FindByKey(ClockName);
	}

	return Result;
}


===========================


=== QuartzSubsystem.h ===
=========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "Subsystems/WorldSubsystem.h"
#include "Quartz/AudioMixerClockManager.h"
#include "Sound/QuartzQuantizationUtilities.h"

#include "QuartzSubsystem.generated.h"


// forwards
namespace Audio
{
	class FMixerDevice;
	class FQuartzClockManager;
	class FQuartzShareableCommandQueue;

}

class FQuartzTickableObject;
class UQuartzClockHandle;
using MetronomeCommandQueuePtr = TSharedPtr<Audio::FQuartzShareableCommandQueue, ESPMode::ThreadSafe>;



struct FQuartzTickableObjectsManager : public FQuartLatencyTracker
{
public:
	AUDIOMIXER_API void Tick(float DeltaTime);
	AUDIOMIXER_API bool IsTickable() const;
	AUDIOMIXER_API void SubscribeToQuartzTick(FQuartzTickableObject* InObjectToTick);
	AUDIOMIXER_API void UnsubscribeFromQuartzTick(FQuartzTickableObject* InObjectToTick);

private:
	// list of objects needing to be ticked by Quartz
	TArray<FQuartzTickableObject *> QuartzTickSubscribers;

	// index to track the next subscriber to tick (if updates are being amortized across multiple UObject Ticks)
	int32 UpdateIndex{ 0 };
};


UCLASS(DisplayName = "Quartz", MinimalAPI)
class UQuartzSubsystem : public UTickableWorldSubsystem
{
	GENERATED_BODY()

public:
	// ctor/dtor
	UQuartzSubsystem() = default;
	virtual ~UQuartzSubsystem() override = default;

	//~ Begin UWorldSubsystem Interface
	AUDIOMIXER_API virtual void Initialize(FSubsystemCollectionBase& Collection) override;
	AUDIOMIXER_API virtual void Deinitialize() override;
	AUDIOMIXER_API virtual bool DoesSupportWorldType(EWorldType::Type WorldType) const override;
	AUDIOMIXER_API void virtual BeginDestroy() override;
	//~ End UWorldSubsystem Interface

	//~ Begin FTickableGameObject Interface
	AUDIOMIXER_API virtual void Tick(float DeltaTime) override;
	AUDIOMIXER_API virtual bool IsTickableWhenPaused() const override;
	AUDIOMIXER_API virtual bool IsTickable() const override;
	AUDIOMIXER_API virtual TStatId GetStatId() const override;
	//~ End FTickableGameObject Interface

	// these calls are forwarded to the internal FQuartzTickableObjectsManager
	AUDIOMIXER_API void SubscribeToQuartzTick(FQuartzTickableObject* InObjectToTick);
	AUDIOMIXER_API void UnsubscribeFromQuartzTick(FQuartzTickableObject* InObjectToTick);

	// get C++ handle (proxy) to a clock if it exists
	AUDIOMIXER_API Audio::FQuartzClockProxy GetProxyForClock(FName ClockName) const;

	// allow an external clock (not ticked by the Audio Mixer or QuartzSubsystem) to be accessible via this subsystem
	AUDIOMIXER_API void AddProxyForExternalClock(const Audio::FQuartzClockProxy& InProxy);

	// static methods
	static AUDIOMIXER_API UQuartzSubsystem* Get(const UWorld* const World);

	// Helper functions for initializing quantized command initialization struct (to consolidate eyesore)
	static AUDIOMIXER_API Audio::FQuartzQuantizedRequestData CreateRequestDataForTickRateChange(UQuartzClockHandle* InClockHandle, const FOnQuartzCommandEventBP& InDelegate, const Audio::FQuartzClockTickRate& InNewTickRate, const FQuartzQuantizationBoundary& InQuantizationBoundary);
	static AUDIOMIXER_API Audio::FQuartzQuantizedRequestData CreateRequestDataForTransportReset(UQuartzClockHandle* InClockHandle, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate);
	static AUDIOMIXER_API Audio::FQuartzQuantizedRequestData CreateRequestDataForStartOtherClock(UQuartzClockHandle* InClockHandle, FName InClockToStart, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate);
	static AUDIOMIXER_API Audio::FQuartzQuantizedRequestData CreateRequestDataForSchedulePlaySound(UQuartzClockHandle* InClockHandle, const FOnQuartzCommandEventBP& InDelegate, const FQuartzQuantizationBoundary& InQuantizationBoundary);
	static AUDIOMIXER_API Audio::FQuartzQuantizedRequestData CreateRequestDataForQuantizedNotify(UQuartzClockHandle* InClockHandle, const FQuartzQuantizationBoundary& InQuantizationBoundary, const FOnQuartzCommandEventBP& InDelegate, float InMsOffset = 0.f);

	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle")
	AUDIOMIXER_API bool IsQuartzEnabled();

	// Clock Creation
	// create a new clock (or return handle if clock already exists)
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject", AdvancedDisplay = "bUseAudioEngineClockManager"))
	AUDIOMIXER_API UQuartzClockHandle* CreateNewClock(const UObject* WorldContextObject, FName ClockName, FQuartzClockSettings InSettings, bool bOverrideSettingsIfClockExists = false, bool bUseAudioEngineClockManager = true);

	// delete an existing clock given its name
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void DeleteClockByName(const UObject* WorldContextObject, FName ClockName);

	// delete an existing clock given its clock handle
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API void DeleteClockByHandle(const UObject* WorldContextObject, UPARAM(ref) UQuartzClockHandle*& InClockHandle);

	// get handle for existing clock
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API UQuartzClockHandle* GetHandleForClock(const UObject* WorldContextObject, FName ClockName);

	// returns true if the clock exists
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API bool DoesClockExist(const UObject* WorldContextObject, FName ClockName);

	// returns true if the clock is running
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API bool IsClockRunning(const UObject* WorldContextObject, FName ClockName);

	// Returns the duration in seconds of the given Quantization Type
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetDurationOfQuantizationTypeInSeconds(const UObject* WorldContextObject, FName ClockName, const EQuartzCommandQuantization& QuantizationType, float Multiplier = 1.0f);

	// Retrieves a timestamp for the clock
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API FQuartzTransportTimeStamp GetCurrentClockTimestamp(const UObject* WorldContextObject, const FName& InClockName);

	// Returns the amount of time, in seconds, the clock has been running. Caution: due to latency, this will not be perfectly accurate
	UFUNCTION(BlueprintCallable, Category = "Quartz Clock Handle", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetEstimatedClockRunTime(const UObject* WorldContextObject, const FName& InClockName);

	// latency data (Game thread -> Audio Render Thread)
	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetGameThreadToAudioRenderThreadAverageLatency(const UObject* WorldContextObject);

	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetGameThreadToAudioRenderThreadMinLatency(const UObject* WorldContextObject);

	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetGameThreadToAudioRenderThreadMaxLatency(const UObject* WorldContextObject);

	// latency data (Audio Render Thread -> Game thread)
	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem")
	AUDIOMIXER_API float GetAudioRenderThreadToGameThreadAverageLatency();

	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem")
	AUDIOMIXER_API float GetAudioRenderThreadToGameThreadMinLatency();

	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem")
	AUDIOMIXER_API float GetAudioRenderThreadToGameThreadMaxLatency();

	// latency data (Round trip)
	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetRoundTripAverageLatency(const UObject* WorldContextObject);

	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetRoundTripMinLatency(const UObject* WorldContextObject);

	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem", meta = (WorldContext = "WorldContextObject"))
	AUDIOMIXER_API float GetRoundTripMaxLatency(const UObject* WorldContextObject);
	
	UFUNCTION(BlueprintCallable, Category = "Quartz Subsystem")
	AUDIOMIXER_API void SetQuartzSubsystemTickableWhenPaused(const bool bInTickableWhenPaused);

	// sharable to allow non-UObjects to un-subscribe if the Subsystem is going to outlive them
	AUDIOMIXER_API TWeakPtr<FQuartzTickableObjectsManager> GetTickableObjectManager() const;

private:
	// deletes proxies to clocks that no longer exists
	AUDIOMIXER_API void PruneStaleProxies();
	static AUDIOMIXER_API void PruneStaleProxiesInternal(TArray<Audio::FQuartzClockProxy>& ContainerToPrune);

	// sharable tickable object manager to allow for non-UObject subscription / un-subscription
	TSharedPtr<FQuartzTickableObjectsManager> TickableObjectManagerPtr { MakeShared<FQuartzTickableObjectsManager>() };

	// Clock manager/proxy-related data that lives on the AudioDevice for persistence.
	TSharedPtr<Audio::FPersistentQuartzSubsystemData> ClockManagerDataPtr { nullptr };

	bool bTickEvenWhenPaused = false;

	// helpers
	AUDIOMIXER_API Audio::FQuartzClockProxy* FindProxyByName(const FName& ClockName);
	AUDIOMIXER_API Audio::FQuartzClockProxy const* FindProxyByName(const FName& ClockName) const;
	AUDIOMIXER_API Audio::FQuartzClockManager* GetClockManager(const UObject* WorldContextObject, bool bUseAudioEngineClockManager = true);

}; // class UQuartzGameSubsystem

=========================


=== SoundFile.h ===
===================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "CoreMinimal.h"

#include "SoundFileIOEnums.h"


namespace Audio
{
	using SoundFileCount = int64;

	/**
	 * Specifies a sound file description.
	 * 
	 * Note that libsndfile reads some of these fields (noteably FormatFlags and bIsSeekable)
	 * at file open time so we zero them out at construction time to avoid unexpected/intermintent issues.
	 */
	struct FSoundFileDescription
	{
		/** The number of frames (interleaved samples) in the sound file. */
		int64 NumFrames = 0;

		/** The sample rate of the sound file. */
		int32 SampleRate = 0;

		/** The number of channels of the sound file. */
		int32 NumChannels = 0;

		/** The format flags of the sound file. */
		int32 FormatFlags = 0;

		/** The number of sections of the sound file. */
		int32 NumSections = 0;

		/** Whether or not the sound file is seekable. */
		int32 bIsSeekable = 0;
	};

	struct FSoundFileConvertFormat
	{
		/** Desired convert format. */
		int32 Format;

		/** Desired convert sample rate. */
		uint32 SampleRate;

		/** For compression-type target formats that used an encoding quality (0.0 = low, 1.0 = high). */
		double EncodingQuality;

		/** Whether or not to peak-normalize the audio file during import. */
		bool bPerformPeakNormalization;

		/** Creates audio engine's default source format */
		static FSoundFileConvertFormat CreateDefault()
		{
			FSoundFileConvertFormat Default = FSoundFileConvertFormat();
			Default.Format = Audio::ESoundFileFormat::WAV | Audio::ESoundFileFormat::PCM_SIGNED_16;
			Default.SampleRate = 48000;
			Default.EncodingQuality = 1.0;
			Default.bPerformPeakNormalization = false;

			return MoveTemp(Default);
		}
	};
	
	/**
	 * FSoundFileChunkInfo which maps to libsndfile SF_CHUNK_INFO struct.
	 */

	struct FSoundFileChunkInfo
	{
		/** Chunk Id **/
		ANSICHAR ChunkId[64];

		/** Size of the Chunk Id **/
		uint32 ChunkIdSize = 0;

		/** Size of the data in this chunk **/
		uint32 DataLength = 0;

		/** Pointer to chunk data **/
		void* DataPtr = nullptr;
	};

	/**
	 * FSoundFileChunkInfoWrapper wraps FSoundFileChunkInfo and manages
	 * chunk data memory.
	 */
	class FSoundFileChunkInfoWrapper
	{
	public:
		FSoundFileChunkInfoWrapper() = default;
		~FSoundFileChunkInfoWrapper() = default;
		FSoundFileChunkInfoWrapper(const FSoundFileChunkInfoWrapper& Other) = delete;
		FSoundFileChunkInfoWrapper& operator=(const FSoundFileChunkInfoWrapper& Other) = delete;

		FSoundFileChunkInfoWrapper(FSoundFileChunkInfoWrapper&& Other) noexcept
		{
			if (Other.ChunkInfo.ChunkIdSize)
			{
				FMemory::Memcpy(ChunkInfo.ChunkId, Other.ChunkInfo.ChunkId, sizeof(ChunkInfo.ChunkId));
			}
			ChunkInfo.ChunkIdSize = Other.ChunkInfo.ChunkIdSize;
			ChunkInfo.DataLength = Other.ChunkInfo.DataLength;
			ChunkInfo.DataPtr = Other.ChunkInfo.DataPtr;

			ChunkData = MoveTemp(Other.ChunkData);
		}

		FSoundFileChunkInfoWrapper& operator=(FSoundFileChunkInfoWrapper&& Other) noexcept
		{
			if (Other.ChunkInfo.ChunkIdSize)
			{
				FMemory::Memcpy(ChunkInfo.ChunkId, Other.ChunkInfo.ChunkId, sizeof(ChunkInfo.ChunkId));
			}
			ChunkInfo.ChunkIdSize = Other.ChunkInfo.ChunkIdSize;
			ChunkInfo.DataLength = Other.ChunkInfo.DataLength;
			ChunkInfo.DataPtr = Other.ChunkInfo.DataPtr;

			ChunkData = MoveTemp(Other.ChunkData);
			
			return *this;
		}

		void AllocateChunkData()
		{
			if (ChunkInfo.DataLength > 0 && ensure(ChunkInfo.DataPtr == nullptr))
			{
				ChunkData = MakeUnique<uint8[]>(ChunkInfo.DataLength);
				ChunkInfo.DataPtr = ChunkData.Get();
			}
		}

		FSoundFileChunkInfo* GetPtr()
		{
			return &ChunkInfo;
		}

		const FSoundFileChunkInfo* GetPtr() const
		{
			return &ChunkInfo;
		}

	private:
		FSoundFileChunkInfo	ChunkInfo;
		TUniquePtr<uint8[]>	ChunkData;
	};
	typedef TArray<FSoundFileChunkInfoWrapper> FSoundFileChunkArray;
	
	/**
	 * ISoundFile
	 */
	class ISoundFile
	{
	public:
		virtual ~ISoundFile() {}
		virtual ESoundFileError::Type GetState(ESoundFileState::Type& OutState) const = 0;
		virtual ESoundFileError::Type GetError() const = 0;
		virtual ESoundFileError::Type GetId(uint32& OutId) const = 0;
		virtual ESoundFileError::Type GetPath(FName& OutPath) const = 0;
		virtual ESoundFileError::Type GetBulkData(TArray<uint8>** OutData) const = 0;
		virtual ESoundFileError::Type GetDataSize(int32& DataSize) const = 0;
		virtual ESoundFileError::Type GetDescription(FSoundFileDescription& OutDescription) const = 0;
		virtual ESoundFileError::Type GetChannelMap(TArray<ESoundFileChannelMap::Type>& OutChannelMap) const = 0;
		virtual ESoundFileError::Type IsStreamed(bool& bOutIsStreamed) const = 0;
	};

	class ISoundFileReader
	{
	public:
		virtual ~ISoundFileReader() {}

		virtual ESoundFileError::Type Init(TSharedPtr<ISoundFile> InSoundFileData, bool bIsStreamed) = 0;
		virtual ESoundFileError::Type Init(const TArray<uint8>* InData) = 0;
		virtual ESoundFileError::Type Release() = 0;
		virtual ESoundFileError::Type SeekFrames(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) = 0;
		virtual ESoundFileError::Type ReadFrames(float* DataPtr, SoundFileCount NumFrames, SoundFileCount& OutNumFramesRead) = 0;
		virtual ESoundFileError::Type ReadFrames(double* DataPtr, SoundFileCount NumFrames, SoundFileCount& OutNumFramesRead) = 0;
		virtual ESoundFileError::Type ReadSamples(float* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSamplesRead) = 0;
		virtual ESoundFileError::Type ReadSamples(double* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSamplesRead) = 0;
		virtual ESoundFileError::Type GetDescription(FSoundFileDescription& OutputDescription, TArray<ESoundFileChannelMap::Type>& OutChannelMap) = 0;
		virtual ESoundFileError::Type GetOptionalChunks(FSoundFileChunkArray& OutChunkInfoArray) = 0;
	};

	class ISoundFileWriter
	{
	public:
		virtual ~ISoundFileWriter() {}

		virtual ESoundFileError::Type Init(const FSoundFileDescription& FileDescription, const TArray<ESoundFileChannelMap::Type>& InChannelMap, double EncodingQuality) = 0;
		virtual ESoundFileError::Type Release() = 0;
		virtual ESoundFileError::Type SeekFrames(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) = 0;
		virtual ESoundFileError::Type WriteFrames(const float* Data, SoundFileCount NumFrames, SoundFileCount& OutNumFramesWritten) = 0;
		virtual ESoundFileError::Type WriteFrames(const double* Data, SoundFileCount NumFrames, SoundFileCount& OutNumFramesWritten) = 0;
		virtual ESoundFileError::Type WriteSamples(const float* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSampleWritten) = 0;
		virtual ESoundFileError::Type WriteSamples(const double* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSampleWritten) = 0;
		virtual ESoundFileError::Type GetData(TArray<uint8>** OutData) = 0;
		virtual ESoundFileError::Type WriteOptionalChunks(const FSoundFileChunkArray& ChunkInfoArray) = 0;
	};
} // namespace Audio
===================


=== SoundFileIO.cpp ===
=======================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "SoundFileIO/SoundFileIO.h"

#include "CoreMinimal.h"

#include "Async/AsyncWork.h"
#include "AudioMixerDevice.h"
#include "Engine/Engine.h"
#include "EngineGlobals.h"
#include "Misc/FileHelper.h"
#include "Modules/ModuleManager.h"
#include "SoundFileIOManager.h"
#include "SoundFile.h"
#include "SoundFileIOEnums.h"
#include "Stats/Stats.h"


namespace Audio::SoundFileUtils
{
	static void CopyOptionalWavChunks(TSharedPtr<ISoundFileReader>& InSoundDataReader, const int32 InInputFormat, TSharedPtr<ISoundFileWriter>& InSoundFileWriter, const int32 InOutputFormat);

	bool AUDIOMIXER_API InitSoundFileIOManager()
	{
		return Audio::SoundFileIOManagerInit();
	}

	bool AUDIOMIXER_API ShutdownSoundFileIOManager()
	{
		return Audio::SoundFileIOManagerShutdown();
	}

	uint32 AUDIOMIXER_API GetNumSamples(const TArray<uint8>& InAudioData)
	{
		FSoundFileIOManager SoundIOManager;
		TSharedPtr<ISoundFileReader> InputSoundDataReader = SoundIOManager.CreateSoundDataReader();

		ESoundFileError::Type Error = InputSoundDataReader->Init(&InAudioData);
		if (Error != ESoundFileError::Type::NONE)
		{
			return 0;
		}

		TArray<ESoundFileChannelMap::Type> ChannelMap;

		FSoundFileDescription InputDescription;
		InputSoundDataReader->GetDescription(InputDescription, ChannelMap);
		InputSoundDataReader->Release();

		return InputDescription.NumFrames * InputDescription.NumChannels;
	}

	bool AUDIOMIXER_API ConvertAudioToWav(const TArray<uint8>& InAudioData, TArray<uint8>& OutWaveData)
	{
		const FSoundFileConvertFormat ConvertFormat = FSoundFileConvertFormat::CreateDefault();

		FSoundFileIOManager SoundIOManager;
		TSharedPtr<ISoundFileReader> InputSoundDataReader = SoundIOManager.CreateSoundDataReader();
		
		ESoundFileError::Type Error = InputSoundDataReader->Init(&InAudioData);
		if (Error != ESoundFileError::Type::NONE)
		{
			return false;
		}

		TArray<ESoundFileChannelMap::Type> ChannelMap;
		
		FSoundFileDescription InputDescription;
		InputSoundDataReader->GetDescription(InputDescription, ChannelMap);

		FSoundFileDescription NewSoundFileDescription;
		NewSoundFileDescription.NumChannels = InputDescription.NumChannels;
		NewSoundFileDescription.NumFrames = InputDescription.NumFrames;
		NewSoundFileDescription.FormatFlags = ConvertFormat.Format;
		NewSoundFileDescription.SampleRate = InputDescription.SampleRate;
		NewSoundFileDescription.NumSections = InputDescription.NumSections;
		NewSoundFileDescription.bIsSeekable = InputDescription.bIsSeekable;

		TSharedPtr<ISoundFileWriter> SoundFileWriter = SoundIOManager.CreateSoundFileWriter();
		Error = SoundFileWriter->Init(NewSoundFileDescription, ChannelMap, ConvertFormat.EncodingQuality);
		if (Error != ESoundFileError::Type::NONE)
		{
			return false;
		}

		// Copy optional chunks before writing data chunk which libsndfile assumes will be the last chunk
		CopyOptionalWavChunks(InputSoundDataReader, InputDescription.FormatFlags, SoundFileWriter, NewSoundFileDescription.FormatFlags);

		// Create a buffer to do the processing 
		SoundFileCount ProcessBufferSamples = static_cast<SoundFileCount>(1024) * NewSoundFileDescription.NumChannels;
		TArray<float> ProcessBuffer;
		ProcessBuffer.Init(0.0f, ProcessBufferSamples);

		// Find the max value if we've been told to do peak normalization on import
		float MaxValue = 0.0f;
		SoundFileCount InputSamplesRead = 0;
		bool bPerformPeakNormalization = ConvertFormat.bPerformPeakNormalization;
		if (bPerformPeakNormalization)
		{
			Error = InputSoundDataReader->ReadSamples(ProcessBuffer.GetData(), ProcessBufferSamples, InputSamplesRead);
			check(Error == ESoundFileError::Type::NONE);

			while (InputSamplesRead)
			{
				for (SoundFileCount Sample = 0; Sample < InputSamplesRead; ++Sample)
				{
					if (ProcessBuffer[Sample] > FMath::Abs(MaxValue))
					{
						MaxValue = ProcessBuffer[Sample];
					}
				}

				Error = InputSoundDataReader->ReadSamples(ProcessBuffer.GetData(), ProcessBufferSamples, InputSamplesRead);
				check(Error == ESoundFileError::Type::NONE);
			}

			// If this happens, it means we have a totally silent file
			if (MaxValue == 0.0)
			{
				bPerformPeakNormalization = false;
			}

			// Seek the file back to the beginning
			SoundFileCount OutOffset;
			InputSoundDataReader->SeekFrames(0, ESoundFileSeekMode::FROM_START, OutOffset);
		}

		bool SamplesProcessed = true;

		// Read the first block of samples
		Error = InputSoundDataReader->ReadSamples(ProcessBuffer.GetData(), ProcessBufferSamples, InputSamplesRead);
		check(Error == ESoundFileError::Type::NONE);

		// Normalize and clamp the input decoded audio
		if (bPerformPeakNormalization)
		{
			for (int32 Sample = 0; Sample < InputSamplesRead; ++Sample)
			{
				ProcessBuffer[Sample] = FMath::Clamp(ProcessBuffer[Sample] / MaxValue, -1.0f, 1.0f);
			}
		}
		else
		{
			for (int32 Sample = 0; Sample < InputSamplesRead; ++Sample)
			{
				ProcessBuffer[Sample] = FMath::Clamp(ProcessBuffer[Sample], -1.0f, 1.0f);
			}
		}

		SoundFileCount SamplesWritten = 0;

		while (InputSamplesRead == ProcessBuffer.Num())
		{
			Error = SoundFileWriter->WriteSamples((const float*)ProcessBuffer.GetData(), InputSamplesRead, SamplesWritten);
			check(Error == ESoundFileError::Type::NONE);
			check(SamplesWritten == InputSamplesRead);

			// read more samples
			Error = InputSoundDataReader->ReadSamples(ProcessBuffer.GetData(), ProcessBufferSamples, InputSamplesRead);
			check(Error == ESoundFileError::Type::NONE);

			// Normalize and clamp the samples
			if (bPerformPeakNormalization)
			{
				for (int32 Sample = 0; Sample < InputSamplesRead; ++Sample)
				{
					ProcessBuffer[Sample] = FMath::Clamp(ProcessBuffer[Sample] / MaxValue, -1.0f, 1.0f);
				}
			}
			else
			{
				for (int32 Sample = 0; Sample < InputSamplesRead; ++Sample)
				{
					ProcessBuffer[Sample] = FMath::Clamp(ProcessBuffer[Sample], -1.0f, 1.0f);
				}
			}
		}

		// Write final block of samples
		Error = SoundFileWriter->WriteSamples((const float*)ProcessBuffer.GetData(), InputSamplesRead, SamplesWritten);
		check(Error == ESoundFileError::Type::NONE);

		// Release the sound file handles as soon as we finished converting the file
		InputSoundDataReader->Release();
		SoundFileWriter->Release();

		// Get the raw binary data.....
		TArray<uint8>* Data = nullptr;
		SoundFileWriter->GetData(&Data);

		OutWaveData.Init(0, Data->Num());
		FMemory::Memcpy(OutWaveData.GetData(), (const void*)&(*Data)[0], OutWaveData.Num());

		return true;
	}

	void CopyOptionalWavChunks(TSharedPtr<ISoundFileReader>& InSoundDataReader, const int32 InInputFormat, TSharedPtr<ISoundFileWriter>& InSoundFileWriter, const int32 InOutputFormat)
	{
		// libsndfile only supports chunk operations with wave file formats
		if ((InInputFormat & ESoundFileFormat::WAV) && (InOutputFormat & ESoundFileFormat::WAV))
		{
			// Get the optional chunks from the input data
			FSoundFileChunkArray OptionalChunks;
			ESoundFileError::Type Error = InSoundDataReader->GetOptionalChunks(OptionalChunks);
			if (Error != ESoundFileError::Type::NONE)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("Error encountered while reading optional chunk data...skipping"));
			}
			else
			{
				// Copy any chunks found over to the output file
				Error = InSoundFileWriter->WriteOptionalChunks(OptionalChunks);
				if (Error != ESoundFileError::Type::NONE)
				{
					UE_LOG(LogAudioMixer, Error, TEXT("Error encountered while writing optional chunk data...skipping"));
				}
			}
		}
	}
}

=======================


=== SoundFileIO.h ===
=====================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once 

#include "CoreMinimal.h"

namespace Audio::SoundFileUtils
{
	bool AUDIOMIXER_API InitSoundFileIOManager();
	bool AUDIOMIXER_API ShutdownSoundFileIOManager();
	uint32 AUDIOMIXER_API GetNumSamples(const TArray<uint8>& InAudioData);
	bool AUDIOMIXER_API ConvertAudioToWav(const TArray<uint8>& InAudioData, TArray<uint8>& OutWaveData);
}

=====================


=== SoundFileIOEnums.h ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "CoreMinimal.h"


namespace Audio
{
	namespace ESoundFileError
	{
		enum class Type : uint8
		{
			NONE = 0,
			INVALID_SOUND_FILE,
			INVALID_SOUND_FILE_HANDLE,
			BAD_ENCODING_QUALITY,
			FAILED_TO_LOAD_BYTE_DATA,
			ALREADY_OPENED,
			ALREADY_HAS_DATA,
			INVALID_DATA,
			FILE_DOESNT_EXIST,
			INVALID_INPUT_FORMAT,
			INVALID_CHANNEL_MAP,
			FAILED_TO_OPEN,
			FAILED_TO_SEEK,
			ALREADY_INITIALIZED,
			LOADING,
			INVALID_STATE,
			INVALID_CHUNK,
			UNKNOWN
		};

		inline const TCHAR* ToString(ESoundFileError::Type SoundFileError)
		{
			switch (SoundFileError)
			{
			case Type::NONE:						return TEXT("NONE");
			case Type::INVALID_SOUND_FILE:			return TEXT("INVALID_SOUND_FILE");
			case Type::INVALID_SOUND_FILE_HANDLE:	return TEXT("INVALID_SOUND_FILE_HANDLE");
			case Type::BAD_ENCODING_QUALITY:		return TEXT("BAD_ENCODING_QUALITY");
			case Type::FAILED_TO_LOAD_BYTE_DATA:	return TEXT("FAILED_TO_LOAD_BYTE_DATA");
			case Type::ALREADY_OPENED:				return TEXT("ALREADY_OPENED");
			case Type::ALREADY_HAS_DATA:			return TEXT("ALREADY_HAS_DATA");
			case Type::INVALID_DATA:				return TEXT("INVALID_DATA");
			case Type::FILE_DOESNT_EXIST:			return TEXT("FILE_DOESNT_EXIST");
			case Type::INVALID_INPUT_FORMAT:		return TEXT("INVALID_INPUT_FORMAT");
			case Type::INVALID_CHANNEL_MAP:			return TEXT("INVALID_CHANNEL_MAP");
			case Type::FAILED_TO_OPEN:				return TEXT("FAILED_TO_OPEN");
			case Type::FAILED_TO_SEEK:				return TEXT("FAILED_TO_SEEK");
			case Type::ALREADY_INITIALIZED:			return TEXT("ALREADY_INITIALIZED");
			case Type::LOADING:						return TEXT("LOADING");
			case Type::INVALID_STATE:				return TEXT("INVALID_STATE");
			default: case Type::UNKNOWN:			return TEXT("UNKNOWN");
			}
		}
	} // namespace ESoundFileError

	namespace ESoundFileSeekMode
	{
		enum Type
		{
			FROM_START = 0,
			FROM_CURRENT = 1,
			FROM_END = 2,
		};
	} // namespace ESoundFileSeekMode

	/**
	 * Specifies the major format type of the sound source.
	 * File formats are fully specified by a major/minor format.
	 *
	 * For example, a Ogg-Vorbis encoding would use:
	 * uint32 FormatFlags = ESoundFormatFlags::OGG | ESoundFormatFlags::VORBIS;
	 */
	namespace ESoundFileFormat
	{
		enum Flags
		{
			// Major Formats
			WAV = 0x010000,		// Microsoft WAV format
			AIFF = 0x020000,		// Apple AIFF format
			FLAC = 0x170000,		// FLAC lossless
			OGG = 0x200000,		// Xiph OGG

			// Uncompressed Minor Formats
			PCM_SIGNED_8 = 0x0001,		// Signed 8 bit PCM
			PCM_SIGNED_16 = 0x0002,		// Signed 16 bit PCM
			PCM_SIGNED_24 = 0x0003,		// Signed 24 bit PCM
			PCM_SIGNED_32 = 0x0004,		// Signed 32 bit PCM
			PCM_UNSIGNED_8 = 0x0005,		// Unsigned 8 bit PCM
			PCM_FLOAT = 0x0006,		// 32 bit float
			PCM_DOUBLE = 0x0007,		// 64 bit float

			// Compressed Minor Formats
			MU_LAW = 0x0010,		// Mu-law encoding
			A_LAW = 0x0011,		// A-law encoding
			IMA_ADPCM = 0x0012,		// IMA ADPCM encoding
			MS_ADPCM = 0x0013,		// Microsoft ADPCM encoding
			GSM_610 = 0x0020,		// GSM 6.10 encoding
			G721_32 = 0x0030,		// 32 kbps G721 ADPCM encoding
			G723_24 = 0x0031,		// 23 kbps G723 ADPCM encoding
			G723_40 = 0x0032,		// 40 kbps G723 ADPCM encoding
			DWVW_12 = 0x0040,		// 12 bit delta-width variable word encoding
			DMVW_16 = 0x0041,		// 16 bit delta-width variable word encoding
			DMVW_24 = 0x0042,		// 24 bit delta-width variable word encoding
			DMVW_N = 0x0043,		// N bit delta-width variable word encoding
			VORBIS = 0x0060,		// Xiph vorbis encoding

			// Endian opts
			ENDIAN_FILE = 0x00000000,	// default file endian
			ENDIAN_LITTLE = 0x10000000,	// little-endian
			ENDIAN_BIG = 0x20000000,	// big-endian
			ENDIAN_CPU = 0x30000000,	// cpu-endian

			// Masks
			MINOR_FORMAT_MASK = 0x0000FFFF,
			MAJOR_FORMAT_MASK = 0x0FFF0000,
			ENDIAN_MASK = 0x30000000,
		};

		inline const TCHAR* ToStringMajor(int32 FormatFlags)
		{
			switch (FormatFlags & ESoundFileFormat::MAJOR_FORMAT_MASK)
			{
			case ESoundFileFormat::WAV:		return TEXT("WAV");
			case ESoundFileFormat::AIFF:	return TEXT("AIFF");
			case ESoundFileFormat::FLAC:	return TEXT("FLAC");
			case ESoundFileFormat::OGG:		return TEXT("OGG");
			default:						return TEXT("INVALID");
			}
		}

		inline const TCHAR* ToStringMinor(int32 FormatFlags)
		{
			switch (FormatFlags & ESoundFileFormat::MINOR_FORMAT_MASK)
			{
			case ESoundFileFormat::PCM_SIGNED_8:	return TEXT("PCM_SIGNED_8");
			case ESoundFileFormat::PCM_SIGNED_16:	return TEXT("PCM_SIGNED_16");
			case ESoundFileFormat::PCM_SIGNED_24:	return TEXT("PCM_SIGNED_24");
			case ESoundFileFormat::PCM_SIGNED_32:	return TEXT("PCM_SIGNED_32");
			case ESoundFileFormat::PCM_UNSIGNED_8:	return TEXT("PCM_UNSIGNED_8");
			case ESoundFileFormat::PCM_FLOAT:		return TEXT("PCM_FLOAT");
			case ESoundFileFormat::PCM_DOUBLE:		return TEXT("PCM_DOUBLE");
			case ESoundFileFormat::MU_LAW:			return TEXT("MU_LAW");
			case ESoundFileFormat::A_LAW:			return TEXT("A_LAW");
			case ESoundFileFormat::IMA_ADPCM:		return TEXT("IMA_ADPCM");
			case ESoundFileFormat::MS_ADPCM:		return TEXT("MS_ADPCM");
			case ESoundFileFormat::GSM_610:			return TEXT("GSM_610");
			case ESoundFileFormat::G721_32:			return TEXT("G721_32");
			case ESoundFileFormat::G723_24:			return TEXT("G723_24");
			case ESoundFileFormat::G723_40:			return TEXT("G723_40");
			case ESoundFileFormat::DWVW_12:			return TEXT("DWVW_12");
			case ESoundFileFormat::DMVW_16:			return TEXT("DMVW_16");
			case ESoundFileFormat::DMVW_24:			return TEXT("DMVW_24");
			case ESoundFileFormat::DMVW_N:			return TEXT("DMVW_N");
			case ESoundFileFormat::VORBIS:			return TEXT("VORBIS");
			default:								return TEXT("INVALID");
			}
		}
	} // namespace ESoundFileFormat;

	/*
	 * Enumeration to specify a sound files intended output channel mapping.
	 * @note These are separated from the device channel mappings purposefully since
	 * the enumeration may not exactly be the same as the output speaker mapping.
	 */
	namespace ESoundFileChannelMap
	{
		// this is used to populate an array which is passed into a sound file API call so must be uint32
		enum class Type : uint32
		{
			INVALID = 0,
			MONO,
			LEFT,
			RIGHT,
			CENTER,
			FRONT_LEFT,
			FRONT_RIGHT,
			FRONT_CENTER,
			BACK_CENTER,
			BACK_LEFT,
			BACK_RIGHT,
			LFE,
			LEFT_CENTER,
			RIGHT_CENTER,
			SIDE_LEFT,
			SIDE_RIGHT,
			TOP_CENTER,
			TOP_FRONT_LEFT,
			TOP_FRONT_RIGHT,
			TOP_FRONT_CENTER,
			TOP_BACK_LEFT,
			TOP_BACK_RIGHT,
			TOP_BACK_CENTER,
		};

		inline const TCHAR* ToString(ESoundFileChannelMap::Type ChannelMap)
		{
			switch (ChannelMap)
			{
			case Type::INVALID:				return TEXT("INVALID");
			case Type::MONO:				return TEXT("MONO");
			case Type::LEFT:				return TEXT("LEFT");
			case Type::RIGHT:				return TEXT("RIGHT");
			case Type::CENTER:				return TEXT("CENTER");
			case Type::FRONT_LEFT:			return TEXT("FRONT_LEFT");
			case Type::FRONT_RIGHT:			return TEXT("FRONT_RIGHT");
			case Type::FRONT_CENTER:		return TEXT("FRONT_CENTER");
			case Type::BACK_CENTER:			return TEXT("BACK_CENTER");
			case Type::BACK_LEFT:			return TEXT("BACK_LEFT");
			case Type::BACK_RIGHT:			return TEXT("BACK_RIGHT");
			case Type::LFE:					return TEXT("LFE");
			case Type::LEFT_CENTER:			return TEXT("LEFT_CENTER");
			case Type::RIGHT_CENTER:		return TEXT("RIGHT_CENTER");
			case Type::SIDE_LEFT:			return TEXT("SIDE_LEFT");
			case Type::SIDE_RIGHT:			return TEXT("SIDE_RIGHT");
			case Type::TOP_CENTER:			return TEXT("TOP_CENTER");
			case Type::TOP_FRONT_LEFT:		return TEXT("TOP_FRONT_LEFT");
			case Type::TOP_FRONT_RIGHT:		return TEXT("TOP_FRONT_RIGHT");
			case Type::TOP_FRONT_CENTER:	return TEXT("TOP_FRONT_CENTER");
			case Type::TOP_BACK_LEFT:		return TEXT("TOP_BACK_LEFT");
			case Type::TOP_BACK_RIGHT:		return TEXT("TOP_BACK_RIGHT");
			case Type::TOP_BACK_CENTER:		return TEXT("TOP_BACK_CENTER");
			default:						return TEXT("UNKNOWN");
			}
		}
	} // namespace ESoundFileChannelMap

	namespace ESoundFileOpenMode
	{
		enum Type
		{
			READING = 0x10,
			WRITING = 0x20,
			UNKNOWN = 0,
		};
	} // namespace ESoundFileOpenMode

	namespace ESoundFileState
	{
		enum Type
		{
			UNINITIALIZED = 0,
			INITIALIZED,
			LOADING,
			LOADED,
			STREAMING,
			WRITING,
			HAS_ERROR,
		};
	} // namespace ESoundFileState
} // namespace Audio
==========================


=== SoundFileIOManager.cpp ===
==============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "SoundFileIOManager.h"
#include "SoundFileIOManagerImpl.h"

#include "CoreMinimal.h"
#include "Templates/UniquePtr.h"

namespace Audio
{
	FSoundFileIOManager::FSoundFileIOManager()
	{
		Impl = TUniquePtr<FSoundFileIOManagerImpl>(new FSoundFileIOManagerImpl());
	}

	FSoundFileIOManager::~FSoundFileIOManager()
	{

	}

	TSharedPtr<ISoundFileReader> FSoundFileIOManager::CreateSoundFileReader()
	{
		if (Impl.IsValid())
		{
			return Impl->CreateSoundFileReader();
		}

		return nullptr;
	}

	TSharedPtr<ISoundFileReader> FSoundFileIOManager::CreateSoundDataReader()
	{
		if (Impl.IsValid())
		{
			return Impl->CreateSoundDataReader();
		}

		return nullptr;
	}

	TSharedPtr<ISoundFileWriter> FSoundFileIOManager::CreateSoundFileWriter()
	{
		if (Impl.IsValid())
		{
			return Impl->CreateSoundFileWriter();
		}

		return nullptr;
	}

	bool FSoundFileIOManager::GetSoundFileDescription(const FString& FilePath, FSoundFileDescription& OutputDescription, TArray<ESoundFileChannelMap::Type>& OutChannelMap)
	{
		if (Impl.IsValid())
		{
			return Impl->GetSoundFileDescription(FilePath, OutputDescription, OutChannelMap);
		}

		return false;
	}

	bool FSoundFileIOManager::GetSoundFileDescription(const FString& FilePath, FSoundFileDescription& OutputDescription)
	{
		if (Impl.IsValid())
		{
			return Impl->GetSoundFileDescription(FilePath, OutputDescription);
		}

		return false;
	}

	bool FSoundFileIOManager::GetFileExtensionForFormatFlags(int32 FormatFlags, FString& OutExtension)
	{
		if (Impl.IsValid())
		{
			return Impl->GetFileExtensionForFormatFlags(FormatFlags, OutExtension);
		}

		return false;
	}

	ESoundFileError::Type FSoundFileIOManager::GetSoundFileInfoFromPath(const FString& FilePath, FSoundFileDescription& Description, TArray<ESoundFileChannelMap::Type>& ChannelMap)
	{
		if (Impl.IsValid())
		{
			return Impl->GetSoundFileInfoFromPath(FilePath, Description, ChannelMap);
		}

		return ESoundFileError::Type::UNKNOWN;
	}

	ESoundFileError::Type FSoundFileIOManager::LoadSoundFileFromPath(const FString& FilePath, FSoundFileDescription& Description, TArray<ESoundFileChannelMap::Type>& ChannelMap, TArray<uint8>& BulkData)
	{
		if (Impl.IsValid())
		{
			return Impl->LoadSoundFileFromPath(FilePath, Description, ChannelMap, BulkData);
		}

		return ESoundFileError::Type::UNKNOWN;
	}
}


==============================


=== SoundFileIOManager.h ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "CoreMinimal.h"
#include "SoundFile.h"
#include "SoundFileIOEnums.h"

namespace Audio
{
	class FSoundFileIOManagerImpl;

	class FSoundFileIOManager
	{
	public:
		FSoundFileIOManager();
		~FSoundFileIOManager();

		TSharedPtr<ISoundFileReader> CreateSoundFileReader();
		TSharedPtr<ISoundFileReader> CreateSoundDataReader();
		TSharedPtr<ISoundFileWriter> CreateSoundFileWriter();

		bool GetSoundFileDescription(const FString& FilePath, FSoundFileDescription& OutputDescription, TArray<ESoundFileChannelMap::Type>& OutChannelMap);
		bool GetSoundFileDescription(const FString& FilePath, FSoundFileDescription& OutputDescription);
		bool GetFileExtensionForFormatFlags(int32 FormatFlags, FString& OutExtension);
		ESoundFileError::Type GetSoundFileInfoFromPath(const FString& FilePath, FSoundFileDescription& Description, TArray<ESoundFileChannelMap::Type>& ChannelMap);
		ESoundFileError::Type LoadSoundFileFromPath(const FString& FilePath, FSoundFileDescription& Description, TArray<ESoundFileChannelMap::Type>& ChannelMap, TArray<uint8>& BulkData);

	private:
		TUniquePtr<FSoundFileIOManagerImpl> Impl;
	};

	bool SoundFileIOManagerInit();
	bool SoundFileIOManagerShutdown();
} // namespace Audio

============================


=== SoundFileIOManagerImpl.cpp ===
==================================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "SoundFileIOManagerImpl.h"

#include "CoreMinimal.h"

#include "Audio.h"
#include "AudioMixer.h"
#include "HAL/PlatformProcess.h"
#include "HAL/PlatformFileManager.h"
#include "Misc/FileHelper.h"
#include "Misc/Paths.h"
#include "Modules/ModuleManager.h"

#ifndef WITH_SNDFILE_IO
#define WITH_SNDFILE_IO (0)
#endif //WITH_SNDFILE_IO


namespace Audio
{
	typedef struct SoundFileHandleOpaque LibSoundFileHandle;
	typedef struct SoundFileChunkIteratorOpaque LibSoundFileChunkIterator;

	//	// Virtual Sound File Function Pointers
	typedef SoundFileCount(*VirtualSoundFileGetLengthFuncPtr)(void* UserData);
	typedef SoundFileCount(*VirtualSoundFileSeekFuncPtr)(SoundFileCount Offset, int32 Mode, void* UserData);
	typedef SoundFileCount(*VirtualSoundFileReadFuncPtr)(void* DataPtr, SoundFileCount ByteCount, void* UserData);
	typedef SoundFileCount(*VirtualSoundFileWriteFuncPtr)(const void* DataPtr, SoundFileCount ByteCount, void* UserData);
	typedef SoundFileCount(*VirtualSoundFileTellFuncPtr)(void* UserData);

	// Struct describing function pointers to call for virtual file IO
	struct FVirtualSoundFileCallbackInfo
	{
		VirtualSoundFileGetLengthFuncPtr VirtualSoundFileGetLength;
		VirtualSoundFileSeekFuncPtr VirtualSoundFileSeek;
		VirtualSoundFileReadFuncPtr VirtualSoundFileRead;
		VirtualSoundFileWriteFuncPtr VirtualSoundFileWrite;
		VirtualSoundFileTellFuncPtr VirtualSoundFileTell;
	};

	// SoundFile Constants
	static const int32 SET_ENCODING_QUALITY = 0x1300;
	static const int32 SET_CHANNEL_MAP_INFO = 0x1101;
	static const int32 GET_CHANNEL_MAP_INFO = 0x1100;
	static const int32 UPDATE_HEADER_NOW = 0x1060;

	// Exported SoundFile Functions
	typedef LibSoundFileHandle*(*SoundFileOpenFuncPtr)(const char* Path, int32 Mode, FSoundFileDescription* Description);
	typedef LibSoundFileHandle*(*SoundFileOpenVirtualFuncPtr)(FVirtualSoundFileCallbackInfo* VirtualFileDescription, int32 Mode, FSoundFileDescription* Description, void* UserData);
	typedef int32(*SoundFileCloseFuncPtr)(LibSoundFileHandle* FileHandle);
	typedef int32(*SoundFileErrorFuncPtr)(LibSoundFileHandle* FileHandle);
	typedef const char*(*SoundFileStrErrorFuncPtr)(LibSoundFileHandle* FileHandle);
	typedef const char*(*SoundFileErrorNumberFuncPtr)(int32 ErrorNumber);
	typedef int32(*SoundFileCommandFuncPtr)(LibSoundFileHandle* FileHandle, int32 Command, void* Data, int32 DataSize);
	typedef int32(*SoundFileFormatCheckFuncPtr)(const FSoundFileDescription* Description);
	typedef SoundFileCount(*SoundFileSeekFuncPtr)(LibSoundFileHandle* FileHandle, SoundFileCount NumFrames, int32 SeekMode);
	typedef const char*(*SoundFileGetVersionFuncPtr)(void);
	typedef SoundFileCount(*SoundFileReadFramesFloatFuncPtr)(LibSoundFileHandle* FileHandle, float* Buffer, SoundFileCount NumFrames);
	typedef SoundFileCount(*SoundFileReadFramesDoubleFuncPtr)(LibSoundFileHandle* FileHandle, double* Buffer, SoundFileCount NumFrames);
	typedef SoundFileCount(*SoundFileWriteFramesFloatFuncPtr)(LibSoundFileHandle* FileHandle, const float* Buffer, SoundFileCount NumFrames);
	typedef SoundFileCount(*SoundFileWriteFramesDoubleFuncPtr)(LibSoundFileHandle* FileHandle, const double* Buffer, SoundFileCount NumFrames);
	typedef SoundFileCount(*SoundFileReadSamplesFloatFuncPtr)(LibSoundFileHandle* FileHandle, float* Buffer, SoundFileCount NumSamples);
	typedef SoundFileCount(*SoundFileReadSamplesDoubleFuncPtr)(LibSoundFileHandle* FileHandle, double* Buffer, SoundFileCount NumSamples);
	typedef SoundFileCount(*SoundFileWriteSamplesFloatFuncPtr)(LibSoundFileHandle* FileHandle, const float* Buffer, SoundFileCount NumSamples);
	typedef SoundFileCount(*SoundFileWriteSamplesDoubleFuncPtr)(LibSoundFileHandle* FileHandle, const double* Buffer, SoundFileCount NumSamples);
	typedef int32(*SoundFileGetChunkSizeFuncPtr)(const LibSoundFileChunkIterator* ChunkIterator, FSoundFileChunkInfo* ChunkInfo);
	typedef int32(*SoundFileGetChunkDataFuncPtr)(const LibSoundFileChunkIterator* ChunkIterator, FSoundFileChunkInfo* ChunkInfo);
	typedef LibSoundFileChunkIterator*(*SoundFileGetChunkIteratorFuncPtr)(LibSoundFileHandle* FileHandle, const FSoundFileChunkInfo* ChunkInfo);
	typedef LibSoundFileChunkIterator*(*SoundFileNextChunkIteratorFuncPtr)(LibSoundFileChunkIterator* ChunkIterator);
	typedef int32(*SoundFileSetChunkFuncPtr)(LibSoundFileHandle* FileHandle, const FSoundFileChunkInfo* ChunkInfo);

	SoundFileOpenFuncPtr SoundFileOpen = nullptr;
	SoundFileOpenVirtualFuncPtr SoundFileOpenVirtual = nullptr;
	SoundFileCloseFuncPtr SoundFileClose = nullptr;
	SoundFileErrorFuncPtr SoundFileError = nullptr;
	SoundFileStrErrorFuncPtr SoundFileStrError = nullptr;
	SoundFileErrorNumberFuncPtr SoundFileErrorNumber = nullptr;
	SoundFileCommandFuncPtr SoundFileCommand = nullptr;
	SoundFileFormatCheckFuncPtr SoundFileFormatCheck = nullptr;
	SoundFileSeekFuncPtr SoundFileSeek = nullptr;
	SoundFileGetVersionFuncPtr SoundFileGetVersion = nullptr;
	SoundFileReadFramesFloatFuncPtr SoundFileReadFramesFloat = nullptr;
	SoundFileReadFramesDoubleFuncPtr SoundFileReadFramesDouble = nullptr;
	SoundFileWriteFramesFloatFuncPtr SoundFileWriteFramesFloat = nullptr;
	SoundFileWriteFramesDoubleFuncPtr SoundFileWriteFramesDouble = nullptr;
	SoundFileReadSamplesFloatFuncPtr SoundFileReadSamplesFloat = nullptr;
	SoundFileReadSamplesDoubleFuncPtr SoundFileReadSamplesDouble = nullptr;
	SoundFileWriteSamplesFloatFuncPtr SoundFileWriteSamplesFloat = nullptr;
	SoundFileWriteSamplesDoubleFuncPtr SoundFileWriteSamplesDouble = nullptr;
	SoundFileGetChunkSizeFuncPtr SoundFileGetChunkSize = nullptr;
	SoundFileGetChunkDataFuncPtr SoundFileGetChunkData = nullptr;
	SoundFileGetChunkIteratorFuncPtr SoundFileGetChunkIterator = nullptr;
	SoundFileNextChunkIteratorFuncPtr SoundFileNextChunkIterator = nullptr;
	SoundFileSetChunkFuncPtr SoundFileSetChunk = nullptr;

	void* SoundFileDllHandle;
	static void* GetSoundFileDllHandle()
	{
		void* DllHandle = nullptr;
#if WITH_SNDFILE_IO 
	#if PLATFORM_WINDOWS
		const FString PlatformPath = TEXT("Win64/");
		const FString DllName = TEXT("libsndfile-1.dll");
	#elif PLATFORM_MAC //PLATFORM_WINDOWS
		const FString PlatformPath = TEXT("Mac/");
		const FString DllName = TEXT("libsndfile.1.dylib");
	#elif PLATFORM_LINUX //PLATFORM_MAC
		const FString PlatformPath = TEXT("Linux/");
		const FString DllName = ("libsndfile.so.1");
	#else //PLATFORM_LINUX
		#pragma message ("Platform not supported");
		const FString PlatformPath;
		const FString DllName;
	#endif //PLATFORM_LINUX

		const FString Path = FPaths::EngineDir() / FString(TEXT("Binaries/ThirdParty/libsndfile/")) / PlatformPath;
		FPlatformProcess::PushDllDirectory(*Path);
		DllHandle = FPlatformProcess::GetDllHandle(*(Path + DllName));
		FPlatformProcess::PopDllDirectory(*Path);

#endif //WITH_SNDFILE_IO
		return DllHandle;
	}

	static bool LoadSoundFileLib()
	{
		SoundFileDllHandle = GetSoundFileDllHandle();
		if (!SoundFileDllHandle)
		{
			UE_LOG(LogAudioMixer, Display, TEXT("Failed to load Sound File dll"));
			return false;
		}

		bool bSuccess = true;

		void* LambdaDLLHandle = SoundFileDllHandle;

		// Helper function to load DLL exports and report warnings
		auto GetSoundFileDllExport = [&LambdaDLLHandle](const TCHAR* FuncName, bool& bInSuccess) -> void*
		{
			if (bInSuccess)
			{
				void* FuncPtr = FPlatformProcess::GetDllExport(LambdaDLLHandle, FuncName);
				if (FuncPtr == nullptr)
				{
					bInSuccess = false;
					UE_LOG(LogAudioMixer, Warning, TEXT("Failed to locate the expected DLL import function '%s' in the SoundFile DLL."), FuncName);
					FPlatformProcess::FreeDllHandle(LambdaDLLHandle);
					LambdaDLLHandle = nullptr;
				}
				return FuncPtr;
			}
			else
			{
				return nullptr;
			}
		};

		SoundFileOpen = (SoundFileOpenFuncPtr)GetSoundFileDllExport(TEXT("sf_open"), bSuccess);
		SoundFileOpenVirtual = (SoundFileOpenVirtualFuncPtr)GetSoundFileDllExport(TEXT("sf_open_virtual"), bSuccess);
		SoundFileClose = (SoundFileCloseFuncPtr)GetSoundFileDllExport(TEXT("sf_close"), bSuccess);
		SoundFileError = (SoundFileErrorFuncPtr)GetSoundFileDllExport(TEXT("sf_error"), bSuccess);
		SoundFileStrError = (SoundFileStrErrorFuncPtr)GetSoundFileDllExport(TEXT("sf_strerror"), bSuccess);
		SoundFileErrorNumber = (SoundFileErrorNumberFuncPtr)GetSoundFileDllExport(TEXT("sf_error_number"), bSuccess);
		SoundFileCommand = (SoundFileCommandFuncPtr)GetSoundFileDllExport(TEXT("sf_command"), bSuccess);
		SoundFileFormatCheck = (SoundFileFormatCheckFuncPtr)GetSoundFileDllExport(TEXT("sf_format_check"), bSuccess);
		SoundFileSeek = (SoundFileSeekFuncPtr)GetSoundFileDllExport(TEXT("sf_seek"), bSuccess);
		SoundFileGetVersion = (SoundFileGetVersionFuncPtr)GetSoundFileDllExport(TEXT("sf_version_string"), bSuccess);
		SoundFileReadFramesFloat = (SoundFileReadFramesFloatFuncPtr)GetSoundFileDllExport(TEXT("sf_readf_float"), bSuccess);
		SoundFileReadFramesDouble = (SoundFileReadFramesDoubleFuncPtr)GetSoundFileDllExport(TEXT("sf_readf_double"), bSuccess);
		SoundFileWriteFramesFloat = (SoundFileWriteFramesFloatFuncPtr)GetSoundFileDllExport(TEXT("sf_writef_float"), bSuccess);
		SoundFileWriteFramesDouble = (SoundFileWriteFramesDoubleFuncPtr)GetSoundFileDllExport(TEXT("sf_writef_double"), bSuccess);
		SoundFileReadSamplesFloat = (SoundFileReadSamplesFloatFuncPtr)GetSoundFileDllExport(TEXT("sf_read_float"), bSuccess);
		SoundFileReadSamplesDouble = (SoundFileReadSamplesDoubleFuncPtr)GetSoundFileDllExport(TEXT("sf_read_double"), bSuccess);
		SoundFileWriteSamplesFloat = (SoundFileWriteSamplesFloatFuncPtr)GetSoundFileDllExport(TEXT("sf_write_float"), bSuccess);
		SoundFileWriteSamplesDouble = (SoundFileWriteSamplesDoubleFuncPtr)GetSoundFileDllExport(TEXT("sf_write_double"), bSuccess);
		SoundFileGetChunkSize = (SoundFileGetChunkSizeFuncPtr)GetSoundFileDllExport(TEXT("sf_get_chunk_size"), bSuccess);
		SoundFileGetChunkData = (SoundFileGetChunkDataFuncPtr)GetSoundFileDllExport(TEXT("sf_get_chunk_data"), bSuccess);
		SoundFileGetChunkIterator = (SoundFileGetChunkIteratorFuncPtr)GetSoundFileDllExport(TEXT("sf_get_chunk_iterator"), bSuccess);
		SoundFileNextChunkIterator = (SoundFileNextChunkIteratorFuncPtr)GetSoundFileDllExport(TEXT("sf_next_chunk_iterator"), bSuccess);
		SoundFileSetChunk = (SoundFileSetChunkFuncPtr)GetSoundFileDllExport(TEXT("sf_set_chunk"), bSuccess);

		// make sure we're successful
		check(bSuccess);
		return bSuccess;
	}

	static bool ShutdownSoundFileLib()
	{
		if (SoundFileDllHandle)
		{
			FPlatformProcess::FreeDllHandle(SoundFileDllHandle);
			SoundFileDllHandle = nullptr;
			SoundFileOpen = nullptr;
			SoundFileOpenVirtual = nullptr;
			SoundFileClose = nullptr;
			SoundFileError = nullptr;
			SoundFileStrError = nullptr;
			SoundFileErrorNumber = nullptr;
			SoundFileCommand = nullptr;
			SoundFileFormatCheck = nullptr;
			SoundFileSeek = nullptr;
			SoundFileGetVersion = nullptr;
			SoundFileReadFramesFloat = nullptr;
			SoundFileReadFramesDouble = nullptr;
			SoundFileWriteFramesFloat = nullptr;
			SoundFileWriteFramesDouble = nullptr;
			SoundFileReadSamplesFloat = nullptr;
			SoundFileReadSamplesDouble = nullptr;
			SoundFileWriteSamplesFloat = nullptr;
			SoundFileWriteSamplesDouble = nullptr;
			SoundFileGetChunkSize = nullptr;
			SoundFileGetChunkData = nullptr;
			SoundFileGetChunkIterator = nullptr;
			SoundFileNextChunkIterator = nullptr;
			SoundFileSetChunk = nullptr;
		}
		return true;
	}

	/**
	Function implementations of virtual function callbacks
	*/
	class ISoundFileParser
	{
	public:
		virtual ~ISoundFileParser() {}

		virtual ESoundFileError::Type GetLengthBytes(SoundFileCount& OutLength) const = 0;
		virtual ESoundFileError::Type SeekBytes(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) = 0;
		virtual ESoundFileError::Type ReadBytes(void* DataPtr, SoundFileCount NumBytes, SoundFileCount& NumBytesRead) = 0;
		virtual ESoundFileError::Type WriteBytes(const void* DataPtr, SoundFileCount NumBytes, SoundFileCount& NumBytesWritten) = 0;
		virtual ESoundFileError::Type GetOffsetBytes(SoundFileCount& OutOffset) const = 0;
	};

	///**
	//* Gets the default channel mapping for the given channel number
	//*/
	static void GetDefaultMappingsForChannelNumber(int32 NumChannels, TArray<ESoundFileChannelMap::Type>& ChannelMap)
	{
		check(ChannelMap.Num() == NumChannels);

		switch (NumChannels)
		{
		case 1:	// MONO
			ChannelMap[0] = ESoundFileChannelMap::Type::MONO;
			break;

		case 2:	// STEREO
			ChannelMap[0] = ESoundFileChannelMap::Type::LEFT;
			ChannelMap[1] = ESoundFileChannelMap::Type::RIGHT;
			break;

		case 3:	// 2.1
			ChannelMap[0] = ESoundFileChannelMap::Type::LEFT;
			ChannelMap[1] = ESoundFileChannelMap::Type::RIGHT;
			ChannelMap[2] = ESoundFileChannelMap::Type::LFE;
			break;

		case 4: // Quadraphonic
			ChannelMap[0] = ESoundFileChannelMap::Type::LEFT;
			ChannelMap[1] = ESoundFileChannelMap::Type::RIGHT;
			ChannelMap[2] = ESoundFileChannelMap::Type::BACK_LEFT;
			ChannelMap[3] = ESoundFileChannelMap::Type::BACK_RIGHT;
			break;

		case 5: // 5.0
			ChannelMap[0] = ESoundFileChannelMap::Type::LEFT;
			ChannelMap[1] = ESoundFileChannelMap::Type::RIGHT;
			ChannelMap[2] = ESoundFileChannelMap::Type::CENTER;
			ChannelMap[3] = ESoundFileChannelMap::Type::SIDE_LEFT;
			ChannelMap[4] = ESoundFileChannelMap::Type::SIDE_RIGHT;
			break;

		case 6: // 5.1
			ChannelMap[0] = ESoundFileChannelMap::Type::LEFT;
			ChannelMap[1] = ESoundFileChannelMap::Type::RIGHT;
			ChannelMap[2] = ESoundFileChannelMap::Type::CENTER;
			ChannelMap[3] = ESoundFileChannelMap::Type::LFE;
			ChannelMap[4] = ESoundFileChannelMap::Type::SIDE_LEFT;
			ChannelMap[5] = ESoundFileChannelMap::Type::SIDE_RIGHT;
			break;

		case 7: // 6.1
			ChannelMap[0] = ESoundFileChannelMap::Type::LEFT;
			ChannelMap[1] = ESoundFileChannelMap::Type::RIGHT;
			ChannelMap[2] = ESoundFileChannelMap::Type::CENTER;
			ChannelMap[3] = ESoundFileChannelMap::Type::LFE;
			ChannelMap[4] = ESoundFileChannelMap::Type::SIDE_LEFT;
			ChannelMap[5] = ESoundFileChannelMap::Type::SIDE_RIGHT;
			ChannelMap[6] = ESoundFileChannelMap::Type::BACK_CENTER;
			break;

		case 8: // 7.1
			ChannelMap[0] = ESoundFileChannelMap::Type::LEFT;
			ChannelMap[1] = ESoundFileChannelMap::Type::RIGHT;
			ChannelMap[2] = ESoundFileChannelMap::Type::CENTER;
			ChannelMap[3] = ESoundFileChannelMap::Type::LFE;
			ChannelMap[4] = ESoundFileChannelMap::Type::BACK_LEFT;
			ChannelMap[5] = ESoundFileChannelMap::Type::BACK_RIGHT;
			ChannelMap[6] = ESoundFileChannelMap::Type::SIDE_LEFT;
			ChannelMap[7] = ESoundFileChannelMap::Type::SIDE_RIGHT;
			break;

		default:
			break;
		}
	}

	static ESoundFileError::Type GetSoundDesriptionInternal(LibSoundFileHandle** OutFileHandle, const FString& FilePath, FSoundFileDescription& OutputDescription, TArray<ESoundFileChannelMap::Type>& OutChannelMap)
	{
		*OutFileHandle = nullptr;

		// Check to see if the file exists
		if (!FPaths::FileExists(FilePath))
		{
			UE_LOG(LogAudioMixer, Error, TEXT("Sound file %s doesn't exist."), *FilePath);
			return ESoundFileError::Type::FILE_DOESNT_EXIST;
		}

		// open a sound file handle to get the description
		if (SoundFileOpen != nullptr)
		{
			*OutFileHandle = SoundFileOpen(TCHAR_TO_ANSI(*FilePath), ESoundFileOpenMode::READING, &OutputDescription);
		}
		else
		{
			UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileOpen."));
			*OutFileHandle = nullptr;
		}

		if (!*OutFileHandle)
		{
			if (!SoundFileStrError)
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			FString StrError = FString(SoundFileStrError(nullptr));
			UE_LOG(LogAudioMixer, Error, TEXT("Failed to open sound file %s: %s"), *FilePath, *StrError);
			return ESoundFileError::Type::FAILED_TO_OPEN;
		}

		// Try to get a channel mapping
		int32 NumChannels = OutputDescription.NumChannels;
		OutChannelMap.Init(ESoundFileChannelMap::Type::INVALID, NumChannels);

		int32 Result = 0;
		if (SoundFileCommand)
		{
			Result = SoundFileCommand(*OutFileHandle, GET_CHANNEL_MAP_INFO, (int32*)OutChannelMap.GetData(), sizeof(int32)*NumChannels);
		}
		else
		{
			UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile wasn't properly loaded with symbols for SoundFileCommand."));
		}

		// If we failed to get the file's channel map definition, then we set the default based on the number of channels
		if (Result == 0)
		{
			GetDefaultMappingsForChannelNumber(NumChannels, OutChannelMap);
		}
		else
		{
			// Check to see if the channel map we did get back is filled with INVALID channels
			bool bIsInvalid = false;
			for (ESoundFileChannelMap::Type ChannelType : OutChannelMap)
			{
				if (ChannelType == ESoundFileChannelMap::Type::INVALID)
				{
					bIsInvalid = true;
					break;
				}
			}
			// If invalid, then we need to get the default channel mapping
			if (bIsInvalid)
			{
				GetDefaultMappingsForChannelNumber(NumChannels, OutChannelMap);
			}
		}

		return ESoundFileError::Type::NONE;
	}

	static ESoundFileError::Type GetOptionalChunksInternal(LibSoundFileHandle* FileHandle, FSoundFileChunkArray& OutChunkInfoArray)
	{
		// Verify that the necessary library function pointers have been properly set
		if (SoundFileGetChunkIterator != nullptr && SoundFileGetChunkSize != nullptr &&
			SoundFileGetChunkData != nullptr && SoundFileNextChunkIterator != nullptr)
		{
			const TArray<uint32>& OptionalChunkIds = FWaveModInfo::GetOptionalWaveChunkIds();

			for (const uint32 Id : OptionalChunkIds)
			{
				FSoundFileChunkInfo ChunkLookup;				
				// Copy chunk ID over. DWORD (4 bytes, each is ANSI char)
				*reinterpret_cast<uint32*>(ChunkLookup.ChunkId) = Id;
				ChunkLookup.ChunkId[4] = 0;		// Null terminate the string just in case.
				
				ChunkLookup.ChunkIdSize = 5;	// 4 bytes, + null.
				

				// Lookup chunk of given Id. Multiple chunks can exist of a given type
				// so we loop here.
				LibSoundFileChunkIterator* ChunkItr = SoundFileGetChunkIterator(FileHandle, &ChunkLookup);
				while (ChunkItr)
				{
					FSoundFileChunkInfoWrapper ChunkInfo;
					// SoundFileGetChunkSize retrieves the chunk data size. Oddly,
					// it does not fill in the chunk Id.
					int32 Result = SoundFileGetChunkSize(ChunkItr, ChunkInfo.GetPtr());
					if (Result == 0 && ChunkInfo.GetPtr()->DataLength > 0)
					{
						ChunkInfo.AllocateChunkData();
						// SoundFileGetChunkData copies in the chunk data and fills
						// in the ChunkId.
						Result = SoundFileGetChunkData(ChunkItr, ChunkInfo.GetPtr());

						if (Result == 0)
						{
							OutChunkInfoArray.Add(MoveTemp(ChunkInfo));
						}
						else
						{
							UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile unable to read invalid chunk: %s"), *FString((ANSICHAR*)ChunkLookup.ChunkId));
							return ESoundFileError::Type::INVALID_CHUNK;
						}
					}

					ChunkItr = SoundFileNextChunkIterator(ChunkItr);
				}
			}
		}
		else
		{
			UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile wasn't properly loaded with symbols for accessing wav chunk data."));
		}

		return ESoundFileError::Type::NONE;
	}

	static ESoundFileError::Type WriteOptionalChunksInternal(LibSoundFileHandle* FileHandle, const FSoundFileChunkArray& ChunkInfoArray)
	{
		// Verify that the necessary library function pointers have been properly set
		if (SoundFileSetChunk != nullptr && SoundFileCommand != nullptr)
		{
			for (const FSoundFileChunkInfoWrapper& ChunkInfo : ChunkInfoArray)
			{
				// Note, libsndfile uses 4-byte pad when writing chunk data
				int32 Result = SoundFileSetChunk(FileHandle, ChunkInfo.GetPtr());
				if (Result)
				{
					UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to write chunk data; Result = %d"), Result);
					return ESoundFileError::Type::INVALID_STATE;
				}
				else
				{
					UE_LOG(LogAudioMixer, VeryVerbose, TEXT("Wrote ChunkId: %s, chunk DataLength: %d"), *FString((ANSICHAR*)ChunkInfo.GetPtr()->ChunkId), ChunkInfo.GetPtr()->DataLength);

					// Update file header after adding a new chunk
					Result = SoundFileCommand(FileHandle, UPDATE_HEADER_NOW, nullptr, 0);
					if (Result)
					{
						UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to update file header; Result = %d"), Result);
						return ESoundFileError::Type::INVALID_STATE;
					}
				}
			}
		}
		else
		{
			UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile wasn't properly loaded with symbols for accessing wav chunk data."));
		}

		return ESoundFileError::Type::NONE;
	}
	
	static SoundFileCount OnSoundFileGetLengthBytes(void* UserData)
	{
		SoundFileCount Length = 0;
		((ISoundFileParser*)UserData)->GetLengthBytes(Length);
		return Length;
	}

	static SoundFileCount OnSoundFileSeekBytes(SoundFileCount Offset, int32 Mode, void* UserData)
	{
		SoundFileCount OutOffset = 0;
		((ISoundFileParser*)UserData)->SeekBytes(Offset, (ESoundFileSeekMode::Type)Mode, OutOffset);
		return OutOffset;
	}

	static SoundFileCount OnSoundFileReadBytes(void* DataPtr, SoundFileCount ByteCount, void* UserData)
	{
		SoundFileCount OutBytesRead = 0;
		((ISoundFileParser*)UserData)->ReadBytes(DataPtr, ByteCount, OutBytesRead);
		return OutBytesRead;
	}

	static SoundFileCount OnSoundFileWriteBytes(const void* DataPtr, SoundFileCount ByteCount, void* UserData)
	{
		SoundFileCount OutBytesWritten = 0;
		((ISoundFileParser*)UserData)->WriteBytes(DataPtr, ByteCount, OutBytesWritten);
		return OutBytesWritten;
	}

	static SoundFileCount OnSoundFileTell(void* UserData)
	{
		SoundFileCount OutOffset = 0;
		((ISoundFileParser*)UserData)->GetOffsetBytes(OutOffset);
		return OutOffset;
	}

	/************************************************************************/
	/* FSoundFileReader														*/
	/************************************************************************/
	class FSoundFileReader final : public ISoundFileParser, public ISoundFileReader
	{
	public:
		FSoundFileReader()
			: CurrentIndexBytes(0)
			, FileHandle(nullptr)
			, State(ESoundFileState::UNINITIALIZED)
			, CurrentError(static_cast<int32>(ESoundFileError::Type::NONE))
		{
		}

		~FSoundFileReader()
		{
			Release();
			check(FileHandle == nullptr);
		}

		ESoundFileError::Type GetLengthBytes(SoundFileCount& OutLength) const override
		{
			if (!SoundFileData.IsValid())
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			int32 DataSize;
			ESoundFileError::Type Error = SoundFileData->GetDataSize(DataSize);
			if (Error == ESoundFileError::Type::NONE)
			{
				OutLength = DataSize;
				return ESoundFileError::Type::NONE;
			}
			return Error;
		}

		ESoundFileError::Type SeekBytes(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) override
		{
			if (!SoundFileData.IsValid())
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			int32 DataSize;
			ESoundFileError::Type Error = SoundFileData->GetDataSize(DataSize);
			if (Error != ESoundFileError::Type::NONE)
			{
				return Error;
			}

			SoundFileCount MaxBytes = DataSize;
			if (MaxBytes == 0)
			{
				OutOffset = 0;
				CurrentIndexBytes = 0;
				return ESoundFileError::Type::NONE;
			}

			switch (SeekMode)
			{
			case ESoundFileSeekMode::FROM_START:
				CurrentIndexBytes = Offset;
				break;

			case ESoundFileSeekMode::FROM_CURRENT:
				CurrentIndexBytes += Offset;
				break;

			case ESoundFileSeekMode::FROM_END:
				CurrentIndexBytes = MaxBytes + Offset;
				break;

			default:
				checkf(false, TEXT("Uknown seek mode!"));
				break;
			}

			// Wrap the byte index to fall between 0 and MaxBytes
			while (CurrentIndexBytes < 0)
			{
				CurrentIndexBytes += MaxBytes;
			}

			while (CurrentIndexBytes > MaxBytes)
			{
				CurrentIndexBytes -= MaxBytes;
			}

			OutOffset = CurrentIndexBytes;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadBytes(void* DataPtr, SoundFileCount NumBytes, SoundFileCount& OutNumBytesRead) override
		{
			if (!SoundFileData.IsValid())
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			SoundFileCount EndByte = CurrentIndexBytes + NumBytes;

			int32 DataSize;
			ESoundFileError::Type Error = SoundFileData->GetDataSize(DataSize);
			if (Error != ESoundFileError::Type::NONE)
			{
				return Error;
			}
			SoundFileCount MaxBytes = DataSize;
			if (EndByte >= MaxBytes)
			{
				NumBytes = MaxBytes - CurrentIndexBytes;
			}

			if (NumBytes > 0)
			{
				TArray<uint8>* BulkData = nullptr;
				Error = SoundFileData->GetBulkData(&BulkData);
				if (Error != ESoundFileError::Type::NONE)
				{
					return Error;
				}

				check(BulkData != nullptr);

				FMemory::Memcpy(DataPtr, (const void*)&(*BulkData)[CurrentIndexBytes], NumBytes);
				CurrentIndexBytes += NumBytes;
			}
			OutNumBytesRead = NumBytes;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type WriteBytes(const void* DataPtr, SoundFileCount NumBytes, SoundFileCount& OutNumBytesWritten) override
		{
			// This should never get called in the reader class
			check(false);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type GetOffsetBytes(SoundFileCount& OutOffset) const override
		{
			OutOffset = CurrentIndexBytes;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type Init(TSharedPtr<ISoundFile> InSoundFileData, bool bIsStreamed) override
		{
			if (bIsStreamed)
			{
				return InitStreamed(InSoundFileData);
			}
			else
			{
				return InitLoaded(InSoundFileData);
			}
		}

		ESoundFileError::Type Init(const TArray<uint8>* InData)
		{
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type Release() override
		{
			if (!SoundFileClose)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileClose"));
				FileHandle = nullptr;
				return ESoundFileError::Type::INVALID_STATE;
			}

			if (FileHandle)
			{
				SoundFileClose(FileHandle);
				FileHandle = nullptr;
			}
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type GetDescription(FSoundFileDescription& OutputDescription, TArray<ESoundFileChannelMap::Type>& OutChannelMap)
		{
			SoundFileData->GetDescription(OutputDescription);
			SoundFileData->GetChannelMap(OutChannelMap);

			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type SeekFrames(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) override
		{
			if (!SoundFileSeek)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileSeek"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			SoundFileCount Pos = SoundFileSeek(FileHandle, Offset, (int32)SeekMode);
			if (Pos == -1)
			{
				if (!SoundFileStrError)
				{
					return SetError(ESoundFileError::Type::INVALID_STATE);
				}

				FString StrErr = SoundFileStrError(FileHandle);
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to seek file: %s"), *StrErr);
				return SetError(ESoundFileError::Type::FAILED_TO_SEEK);
			}
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadFrames(float* DataPtr, SoundFileCount NumFrames, SoundFileCount& OutNumFramesRead) override
		{
			if (!SoundFileReadFramesFloat)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileReadFramesFloat"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumFramesRead = SoundFileReadFramesFloat(FileHandle, DataPtr, NumFrames);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadFrames(double* DataPtr, SoundFileCount NumFrames, SoundFileCount& OutNumFramesRead) override
		{
			if (!SoundFileReadFramesDouble)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileReadFramesDouble"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumFramesRead = SoundFileReadFramesDouble(FileHandle, DataPtr, NumFrames);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadSamples(float* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSamplesRead) override
		{
			if (!SoundFileReadSamplesFloat)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileReadSamplesFloat"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumSamplesRead = SoundFileReadSamplesFloat(FileHandle, DataPtr, NumSamples);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadSamples(double* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSamplesRead) override
		{
			if (!SoundFileReadSamplesDouble)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileReadSamplesDouble"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumSamplesRead = SoundFileReadSamplesDouble(FileHandle, DataPtr, NumSamples);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type GetOptionalChunks(FSoundFileChunkArray& OutChunkInfoArray) override
		{
			return GetOptionalChunksInternal(FileHandle, OutChunkInfoArray);
		}

	private:

		ESoundFileError::Type InitLoaded(TSharedPtr<ISoundFile> InSoundFileData)
		{
			if (!(State.GetValue() == ESoundFileState::UNINITIALIZED || State.GetValue() == ESoundFileState::LOADING))
			{
				return SetError(ESoundFileError::Type::ALREADY_INITIALIZED);
			}

			check(InSoundFileData.IsValid());
			check(FileHandle == nullptr);

			// Setting sound file data initializes this sound file
			SoundFileData = InSoundFileData;
			check(SoundFileData.IsValid());

			bool bIsStreamed;
			ESoundFileError::Type Error = SoundFileData->IsStreamed(bIsStreamed);
			if (Error != ESoundFileError::Type::NONE)
			{
				return Error;
			}

			if (bIsStreamed)
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			ESoundFileState::Type SoundFileState;
			Error = SoundFileData->GetState(SoundFileState);
			if (Error != ESoundFileError::Type::NONE)
			{
				return Error;
			}

			if (SoundFileState != ESoundFileState::LOADED)
			{
				return ESoundFileError::Type::INVALID_STATE;
			}

			// Open up a virtual file handle with this data
			FVirtualSoundFileCallbackInfo VirtualSoundFileInfo;
			VirtualSoundFileInfo.VirtualSoundFileGetLength = OnSoundFileGetLengthBytes;
			VirtualSoundFileInfo.VirtualSoundFileSeek = OnSoundFileSeekBytes;
			VirtualSoundFileInfo.VirtualSoundFileRead = OnSoundFileReadBytes;
			VirtualSoundFileInfo.VirtualSoundFileWrite = OnSoundFileWriteBytes;
			VirtualSoundFileInfo.VirtualSoundFileTell = OnSoundFileTell;

			FSoundFileDescription Description;
			SoundFileData->GetDescription(Description);

			if (!SoundFileFormatCheck)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileFormatCheck"));
				return SetError(ESoundFileError::Type::INVALID_STATE);
			}

			if (!SoundFileFormatCheck(&Description))
			{
				return SetError(ESoundFileError::Type::INVALID_INPUT_FORMAT);
			}

			if (!SoundFileOpenVirtual)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileOpenVirtual"));
				FileHandle = nullptr;
			}
			else
			{
				FileHandle = SoundFileOpenVirtual(&VirtualSoundFileInfo, ESoundFileOpenMode::READING, &Description, (void*)this);
			}
			
			if (!FileHandle)
			{
				if (!SoundFileStrError)
				{
					return SetError(ESoundFileError::Type::INVALID_DATA);
				}

				FString StrErr = SoundFileStrError(nullptr);
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to intitialize sound file: %s"), *StrErr);
				return SetError(ESoundFileError::Type::FAILED_TO_OPEN);
			}

			State.Set(ESoundFileState::INITIALIZED);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type InitStreamed(TSharedPtr<ISoundFile> InSoundFileData)
		{
			if (!(State.GetValue() == ESoundFileState::UNINITIALIZED || State.GetValue() == ESoundFileState::LOADING))
			{
				return SetError(ESoundFileError::Type::ALREADY_INITIALIZED);
			}

			check(InSoundFileData.IsValid());
			check(FileHandle == nullptr);

			// Setting sound file data initializes this sound file
			SoundFileData = InSoundFileData;
			check(SoundFileData.IsValid());

			bool bIsStreamed;
			ESoundFileError::Type Error = SoundFileData->IsStreamed(bIsStreamed);
			if (Error != ESoundFileError::Type::NONE)
			{
				return Error;
			}

			if (!bIsStreamed)
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			ESoundFileState::Type SoundFileState;
			Error = SoundFileData->GetState(SoundFileState);
			if (Error != ESoundFileError::Type::NONE)
			{
				return Error;
			}

			if (SoundFileState != ESoundFileState::STREAMING)
			{
				return ESoundFileError::Type::INVALID_STATE;
			}

			FName NamePath;
			Error = SoundFileData->GetPath(NamePath);
			if (Error != ESoundFileError::Type::NONE)
			{
				return Error;
			}

			FString FilePath = NamePath.GetPlainNameString();

			FSoundFileDescription Description;
			TArray<ESoundFileChannelMap::Type> ChannelMap;
			Error = GetSoundDesriptionInternal(&FileHandle, FilePath, Description, ChannelMap);
			if (Error == ESoundFileError::Type::NONE)
			{
				// Tell this reader that we're in streaming mode.
				State.Set(ESoundFileState::STREAMING);
				return ESoundFileError::Type::NONE;
			}
			else
			{
				return SetError(Error);
			}
		}

		ESoundFileError::Type SetError(ESoundFileError::Type InError)
		{
			if (InError != ESoundFileError::Type::NONE)
			{
				State.Set(ESoundFileState::HAS_ERROR);
			}
			CurrentError.Set(static_cast<int32>(InError));
			return InError;
		}

		TSharedPtr<ISoundFile>	SoundFileData;
		SoundFileCount			CurrentIndexBytes;
		LibSoundFileHandle*		FileHandle;
		FThreadSafeCounter		State;
		FThreadSafeCounter		CurrentError;
	};


	/************************************************************************/
	/* FSoundDataReader														*/
	/************************************************************************/
	class FSoundDataReader : public ISoundFileParser, public ISoundFileReader
	{
	public:
		FSoundDataReader()
			: CurrentIndexBytes(0)
			, State(ESoundFileState::UNINITIALIZED)
			, CurrentError(static_cast<int32>(ESoundFileError::Type::NONE))
			, ChannelMap()
		{
		}

		~FSoundDataReader()
		{
			Release();
		}

		ESoundFileError::Type GetLengthBytes(SoundFileCount& OutLength) const override
		{
			if (SoundData == nullptr)
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			OutLength = SoundData->GetAllocatedSize();

			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type SeekBytes(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) override
		{
			if (SoundData == nullptr)
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			int32 DataSize = SoundData->GetAllocatedSize();

			SoundFileCount MaxBytes = DataSize;
			if (MaxBytes == 0)
			{
				OutOffset = 0;
				CurrentIndexBytes = 0;
				return ESoundFileError::Type::NONE;
			}

			switch (SeekMode)
			{
			case ESoundFileSeekMode::FROM_START:
				CurrentIndexBytes = Offset;
				break;

			case ESoundFileSeekMode::FROM_CURRENT:
				CurrentIndexBytes += Offset;
				break;

			case ESoundFileSeekMode::FROM_END:
				CurrentIndexBytes = MaxBytes + Offset;
				break;

			default:
				checkf(false, TEXT("Uknown seek mode!"));
				break;
			}

			// Wrap the byte index to fall between 0 and MaxBytes
			while (CurrentIndexBytes < 0)
			{
				CurrentIndexBytes += MaxBytes;
			}

			while (CurrentIndexBytes > MaxBytes)
			{
				CurrentIndexBytes -= MaxBytes;
			}

			OutOffset = CurrentIndexBytes;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadBytes(void* DataPtr, SoundFileCount NumBytes, SoundFileCount& OutNumBytesRead) override
		{
			if (SoundData == nullptr)
			{
				return ESoundFileError::Type::INVALID_DATA;
			}

			SoundFileCount EndByte = CurrentIndexBytes + NumBytes;

			int32 DataSize = SoundData->GetAllocatedSize();
			
			SoundFileCount MaxBytes = DataSize;
			if (EndByte >= MaxBytes)
			{
				NumBytes = MaxBytes - CurrentIndexBytes;
			}

			if (NumBytes > 0)
			{
				FMemory::Memcpy(DataPtr, (const void*)&(*SoundData)[CurrentIndexBytes], NumBytes);
				CurrentIndexBytes += NumBytes;
			}
			OutNumBytesRead = NumBytes;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type WriteBytes(const void* DataPtr, SoundFileCount NumBytes, SoundFileCount& OutNumBytesWritten) override
		{
			// This should never get called in the reader class
			check(false);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type GetOffsetBytes(SoundFileCount& OutOffset) const override
		{
			OutOffset = CurrentIndexBytes;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type Init(TSharedPtr<ISoundFile> InSoundFileData, bool bIsStreamed) override
		{
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type Init(const TArray<uint8>* InData)
		{
			SoundData = InData;

			// Open up a virtual file handle with this data
			FVirtualSoundFileCallbackInfo VirtualSoundFileInfo;
			VirtualSoundFileInfo.VirtualSoundFileGetLength = OnSoundFileGetLengthBytes;
			VirtualSoundFileInfo.VirtualSoundFileSeek = OnSoundFileSeekBytes;
			VirtualSoundFileInfo.VirtualSoundFileRead = OnSoundFileReadBytes;
			VirtualSoundFileInfo.VirtualSoundFileWrite = OnSoundFileWriteBytes;
			VirtualSoundFileInfo.VirtualSoundFileTell = OnSoundFileTell;

			if (SoundFileOpenVirtual)
			{
				FileHandle = SoundFileOpenVirtual(&VirtualSoundFileInfo, ESoundFileOpenMode::READING, &Description, (void*)this);
			}
			else
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileOpenVirtual."));
				FileHandle = nullptr;
			}

			if (!FileHandle)
			{
				if (!SoundFileStrError)
				{
					return SetError(ESoundFileError::Type::INVALID_DATA);
				}

				FString StrErr = SoundFileStrError(nullptr);
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to initialize sound file: %s"), *StrErr);
				return SetError(ESoundFileError::Type::FAILED_TO_OPEN);
			}

			// Try to get a channel mapping
			int32 NumChannels = Description.NumChannels;
			ChannelMap.Init(ESoundFileChannelMap::Type::INVALID, NumChannels);
			
			int32 Result = 0;
			if (SoundFileCommand)
			{
				Result = SoundFileCommand(FileHandle, GET_CHANNEL_MAP_INFO, (int32*)ChannelMap.GetData(), sizeof(int32)*NumChannels);
			}
			else
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileCommand."));
			}

			// If we failed to get the file's channel map definition, then we set the default based on the number of channels
			if (Result == 0)
			{
				GetDefaultMappingsForChannelNumber(NumChannels, ChannelMap);
			}
			else
			{
				// Check to see if the channel map we did get back is filled with INVALID channels
				bool bIsInvalid = false;
				for (ESoundFileChannelMap::Type ChannelType : ChannelMap)
				{
					if (ChannelType == ESoundFileChannelMap::Type::INVALID)
					{
						bIsInvalid = true;
						break;
					}
				}
				// If invalid, then we need to get the default channel mapping
				if (bIsInvalid)
				{
					GetDefaultMappingsForChannelNumber(NumChannels, ChannelMap);
				}
			}

			State.Set(ESoundFileState::INITIALIZED);

			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type Release() override final
		{
			SoundData = nullptr;

			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type GetDescription(FSoundFileDescription& OutputDescription, TArray<ESoundFileChannelMap::Type>& OutChannelMap)
		{
			OutputDescription = Description;
			OutChannelMap = ChannelMap;

			return ESoundFileError::Type::NONE;
		}


		ESoundFileError::Type SeekFrames(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) override
		{
			if (!SoundFileSeek)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load."));
				return ESoundFileError::Type::INVALID_STATE;
			}

			SoundFileCount Pos = SoundFileSeek(FileHandle, Offset, (int32)SeekMode);
			if (Pos == -1)
			{
				if (!SoundFileStrError)
				{
					return SetError(ESoundFileError::Type::INVALID_DATA);
				}

				FString StrErr = SoundFileStrError(FileHandle);
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to seek file: %s"), *StrErr);
				return SetError(ESoundFileError::Type::FAILED_TO_SEEK);
			}
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadFrames(float* DataPtr, SoundFileCount NumFrames, SoundFileCount& OutNumFramesRead) override
		{
			if (!SoundFileReadFramesFloat)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileReadFramesFloat"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumFramesRead = SoundFileReadFramesFloat(FileHandle, DataPtr, NumFrames);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadFrames(double* DataPtr, SoundFileCount NumFrames, SoundFileCount& OutNumFramesRead) override
		{
			if (!SoundFileReadFramesDouble)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileReadFramesDouble"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumFramesRead = SoundFileReadFramesDouble(FileHandle, DataPtr, NumFrames);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadSamples(float* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSamplesRead) override
		{
			if (!SoundFileReadSamplesFloat)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileReadSamplesFloat"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumSamplesRead = SoundFileReadSamplesFloat(FileHandle, DataPtr, NumSamples);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadSamples(double* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSamplesRead) override
		{
			if (!SoundFileReadSamplesDouble)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileReadSamplesDouble"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumSamplesRead = SoundFileReadSamplesDouble(FileHandle, DataPtr, NumSamples);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type GetOptionalChunks(FSoundFileChunkArray& OutChunkInfoArray) override
		{
			return GetOptionalChunksInternal(FileHandle, OutChunkInfoArray);
		}

	private:

		ESoundFileError::Type SetError(ESoundFileError::Type InError)
		{
			if (InError != ESoundFileError::Type::NONE)
			{
				State.Set(ESoundFileState::HAS_ERROR);
			}
			CurrentError.Set(static_cast<int32>(InError));
			return InError;
		}

		const TArray<uint8>*	SoundData;
		SoundFileCount			CurrentIndexBytes;
		FThreadSafeCounter		State;
		FThreadSafeCounter		CurrentError;
		FSoundFileDescription	Description;
		TArray<ESoundFileChannelMap::Type> ChannelMap;
		LibSoundFileHandle*		FileHandle;
	};


	/************************************************************************/
	/* FSoundFileWriter														*/
	/************************************************************************/
	class FSoundFileWriter : public ISoundFileParser, public ISoundFileWriter
	{
	public:

		FSoundFileWriter()
			: CurrentIndexBytes(0)
			, FileHandle(nullptr)
			, EncodingQuality(0.0)
			, State(ESoundFileState::UNINITIALIZED)
			, CurrentError(static_cast<int32>(ESoundFileError::Type::NONE))
		{

		}

		~FSoundFileWriter()
		{

		}

		ESoundFileError::Type GetLengthBytes(SoundFileCount& OutLength) const override
		{
			OutLength = BulkData.Num();
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type SeekBytes(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) override
		{
			int32 DataSize = BulkData.Num();

			if (DataSize == 0)
			{
				OutOffset = 0;
				CurrentIndexBytes = 0;
				return ESoundFileError::Type::NONE;
			}

			switch (SeekMode)
			{
			case ESoundFileSeekMode::FROM_START:
				CurrentIndexBytes = Offset;
				break;

			case ESoundFileSeekMode::FROM_CURRENT:
				CurrentIndexBytes += Offset;
				break;

			case ESoundFileSeekMode::FROM_END:
				CurrentIndexBytes = DataSize + Offset;
				break;

			default:
				checkf(false, TEXT("Uknown seek mode!"));
				break;
			}

			OutOffset = CurrentIndexBytes;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type ReadBytes(void* DataPtr, SoundFileCount NumBytes, SoundFileCount& OutNumBytesRead) override
		{
			// This shouldn't get called in the writer
			check(false);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type WriteBytes(const void* DataPtr, SoundFileCount NumBytes, SoundFileCount& OutNumBytesWritten) override
		{
			const uint8* InDataBytes = (const uint8*)DataPtr;

			SoundFileCount BulkDataLength = BulkData.Num();

			// If we need more room, we add it here.
			int64 NumExtraBytesNeeded = (CurrentIndexBytes + NumBytes) - BulkDataLength;
			if (NumExtraBytesNeeded > 0)
			{
				BulkData.AddUninitialized(NumExtraBytesNeeded);
			}

			// Copy the input data into our current place in the BulkData.
			uint8* BulkDataPtr = BulkData.GetData();
			FMemory::Memcpy(&BulkDataPtr[CurrentIndexBytes], InDataBytes, NumBytes);

			// Seek our cursor forward accordingly.
			CurrentIndexBytes += NumBytes;
			OutNumBytesWritten = NumBytes;

			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type GetOffsetBytes(SoundFileCount& OutOffset) const override
		{
			OutOffset = CurrentIndexBytes;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type Init(const FSoundFileDescription& InDescription, const TArray<ESoundFileChannelMap::Type>& InChannelMap, double InEncodingQuality) override
		{
			State.Set(ESoundFileState::INITIALIZED);

			BulkData.Reset();
			Description = InDescription;
			ChannelMap = InChannelMap;
			EncodingQuality = InEncodingQuality;

			if (!SoundFileFormatCheck)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileFormatCheck"));
				return SetError(ESoundFileError::Type::INVALID_STATE);
			}

			// First check the input format to make sure it's valid
			if (!SoundFileFormatCheck(&InDescription))
			{
				UE_LOG(LogAudioMixer,
					Error,
					TEXT("Sound file input format (%s - %s) is invalid."),
					ESoundFileFormat::ToStringMajor(InDescription.FormatFlags),
					ESoundFileFormat::ToStringMinor(InDescription.FormatFlags));

				return SetError(ESoundFileError::Type::INVALID_INPUT_FORMAT);
			}

			// Make sure we have the right number of channels and our channel map size
			if (InChannelMap.Num() != InDescription.NumChannels)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("Channel map didn't match the input NumChannels"));
				return SetError(ESoundFileError::Type::INVALID_CHANNEL_MAP);
			}

			FVirtualSoundFileCallbackInfo VirtualSoundFileInfo;
			VirtualSoundFileInfo.VirtualSoundFileGetLength = OnSoundFileGetLengthBytes;
			VirtualSoundFileInfo.VirtualSoundFileSeek = OnSoundFileSeekBytes;
			VirtualSoundFileInfo.VirtualSoundFileRead = OnSoundFileReadBytes;
			VirtualSoundFileInfo.VirtualSoundFileWrite = OnSoundFileWriteBytes;
			VirtualSoundFileInfo.VirtualSoundFileTell = OnSoundFileTell;

			if (SoundFileOpenVirtual)
			{
				FileHandle = SoundFileOpenVirtual(&VirtualSoundFileInfo, ESoundFileOpenMode::WRITING, &Description, (void*)this);
			}
			else
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileOpenVirtual"));
				FileHandle = nullptr;
			}

			if (!FileHandle)
			{
				if (!SoundFileStrError)
				{
					return SetError(ESoundFileError::Type::INVALID_DATA);
				}

				FString StrErr = FString(SoundFileStrError(nullptr));
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to open empty sound file: %s"), *StrErr);
				return SetError(ESoundFileError::Type::FAILED_TO_OPEN);
			}

			int32 Result = 0;
			if (SoundFileCommand)
			{
				Result = SoundFileCommand(FileHandle, SET_CHANNEL_MAP_INFO, (int32*)InChannelMap.GetData(), sizeof(int32)*Description.NumChannels);
			}
			else
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileCommand"));
			}

			if (Result != 1)
			{
				if (!SoundFileStrError)
				{
					return ESoundFileError::Type::INVALID_DATA;
				}

				// The result is returning 0 (false), however 'No Error'
				// is provided and the file mapping is correct.
				FString StrErr = SoundFileStrError(nullptr);
				if (StrErr != TEXT("No Error."))
				{
					UE_LOG(LogAudioMixer, Error, TEXT("Failed to set the channel map on empty file for writing: %s"), *StrErr);
					return SetError(ESoundFileError::Type::INVALID_CHANNEL_MAP);
				}
			}

			if ((Description.FormatFlags & ESoundFileFormat::MAJOR_FORMAT_MASK) == ESoundFileFormat::OGG)
			{
				int32 Result2 = 0;
				if (SoundFileCommand)
				{
					Result2 = SoundFileCommand(FileHandle, SET_ENCODING_QUALITY, &EncodingQuality, sizeof(double));
				}
				else
				{
					UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileCommand"));
				}

				if (Result2 != 1)
				{
					if (!SoundFileStrError)
					{
						UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileStrError"));
						return ESoundFileError::Type::INVALID_DATA;
					}

					FString StrErr = SoundFileStrError(FileHandle);
					UE_LOG(LogAudioMixer, Error, TEXT("Failed to set encoding quality: %s"), *StrErr);
					return SetError(ESoundFileError::Type::BAD_ENCODING_QUALITY);
				}
			}

			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type Release() override
		{
			if (!SoundFileClose)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileClose"));
				FileHandle = nullptr;
				return ESoundFileError::Type::INVALID_STATE;
			}

			if (FileHandle)
			{
				int32 Result = SoundFileClose(FileHandle);
				check(Result == 0);
				FileHandle = nullptr;
			}
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type SeekFrames(SoundFileCount Offset, ESoundFileSeekMode::Type SeekMode, SoundFileCount& OutOffset) override
		{
			if (!SoundFileSeek)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileSeek"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			SoundFileCount Pos = SoundFileSeek(FileHandle, Offset, (int32)SeekMode);
			if (Pos == -1)
			{
				if (!SoundFileStrError)
				{
					return ESoundFileError::Type::INVALID_DATA;
				}

				FString StrErr = SoundFileStrError(FileHandle);
				UE_LOG(LogAudioMixer, Error, TEXT("Failed to seek file: %s"), *StrErr);
				return SetError(ESoundFileError::Type::FAILED_TO_SEEK);
			}
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type WriteFrames(const float* DataPtr, SoundFileCount NumFrames, SoundFileCount& OutNumFramesWritten) override
		{
			if (!SoundFileWriteFramesFloat)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileWriteFramesFloat"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumFramesWritten = SoundFileWriteFramesFloat(FileHandle, DataPtr, NumFrames);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type WriteFrames(const double* DataPtr, SoundFileCount NumFrames, SoundFileCount& OutNumFramesWritten) override
		{
			if (!SoundFileWriteFramesDouble)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileWriteFramesDouble"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumFramesWritten = SoundFileWriteFramesDouble(FileHandle, DataPtr, NumFrames);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type WriteSamples(const float* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSampleWritten) override
		{
			if (!SoundFileWriteSamplesFloat)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileWriteSamplesFloat"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumSampleWritten = SoundFileWriteSamplesFloat(FileHandle, DataPtr, NumSamples);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type WriteSamples(const double* DataPtr, SoundFileCount NumSamples, SoundFileCount& OutNumSampleWritten) override
		{
			if (!SoundFileWriteSamplesDouble)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileWriteSamplesDouble"));
				return ESoundFileError::Type::INVALID_STATE;
			}

			OutNumSampleWritten = SoundFileWriteSamplesDouble(FileHandle, DataPtr, NumSamples);
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type GetData(TArray<uint8>** OutBulkData) override
		{
			*OutBulkData = &BulkData;
			return ESoundFileError::Type::NONE;
		}

		ESoundFileError::Type WriteOptionalChunks(const FSoundFileChunkArray& ChunkInfoArray) override
		{
			return WriteOptionalChunksInternal(FileHandle, ChunkInfoArray);
		}

	private:

		ESoundFileError::Type SetError(ESoundFileError::Type InError)
		{
			if (InError != ESoundFileError::Type::NONE)
			{
				State.Set(ESoundFileState::HAS_ERROR);
			}
			CurrentError.Set(static_cast<int32>(InError));
			return InError;
		}

		SoundFileCount						CurrentIndexBytes;
		LibSoundFileHandle*					FileHandle;
		FSoundFileDescription				Description;
		TArray<ESoundFileChannelMap::Type>	ChannelMap;
		TArray<uint8>						BulkData;
		double								EncodingQuality;
		FThreadSafeCounter					State;
		FThreadSafeCounter					CurrentError;	
	};

	//////////////////////////////////////////////////////////////////////////

	bool SoundFileIOManagerInit()
	{
		return LoadSoundFileLib();
	}

	bool SoundFileIOManagerShutdown()
	{
		return ShutdownSoundFileLib();
	}

	//////////////////////////////////////////////////////////////////////////
	FSoundFileIOManagerImpl::FSoundFileIOManagerImpl()
	{

	}

	FSoundFileIOManagerImpl::~FSoundFileIOManagerImpl()
	{

	}

	TSharedPtr<ISoundFileReader> FSoundFileIOManagerImpl::CreateSoundFileReader()
	{
		return TSharedPtr<ISoundFileReader>(new FSoundFileReader());
	}

	TSharedPtr<ISoundFileReader> FSoundFileIOManagerImpl::CreateSoundDataReader()
	{
		return TSharedPtr<ISoundFileReader>(new FSoundDataReader());
	}

	TSharedPtr<ISoundFileWriter> FSoundFileIOManagerImpl::CreateSoundFileWriter()
	{
		return TSharedPtr<ISoundFileWriter>(new FSoundFileWriter());
	}

	bool FSoundFileIOManagerImpl::GetSoundFileDescription(const FString& FilePath, FSoundFileDescription& OutputDescription, TArray<ESoundFileChannelMap::Type>& OutChannelMap)
	{
		LibSoundFileHandle* FileHandle = nullptr;
		ESoundFileError::Type Error = GetSoundDesriptionInternal(&FileHandle, FilePath, OutputDescription, OutChannelMap);
		if (Error == ESoundFileError::Type::NONE)
		{
			check(FileHandle != nullptr);

			if (!SoundFileClose)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileClose"));
				return false;
			}

			SoundFileClose(FileHandle);
			return true;
		}
		return false;
	}

	bool FSoundFileIOManagerImpl::GetSoundFileDescription(const FString& FilePath, FSoundFileDescription& OutputDescription)
	{
		TArray<ESoundFileChannelMap::Type> OutChannelMap;
		return GetSoundFileDescription(FilePath, OutputDescription, OutChannelMap);
	}

	bool FSoundFileIOManagerImpl::GetFileExtensionForFormatFlags(int32 FormatFlags, FString& OutExtension)
	{
		if (FormatFlags & ESoundFileFormat::OGG)
		{
			OutExtension = TEXT("ogg");
		}
		else if (FormatFlags & ESoundFileFormat::WAV)
		{
			OutExtension = TEXT("wav");
		}
		else if (FormatFlags & ESoundFileFormat::AIFF)
		{
			OutExtension = TEXT("aiff");
		}
		else if (FormatFlags & ESoundFileFormat::FLAC)
		{
			OutExtension = TEXT("flac");
		}
		else
		{
			return false;
		}

		return true;
	}

	ESoundFileError::Type FSoundFileIOManagerImpl::GetSoundFileInfoFromPath(const FString& FilePath, FSoundFileDescription& Description, TArray<ESoundFileChannelMap::Type>& ChannelMap)
	{
		// Load the description and channel map info
		LibSoundFileHandle* FileHandle = nullptr;
		ESoundFileError::Type Error = GetSoundDesriptionInternal(&FileHandle, FilePath, Description, ChannelMap);
		if (FileHandle)
		{
			if (!SoundFileClose)
			{
				UE_LOG(LogAudioMixer, Error, TEXT("LibSoundFile failed to load symbols for SoundFileClose"));
				return Error;
			}

			SoundFileClose(FileHandle);
		}
		return Error;
	}

	ESoundFileError::Type FSoundFileIOManagerImpl::LoadSoundFileFromPath(const FString& FilePath, FSoundFileDescription& Description, TArray<ESoundFileChannelMap::Type>& ChannelMap, TArray<uint8>& BulkData)
	{
		ESoundFileError::Type Error = GetSoundFileInfoFromPath(FilePath, Description, ChannelMap);
		if (Error != ESoundFileError::Type::NONE)
		{
			return Error;
		}

		// Now read the data from disk into the bulk data array
		if (FFileHelper::LoadFileToArray(BulkData, *FilePath))
		{
			return ESoundFileError::Type::NONE;
		}
		else
		{
			return ESoundFileError::Type::FAILED_TO_LOAD_BYTE_DATA;
		}
	}
}


==================================


=== SoundFileIOManagerImpl.h ===
================================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "CoreMinimal.h"

#include "SoundFile.h"
#include "SoundFileIOEnums.h"


namespace Audio
{
	class FSoundFileIOManagerImpl
	{
	public:
		FSoundFileIOManagerImpl();
		~FSoundFileIOManagerImpl();

		TSharedPtr<ISoundFileReader> CreateSoundFileReader();
		TSharedPtr<ISoundFileReader> CreateSoundDataReader();
		TSharedPtr<ISoundFileWriter> CreateSoundFileWriter();

		bool GetSoundFileDescription(const FString& FilePath, FSoundFileDescription& OutputDescription, TArray<ESoundFileChannelMap::Type>& OutChannelMap);
		bool GetSoundFileDescription(const FString& FilePath, FSoundFileDescription& OutputDescription);
		bool GetFileExtensionForFormatFlags(int32 FormatFlags, FString& OutExtension);
		ESoundFileError::Type GetSoundFileInfoFromPath(const FString& FilePath, FSoundFileDescription& Description, TArray<ESoundFileChannelMap::Type>& ChannelMap);
		ESoundFileError::Type LoadSoundFileFromPath(const FString& FilePath, FSoundFileDescription& Description, TArray<ESoundFileChannelMap::Type>& ChannelMap, TArray<uint8>& BulkData);
	};
} // namespace Audio

================================


=== SoundWaveDecoder.cpp ===
============================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "SoundWaveDecoder.h"
#include "AudioThread.h"
#include "Misc/ScopeTryLock.h"
#include "AudioThread.h"
#include "AudioDecompress.h"
#include "AudioMixer.h"
#include "AudioMixerBuffer.h"
#include "AudioMixerSourceBuffer.h"

namespace Audio
{
	FDecodingSoundSource::FDecodingSoundSource(FAudioDevice* AudioDevice, const FSourceDecodeInit& InitData)
		: Handle(InitData.Handle)
		, AudioDeviceID(0)
		, SoundWave(InitData.SoundWave)
		, MixerBuffer(nullptr)
		, SampleRate(INDEX_NONE)
		, SeekTime(InitData.SeekTime)
		, bForceSyncDecode(InitData.bForceSyncDecode)
	{
		SourceInfo.VolumeParam.Init();
		SourceInfo.VolumeParam.SetValue(InitData.VolumeScale);
		SourceInfo.PitchScale = InitData.PitchScale;

		if (nullptr != AudioDevice)
		{
			AudioDeviceID = AudioDevice->DeviceID;
		}

		MixerBuffer = FMixerBuffer::Init(AudioDevice, InitData.SoundWave, true);
	}

	FDecodingSoundSource::~FDecodingSoundSource()
	{
		FScopeLock Lock(&MixerSourceBufferCritSec);

		if (MixerSourceBuffer.IsValid())
		{
			MixerSourceBuffer->OnEndGenerate();
			MixerSourceBuffer.Reset();
		}
	}

	bool FDecodingSoundSource::PreInit(int32 InSampleRate)
	{
		SampleRate = InSampleRate;

#if AUDIO_SOURCE_DECODER_DEBUG
		SineTone[0].Init(InSampleRate, 220.0f, 0.5f);
		SineTone[1].Init(InSampleRate, 440.0f, 0.5f);
#endif

		if (!SoundWave || !MixerBuffer)
		{
			return false;
		}

		const ELoopingMode LoopingMode = SoundWave->bLooping ? ELoopingMode::LOOP_Forever : ELoopingMode::LOOP_Never;
		const bool bIsSeeking = SeekTime > 0.0f;

		bool bIsValid = false;
		{
			FScopeLock Lock(&MixerSourceBufferCritSec);

			FMixerSourceBufferInitArgs Args;
			Args.AudioDeviceID = AudioDeviceID;
			Args.SampleRate = InSampleRate;
			Args.Buffer = MixerBuffer;
			Args.SoundWave = SoundWave;
			Args.LoopingMode = LoopingMode;
			Args.bIsSeeking = bIsSeeking;
			Args.bForceSyncDecode = bForceSyncDecode;
			Args.StartTime = SeekTime;
			MixerSourceBuffer = FMixerSourceBuffer::Create(Args);

			bIsValid = MixerSourceBuffer.IsValid();
		}

		return bIsValid;
	}

	bool FDecodingSoundSource::IsReadyToInit()
	{
		FScopeLock Lock(&MixerSourceBufferCritSec);
		if (!MixerSourceBuffer.IsValid())
		{
			return false;
		}

		if (MixerBuffer && MixerBuffer->IsRealTimeSourceReady())
		{
			// Check if we have a realtime audio task already (doing first decode)
			if (MixerSourceBuffer->IsAsyncTaskInProgress())
			{
				// not ready
				return MixerSourceBuffer->IsAsyncTaskDone();
			}
			else
			{
				// Now check to see if we need to kick off a decode the first chunk of audio
				const EBufferType::Type BufferType = MixerBuffer->GetType();
				if ((BufferType == EBufferType::PCMRealTime || BufferType == EBufferType::Streaming) && SoundWave)
				{
					// If any of these conditions meet, we need to do an initial async decode before we're ready to start playing the sound
					if (SeekTime > 0.0f || !SoundWave->CachedRealtimeFirstBuffer)
					{
						// Before reading more PCMRT data, we first need to seek the buffer
						if (SeekTime > 0.0f)
						{
							MixerBuffer->Seek(SeekTime);
						}

						ICompressedAudioInfo* CompressedAudioInfo = MixerBuffer->GetDecompressionState(false);

						MixerSourceBuffer->ReadMoreRealtimeData(CompressedAudioInfo, 0, EBufferReadMode::Asynchronous);

						// not ready
						return false;
					}
				}
			}

			return true;
		}
		return false;
	}

	void FDecodingSoundSource::Init()
	{
		if (MixerBuffer->GetNumChannels() > 0 && MixerBuffer->GetNumChannels() <= 2)
		{
			FScopeLock Lock(&MixerSourceBufferCritSec);
			if (MixerSourceBuffer.IsValid())
			{

				// Pass the decompression state off to the mixer source buffer if it hasn't already done so
				ICompressedAudioInfo* Decoder = MixerBuffer->GetDecompressionState(false);
				MixerSourceBuffer->SetDecoder(Decoder);

				if (!MixerSourceBuffer->IsAsyncTaskInProgress())
				{
					MixerSourceBuffer->ReadMoreRealtimeData(Decoder, 0, EBufferReadMode::Asynchronous);
				}

				SourceInfo.NumSourceChannels = MixerBuffer->GetNumChannels();
				SourceInfo.TotalNumFrames = MixerBuffer->GetNumFrames();

				SourceInfo.CurrentFrameValues.AddZeroed(SourceInfo.NumSourceChannels);
				SourceInfo.NextFrameValues.AddZeroed(SourceInfo.NumSourceChannels);

				SourceInfo.BasePitchScale = MixerBuffer->GetSampleRate() / SampleRate;

				SourceInfo.PitchParam.Init();
				SourceInfo.PitchParam.SetValue(SourceInfo.BasePitchScale * SourceInfo.PitchScale);

				MixerSourceBuffer->Init();
				MixerSourceBuffer->OnBeginGenerate();

				bInitialized = true;
			}
		}
	}

	void FDecodingSoundSource::SetPitchScale(float InPitchScale, uint32 NumFrames)
	{
		SourceInfo.PitchParam.SetValue(SourceInfo.BasePitchScale * InPitchScale, NumFrames);
		SourceInfo.PitchResetFrame = SourceInfo.NumFramesGenerated + NumFrames;
	}

	void FDecodingSoundSource::SetVolumeScale(float InVolumeScale, uint32 NumFrames)
	{
		SourceInfo.VolumeParam.SetValue(InVolumeScale, NumFrames);
		SourceInfo.VolumeResetFrame = SourceInfo.NumFramesGenerated + NumFrames;
	}

	void FDecodingSoundSource::SetForceSyncDecode(bool bShouldForceSyncDecode)
	{
		bForceSyncDecode = bShouldForceSyncDecode;
	}

	void FDecodingSoundSource::ReadFrame()
	{
		if (!MixerSourceBuffer.IsValid())
		{
			SourceInfo.bIsLastBuffer = true;
			return;
		}

		TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe>MixerSourceBufferLocal = MixerSourceBuffer;

		bool bNextFrameOutOfRange = (SourceInfo.CurrentFrameIndex + FMath::CeilToInt(SourceInfo.CurrentFrameAlpha)) >= SourceInfo.CurrentAudioChunkNumFrames;
		bool bCurrentFrameOutOfRange = SourceInfo.CurrentFrameIndex >= SourceInfo.CurrentAudioChunkNumFrames;

		bool bReadCurrentFrame = true;

		while (bNextFrameOutOfRange || bCurrentFrameOutOfRange)
		{
			if (bNextFrameOutOfRange && !bCurrentFrameOutOfRange)
			{
				bReadCurrentFrame = false;

				const float* AudioData = SourceInfo.CurrentPCMBuffer->AudioData.GetData();

				if (!AudioData)
				{
					SourceInfo.bIsLastBuffer = true;
					return;
				}

				const int32 CurrentSampleIndex = SourceInfo.CurrentFrameIndex * SourceInfo.NumSourceChannels;

				for (int32 Channel = 0; Channel < SourceInfo.NumSourceChannels; ++Channel)
				{
					SourceInfo.CurrentFrameValues[Channel] = AudioData[CurrentSampleIndex + Channel];
				}

				if (SourceInfo.CurrentPCMBuffer->LoopCount == Audio::LOOP_FOREVER && !SourceInfo.CurrentPCMBuffer->bRealTimeBuffer)
				{
					SourceInfo.CurrentFrameIndex = FMath::Max(SourceInfo.CurrentFrameIndex - SourceInfo.CurrentAudioChunkNumFrames, 0);
					break;
				}

				MixerSourceBufferLocal->OnBufferEnd();
			}

			auto const NumBuffersQueued = MixerSourceBufferLocal->GetNumBuffersQueued();
			if (MixerSourceBufferLocal->GetNumBuffersQueued() > 0 && (SourceInfo.NumSourceChannels > 0))
			{
				check(MixerSourceBufferLocal.IsValid());
				SourceInfo.CurrentPCMBuffer = MixerSourceBufferLocal->GetNextBuffer();
				if (!SourceInfo.CurrentPCMBuffer)
				{
					SourceInfo.bIsLastBuffer = true;
					return;
				}

				SourceInfo.CurrentAudioChunkNumFrames = SourceInfo.CurrentPCMBuffer->AudioData.Num() / SourceInfo.NumSourceChannels;

				if (bReadCurrentFrame)
				{
					SourceInfo.CurrentFrameIndex = FMath::Max(SourceInfo.CurrentFrameIndex - SourceInfo.CurrentAudioChunkNumFrames, 0);
				}
				else
				{
					SourceInfo.CurrentFrameIndex = INDEX_NONE;
				}
			}
			else
			{
				SourceInfo.bIsLastBuffer = true;
				return;
			}

			bNextFrameOutOfRange = (SourceInfo.CurrentFrameIndex + 1) >= SourceInfo.CurrentAudioChunkNumFrames;
			bCurrentFrameOutOfRange = SourceInfo.CurrentFrameIndex >= SourceInfo.CurrentAudioChunkNumFrames;
		}

		const float* AudioData = SourceInfo.CurrentPCMBuffer->AudioData.GetData();

		if (!AudioData)
		{
			SourceInfo.bIsLastBuffer = true;
			return;
		}

		const int32 NextSampleIndex = (SourceInfo.CurrentFrameIndex + 1) * SourceInfo.NumSourceChannels;

		if (bReadCurrentFrame)
		{
			const int32 CurrentSampleIndex = SourceInfo.CurrentFrameIndex * SourceInfo.NumSourceChannels;
			for (int32 Channel = 0; Channel < SourceInfo.NumSourceChannels; ++Channel)
			{
				SourceInfo.CurrentFrameValues[Channel] = AudioData[CurrentSampleIndex + Channel];
				SourceInfo.NextFrameValues[Channel] = AudioData[NextSampleIndex + Channel];
			}
		}
		else
		{
			for (int32 Channel = 0; Channel < SourceInfo.NumSourceChannels; ++Channel)
			{
				SourceInfo.NextFrameValues[Channel] = AudioData[NextSampleIndex + Channel];
			}
		}
	}

	void FDecodingSoundSource::GetAudioBufferInternal(const int32 InNumFrames, const int32 InNumChannels, FAlignedFloatBuffer& OutAudioBuffer)
	{
#if AUDIO_SOURCE_DECODER_DEBUG
		int32 SampleIndex = 0;
		float* OutAudioBufferPtr = OutAudioBuffer.GetData();
		for (int32 FrameIndex = 0; FrameIndex < InNumFrames; ++FrameIndex)
		{
			for (int32 ChannelIndex = 0; ChannelIndex < InNumChannels; ++ChannelIndex)
			{
				OutAudioBufferPtr[SampleIndex++] = SineTone[ChannelIndex].ProcessAudio();
			}
		}
#else
		int32 SampleIndex = 0;
		float* OutAudioBufferPtr = OutAudioBuffer.GetData();
		float* CurrentFrameValuesPtr = SourceInfo.CurrentFrameValues.GetData();
		float* NextFrameValuesPtr = SourceInfo.NextFrameValues.GetData();

		for (int32 FrameIndex = 0; FrameIndex < InNumFrames; ++FrameIndex)
		{
			if (SourceInfo.bIsLastBuffer)
			{
				break;
			}

			bool bReadFrame = !SourceInfo.bHasStarted;
			SourceInfo.bHasStarted = true;

			while (SourceInfo.CurrentFrameAlpha >= 1.0f)
			{
				bReadFrame = true;
				SourceInfo.CurrentFrameIndex++;
				SourceInfo.NumFramesRead++;
				SourceInfo.CurrentFrameAlpha -= 1.0f;
			}


			if (!MixerSourceBuffer.IsValid())
			{
				bReadFrame = false;
				SourceInfo.bIsLastBuffer = true;
				break;
			}

			// assign "CurrentAlpha" before we update it so ReadFrame() can use the "next" value
			const float CurrentAlpha = SourceInfo.CurrentFrameAlpha;
			const float CurrentVolumeScale = SourceInfo.VolumeParam.Update();

			const float CurrentPitchScale = SourceInfo.PitchParam.Update();
			SourceInfo.CurrentFrameAlpha += CurrentPitchScale;

			if (bReadFrame)
			{
				ReadFrame();
				if (SourceInfo.bIsLastBuffer)
				{
					break;
				}
			}


			for (int32 Channel = 0; Channel < SourceInfo.NumSourceChannels; ++Channel)
			{
				const float CurrFrameValue = CurrentFrameValuesPtr[Channel];
				const float NextFrameValue = NextFrameValuesPtr[Channel];

				OutAudioBufferPtr[SampleIndex++] = CurrentVolumeScale * FMath::Lerp(CurrFrameValue, NextFrameValue, CurrentAlpha);
			}

			SourceInfo.NumFramesGenerated++;

			if (SourceInfo.NumFramesGenerated >= SourceInfo.PitchResetFrame)
			{
				SourceInfo.PitchResetFrame = INDEX_NONE;
				SourceInfo.PitchParam.Reset();
			}

			if (SourceInfo.NumFramesGenerated >= SourceInfo.VolumeResetFrame)
			{
				SourceInfo.VolumeResetFrame = INDEX_NONE;
				SourceInfo.VolumeParam.Reset();
			}
		}
#endif
	}

	bool FDecodingSoundSource::GetAudioBuffer(const int32 InNumFrames, const int32 InNumChannels, FAlignedFloatBuffer& OutAudioBuffer)
	{
		FScopeTryLock Lock(&MixerSourceBufferCritSec);

		if (!bInitialized || !Lock.IsLocked())
		{
			return false;
		}

		OutAudioBuffer.Reset();
		OutAudioBuffer.AddZeroed(InNumFrames * InNumChannels);

		if (SourceInfo.bIsLastBuffer)
		{
			return false;
		}

		if (InNumChannels == SourceInfo.NumSourceChannels)
		{
			GetAudioBufferInternal(InNumFrames, InNumChannels, OutAudioBuffer);
		}
		else
		{

			ScratchBuffer.Reset();
			ScratchBuffer.AddZeroed(InNumFrames * SourceInfo.NumSourceChannels);

			GetAudioBufferInternal(InNumFrames, InNumChannels, ScratchBuffer);

			float* BufferPtr = OutAudioBuffer.GetData();
			float* ScratchBufferPtr = ScratchBuffer.GetData();

			int32 OutputSampleIndex = 0;
			int32 InputSampleIndex = 0;

			// Need to upmix the audio
			if (InNumChannels == 2 && SourceInfo.NumSourceChannels == 1)
			{
				for (int32 FrameIndex = 0; FrameIndex < InNumFrames; ++FrameIndex, ++InputSampleIndex)
				{
					for (int32 ChannelIndex = 0; ChannelIndex < InNumChannels; ++ChannelIndex)
					{
						BufferPtr[OutputSampleIndex++] = 0.5f * ScratchBufferPtr[InputSampleIndex];
					}
				}
			}
			// Need to downmix the audio
			else
			{
				check(InNumChannels == 1 && SourceInfo.NumSourceChannels == 2);

				for (int32 FrameIndex = 0; FrameIndex < InNumFrames; ++FrameIndex, ++InputSampleIndex)
				{
					for (int32 ChannelIndex = 0; ChannelIndex < InNumChannels; ++ChannelIndex)
					{
						BufferPtr[OutputSampleIndex++] = 0.5f * (ScratchBufferPtr[InputSampleIndex] + ScratchBufferPtr[InputSampleIndex + 1]);
					}
				}
			}
		}

		return true;
	}

	FSoundSourceDecoder::FSoundSourceDecoder()
		: AudioThreadId(0)
		, AudioDevice(nullptr)
		, SampleRate(0)
	{
	}

	FSoundSourceDecoder::~FSoundSourceDecoder()
	{
		
	}

	void FSoundSourceDecoder::AddReferencedObjects(FReferenceCollector & Collector)
	{
		for (auto& Entry : PrecachingSources)
		{
			FSourceDecodeInit& DecodingSoundInitPtr = Entry.Value;
			Collector.AddReferencedObject(DecodingSoundInitPtr.SoundWave);
		}

		for (auto& Entry : InitializingDecodingSources)
		{
			FDecodingSoundSourcePtr DecodingSoundSourcePtr = Entry.Value;
			Collector.AddReferencedObject(DecodingSoundSourcePtr->GetSoundWavePtr());
		}

		FScopeLock Lock(&DecodingSourcesCritSec);
		for (auto& Entry : DecodingSources)
		{
			FDecodingSoundSourcePtr DecodingSoundSourcePtr = Entry.Value;
			Collector.AddReferencedObject(DecodingSoundSourcePtr->GetSoundWavePtr());
		}
	}

	void FSoundSourceDecoder::Init(FAudioDevice* InAudioDevice, int32 InSampleRate)
	{
		AudioDevice = InAudioDevice;
		SampleRate = InSampleRate;
	}

	FDecodingSoundSourceHandle FSoundSourceDecoder::CreateSourceHandle(USoundWave* InSoundWave)
	{
		// Init the handle ids
		static int32 SoundWaveDecodingHandles = 0;

		// Create a new handle
		FDecodingSoundSourceHandle Handle;
		Handle.Id = SoundWaveDecodingHandles++;
		Handle.SoundWaveName = InSoundWave->GetFName();
		return Handle;
	}

	void FSoundSourceDecoder::EnqueueDecoderCommand(TFunction<void()> Command)
	{
		CommandQueue.Enqueue(Command);
	}

	void FSoundSourceDecoder::PumpDecoderCommandQueue()
	{
		TFunction<void()> Command;
		while (CommandQueue.Dequeue(Command))
		{
			Command();
		}
	}

	bool FSoundSourceDecoder::InitDecodingSourceInternal(const FSourceDecodeInit& InitData)
	{
		FDecodingSoundSourcePtr DecodingSoundWaveDataPtr = FDecodingSoundSourcePtr(new FDecodingSoundSource(AudioDevice, InitData));

		if (DecodingSoundWaveDataPtr->PreInit(SampleRate))
		{
			DecodingSoundWaveDataPtr->SetForceSyncDecode(InitData.bForceSyncDecode);
			InitializingDecodingSources.Add(InitData.Handle.Id, DecodingSoundWaveDataPtr);

			// Add this decoding sound wave to a data structure we can access safely from audio render thread
			EnqueueDecoderCommand([this, InitData, DecodingSoundWaveDataPtr]()
			{
				FScopeLock Lock(&DecodingSourcesCritSec);
				DecodingSources.Add(InitData.Handle.Id, DecodingSoundWaveDataPtr);

				UE_LOG(LogAudioMixer, Verbose, TEXT("Decoding SoundWave '%s' (Num Decoding: %d)"),
					*InitData.Handle.SoundWaveName.ToString(), DecodingSources.Num());
			});

			return true;
		}

		UE_LOG(LogAudioMixer, Warning, TEXT("Failed to initialize sound wave %s."), InitData.SoundWave ? *InitData.SoundWave->GetName() : TEXT("Unset"));
		return false;
	}

	bool FSoundSourceDecoder::InitDecodingSource(const FSourceDecodeInit& InitData)
	{
		check(IsInAudioThread());

		if (InitData.SoundWave == nullptr)
		{
			UE_LOG(LogAudioMixer, Error, TEXT("Cannot Decode NULL SoundWave"));
			return false;
		}

		if (InitData.SoundWave->NumChannels == 0)
		{
			UE_LOG(LogAudioMixer, Error, TEXT("Cannot Decode invalid or corrupt sound wave %s. NumChannels = 0"), *InitData.SoundWave->GetName());
			return false;
		}

		if (InitData.SoundWave->NumChannels <= 0 || InitData.SoundWave->NumChannels > 2)
		{
			UE_LOG(LogAudioMixer, Error, TEXT("Only supporting 1 or 2 channel decodes in sound source decoder."), *InitData.SoundWave->GetName());
			return false;
		}


		if (InitData.SoundWave->bIsSourceBus || InitData.SoundWave->bProcedural)
		{
			UE_LOG(LogAudioMixer, Warning, TEXT("Sound wave decoder does not support buses or procedural sounds."));
			return false;
		}

		// Start the soundwave precache
		const ESoundWavePrecacheState PrecacheState = InitData.SoundWave->GetPrecacheState();
		if (PrecacheState == ESoundWavePrecacheState::InProgress)
		{
			if (!PrecachingSources.Contains(InitData.Handle.Id))
			{
				PrecachingSources.Add(InitData.Handle.Id, InitData);
			}
			return true;
		}
		else
		{
			if (PrecacheState == ESoundWavePrecacheState::NotStarted)
			{
				AudioDevice->Precache(InitData.SoundWave, true);
			}
			check(InitData.SoundWave->GetPrecacheState() == ESoundWavePrecacheState::Done);
			return InitDecodingSourceInternal(InitData);
		}
	}

	void FSoundSourceDecoder::RemoveDecodingSource(const FDecodingSoundSourceHandle& Handle)
	{
		FScopeLock Lock(&DecodingSourcesCritSec);
		DecodingSources.Remove(Handle.Id);
	}

	void FSoundSourceDecoder::Reset()
	{
		PumpDecoderCommandQueue();

		FScopeLock Lock(&DecodingSourcesCritSec);

		DecodingSources.Reset();
		InitializingDecodingSources.Reset();
		PrecachingSources.Reset();
	}

	void FSoundSourceDecoder::SetSourcePitchScale(const FDecodingSoundSourceHandle& Handle, float InPitchScale)
	{

	}

	void FSoundSourceDecoder::SetSourceVolumeScale(const FDecodingSoundSourceHandle& InHandle, float InVolumeScale)
	{
		FScopeLock Lock(&DecodingSourcesCritSec);
		FDecodingSoundSourcePtr* DecodingSoundWaveDataPtr = DecodingSources.Find(InHandle.Id);
		if (!DecodingSoundWaveDataPtr)
		{
			return;
		}
		(*DecodingSoundWaveDataPtr)->SetVolumeScale(InVolumeScale);
	}

	void FSoundSourceDecoder::Update()
	{
		check(IsInAudioThread());

		TArray<int32> TempIds;

		for (auto& Entry : PrecachingSources)
		{
			int32 Id = Entry.Key;
			FSourceDecodeInit& InitData = Entry.Value;
			if (InitData.SoundWave->GetPrecacheState() == ESoundWavePrecacheState::Done)
			{
				InitDecodingSourceInternal(InitData);
				TempIds.Add(Id);
			}
		}

		// Remove the Id's that have initialized
		for (int32 Id : TempIds)
		{
			PrecachingSources.Remove(Id);
		}

		TempIds.Reset();
		for (auto& Entry : InitializingDecodingSources)
		{
			int32 Id = Entry.Key;
			FDecodingSoundSourcePtr DecodingSoundSourcePtr = Entry.Value;

			if (DecodingSoundSourcePtr->IsReadyToInit())
			{
				DecodingSoundSourcePtr->Init();

				// Add to local array here to clean up the map quickly
				TempIds.Add(Id);
			}
		}
		
		// Remove the Id's that have initialized
		for (int32 Id : TempIds)
		{
			InitializingDecodingSources.Remove(Id);
		}

	}

	void FSoundSourceDecoder::UpdateRenderThread()
	{
		PumpDecoderCommandQueue();
	}

	bool FSoundSourceDecoder::IsFinished(const FDecodingSoundSourceHandle& InHandle) const
	{
		FScopeLock Lock(&DecodingSourcesCritSec);

		const FDecodingSoundSourcePtr* DecodingSoundWaveDataPtr = DecodingSources.Find(InHandle.Id);
		if (!DecodingSoundWaveDataPtr || !DecodingSoundWaveDataPtr->IsValid())
		{
			return true;
		}

		return (*DecodingSoundWaveDataPtr)->IsFinished();
	}

	bool FSoundSourceDecoder::IsInitialized(const FDecodingSoundSourceHandle& InHandle) const
	{
		FScopeLock Lock(&DecodingSourcesCritSec);

		const FDecodingSoundSourcePtr* DecodingSoundWaveDataPtr = DecodingSources.Find(InHandle.Id);
		if (!DecodingSoundWaveDataPtr)
		{
			return true;
		}

		return (*DecodingSoundWaveDataPtr)->IsInitialized();
	}


	bool FSoundSourceDecoder::GetSourceBuffer(const FDecodingSoundSourceHandle& InHandle, const int32 NumOutFrames, const int32 NumOutChannels, FAlignedFloatBuffer& OutAudioBuffer)
	{
		check(InHandle.Id != INDEX_NONE);
		FScopeLock Lock(&DecodingSourcesCritSec);

		FDecodingSoundSourcePtr DecodingSoundWaveDataPtr = DecodingSources.FindRef(InHandle.Id);
		if (DecodingSoundWaveDataPtr.IsValid())
		{
			DecodingSoundWaveDataPtr->GetAudioBuffer(NumOutFrames, NumOutChannels, OutAudioBuffer);
			return true;
		}

		return false;
	}

}

============================


=== SoundWaveDecoder.h ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#pragma once

#include "CoreMinimal.h"
#include "AudioDevice.h"
#include "Sound/SoundWave.h"
#include "DSP/SinOsc.h"
#include "DSP/ParamInterpolator.h"
#include "Misc/ScopeLock.h"



class FAudioDevice;

#define AUDIO_SOURCE_DECODER_DEBUG 0

namespace Audio
{
	class FMixerBuffer;
	class FMixerSourceBuffer;
	struct FMixerSourceVoiceBuffer;

	struct FDecodingSoundSourceHandle
	{
		FDecodingSoundSourceHandle()
			: Id(INDEX_NONE)
		{}

		int32 Id;
		FName SoundWaveName;
	};

	struct FSourceDecodeInit
	{
		FSourceDecodeInit()
			: SoundWave(nullptr)
			, SeekTime(0.0f)
			, PitchScale(1.0f)
			, VolumeScale(1.0f)
			, bForceSyncDecode(false)
		{}

		TObjectPtr<USoundWave> SoundWave;
		float SeekTime;
		float PitchScale;
		float VolumeScale;
		bool bForceSyncDecode;
		FDecodingSoundSourceHandle Handle;
	};

	class FDecodingSoundSource
	{
	public:
		FDecodingSoundSource(FAudioDevice* AudioDevice, const FSourceDecodeInit& InitData);
		~FDecodingSoundSource();

		// Called before we initialize
		bool PreInit(int32 OutputSampleRate);

		// Queries if we're ready to initialize
		bool IsReadyToInit();

		// Initializes the decoding source
		void Init();

		// Returns if we've been initialized
		bool IsInitialized() const { return bInitialized; }

		// If the sound source finished playing all its source. Will only return true for non-looping sources.
		bool IsFinished() const { return !bInitialized || SourceInfo.bIsLastBuffer; }
		
		// Sets the pitch scale
		void SetPitchScale(float InPitchScale, uint32 NumFrames = 512);

		// Sets the volume scale
		void SetVolumeScale(float InVolumeScale, uint32 NumFrames = 512);

		// Sets the ForceSyncDecode flag. (Decodes for this soundwave will not happen in an async task if true)
		void SetForceSyncDecode(bool bShouldForceSyncDecode);

		// Get audio buffer
		bool GetAudioBuffer(const int32 InNumFrames, const int32 InNumChannels, FAlignedFloatBuffer& OutAudioBuffer);

		// Return the underlying sound wave
		USoundWave* GetSoundWave() { return SoundWave; }
    
		TObjectPtr<USoundWave>& GetSoundWavePtr() { return SoundWave; }

	private:

		void ReadFrame();
		void GetAudioBufferInternal(const int32 InNumFrames, const int32 InNumChannels, FAlignedFloatBuffer& OutAudioBuffer);

		// Handle to the decoding source
		FDecodingSoundSourceHandle Handle;

		FDeviceId AudioDeviceID;

		// The sound wave object with which this sound is generating
		TObjectPtr<USoundWave> SoundWave;

		// Mixer buffer object which is a convenience wrapper around some buffer initialization and management
		FMixerBuffer* MixerBuffer;

		// Critical Section around mixer source buffer access
		FCriticalSection MixerSourceBufferCritSec;

		// Object which handles bulk of decoding operations
		TSharedPtr<FMixerSourceBuffer, ESPMode::ThreadSafe> MixerSourceBuffer;

		// Scratch buffer used for upmixing and downmixing the audio
		FAlignedFloatBuffer ScratchBuffer;

		// Sample rate of the source
		int32 SampleRate;

		// Current seek time
		float SeekTime;

		// If we've initialized	
		FThreadSafeBool bInitialized;

		// force the decoding of this sound to be synchronous
		bool bForceSyncDecode{false};

		// Object used for source generation from decoded buffers
		struct FSourceInfo
		{
			// Number of channels of source file
			int32 NumSourceChannels;

			// Total number of frames of source file
			uint32 TotalNumFrames;

			// Total number of frames played (or read from decoded buffers) so far. Will always be less than TotalNumFrames
			uint32 NumFramesRead;

			// Total number of frames generated (could be larger or smaller than number of frames read)
			uint32 NumFramesGenerated;

			// The current frame alpha (how far we are between current and next frame)
			float CurrentFrameAlpha;

			// The current frame index
			int32 CurrentFrameIndex;

			// Number of frames of current decoded chunk
			int32 CurrentAudioChunkNumFrames;

			// The pitch scale to use to account for sample rate differences of source to output sample rate
			float BasePitchScale;
			float PitchScale;

			// The pitch param object, allows easy pitch interpolation
			FParam PitchParam;

			// The frame count (from frames generated) to reset the pitch param
			uint32 PitchResetFrame;

			// The volume param object, allows easy volume interpolation
			FParam VolumeParam;

			// The frame count (from frames generated) to reset the volume param
			uint32 VolumeResetFrame;

			// Buffer to store current decoded audio frame
			TArray<float> CurrentFrameValues;

			// Buffer to store next decoded audio frame
			TArray<float> NextFrameValues;

			// The current decoded PCM buffer we are reading from
			TSharedPtr<FMixerSourceVoiceBuffer, ESPMode::ThreadSafe> CurrentPCMBuffer;

			// If this sound is done (has decoded all data)
			bool bIsDone;

			// If this sound hasn't yet started rendering audio
			bool bHasStarted;

			// If this is the last decoded buffer
			bool bIsLastBuffer;

			FSourceInfo()
				: NumSourceChannels(0)
				, TotalNumFrames(0)
				, NumFramesRead(0)
				, NumFramesGenerated(0)
				, CurrentFrameAlpha(0.0f)
				, CurrentFrameIndex(0)
				, CurrentAudioChunkNumFrames(0)
				, BasePitchScale(1.0f)
				, PitchScale(1.0f)
				, PitchResetFrame(0)
				, VolumeResetFrame(0)
				, bIsDone(false)
				, bHasStarted(false)
				, bIsLastBuffer(false)
			{}

		};

		FSourceInfo SourceInfo;

#if AUDIO_SOURCE_DECODER_DEBUG
		FSineOsc SineTone[2];
#endif

	};

	typedef TSharedPtr<FDecodingSoundSource> FDecodingSoundSourcePtr;
	
	class FSoundSourceDecoder : public FGCObject
	{
	public:
		AUDIOMIXER_API FSoundSourceDecoder();
		AUDIOMIXER_API virtual ~FSoundSourceDecoder();

		//~ Begin FGCObject
		AUDIOMIXER_API virtual void AddReferencedObjects(FReferenceCollector & Collector) override;
		virtual FString GetReferencerName() const override
		{
			return TEXT("Audio::FSoundSourceDecoder");
		}
		//~ End FGCObject

		// Initialize the source decoder at the given output sample rate
		// Sources will automatically sample rate convert to match this output
		AUDIOMIXER_API void Init(FAudioDevice* InAudioDevice, int32 SampleRate);

		// Creates a new decoding sound source handle
		AUDIOMIXER_API FDecodingSoundSourceHandle CreateSourceHandle(USoundWave* InSoundWave);

		// Called from the audio thread
		AUDIOMIXER_API void Update();

		// Called from the audio render thread
		AUDIOMIXER_API void UpdateRenderThread();

		// Initialize a decoding instance of this sound wave object. Call only from game thread.
		AUDIOMIXER_API bool InitDecodingSource(const FSourceDecodeInit& InitData);

		// Removes the decoding source from the decoder
		AUDIOMIXER_API void RemoveDecodingSource(const FDecodingSoundSourceHandle& Handle);

		// Resets internal state of decoder
		AUDIOMIXER_API void Reset();

		// Sets the source pitch scale
		AUDIOMIXER_API void SetSourcePitchScale(const FDecodingSoundSourceHandle& Handle, float InPitchScale);

		// Sets the source volume scale
		AUDIOMIXER_API void SetSourceVolumeScale(const FDecodingSoundSourceHandle& Handle, float InVolumeScale);

		// Get a decoded buffer for the given decoding sound wave handle. Call only from audio render thread or audio render thread task.
		AUDIOMIXER_API bool GetSourceBuffer(const FDecodingSoundSourceHandle& InHandle, const int32 NumOutFrames, const int32 NumOutChannels, FAlignedFloatBuffer& OutAudioBuffer);

		// Queries if the decoding source is finished
		AUDIOMIXER_API bool IsFinished(const FDecodingSoundSourceHandle& InHandle) const;

		AUDIOMIXER_API bool IsInitialized(const FDecodingSoundSourceHandle& InHandle) const;

	private:
		// Sends a command to the audio render thread from audio thread
		AUDIOMIXER_API void EnqueueDecoderCommand(TFunction<void()> Command);
		AUDIOMIXER_API void PumpDecoderCommandQueue();
		AUDIOMIXER_API bool InitDecodingSourceInternal(const FSourceDecodeInit& InitData);

		int32 AudioThreadId;
		FAudioDevice* AudioDevice;
		int32 SampleRate;
		mutable FCriticalSection DecodingSourcesCritSec;
		TMap<int32, FDecodingSoundSourcePtr> InitializingDecodingSources;
		TMap<int32, FDecodingSoundSourcePtr> DecodingSources;
		TMap<int32, FSourceDecodeInit> PrecachingSources;

		TQueue<TFunction<void()>> CommandQueue;
	};

}

==========================


=== SynthComponent.cpp ===
==========================

// Copyright Epic Games, Inc. All Rights Reserved.

#include "Components/SynthComponent.h"

#include "AudioDevice.h"
#include "AudioMixerLog.h"
#include "Engine/World.h"
#include "Sound/AudioSettings.h"

#include UE_INLINE_GENERATED_CPP_BY_NAME(SynthComponent)


USynthSound::USynthSound(const FObjectInitializer& ObjectInitializer)
	: Super(ObjectInitializer)
{
}

void USynthSound::Init(USynthComponent* InSynthComponent, const int32 InNumChannels, const int32 InSampleRate, const int32 InCallbackSize)
{
	check(InSynthComponent);

	OwningSynthComponent = InSynthComponent;
	VirtualizationMode = EVirtualizationMode::PlayWhenSilent;
	NumChannels = InNumChannels;
	NumSamplesToGeneratePerCallback = InCallbackSize;
	bCanProcessAsync = true;

	Duration = INDEFINITELY_LOOPING_DURATION;
	bLooping = true;
	SampleRate = InSampleRate;
}

void USynthSound::StartOnAudioDevice(FAudioDevice* InAudioDevice)
{
}

void USynthSound::OnBeginGenerate()
{
	if (ensure(OwningSynthComponent.IsValid()))
	{
		OwningSynthComponent->OnBeginGenerate();
	}
}

int32 USynthSound::OnGeneratePCMAudio(TArray<uint8>& OutAudio, int32 NumSamples)
{
	LLM_SCOPE(ELLMTag::AudioSynthesis);

	OutAudio.Reset();

	// If running with audio mixer, the output audio buffer will be in floats already
	OutAudio.AddZeroed(NumSamples * sizeof(float));

	// Mark pending kill can null this out on the game thread in rare cases.
	if (!OwningSynthComponent.IsValid())
	{
		return 0;
	}

	return OwningSynthComponent->OnGeneratePCMAudio((float*)OutAudio.GetData(), NumSamples);

}	

void USynthSound::OnEndGenerate()
{
	// Mark pending kill can null this out on the game thread in rare cases.
	if (OwningSynthComponent.IsValid())
	{
		OwningSynthComponent->OnEndGenerate();
	}
}

ISoundGeneratorPtr USynthSound::CreateSoundGenerator(const FSoundGeneratorInitParams& InParams)
{
	if (OwningSynthComponent.IsValid())
	{
		return OwningSynthComponent->CreateSoundGeneratorInternal(InParams);
	}
	return nullptr;
}

Audio::EAudioMixerStreamDataFormat::Type USynthSound::GetGeneratedPCMDataFormat() const
{
	// Only audio mixer supports return float buffers
	return Audio::EAudioMixerStreamDataFormat::Float;
}

USynthComponent::USynthComponent(const FObjectInitializer& ObjectInitializer)
	: Super(ObjectInitializer)
{
	bAutoActivate = false;

	bStopWhenOwnerDestroyed = true;

	bEnableBusSends = true;
	bEnableBaseSubmix = true;
	bEnableSubmixSends = true;

	bNeverNeedsRenderUpdate = true;
	bUseAttachParentBound = true; // Avoid CalcBounds() when transform changes.

	bIsSynthPlaying = false;
	bIsInitialized = false;
	bIsUISound = false;
	bAlwaysPlay = true;
	Synth = nullptr;

	PreferredBufferLength = DEFAULT_PROCEDURAL_SOUNDWAVE_BUFFER_SIZE;

#if WITH_EDITORONLY_DATA
	bVisualizeComponent = false;
#endif
}

void USynthComponent::OnAudioComponentEnvelopeValue(const UAudioComponent* InAudioComponent, const USoundWave* SoundWave, const float EnvelopeValue)
{
	if (OnAudioEnvelopeValue.IsBound())
	{
		OnAudioEnvelopeValue.Broadcast(EnvelopeValue);
	}

	if (OnAudioEnvelopeValueNative.IsBound())
	{
		OnAudioEnvelopeValueNative.Broadcast(InAudioComponent, EnvelopeValue);
	}
}

void USynthComponent::BeginDestroy()
{
	Super::BeginDestroy();
	Stop();
}

void USynthComponent::Activate(bool bReset)
{
	if (bReset || ShouldActivate())
	{
		Start();
		if (IsActive())
		{
			OnComponentActivated.Broadcast(this, bReset);
		}
	}
}

void USynthComponent::Deactivate()
{
	if (ShouldActivate() == false)
	{
		Stop();

		if (!IsActive())
		{
			OnComponentDeactivated.Broadcast(this);
		}
	}
}

void USynthComponent::Initialize(int32 SampleRateOverride)
{
	// This will try to create the audio component if it hasn't yet been created
	CreateAudioComponent();

	// Try to get a proper sample rate
	int32 SampleRate = SampleRateOverride;
	if (SampleRate == INDEX_NONE)
	{
		// Check audio device if we've not explicitly been told what sample rate to use
		FAudioDevice* AudioDevice = GetAudioDevice();
		if (AudioDevice)
		{
			SampleRate = AudioDevice->SampleRate;
		}
	}

	// Only allow initialization if we have a proper sample rate
	if (SampleRate != INDEX_NONE)
	{
#if SYNTH_GENERATOR_TEST_TONE
		NumChannels = 2;
		TestSineLeft.Init(SampleRate, 440.0f, 0.5f);
		TestSineRight.Init(SampleRate, 220.0f, 0.5f);
#else
		// Initialize the synth component
		Init(SampleRate);

		if (NumChannels < 0 || NumChannels > 8)
		{
			UE_LOG(LogAudioMixer, Error, TEXT("Synthesis component '%s' has set an invalid channel count '%d'."), *GetName(), NumChannels);
		}

		NumChannels = FMath::Clamp(NumChannels, 1, 8);
#endif

		if (!Synth)
		{
			Synth = NewObject<USynthSound>();
		}

		// Copy sound base data to the sound
		Synth->SourceEffectChain = SourceEffectChain;
		Synth->SoundSubmixObject = SoundSubmix;
		Synth->SoundSubmixSends = SoundSubmixSends;
		Synth->BusSends = BusSends;
		Synth->PreEffectBusSends = PreEffectBusSends;
		Synth->bEnableBusSends = bEnableBusSends;
		Synth->bEnableBaseSubmix = bEnableBaseSubmix;
		Synth->bEnableSubmixSends = bEnableSubmixSends;

		Synth->Init(this, NumChannels, SampleRate, PreferredBufferLength);

		// Retrieve the synth component's audio device vs the audio component's
		if (FAudioDevice* AudioDevice = GetAudioDevice())
		{
			Synth->StartOnAudioDevice(AudioDevice);
		}
	}
}

UAudioComponent* USynthComponent::GetAudioComponent()
{
	return AudioComponent;
}

void USynthComponent::CreateAudioComponent()
{
	if (!AudioComponent)
	{
		// Create the audio component which will be used to play the procedural sound wave
		AudioComponent = NewObject<UAudioComponent>(this, NAME_None, RF_Transactional | RF_Transient | RF_TextExportTransient);
		AudioComponent->CreationMethod = CreationMethod;

		AudioComponent->OnAudioSingleEnvelopeValueNative.AddUObject(this, &USynthComponent::OnAudioComponentEnvelopeValue);

		if (!AudioComponent->GetAttachParent() && !AudioComponent->IsAttachedTo(this))
		{
			AActor* Owner = GetOwner();

			// If the media component has no owner or the owner doesn't have a world
			if (!Owner || !Owner->GetWorld())
			{
				// Attempt to retrieve the synth component's world and register the audio component with it
				// This ensures that the synth component plays on the correct world in cases where there isn't an owner
				if (UWorld* World = GetWorld())
				{
					AudioComponent->RegisterComponentWithWorld(World);
					AudioComponent->AttachToComponent(this, FAttachmentTransformRules::KeepRelativeTransform);
				}
				else
				{
					AudioComponent->SetupAttachment(this);
				}
			}
			else
			{
				AudioComponent->AttachToComponent(this, FAttachmentTransformRules::KeepRelativeTransform);
				AudioComponent->RegisterComponent();
			}
		}
	}

	if (AudioComponent)
	{
		AudioComponent->bAutoActivate = false;
		AudioComponent->bStopWhenOwnerDestroyed = true;
		AudioComponent->bShouldRemainActiveIfDropped = true;
		AudioComponent->Mobility = EComponentMobility::Movable;

#if WITH_EDITORONLY_DATA
		AudioComponent->bVisualizeComponent = false;
#endif

		// Set defaults to be the same as audio component defaults
		AudioComponent->EnvelopeFollowerAttackTime = EnvelopeFollowerAttackTime;
		AudioComponent->EnvelopeFollowerReleaseTime = EnvelopeFollowerReleaseTime;
		AudioComponent->bAlwaysPlay = bAlwaysPlay;
	}
}

void USynthComponent::OnRegister()
{
	CreateAudioComponent();

	Super::OnRegister();
}

void USynthComponent::OnUnregister()
{
	// Route OnUnregister event.
	Super::OnUnregister();

	// Don't stop audio and clean up component if owner has been destroyed (default behaviour). This function gets
	// called from AActor::ClearComponents when an actor gets destroyed which is not usually what we want for one-
	// shot sounds.
	AActor* Owner = GetOwner();
	if (!Owner || bStopWhenOwnerDestroyed)
	{
		Stop();
	}

	// Make sure the audio component is destroyed during unregister
	if (AudioComponent && !AudioComponent->IsBeingDestroyed())
	{
		if (Owner && Owner->GetWorld())
		{
			AudioComponent->DetachFromComponent(FDetachmentTransformRules::KeepRelativeTransform);
			AudioComponent->UnregisterComponent();
		}
		AudioComponent->DestroyComponent();
		AudioComponent = nullptr;
	}

	// Clear out the synth component's reference to the sound generator or it will leak until it gets GC'd
	// Normally this is ok to wait till GC but some derived synths might need for the handle to be released
	SoundGenerator.Reset();
}

void USynthComponent::EndPlay(const EEndPlayReason::Type Reason) 
{	
	Super::EndPlay(Reason);

	if (GetOwner() && (Reason == EEndPlayReason::LevelTransition || Reason == EEndPlayReason::RemovedFromWorld || Reason == EEndPlayReason::Destroyed))
	{
		// If our world or sublevel is going away, stop immediately to prevent the containing world/level from being leaked via hard references from the audio device.
		Stop();
	}
}

USoundClass* USynthComponent::GetSoundClass()
{
	if (SoundClass)
	{
		return SoundClass;
	}

	const UAudioSettings* AudioSettings = GetDefault<UAudioSettings>();
	if (ensure(AudioSettings))
	{
		return AudioSettings->GetDefaultSoundClass();
	}

	return nullptr;
}

bool USynthComponent::IsReadyForOwnerToAutoDestroy() const
{
	const bool bIsAudioComponentReadyForDestroy = !AudioComponent || (AudioComponent && !AudioComponent->IsPlaying());
	const bool bIsSynthSoundReadyForDestroy = !Synth || !Synth->IsGeneratingAudio();
	return bIsAudioComponentReadyForDestroy && bIsSynthSoundReadyForDestroy;
}

#if WITH_EDITOR
void USynthComponent::PostEditChangeProperty(FPropertyChangedEvent& PropertyChangedEvent)
{
	if (IsActive())
	{
		// If this is an auto destroy component we need to prevent it from being auto-destroyed since we're really just restarting it
		const bool bWasAutoDestroy = bAutoDestroy;
		bAutoDestroy = false;
		Stop();
		bAutoDestroy = bWasAutoDestroy;
		Start();
	}

	Super::PostEditChangeProperty(PropertyChangedEvent);
}
#endif //WITH_EDITOR

#if WITH_EDITORONLY_DATA
void USynthComponent::PostLoad()
{
	Super::PostLoad();
	if (bOutputToBusOnly_DEPRECATED)
	{
		bEnableBusSends = true;
		bEnableBaseSubmix = !bOutputToBusOnly_DEPRECATED;
		bEnableSubmixSends = !bOutputToBusOnly_DEPRECATED;
		bOutputToBusOnly_DEPRECATED = false;
	}
}
#endif //WITH_EDITORONLY_DATA

void USynthComponent::Serialize(FArchive& Ar)
{
	Super::Serialize(Ar);

#if WITH_EDITORONLY_DATA
	if (Ar.IsLoading())
	{
		if (ConcurrencySettings_DEPRECATED != nullptr)
		{
			ConcurrencySet.Add(ConcurrencySettings_DEPRECATED);
			ConcurrencySettings_DEPRECATED = nullptr;
		}
	}
#endif // WITH_EDITORONLY_DATA

}

void USynthComponent::PumpPendingMessages()
{
	TFunction<void()> Command;
	while (CommandQueue.Dequeue(Command))
	{
		Command();
	}
}

FAudioDevice* USynthComponent::GetAudioDevice() const
{
	// If the synth component has a world, that means it was already registed with that world
	if (UWorld* World = GetWorld())
	{
		return World->AudioDeviceHandle.GetAudioDevice();
	}

	// Otherwise, retrieve the audio component's audio device (probably from it's owner)
	if (AudioComponent)
	{
		return AudioComponent->GetAudioDevice();
	}
	
	// No audio device
	return nullptr;
}

int32 USynthComponent::OnGeneratePCMAudio(float* GeneratedPCMData, int32 NumSamples)
{
	LLM_SCOPE(ELLMTag::AudioSynthesis);

	PumpPendingMessages();

	check(NumSamples > 0);

	// Only call into the synth if we're actually playing, otherwise, we'll write out zero's
	if (bIsSynthPlaying)
	{
		return OnGenerateAudio(GeneratedPCMData, NumSamples);
	}
	return NumSamples;
}

void USynthComponent::Start()
{
	// Only need to start if we're not already active
	if (IsActive())
	{
		return;
	}

	// We will also ensure that this synth was initialized before attempting to play.
	Initialize();

	// If there is no Synth USoundBase, we can't start. This can happen if start is called in a cook, a server, or
	// if the audio engine is set to "noaudio".
	// TODO: investigate if this should be handled elsewhere before this point
	if (!Synth)
	{
		return;
	}

	if (AudioComponent)
	{
		// Copy the attenuation and concurrency data from the synth component to the audio component
		AudioComponent->AttenuationSettings = AttenuationSettings;
		AudioComponent->bOverrideAttenuation = bOverrideAttenuation;
		AudioComponent->bIsUISound = bIsUISound;
		AudioComponent->bIsPreviewSound = bIsPreviewSound;
		AudioComponent->bAllowSpatialization = bAllowSpatialization;
		AudioComponent->ConcurrencySet = ConcurrencySet;
		AudioComponent->AttenuationOverrides = AttenuationOverrides;
		AudioComponent->SoundClassOverride = SoundClass;
		AudioComponent->EnvelopeFollowerAttackTime = EnvelopeFollowerAttackTime;
		AudioComponent->EnvelopeFollowerReleaseTime = EnvelopeFollowerReleaseTime;
		AudioComponent->ModulationRouting = ModulationRouting;

		// Copy sound base data to the sound
		Synth->AttenuationSettings = AttenuationSettings;
		Synth->SourceEffectChain = SourceEffectChain;
		Synth->SoundSubmixObject = SoundSubmix;
		Synth->SoundSubmixSends = SoundSubmixSends;

		// Set the audio component's sound to be our procedural sound wave
		AudioComponent->SetSound(Synth);
		AudioComponent->Play(0);

		SetActiveFlag(AudioComponent->IsActive());

		bIsSynthPlaying = true;
	}
}

void USynthComponent::Stop()
{
	if (IsActive())
	{
		if (AudioComponent)
		{
			AudioComponent->Stop();		
			
			if (FAudioDevice* AudioDevice = AudioComponent->GetAudioDevice())
			{
				AudioDevice->StopSoundsUsingResource(Synth);
			}
		}

		SetActiveFlag(false);
	}
}

bool USynthComponent::IsPlaying() const
{
	return AudioComponent && AudioComponent->IsPlaying();
}

void USynthComponent::SetVolumeMultiplier(float VolumeMultiplier)
{
	if (AudioComponent)
	{
		AudioComponent->SetVolumeMultiplier(VolumeMultiplier);
	}
}

void USynthComponent::SetSubmixSend(USoundSubmixBase* Submix, float SendLevel)
{
	if (AudioComponent)
	{
		AudioComponent->SetSubmixSend(Submix, SendLevel);
	}
}

void USynthComponent::SetSourceBusSendPreEffect(USoundSourceBus* SoundSourceBus, float SourceBusSendLevel)
{
	if (AudioComponent)
	{
		AudioComponent->SetSourceBusSendPreEffect(SoundSourceBus, SourceBusSendLevel);
	}
}

void USynthComponent::SetSourceBusSendPostEffect(USoundSourceBus* SoundSourceBus, float SourceBusSendLevel)
{
	if (AudioComponent)
	{
		AudioComponent->SetSourceBusSendPostEffect(SoundSourceBus, SourceBusSendLevel);
	}
}

void USynthComponent::SetAudioBusSendPreEffect(UAudioBus* AudioBus, float AudioBusSendLevel)
{
	if (AudioComponent)
	{
		AudioComponent->SetAudioBusSendPreEffect(AudioBus, AudioBusSendLevel);
	}
}

void USynthComponent::SetAudioBusSendPostEffect(UAudioBus* AudioBus, float AudioBusSendLevel)
{
	if (AudioComponent)
	{
		AudioComponent->SetAudioBusSendPostEffect(AudioBus, AudioBusSendLevel);
	}
}

void USynthComponent::SetLowPassFilterEnabled(bool InLowPassFilterEnabled)
{
	if (AudioComponent)
	{
		AudioComponent->SetLowPassFilterEnabled(InLowPassFilterEnabled);
	}
}

void USynthComponent::SetLowPassFilterFrequency(float InLowPassFilterFrequency)
{
	if (AudioComponent)
	{
		AudioComponent->SetLowPassFilterFrequency(InLowPassFilterFrequency);
	}
}

void USynthComponent::SetOutputToBusOnly(bool bInOutputToBusOnly)
{
	if (AudioComponent)
	{
		AudioComponent->SetOutputToBusOnly(bInOutputToBusOnly);
	}
}

void USynthComponent::FadeIn(float FadeInDuration, float FadeVolumeLevel/* = 1.0f*/, float StartTime/* = 0.0f*/, const EAudioFaderCurve FadeCurve/* = EAudioFaderCurve::Linear*/) const
{
	if(AudioComponent)
	{
		AudioComponent->FadeIn(FadeInDuration, FadeVolumeLevel, StartTime, FadeCurve);
	}
}

void USynthComponent::FadeOut(float FadeOutDuration, float FadeVolumeLevel, const EAudioFaderCurve FadeCurve/* = EAudioFaderCurve::Linear*/) const
{
	if(AudioComponent)
	{
		AudioComponent->FadeOut(FadeOutDuration, FadeVolumeLevel, FadeCurve);
	}
}

void USynthComponent::AdjustVolume(float AdjustVolumeDuration, float AdjustVolumeLevel, const EAudioFaderCurve FadeCurve/* = EAudioFaderCurve::Linear*/) const
{
	if(AudioComponent)
	{
		AudioComponent->AdjustVolume(AdjustVolumeDuration, AdjustVolumeLevel, FadeCurve);
	}
}

void USynthComponent::SetModulationRouting(const TSet<USoundModulatorBase*>& Modulators, const EModulationDestination Destination, const EModulationRouting RoutingMethod)
{
	if (AudioComponent)
	{
		AudioComponent->SetModulationRouting(Modulators, Destination, RoutingMethod);
	}
}

TSet<USoundModulatorBase*> USynthComponent::GetModulators(const EModulationDestination Destination)
{
	if (AudioComponent)
	{
		return AudioComponent->GetModulators(Destination);
	}

	return TSet<USoundModulatorBase*>();
}

void USynthComponent::SynthCommand(TFunction<void()> Command)
{
	if (SoundGenerator.IsValid())
	{
		UE_LOG(LogAudioMixer, Error, TEXT("Synthesis component '%s' has implemented a sound generator interface. Do not call SynthCommand on the USynthComponent)."), *GetName());
	}
	else
	{
		CommandQueue.Enqueue(MoveTemp(Command));
	}
}

ISoundGeneratorPtr USynthComponent::CreateSoundGeneratorInternal(const FSoundGeneratorInitParams& InParams)
{
	LLM_SCOPE(ELLMTag::AudioSynthesis);	
	return SoundGenerator = CreateSoundGenerator(InParams);
}


==========================


=== SynthComponent.h ===
========================

// Copyright Epic Games, Inc. All Rights Reserved.
#pragma once

#include "AudioMixerTypes.h"
#include "Components/AudioComponent.h"
#include "CoreMinimal.h"
#include "Engine/EngineTypes.h"
#include "IAudioExtensionPlugin.h"
#include "Sound/SoundWaveProcedural.h"
#include "Sound/SoundGenerator.h"
#include "UObject/ObjectMacros.h"

#include "SynthComponent.generated.h"

#define SYNTH_GENERATOR_TEST_TONE 0

#if SYNTH_GENERATOR_TEST_TONE
#include "DSP/SinOsc.h"
#endif

class UAudioBus;
class USoundSourceBus;

/** Simple interface class to allow objects to route audio between them. */
class IAudioBufferListener
{
public:
	virtual void OnGeneratedBuffer(const float* AudioBuffer, const int32 NumSamples, const int32 NumChannels) = 0;
};

class USynthComponent;
class USoundConcurrency;

/**
* Called by a synth component and returns the sound's envelope value (using an envelope follower in the audio renderer).
* This only works in the audio mixer.
*/
DECLARE_DYNAMIC_MULTICAST_DELEGATE_OneParam(FOnSynthEnvelopeValue, const float, EnvelopeValue);

/** shadow delegate declaration for above */
DECLARE_MULTICAST_DELEGATE_TwoParams(FOnSynthEnvelopeValueNative, const class UAudioComponent*, const float);


UCLASS(MinimalAPI)
class USynthSound : public USoundWaveProcedural
{
	GENERATED_UCLASS_BODY()

	AUDIOMIXER_API void Init(USynthComponent* InSynthComponent, const int32 InNumChannels, const int32 SampleRate, const int32 InCallbackSize);
	AUDIOMIXER_API void StartOnAudioDevice(FAudioDevice* InAudioDevice);

	/** Begin USoundWave */
	AUDIOMIXER_API virtual void OnBeginGenerate() override;
	AUDIOMIXER_API virtual int32 OnGeneratePCMAudio(TArray<uint8>& OutAudio, int32 NumSamples) override;
	AUDIOMIXER_API virtual void OnEndGenerate() override;
	AUDIOMIXER_API virtual Audio::EAudioMixerStreamDataFormat::Type GetGeneratedPCMDataFormat() const override;
	AUDIOMIXER_API virtual ISoundGeneratorPtr CreateSoundGenerator(const FSoundGeneratorInitParams& InParams) override;
	/** End USoundWave */

protected:
	UPROPERTY()
	TWeakObjectPtr<USynthComponent> OwningSynthComponent = nullptr;

	TArray<float> FloatBuffer;

public:
	USynthComponent* GetOwningSynthComponent()
	{
		return OwningSynthComponent.Get();
	}
	
	TWeakObjectPtr<USynthComponent>& GetOwningSynthComponentPtr()
	{
		return OwningSynthComponent;
	}
};

UCLASS(abstract, ClassGroup = Synth, hidecategories = (Object, ActorComponent, Physics, Rendering, Mobility, LOD), MinimalAPI)
class USynthComponent : public USceneComponent
{
	GENERATED_BODY()

public:
	AUDIOMIXER_API USynthComponent(const FObjectInitializer& ObjectInitializer);

	//~ Begin USceneComponent Interface
	AUDIOMIXER_API virtual void Activate(bool bReset = false) override;
	AUDIOMIXER_API virtual void Deactivate() override;
	//~ End USceneComponent Interface

	//~ Begin ActorComponent Interface.
	AUDIOMIXER_API virtual void OnRegister() override;
	AUDIOMIXER_API virtual void OnUnregister() override;
	AUDIOMIXER_API virtual bool IsReadyForOwnerToAutoDestroy() const override;
	AUDIOMIXER_API virtual void EndPlay(const EEndPlayReason::Type Reason) override;
	//~ End ActorComponent Interface.

	//~ Begin UObject Interface.
#if WITH_EDITOR
	AUDIOMIXER_API virtual void PostEditChangeProperty(FPropertyChangedEvent& PropertyChangedEvent) override;
#endif // WITH_EDITOR

#if WITH_EDITORONLY_DATA
	AUDIOMIXER_API virtual void PostLoad() override;
#endif //WITH_EDITORONLY_DATA

	AUDIOMIXER_API virtual void Serialize(FArchive& Ar) override;
	//~ End UObject Interface

	// Starts the synth generating audio.
	UFUNCTION(BlueprintCallable, Category = "Synth|Components|Audio")
	AUDIOMIXER_API void Start();

	// Stops the synth generating audio.
	UFUNCTION(BlueprintCallable, Category = "Synth|Components|Audio")
	AUDIOMIXER_API void Stop();

	/** Returns true if this component is currently playing. */
	UFUNCTION(BlueprintCallable, Category = "Synth|Components|Audio")
	AUDIOMIXER_API bool IsPlaying() const;

	/** Set a new volume multiplier */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void SetVolumeMultiplier(float VolumeMultiplier);

	/** Sets how much audio the sound should send to the given submix. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void SetSubmixSend(USoundSubmixBase* Submix, float SendLevel);

	/** Sets how much audio the sound should send to the given SourceBus (pre effect). */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void SetSourceBusSendPreEffect(USoundSourceBus* SoundSourceBus, float SourceBusSendLevel);

	/** Sets how much audio the sound should send to the given SourceBus (post effect). */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void SetSourceBusSendPostEffect(USoundSourceBus* SoundSourceBus, float SourceBusSendLevel);

	/** Sets how much audio the sound should send to the given AudioBus (pre effect). */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void SetAudioBusSendPreEffect(UAudioBus* AudioBus, float AudioBusSendLevel);

	/** Sets how much audio the sound should send to the given AudioBus (post effect). */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void SetAudioBusSendPostEffect(UAudioBus* AudioBus, float AudioBusSendLevel);

	/** Sets whether or not the low pass filter is enabled on the audio component. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void SetLowPassFilterEnabled(bool InLowPassFilterEnabled);

	/** Sets lowpass filter frequency of the audio component. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API virtual void SetLowPassFilterFrequency(float InLowPassFilterFrequency);

	/** Sets whether or not the synth component outputs its audio to any source or audio buses. */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void SetOutputToBusOnly(bool bInOutputToBusOnly);

	/**
	 * This function allows designers to call Play on an Audio Component instance while applying a volume curve over time. 
	 * Parameters allow designers to indicate the duration of the fade, the curve shape, and the start time if seeking into the sound.
	 *
	 * @param FadeInDuration How long it should take to reach the FadeVolumeLevel
	 * @param FadeVolumeLevel The percentage of the AudioComponents's calculated volume to fade to
	 * @param FadeCurve The curve to use when interpolating between the old and new volume
	 */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void FadeIn(float FadeInDuration, float FadeVolumeLevel = 1.0f, float StartTime = 0.0f, const EAudioFaderCurve FadeCurve = EAudioFaderCurve::Linear) const;

	/**
	 * This function allows designers to call a delayed Stop on an Audio Component instance while applying a
	 * volume curve over time. Parameters allow designers to indicate the duration of the fade and the curve shape.
	 *
	 * @param FadeOutDuration how long it should take to reach the FadeVolumeLevel
	 * @param FadeVolumeLevel the percentage of the AudioComponents's calculated volume in which to fade to
	 * @param FadeCurve The curve to use when interpolating between the old and new volume
	 */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void FadeOut(float FadeOutDuration, float FadeVolumeLevel, const EAudioFaderCurve FadeCurve = EAudioFaderCurve::Linear) const;

	/** This function allows designers to trigger an adjustment to the sound instanceâ€™s playback Volume with options for smoothly applying a curve over time.
     * @param AdjustVolumeDuration The length of time in which to interpolate between the initial volume and the new volume.
     * @param AdjustVolumeLevel The new volume to set the Audio Component to.
     * @param FadeCurve The curve used when interpolating between the old and new volume.
     */
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio")
	AUDIOMIXER_API void AdjustVolume(float AdjustVolumeDuration, float AdjustVolumeLevel, const EAudioFaderCurve FadeCurve = EAudioFaderCurve::Linear) const;

	/**
	* Sets the routing for one of the given Synth component's Modulation Destinations.
	* @param Modulators The set of modulators to apply to the given destination on the component.
	* @param Destination The destination to assign the modulators to.
	* @param RoutingMethod The routing method to use for the given modulator.
	*/
	UFUNCTION(BlueprintCallable, Category = "Audio|Components|Audio", DisplayName = "Set Modulation Routing")
	AUDIOMIXER_API void SetModulationRouting(const TSet<USoundModulatorBase*>& Modulators, const EModulationDestination Destination, const EModulationRouting RoutingMethod = EModulationRouting::Inherit);
	
	/**
	* Gets the set of currently active modulators for a given Modulation Destination.
	* @param Destination The Destination to retrieve the Modulators from.
	* @return The set of of Modulators applied to this component for the given Destination.
	*/
	UFUNCTION(BlueprintPure, Category = "Audio|Components|Audio", DisplayName = "Get Modulators")
	AUDIOMIXER_API UPARAM(DisplayName = "Modulators") TSet<USoundModulatorBase*> GetModulators(const EModulationDestination Destination);

	/** Auto destroy this component on completion */
	UPROPERTY()
	uint8 bAutoDestroy : 1;

	/** Stop sound when owner is destroyed */
	UPROPERTY()
	uint8 bStopWhenOwnerDestroyed : 1;

	/** Is this audio component allowed to be spatialized? */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Attenuation)
	uint8 bAllowSpatialization : 1;

	/** Should the Attenuation Settings asset be used (false) or should the properties set directly on the component be used for attenuation properties */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Attenuation)
	uint8 bOverrideAttenuation : 1;

#if WITH_EDITORONLY_DATA
	/** Whether or not to only send this audio's output to a bus. If true, this sound will not be audible except through bus sends. */
	UPROPERTY()
	uint32 bOutputToBusOnly_DEPRECATED : 1;
#endif //WITH_EDITORONLY_DATA

	/** Whether or not to enable sending this audio's output to buses.  */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Effects)
	uint32 bEnableBusSends : 1;

	/** If enabled, sound will route to the Master Submix by default or to the Base Submix if defined. If disabled, sound will route ONLY to the Submix Sends and/or Bus Sends */
	UPROPERTY(EditAnywhere, Category = Effects)
	uint32 bEnableBaseSubmix : 1;

	/** Whether or not to enable Submix Sends other than the Base Submix.*/
	UPROPERTY(EditAnywhere, Category = Effects, meta = (DisplayAfter = "SoundSubmixObject"))
	uint32 bEnableSubmixSends : 1;

	/** If bOverrideSettings is false, the asset to use to determine attenuation properties for sounds generated by this component */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Attenuation, meta = (EditCondition = "!bOverrideAttenuation"))
	TObjectPtr<class USoundAttenuation> AttenuationSettings;

	/** If bOverrideSettings is true, the attenuation properties to use for sounds generated by this component */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Attenuation, meta = (EditCondition = "bOverrideAttenuation"))
	struct FSoundAttenuationSettings AttenuationOverrides;

	/** What sound concurrency to use for sounds generated by this audio component */
	UPROPERTY()
	TObjectPtr<USoundConcurrency> ConcurrencySettings_DEPRECATED;

	/** What sound concurrency to use for sounds generated by this audio component */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Concurrency)
	TSet<TObjectPtr<USoundConcurrency>> ConcurrencySet;

	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Modulation)
	FSoundModulationDefaultRoutingSettings ModulationRouting;

	/** Sound class this sound belongs to */
	UPROPERTY(EditAnywhere, Category = SoundClass)
	TObjectPtr<USoundClass> SoundClass;

	/** The source effect chain to use for this sound. */
	UPROPERTY(EditAnywhere, Category = Effects)
	TObjectPtr<USoundEffectSourcePresetChain> SourceEffectChain;

	/** Submix this sound belongs to */
	UPROPERTY(EditAnywhere, Category = Effects, meta = (EditCondition = "bEnableBaseSubmix", DisplayName = "Base Submix"))
	TObjectPtr<USoundSubmixBase> SoundSubmix;

	/** An array of submix sends. Audio from this sound will send a portion of its audio to these effects.  */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Effects, meta = (EditCondition = "bEnableSubmixSends"))
	TArray<FSoundSubmixSendInfo> SoundSubmixSends;

	/** This sound will send its audio output to this list of buses if there are bus instances playing after source effects are processed.  */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Effects, meta = (DisplayName = "Post-Effect Bus Sends", EditCondition = "bEnableBusSends"))
	TArray<FSoundSourceBusSendInfo> BusSends;

	/** This sound will send its audio output to this list of buses if there are bus instances playing before source effects are processed.  */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Effects, meta = (DisplayName = "Pre-Effect Bus Sends", EditCondition = "bEnableBusSends"))
	TArray<FSoundSourceBusSendInfo> PreEffectBusSends;

	/** Whether or not this sound plays when the game is paused in the UI */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sound)
	uint8 bIsUISound : 1;

	/** Whether or not this synth is playing as a preview sound */
	UPROPERTY()
	uint8 bIsPreviewSound : 1;

	/** Whether to artificially prioritize the component to play */
	uint8 bAlwaysPlay : 1;

	/** Call if creating this synth component not via an actor component in BP, but in code or some other location. 
	 *  Optionally override the sample rate of the sound wave, otherwise it uses the audio device's sample rate. 
	 */
	AUDIOMIXER_API void Initialize(int32 SampleRateOverride = INDEX_NONE);

	/** Creates the audio component if it hasn't already been created yet. This should only be used when trying to
	 *  assign explicit settings to the AudioComponent before calling Start(). 
	 */
	AUDIOMIXER_API void CreateAudioComponent();

	/** Retrieves this synth component's audio component. */
	AUDIOMIXER_API UAudioComponent* GetAudioComponent();

	/** The attack time in milliseconds for the envelope follower. Delegate callbacks can be registered to get the
	 *  envelope value of sounds played with this audio component. Only used in audio mixer.
	 */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sound, meta = (ClampMin = "0", UIMin = "0"))
	int32 EnvelopeFollowerAttackTime;

	/** The release time in milliseconds for the envelope follower. Delegate callbacks can be registered to get the
	 *  envelope value of sounds played with this audio component. Only used in audio mixer. 
	 */
	UPROPERTY(EditAnywhere, BlueprintReadWrite, Category = Sound, meta = (ClampMin = "0", UIMin = "0"))
	int32 EnvelopeFollowerReleaseTime;

	UPROPERTY(BlueprintAssignable)
	FOnSynthEnvelopeValue OnAudioEnvelopeValue;

	/** Shadow delegate for non UObject subscribers */
	FOnSynthEnvelopeValueNative OnAudioEnvelopeValueNative;

	AUDIOMIXER_API void OnAudioComponentEnvelopeValue(const UAudioComponent* AudioComponent, const USoundWave* SoundWave, const float EnvelopeValue);

	// Adds and removes audio buffer listener
	AUDIOMIXER_API void AddAudioBufferListener(IAudioBufferListener* InAudioBufferListener);
	AUDIOMIXER_API void RemoveAudioBufferListener(IAudioBufferListener* InAudioBufferListener);

	AUDIOMIXER_API virtual USoundClass* GetSoundClass();

	AUDIOMIXER_API virtual void BeginDestroy() override;

protected:

	// Method to execute parameter changes on game thread in audio render thread
	AUDIOMIXER_API void SynthCommand(TFunction<void()> Command);

	// Called when synth is created.
	virtual bool Init(int32& SampleRate) { return true; }

	UE_DEPRECATED(4.26, "Use OnBeginGenerate to get a callback before audio is generating on the audio render thread")
	virtual void OnStart() {}

	UE_DEPRECATED(4.26, "Use OnEndGenerate to get a callback when audio stops generating on the audio render thread")
	virtual void OnStop() {}

	// Called when the synth component begins generating audio in render thread
	virtual void OnBeginGenerate() {}

	// Called when the synth has finished generating audio on the render thread
	virtual void OnEndGenerate() {}

	// Called when more audio is needed to be generated
	// This method of generating audio is soon to be deprecated. For all new synth components, create an FSoundGenerator instance and implement CreateSoundGenerator method to create an instance.
	virtual int32 OnGenerateAudio(float* OutAudio, int32 NumSamples) { return 0; }

	// Implemented by the synth component to create a generator object instead of generating audio directly on the synth component.
	// This method prevents UObjects from having to exist in the audio render thread.
	virtual ISoundGeneratorPtr CreateSoundGenerator(const FSoundGeneratorInitParams& InParams) { return nullptr; }

	// Called by procedural sound wave
	// Returns the number of samples actually generated
	AUDIOMIXER_API int32 OnGeneratePCMAudio(float* GeneratedPCMData, int32 NumSamples);

	// Gets the audio device associated with this synth component
	AUDIOMIXER_API FAudioDevice* GetAudioDevice() const;

	// Can be set by the derived class, defaults to 2
	int32 NumChannels;

	// Can be set by the derived class- sets the preferred callback size for the synth component.
	int32 PreferredBufferLength;

private:
	// Creates the synth component's sound generator, calls into overridden client code to create the instance.
	AUDIOMIXER_API ISoundGeneratorPtr CreateSoundGeneratorInternal(const FSoundGeneratorInitParams& InParams);

	UPROPERTY(Transient)
	TObjectPtr<USynthSound> Synth;

	UPROPERTY(Transient)
	TObjectPtr<UAudioComponent> AudioComponent;

	AUDIOMIXER_API void PumpPendingMessages();

#if SYNTH_GENERATOR_TEST_TONE
	Audio::FSineOsc TestSineLeft;
	Audio::FSineOsc TestSineRight;
#endif

	// Whether or not synth is playing
	bool bIsSynthPlaying;
	bool bIsInitialized;

	TQueue<TFunction<void()>> CommandQueue;

	// Synth component's handle to its sound generator instance.
	// used to forward BP functions to the instance directly.
	ISoundGeneratorPtr SoundGenerator;

	friend class USynthSound;
};

========================

